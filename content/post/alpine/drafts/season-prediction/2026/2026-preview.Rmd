---
title: "2026 Alpine Season Preview"
author: "Syver Johansen"
date: "2025-01-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## 2026 Alpine Season Preview

This preview analyzes the upcoming 2026 alpine skiing season, including points predictions, breakthrough potential candidates, and competitive analysis across all disciplines.

### Load Libraries

```{r load-packages, message=FALSE, warning=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(readr)
library(ggplot2)
library(openxlsx)
library(moments)  # for skewness/kurtosis
library(mgcv)     # for GAM models
library(glmnet)   # for LASSO feature selection
library(Boruta)   # for Boruta feature selection
library(leaps)    # for exhaustive search
library(MASS)     # for polr (ordinal logistic regression)
```

### Load Data

```{r load-data}
# Load men's and ladies alpine chrono data from CSV files
cat("=== ALPINE DATA LOADING & VALIDATION ===\n")

# Check if files exist before loading
men_file <- '/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/men_chrono.csv'
ladies_file <- '/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/ladies_chrono.csv'

if (!file.exists(men_file)) stop("Men's alpine data file not found: ", men_file)
if (!file.exists(ladies_file)) stop("Ladies alpine data file not found: ", ladies_file)

cat("✓ Alpine data files exist\n")

# Load data with error handling
tryCatch({
  M_chrono <- read_csv(men_file, show_col_types = FALSE)
  cat("✓ Men's alpine data loaded:", nrow(M_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load men's alpine data: ", e$message)
})

tryCatch({
  L_chrono <- read_csv(ladies_file, show_col_types = FALSE)
  cat("✓ Ladies alpine data loaded:", nrow(L_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load ladies alpine data: ", e$message)
})

# Validate required columns exist
required_cols <- c("Skier", "Date", "Season", "Event", "Nation", "Distance", "Place", "Race", "ID")
missing_men <- setdiff(required_cols, names(M_chrono))
missing_ladies <- setdiff(required_cols, names(L_chrono))

if (length(missing_men) > 0) {
  stop("Missing required columns in men's alpine data: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing required columns in ladies alpine data: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required columns present in both alpine datasets\n")

# Check for completely empty datasets
if (nrow(M_chrono) == 0) stop("Men's alpine dataset is empty")
if (nrow(L_chrono) == 0) stop("Ladies alpine dataset is empty")

# Validate data types and ranges
cat("\n--- Alpine Data Quality Checks ---\n")

# Check Place column (should be positive integers)
invalid_places_m <- sum(is.na(M_chrono$Place) | M_chrono$Place < 0 | !is.finite(M_chrono$Place))
invalid_places_l <- sum(is.na(L_chrono$Place) | L_chrono$Place < 0 | !is.finite(L_chrono$Place))

cat("Men's invalid Place values:", invalid_places_m, "\n")
cat("Ladies invalid Place values:", invalid_places_l, "\n")

if (invalid_places_m > nrow(M_chrono) * 0.1) {
  warning("More than 10% of men's Place values are invalid")
}
if (invalid_places_l > nrow(L_chrono) * 0.1) {
  warning("More than 10% of ladies Place values are invalid")
}

# Check for missing Skier names
missing_skiers_m <- sum(is.na(M_chrono$Skier) | M_chrono$Skier == "")
missing_skiers_l <- sum(is.na(L_chrono$Skier) | L_chrono$Skier == "")

cat("Men's missing skier names:", missing_skiers_m, "\n")
cat("Ladies missing skier names:", missing_skiers_l, "\n")

if (missing_skiers_m > nrow(M_chrono) * 0.05) {
  warning("More than 5% of men's skier names are missing")
}
if (missing_skiers_l > nrow(L_chrono) * 0.05) {
  warning("More than 5% of ladies skier names are missing")
}

# Check Season range
season_range_m <- range(M_chrono$Season, na.rm = TRUE)
season_range_l <- range(L_chrono$Season, na.rm = TRUE)

cat("Men's season range:", season_range_m[1], "to", season_range_m[2], "\n")
cat("Ladies season range:", season_range_l[1], "to", season_range_l[2], "\n")

# Expected season range (adjust based on your data)
expected_min_season <- 2010
expected_max_season <- 2025

if (season_range_m[1] < expected_min_season || season_range_m[2] > expected_max_season) {
  warning("Men's season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}
if (season_range_l[1] < expected_min_season || season_range_l[2] > expected_max_season) {
  warning("Ladies season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}

cat("Men's missing Skier names:", missing_skiers_m, "\n")
cat("Ladies missing Skier names:", missing_skiers_l, "\n")

if (missing_skiers_m > 0) warning("Men's alpine data has missing skier names")
if (missing_skiers_l > 0) warning("Ladies alpine data has missing skier names")

# Date validation
date_errors_m <- sum(is.na(M_chrono$Date))
date_errors_l <- sum(is.na(L_chrono$Date))

cat("Men's invalid dates:", date_errors_m, "\n")
cat("Ladies invalid dates:", date_errors_l, "\n")

# Define excluded athletes - remove them from all analysis (retired/inactive)
# Legacy retirements


# 2025 Retirements - Men
excluded_men <- c("Yannick Chabloz", "Sebastian Foss-Solevåg", "Nico Gauer", 
                        "Stefano Gross", "Boštjan Kline", "Urs Kryenbühl", 
                        "Stefan Luitz", "Adrian Meisen", "Reto Schmidiger", 
                        "Dominik Schwaiger", "Rasmus Windingstad")

# 2025 Retirements - Ladies  
excluded_ladies <- c("Michelle Niederwieser", "Roni Remme", "Charlotta Säfvenberg",
                           "Anna Schillinger", "Elena Stoffel", "Tamara Tippler",
                           "Vera Tschurtschenthaler", "Stephanie Venier")

# Combine all excluded athletes


cat("\n--- Alpine Athlete Exclusion ---\n")
cat("Excluding men:", paste(excluded_men, collapse = ", "), "\n")
cat("Excluding ladies:", paste(excluded_ladies, collapse = ", "), "\n")

# Count how many records will be excluded
excluded_count_m <- sum(M_chrono$Skier %in% excluded_men)
excluded_count_l <- sum(L_chrono$Skier %in% excluded_ladies)

cat("Men's records to exclude:", excluded_count_m, "\n")
cat("Ladies records to exclude:", excluded_count_l, "\n")

# Filter out excluded athletes from raw data
M_chrono_original_rows <- nrow(M_chrono)
L_chrono_original_rows <- nrow(L_chrono)

M_chrono <- M_chrono %>%
  filter(!Skier %in% excluded_men)

L_chrono <- L_chrono %>%
  filter(!Skier %in% excluded_ladies)

# Verify exclusion worked correctly
actual_excluded_m <- M_chrono_original_rows - nrow(M_chrono)
actual_excluded_l <- L_chrono_original_rows - nrow(L_chrono)

if (actual_excluded_m != excluded_count_m) {
  warning("Mismatch in men's exclusion: expected ", excluded_count_m, ", actual ", actual_excluded_m)
}
if (actual_excluded_l != excluded_count_l) {
  warning("Mismatch in ladies exclusion: expected ", excluded_count_l, ", actual ", actual_excluded_l)
}

cat("✓ Men's alpine data after exclusion:", nrow(M_chrono), "rows\n")
cat("✓ Ladies alpine data after exclusion:", nrow(L_chrono), "rows\n")

# Alpine World Cup points mapping with validation
cat("\n--- Alpine Points System Validation ---\n")

# Standard alpine World Cup points (top 30 get points)
alpine_points <- c(100,80,60,50,45,40,36,32,29,26,24,22,20,18,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)

# Validate points arrays
if (length(alpine_points) != 30) stop("Alpine World Cup points array should have 30 values")

# Check points are in descending order (except for the first three which follow 100,80,60 pattern)
expected_first_three <- c(100, 80, 60)
if (!identical(alpine_points[1:3], expected_first_three)) {
  stop("Alpine points should start with 100, 80, 60")
}

# Check remaining points are in descending order
if (!all(diff(alpine_points[4:length(alpine_points)]) <= 0)) {
  stop("Alpine points from 4th place onward not in descending order")
}

cat("✓ Alpine points system validated (", length(alpine_points), "positions get points)\n")

# Function to safely fetch alpine points based on Place with validation
get_alpine_points <- function(place, points_list = alpine_points) {
  if (is.na(place) || !is.finite(place)) {
    return(0)
  }
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

# Test the get_alpine_points function
test_cases <- c(1, 3, 10, 30, 31, -1, NA, Inf)
cat("Testing get_alpine_points function:\n")
for (test_place in test_cases) {
  result <- get_alpine_points(test_place, alpine_points)
  cat(sprintf("  Place %s -> %s points\n", 
              ifelse(is.na(test_place), "NA", as.character(test_place)), result))
}

cat("\n=== ALPINE DATA LOADING COMPLETE ===\n")
cat(sprintf("Final alpine dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_chrono), nrow(L_chrono)))
cat(sprintf("Men's unique alpine skiers: %d\n", length(unique(M_chrono$Skier))))
cat(sprintf("Ladies unique alpine skiers: %d\n", length(unique(L_chrono$Skier))))
cat(sprintf("Men's season range: %s - %s\n", min(M_chrono$Season, na.rm = TRUE), max(M_chrono$Season, na.rm = TRUE)))
cat(sprintf("Ladies season range: %s - %s\n", min(L_chrono$Season, na.rm = TRUE), max(L_chrono$Season, na.rm = TRUE)))
```

### Data Processing

```{r process-data}
cat("=== ALPINE DATA PROCESSING & VALIDATION ===\n")

# Function to process alpine chrono data (works for both men and ladies)
process_alpine_chrono_data <- function(chrono_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Processing %s Alpine Data ---\n", data_name))
  
  # Input validation
  if (nrow(chrono_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  # Check for required columns before processing
  required_cols <- c("Event", "Nation", "Place", "Distance", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(chrono_df))
  if (length(missing_cols) > 0) {
    stop(sprintf("Missing required columns in %s alpine data: %s", data_name, paste(missing_cols, collapse = ", ")))
  }
  
  original_rows <- nrow(chrono_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Add Alpine World Cup points
  cat("Adding Alpine World Cup points...\n")
  df <- chrono_df %>%
    mutate(Points = map_int(Place, ~ get_alpine_points(.x, alpine_points)))
  
  # Validate points assignment
  points_na <- sum(is.na(df$Points))
  points_negative <- sum(df$Points < 0, na.rm = TRUE)
  
  if (points_na > 0) {
    warning(sprintf("%s: %d rows have NA points", data_name, points_na))
  }
  if (points_negative > 0) {
    warning(sprintf("%s: %d rows have negative points", data_name, points_negative))
  }
  
  cat(sprintf("Alpine points range: %d - %d\n", min(df$Points, na.rm = TRUE), max(df$Points, na.rm = TRUE)))
  
  # Count events before filtering
  event_counts_before <- table(df$Event)
  cat("Events before filtering:\n")
  print(event_counts_before)
  
  # Filter for relevant alpine events (only World Cup and Offseason)
  cat("Filtering for relevant alpine events (World Cup, Offseason)...\n")
  relevant_events <- c("World Cup", "Offseason")
  
  df <- df %>%
    filter(Event %in% relevant_events) %>%
    arrange(Date, Race, Place) %>%
    group_by(ID, Season) %>%
    mutate(
      Cumulative_Points = cumsum(Points),
      Races_in_Season = n()
    ) %>%
    ungroup()
  
  filtered_rows <- nrow(df)
  cat(sprintf("After alpine event filtering: %d rows (removed %d rows)\n", filtered_rows, original_rows - filtered_rows))
  
  # Count events after filtering
  event_counts_after <- table(df$Event)
  cat("Alpine events after filtering:\n")
  print(event_counts_after)
  
  # Validate cumulative points calculation
  invalid_cumulative <- df %>%
    group_by(ID, Season) %>%
    mutate(expected_cumulative = cumsum(Points)) %>%
    ungroup() %>%
    filter(Cumulative_Points != expected_cumulative) %>%
    nrow()
  
  if (invalid_cumulative > 0) {
    warning(sprintf("%s: %d rows have incorrect cumulative points", data_name, invalid_cumulative))
  } else {
    cat("✓ Cumulative points calculation validated\n")
  }
  
  # Alpine doesn't have team events like cross-country, but check for any unusual distances
  cat("Checking alpine disciplines...\n")
  discipline_counts <- table(df$Distance)
  cat("Alpine disciplines:\n")
  print(discipline_counts)
  
  # Calculate maximum possible points per season 
  cat("Calculating maximum possible alpine points per season...\n")
  max_points_per_season <- df %>%
    group_by(Season, Date, Race) %>%
    summarise(Max_Race_Points = max(Points), .groups = 'drop') %>%
    group_by(Season) %>%
    summarise(Max_Points = sum(Max_Race_Points), .groups = 'drop')
  
  # Validate max points calculation
  if (nrow(max_points_per_season) == 0) {
    stop(sprintf("%s: No seasons found for alpine max points calculation", data_name))
  }
  
  # Check for seasons with zero max points
  zero_max_seasons <- max_points_per_season %>% filter(Max_Points == 0)
  if (nrow(zero_max_seasons) > 0) {
    warning(sprintf("%s: %d alpine seasons have zero max points", data_name, nrow(zero_max_seasons)))
    print(zero_max_seasons)
  }
  
  cat(sprintf("Alpine max points range by season: %d - %d\n", 
              min(max_points_per_season$Max_Points), max(max_points_per_season$Max_Points)))
  
  # Join max points and calculate percentage
  cat("Calculating percentage of maximum alpine points...\n")
  before_join <- nrow(df)
  
  df <- df %>%
    left_join(max_points_per_season, by = "Season") %>%
    mutate(Pct_of_Max_Points = Cumulative_Points / Max_Points)
  
  after_join <- nrow(df)
  if (before_join != after_join) {
    warning(sprintf("%s: Row count changed during alpine max points join: %d -> %d", data_name, before_join, after_join))
  }
  
  # Validate percentage calculations
  pct_na <- sum(is.na(df$Pct_of_Max_Points))
  pct_negative <- sum(df$Pct_of_Max_Points < 0, na.rm = TRUE)
  pct_over_one <- sum(df$Pct_of_Max_Points > 1, na.rm = TRUE)
  
  if (pct_na > 0) {
    warning(sprintf("%s: %d rows have NA percentage of max alpine points", data_name, pct_na))
  }
  if (pct_negative > 0) {
    warning(sprintf("%s: %d rows have negative percentage of max alpine points", data_name, pct_negative))
  }
  if (pct_over_one > 0) {
    warning(sprintf("%s: %d rows have percentage > 100%% of max alpine points", data_name, pct_over_one))
  }
  
  cat(sprintf("Alpine percentage range: %.3f - %.3f\n", 
              min(df$Pct_of_Max_Points, na.rm = TRUE), max(df$Pct_of_Max_Points, na.rm = TRUE)))
  
  # Final validation checks
  cat("\n--- Final Alpine Validation ---\n")
  
  # Check for required columns in output
  expected_output_cols <- c("Points", "Cumulative_Points", "Races_in_Season", "Max_Points", "Pct_of_Max_Points")
  missing_output_cols <- setdiff(expected_output_cols, names(df))
  if (length(missing_output_cols) > 0) {
    stop(sprintf("%s: Missing expected alpine output columns: %s", data_name, paste(missing_output_cols, collapse = ", ")))
  }
  
  # Summary statistics
  cat(sprintf("✓ Alpine processing complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(df), 100 * nrow(df) / original_rows))
  cat(sprintf("Unique alpine skiers: %d\n", length(unique(df$Skier))))
  cat(sprintf("Alpine seasons covered: %d (%s - %s)\n", 
              length(unique(df$Season)), min(df$Season), max(df$Season)))
  cat(sprintf("Average alpine races per season per skier: %.1f\n", mean(df$Races_in_Season)))
  
  return(df)
}

# Process both alpine datasets with validation
cat("\n=== PROCESSING MEN'S ALPINE DATA ===\n")
tryCatch({
  M_processed <- process_alpine_chrono_data(M_chrono, "Men's")
}, error = function(e) {
  stop("Failed to process men's alpine data: ", e$message)
})

cat("\n=== PROCESSING LADIES ALPINE DATA ===\n")
tryCatch({
  L_processed <- process_alpine_chrono_data(L_chrono, "Ladies")
}, error = function(e) {
  stop("Failed to process ladies alpine data: ", e$message)
})

# Cross-validation between alpine datasets
cat("\n=== CROSS-DATASET ALPINE VALIDATION ===\n")

# Compare season ranges
men_seasons <- sort(unique(M_processed$Season))
ladies_seasons <- sort(unique(L_processed$Season))

cat("Men's alpine seasons:", paste(range(men_seasons), collapse = " - "), "(", length(men_seasons), "seasons )\n")
cat("Ladies alpine seasons:", paste(range(ladies_seasons), collapse = " - "), "(", length(ladies_seasons), "seasons )\n")

# Check for season overlap
common_seasons <- intersect(men_seasons, ladies_seasons)
cat("Common alpine seasons:", length(common_seasons), "\n")

if (length(common_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine data")
}

# Compare event distributions
men_events <- table(M_processed$Event)
ladies_events <- table(L_processed$Event)

cat("\nAlpine event distribution comparison:\n")
all_events <- sort(unique(c(names(men_events), names(ladies_events))))

for (event in all_events) {
  men_count <- ifelse(event %in% names(men_events), men_events[event], 0)
  ladies_count <- ifelse(event %in% names(ladies_events), ladies_events[event], 0)
  cat(sprintf("  %s: Men %d, Ladies %d\n", event, men_count, ladies_count))
}

# Test with star athletes to validate processing
cat("\n=== ALPINE STAR ATHLETE VALIDATION ===\n")

# Test Marco Odermatt (men)
odermatt_data <- M_processed %>% 
  filter(Skier == "Marco Odermatt") %>%
  arrange(Season, Date)

if (nrow(odermatt_data) > 0) {
  cat("✓ Marco Odermatt found in men's data\n")
  cat(sprintf("  Seasons: %s - %s\n", min(odermatt_data$Season), max(odermatt_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(odermatt_data)))
  cat(sprintf("  Career points: %d\n", sum(odermatt_data$Points)))
  
  # Show recent season performance
  recent_season <- max(odermatt_data$Season)
  recent_data <- odermatt_data %>% filter(Season == recent_season)
  cat(sprintf("  %d season: %d races, %d points, %.1f%% of max\n", 
              recent_season, nrow(recent_data), sum(recent_data$Points),
              max(recent_data$Pct_of_Max_Points) * 100))
} else {
  warning("Marco Odermatt not found in men's alpine data")
}

M_processed %>% filter(Skier == "Lucas Pinheiro Braathen")

# Test Mikaela Shiffrin (ladies)
shiffrin_data <- L_processed %>% 
  filter(Skier == "Mikaela Shiffrin") %>%
  arrange(Season, Date)

if (nrow(shiffrin_data) > 0) {
  cat("✓ Mikaela Shiffrin found in ladies data\n")
  cat(sprintf("  Seasons: %s - %s\n", min(shiffrin_data$Season), max(shiffrin_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(shiffrin_data)))
  cat(sprintf("  Career points: %d\n", sum(shiffrin_data$Points)))
  
  # Show recent season performance
  recent_season <- max(shiffrin_data$Season)
  recent_data <- shiffrin_data %>% filter(Season == recent_season)
  cat(sprintf("  %d season: %d races, %d points, %.1f%% of max\n", 
              recent_season, nrow(recent_data), sum(recent_data$Points),
              max(recent_data$Pct_of_Max_Points) * 100))
} else {
  warning("Mikaela Shiffrin not found in ladies alpine data")
}

cat("\n=== ALPINE DATA PROCESSING COMPLETE ===\n")
cat(sprintf("Final alpine dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_processed), nrow(L_processed)))
```

### ELO Data Preparation

```{r elo-prep}
cat("=== ALPINE ELO DATA PREPARATION ===\n")

# Helper function for quartile replacement (handles NAs by replacing with 1st quartile within season)
replace_na_with_quartile <- function(x, var_name) {
  if (all(is.na(x))) {
    warning(sprintf("All values NA for %s in this season - using global mean", var_name))
    return(rep(mean(x, na.rm = TRUE), length(x)))
  }
  
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  if (is.na(q1)) {
    warning(sprintf("Cannot calculate quartile for %s - using mean", var_name))
    q1 <- mean(x, na.rm = TRUE)
  }
  
  return(replace(x, is.na(x), q1))
}

# Function to prepare alpine ELO data for modeling (works for both men and ladies)
prepare_alpine_elo_data <- function(processed_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Preparing %s Alpine ELO Data ---\n", data_name))
  
  # Input validation
  if (nrow(processed_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  original_rows <- nrow(processed_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Check for offseason data
  offseason_count <- sum(processed_df$Event == "Offseason", na.rm = TRUE)
  cat(sprintf("Offseason events available: %d\n", offseason_count))
  
  if (offseason_count == 0) {
    stop(sprintf("%s: No offseason data found for alpine ELO preparation", data_name))
  }
  
  # Check for required alpine ELO columns before processing
  required_elo_cols <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                         "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")
  
  available_elo_cols <- intersect(required_elo_cols, names(processed_df))
  missing_elo_cols <- setdiff(required_elo_cols, names(processed_df))
  
  cat(sprintf("Available alpine ELO columns: %d/%d\n", length(available_elo_cols), length(required_elo_cols)))
  if (length(missing_elo_cols) > 0) {
    cat("Missing alpine ELO columns:", paste(missing_elo_cols, collapse = ", "), "\n")
    warning(sprintf("%s: Missing some alpine ELO columns - proceeding with available columns", data_name))
  }
  
  # Filter for offseason data and create previous season ELO values
  cat("Filtering for offseason data and creating lag features...\n")
  
  elo_df <- processed_df %>%
    filter(Event == "Offseason") %>%
    arrange(ID, Season)
  
  filtered_rows <- nrow(elo_df)
  cat(sprintf("After offseason filter: %d rows (%.1f%% of input)\n", 
              filtered_rows, 100 * filtered_rows / original_rows))
  
  if (filtered_rows == 0) {
    stop(sprintf("%s: No rows remaining after offseason filtering", data_name))
  }
  
  # Create lag features for alpine disciplines with validation
  cat("Creating alpine discipline lag features...\n")
  
  elo_df <- elo_df %>%
    group_by(ID) %>%
    mutate(
      Prev_Pelo = if("Pelo" %in% names(.)) lag(Pelo) else NA_real_,
      Prev_Downhill = if("Downhill_Pelo" %in% names(.)) lag(Downhill_Pelo) else NA_real_,
      Prev_Super_G = if("Super G_Pelo" %in% names(.)) lag(`Super G_Pelo`) else NA_real_,
      Prev_Giant_Slalom = if("Giant Slalom_Pelo" %in% names(.)) lag(`Giant Slalom_Pelo`) else NA_real_,
      Prev_Slalom = if("Slalom_Pelo" %in% names(.)) lag(Slalom_Pelo) else NA_real_,
      Prev_Combined = if("Combined_Pelo" %in% names(.)) lag(Combined_Pelo) else NA_real_,
      Prev_Tech = if("Tech_Pelo" %in% names(.)) lag(Tech_Pelo) else NA_real_,
      Prev_Speed = if("Speed_Pelo" %in% names(.)) lag(Speed_Pelo) else NA_real_,
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
    ) %>%
    ungroup()
  
  # Validate lag feature creation
  lag_features <- paste0("Prev_", c("Pelo", "Downhill", "Super_G", "Giant_Slalom", "Slalom", 
                                    "Combined", "Tech", "Speed", "Pct_of_Max_Points"))
  
  created_lag_features <- intersect(lag_features, names(elo_df))
  cat(sprintf("Created alpine lag features: %d/%d\n", length(created_lag_features), length(lag_features)))
  
  # Apply season filter
  cat("Applying season filter (> 2015)...\n")
  before_season_filter <- nrow(elo_df)
  
  elo_df <- elo_df %>%
    filter(Season > 2015)
  
  after_season_filter <- nrow(elo_df)
  cat(sprintf("After season filter: %d rows (removed %d rows from ≤2015)\n", 
              after_season_filter, before_season_filter - after_season_filter))
  
  if (after_season_filter == 0) {
    stop(sprintf("%s: No rows remaining after alpine season filtering (>2015)", data_name))
  }
  
  # Validate season range
  season_range <- range(elo_df$Season, na.rm = TRUE)
  cat(sprintf("Final alpine season range: %.0f - %.0f\n", season_range[1], season_range[2]))
  
  # Handle missing values by replacing with quartiles within each season
  cat("\n--- Alpine ELO Missing Value Treatment ---\n")
  
  # Count NAs before treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_before <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_before) > 0) {
    cat("Alpine ELO NAs before treatment:\n")
    print(na_summary_before)
  } else {
    cat("No NAs found in alpine lag features\n")
  }
  
  # Apply quartile replacement by season for alpine disciplines
  cat("Applying quartile replacement by season for alpine disciplines...\n")
  
  elo_df <- elo_df %>%
    group_by(Season) %>%
    mutate(
      Prev_Downhill = if("Prev_Downhill" %in% names(.)) replace_na_with_quartile(Prev_Downhill, "Prev_Downhill") else Prev_Downhill,
      Prev_Super_G = if("Prev_Super_G" %in% names(.)) replace_na_with_quartile(Prev_Super_G, "Prev_Super_G") else Prev_Super_G,
      Prev_Giant_Slalom = if("Prev_Giant_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Giant_Slalom, "Prev_Giant_Slalom") else Prev_Giant_Slalom,
      Prev_Slalom = if("Prev_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Slalom, "Prev_Slalom") else Prev_Slalom,
      Prev_Combined = if("Prev_Combined" %in% names(.)) replace_na_with_quartile(Prev_Combined, "Prev_Combined") else Prev_Combined,
      Prev_Tech = if("Prev_Tech" %in% names(.)) replace_na_with_quartile(Prev_Tech, "Prev_Tech") else Prev_Tech,
      Prev_Speed = if("Prev_Speed" %in% names(.)) replace_na_with_quartile(Prev_Speed, "Prev_Speed") else Prev_Speed,
      Prev_Pelo = if("Prev_Pelo" %in% names(.)) replace_na_with_quartile(Prev_Pelo, "Prev_Pelo") else Prev_Pelo,
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate missing value treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_after <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_after) > 0) {
    cat("Remaining alpine ELO NAs after treatment:\n")
    print(na_summary_after)
    warning(sprintf("%s: Some alpine ELO NAs remain after quartile replacement", data_name))
  } else {
    cat("✓ All alpine ELO NAs successfully treated\n")
  }
  
  # Final validation checks
  cat("\n--- Final Alpine ELO Validation ---\n")
  
  # Check for infinite values
  numeric_cols <- select_if(elo_df, is.numeric) %>% names()
  if (length(numeric_cols) > 0) {
    inf_check <- elo_df[numeric_cols] %>%
      summarise_all(~ sum(!is.finite(.))) %>%
      gather(variable, inf_count) %>%
      filter(inf_count > 0)
  } else {
    inf_check <- data.frame(variable = character(0), inf_count = numeric(0))
  }
  
  if (nrow(inf_check) > 0) {
    cat("Infinite values found in alpine ELO data:\n")
    print(inf_check)
    warning(sprintf("%s: Contains infinite values", data_name))
  } else {
    cat("✓ No infinite values detected in alpine ELO data\n")
  }
  
  # Validate key relationships for alpine
  if ("Age" %in% names(elo_df)) {
    age_issues <- elo_df %>%
      filter(Age < 15 | Age > 50) %>%
      nrow()
    
    if (age_issues > 0) {
      warning(sprintf("%s: %d rows with unusual ages (<15 or >50)", data_name, age_issues))
    }
    
    cat(sprintf("Alpine skier age range: %.0f - %.0f\n", min(elo_df$Age, na.rm = TRUE), max(elo_df$Age, na.rm = TRUE)))
  }
  
  # Summary statistics
  cat(sprintf("✓ Alpine ELO preparation complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(elo_df), 100 * nrow(elo_df) / original_rows))
  cat(sprintf("Unique alpine skiers: %d\n", length(unique(elo_df$Skier))))
  cat(sprintf("Alpine seasons: %d (%s)\n", 
              length(unique(elo_df$Season)), paste(sort(unique(elo_df$Season)), collapse = ", ")))
  
  return(elo_df)
}

# Prepare alpine ELO data for both men and ladies with comprehensive validation
cat("\n=== PREPARING MEN'S ALPINE ELO DATA ===\n")
tryCatch({
  M_elo <- prepare_alpine_elo_data(M_processed, "Men's")
}, error = function(e) {
  stop("Failed to prepare men's alpine ELO data: ", e$message)
})

cat("\n=== PREPARING LADIES ALPINE ELO DATA ===\n")
tryCatch({
  L_elo <- prepare_alpine_elo_data(L_processed, "Ladies")
}, error = function(e) {
  stop("Failed to prepare ladies alpine ELO data: ", e$message)
})

# Cross-validation between alpine ELO datasets
cat("\n=== CROSS-DATASET ALPINE ELO VALIDATION ===\n")

# Compare season ranges
men_elo_seasons <- sort(unique(M_elo$Season))
ladies_elo_seasons <- sort(unique(L_elo$Season))

cat("Men's alpine ELO seasons:", paste(range(men_elo_seasons), collapse = " - "), "(", length(men_elo_seasons), "seasons )\n")
cat("Ladies alpine ELO seasons:", paste(range(ladies_elo_seasons), collapse = " - "), "(", length(ladies_elo_seasons), "seasons )\n")

# Check for season overlap
common_elo_seasons <- intersect(men_elo_seasons, ladies_elo_seasons)
cat("Common alpine ELO seasons:", length(common_elo_seasons), "\n")

if (length(common_elo_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine ELO data")
}

# Validate alpine ELO distributions
cat("\n--- Alpine ELO Distribution Analysis ---\n")

# Check ELO ranges for men
if ("Prev_Pelo" %in% names(M_elo)) {
  men_pelo_range <- range(M_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Men's Prev_Pelo range: %.0f - %.0f\n", men_pelo_range[1], men_pelo_range[2]))
}

if ("Prev_Tech" %in% names(M_elo)) {
  men_tech_range <- range(M_elo$Prev_Tech, na.rm = TRUE)
  cat(sprintf("Men's Prev_Tech range: %.0f - %.0f\n", men_tech_range[1], men_tech_range[2]))
}

if ("Prev_Speed" %in% names(M_elo)) {
  men_speed_range <- range(M_elo$Prev_Speed, na.rm = TRUE)
  cat(sprintf("Men's Prev_Speed range: %.0f - %.0f\n", men_speed_range[1], men_speed_range[2]))
}

# Check ELO ranges for ladies
if ("Prev_Pelo" %in% names(L_elo)) {
  ladies_pelo_range <- range(L_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Ladies Prev_Pelo range: %.0f - %.0f\n", ladies_pelo_range[1], ladies_pelo_range[2]))
}

if ("Prev_Tech" %in% names(L_elo)) {
  ladies_tech_range <- range(L_elo$Prev_Tech, na.rm = TRUE)
  cat(sprintf("Ladies Prev_Tech range: %.0f - %.0f\n", ladies_tech_range[1], ladies_tech_range[2]))
}

if ("Prev_Speed" %in% names(L_elo)) {
  ladies_speed_range <- range(L_elo$Prev_Speed, na.rm = TRUE)
  cat(sprintf("Ladies Prev_Speed range: %.0f - %.0f\n", ladies_speed_range[1], ladies_speed_range[2]))
}

cat("\n=== ALPINE ELO DATA PREPARATION COMPLETE ===\n")
cat(sprintf("Final alpine ELO dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))
```

### Season Points Prediction Model

```{r comprehensive-feature-selection}
cat("=== COMPREHENSIVE ALPINE FEATURE SELECTION & VALIDATION ===\n")

# Comprehensive Feature Selection using multiple methods with validation
# Adapted for alpine skiing disciplines and ELO ratings

cat("\n--- Alpine Training Data Preparation ---\n")

# Input validation for alpine ELO datasets
if (nrow(M_elo) == 0) {
  stop("Men's alpine ELO dataset is empty")
}
if (nrow(L_elo) == 0) {
  stop("Ladies alpine ELO dataset is empty")
}

cat(sprintf("Input alpine datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))

# Prepare training data - include more historical seasons to capture early breakthroughs
# Use data from 2016+ to include breakthrough seasons in alpine
cat("Filtering alpine training data (2016-2025, non-NA Pct_of_Max_Points)...\n")

# Check available seasons before filtering
men_seasons_available <- sort(unique(M_elo$Season))
ladies_seasons_available <- sort(unique(L_elo$Season))

cat(sprintf("Men's alpine available seasons: %s\n", paste(range(men_seasons_available), collapse = " - ")))
cat(sprintf("Ladies alpine available seasons: %s\n", paste(range(ladies_seasons_available), collapse = " - ")))

# Apply training filters with validation
train_men <- M_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

train_ladies <- L_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

# Validate training datasets
if (nrow(train_men) == 0) {
  stop("No men's alpine training data remains after filtering")
}
if (nrow(train_ladies) == 0) {
  stop("No ladies alpine training data remains after filtering")
}

cat(sprintf("Alpine training datasets: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Check season coverage in training data
train_men_seasons <- sort(unique(train_men$Season))
train_ladies_seasons <- sort(unique(train_ladies$Season))

cat(sprintf("Men's alpine training seasons: %s (%d seasons)\n", 
            paste(train_men_seasons, collapse = ", "), length(train_men_seasons)))
cat(sprintf("Ladies alpine training seasons: %s (%d seasons)\n", 
            paste(train_ladies_seasons, collapse = ", "), length(train_ladies_seasons)))

if (length(train_men_seasons) < 3) {
  warning("Men's alpine training data has fewer than 3 seasons - may affect model robustness")
}
if (length(train_ladies_seasons) < 3) {
  warning("Ladies alpine training data has fewer than 3 seasons - may affect model robustness")
}

# Define and validate potential alpine features
cat("\n--- Alpine Feature Validation ---\n")

all_features <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                  "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", 
                  "Prev_Pct_of_Max_Points", "Age")

# Check feature availability in alpine training datasets
men_available_features <- intersect(all_features, names(train_men))
ladies_available_features <- intersect(all_features, names(train_ladies))

cat(sprintf("Men's available alpine features: %d/%d\n", length(men_available_features), length(all_features)))
cat(sprintf("Ladies available alpine features: %d/%d\n", length(ladies_available_features), length(all_features)))

# Report missing features
men_missing_features <- setdiff(all_features, men_available_features)
ladies_missing_features <- setdiff(all_features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing alpine features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing alpine features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from ladies training data")
}

# Update feature lists to only include available features
all_features_men <- men_available_features
all_features_ladies <- ladies_available_features

if (length(all_features_men) < 3) {
  stop("Insufficient alpine features for men's modeling (need at least 3)")
}
if (length(all_features_ladies) < 3) {
  stop("Insufficient alpine features for ladies modeling (need at least 3)")
}

# Validate alpine feature data quality
cat("\n--- Alpine Feature Data Quality Checks ---\n")

# Check for missing values in alpine features
men_feature_na_counts <- sapply(train_men[all_features_men], function(x) sum(is.na(x)))
ladies_feature_na_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(is.na(x)))

if (any(men_feature_na_counts > 0)) {
  cat("Men's alpine features with NAs:\n")
  print(men_feature_na_counts[men_feature_na_counts > 0])
  warning("Men's alpine training data contains missing values in features")
}
if (any(ladies_feature_na_counts > 0)) {
  cat("Ladies alpine features with NAs:\n")
  print(ladies_feature_na_counts[ladies_feature_na_counts > 0])
  warning("Ladies alpine training data contains missing values in features")
}

# Check for infinite values
men_feature_inf_counts <- sapply(train_men[all_features_men], function(x) sum(!is.finite(x)))
ladies_feature_inf_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(!is.finite(x)))

if (any(men_feature_inf_counts > 0)) {
  cat("Men's alpine features with infinite values:\n")
  print(men_feature_inf_counts[men_feature_inf_counts > 0])
  warning("Men's alpine training data contains infinite values")
}
if (any(ladies_feature_inf_counts > 0)) {
  cat("Ladies alpine features with infinite values:\n")
  print(ladies_feature_inf_counts[ladies_feature_inf_counts > 0])
  warning("Ladies alpine training data contains infinite values")
}

# Check target variable quality
men_target_na <- sum(is.na(train_men$Pct_of_Max_Points))
ladies_target_na <- sum(is.na(train_ladies$Pct_of_Max_Points))

if (men_target_na > 0) {
  warning(sprintf("Men's alpine target variable has %d NA values", men_target_na))
}
if (ladies_target_na > 0) {
  warning(sprintf("Ladies alpine target variable has %d NA values", ladies_target_na))
}

cat(sprintf("Alpine target variable ranges: Men %.3f-%.3f, Ladies %.3f-%.3f\n",
            min(train_men$Pct_of_Max_Points, na.rm = TRUE), max(train_men$Pct_of_Max_Points, na.rm = TRUE),
            min(train_ladies$Pct_of_Max_Points, na.rm = TRUE), max(train_ladies$Pct_of_Max_Points, na.rm = TRUE)))

cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION FOR MEN ===\n")

# 1. CORRELATION ANALYSIS with validation
cat("1. ALPINE CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for correlation analysis\n")
    cor_matrix_men <- NULL
    high_cor_men <- data.frame()
  } else {
    cor_matrix_men <- cor(train_men[all_features_men], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_men))) {
      warning("Alpine correlation matrix contains NA values")
    }
    
    high_cor_men <- which(abs(cor_matrix_men) > 0.7 & upper.tri(cor_matrix_men), arr.ind = TRUE)
    if(nrow(high_cor_men) > 0) {
      cat("High alpine correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_men)) {
        row_name <- rownames(cor_matrix_men)[high_cor_men[i,1]]
        col_name <- colnames(cor_matrix_men)[high_cor_men[i,2]]
        cor_val <- cor_matrix_men[high_cor_men[i,1], high_cor_men[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high alpine correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine correlation analysis:", e$message, "\n")
  cor_matrix_men <- NULL
  high_cor_men <- data.frame()
})

# 2. LASSO REGULARIZATION with validation
cat("2. ALPINE LASSO REGULARIZATION:\n")
lasso_selected_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_men <- as.matrix(train_men[all_features_men])
  y_men <- train_men$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_men))) {
    warning("Non-finite values in alpine feature matrix for LASSO")
  }
  if (any(!is.finite(y_men))) {
    warning("Non-finite values in alpine target variable for LASSO")
  }
  
  cv_lasso_men <- cv.glmnet(x_men, y_men, alpha = 1, nfolds = 5)
  best_lambda_men <- cv_lasso_men$lambda.min
  lasso_coef_men <- coef(cv_lasso_men, s = best_lambda_men)
  
  lasso_selected_men <- rownames(lasso_coef_men)[which(lasso_coef_men != 0)][-1]  # Remove intercept
  
  if (length(lasso_selected_men) > 0) {
    cat("Alpine LASSO selected features:\n")
    for (feature in lasso_selected_men) {
      coef_val <- lasso_coef_men[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by alpine LASSO (may indicate weak predictors)\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_men))
  
}, error = function(e) {
  cat("Error in alpine LASSO analysis:", e$message, "\n")
  lasso_selected_men <- character(0)
})

# 3. BORUTA FEATURE SELECTION with validation
cat("3. ALPINE BORUTA FEATURE SELECTION:\n")
boruta_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_men <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                         data = train_men, doTrace = 0)
    
    boruta_selected_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_men) > 0) {
      cat("Alpine Boruta confirmed features:\n")
      for (feature in boruta_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by alpine Boruta\n")
    }
    
    # Check for tentative features
    tentative_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Tentative"]
    if (length(tentative_men) > 0) {
      cat("Alpine Boruta tentative features:\n")
      for (feature in tentative_men) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in alpine Boruta analysis:", e$message, "\n")
  boruta_selected_men <- character(0)
})

# 4. EXHAUSTIVE SEARCH with validation
cat("4. ALPINE EXHAUSTIVE SEARCH:\n")
leaps_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for exhaustive search\n")
  } else if (length(all_features_men) > 8) {
    cat("Too many alpine features for exhaustive search - using best subset\n")
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, nvmax = min(8, length(all_features_men)))
  } else {
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, really.big = TRUE)
  }
  
  if (exists("leaps_men")) {
    summary_leaps_men <- summary(leaps_men)
    best_model_size <- which.max(summary_leaps_men$adjr2)
    leaps_selected_men <- names(which(summary_leaps_men$which[best_model_size, -1]))  # Remove intercept
    
    if (length(leaps_selected_men) > 0) {
      cat("Alpine exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_men$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by alpine exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine exhaustive search:", e$message, "\n")
  leaps_selected_men <- character(0)
})

# 5. CONSENSUS FEATURE SELECTION
cat("5. ALPINE CONSENSUS FEATURE SELECTION:\n")

all_selected_men <- c(lasso_selected_men, boruta_selected_men, leaps_selected_men)
if (length(all_selected_men) > 0) {
  feature_counts_men <- table(all_selected_men)
  consensus_men <- names(feature_counts_men)[feature_counts_men >= 2]  # Features selected by 2+ methods
  
  if (length(consensus_men) > 0) {
    cat("Alpine consensus features (selected by 2+ methods):\n")
    for (feature in consensus_men) {
      count <- feature_counts_men[feature]
      methods <- c(
        if (feature %in% lasso_selected_men) "LASSO" else NULL,
        if (feature %in% boruta_selected_men) "Boruta" else NULL,
        if (feature %in% leaps_selected_men) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No alpine consensus features - using union of all methods\n")
    consensus_men <- unique(all_selected_men)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_men) && "Pct_of_Max_Points" %in% names(train_men)) {
    target_cors <- cor(train_men[all_features_men], train_men$Pct_of_Max_Points, use = "complete.obs")
    consensus_men <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_men))]
  } else {
    consensus_men <- all_features_men[1:min(3, length(all_features_men))]
  }
}

final_features_men <- consensus_men
cat(sprintf("Final alpine features for men: %s\n", paste(final_features_men, collapse = ", ")))

cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION FOR LADIES ===\n")

# Repeat the same process for ladies with alpine-specific adaptations
# 1. CORRELATION ANALYSIS
cat("1. ALPINE CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient alpine features for correlation analysis\n")
    cor_matrix_ladies <- NULL
    high_cor_ladies <- data.frame()
  } else {
    cor_matrix_ladies <- cor(train_ladies[all_features_ladies], use = "complete.obs")
    
    if (any(is.na(cor_matrix_ladies))) {
      warning("Alpine correlation matrix contains NA values")
    }
    
    high_cor_ladies <- which(abs(cor_matrix_ladies) > 0.7 & upper.tri(cor_matrix_ladies), arr.ind = TRUE)
    if(nrow(high_cor_ladies) > 0) {
      cat("High alpine correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_ladies)) {
        row_name <- rownames(cor_matrix_ladies)[high_cor_ladies[i,1]]
        col_name <- colnames(cor_matrix_ladies)[high_cor_ladies[i,2]]
        cor_val <- cor_matrix_ladies[high_cor_ladies[i,1], high_cor_ladies[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high alpine correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine correlation analysis:", e$message, "\n")
  cor_matrix_ladies <- NULL
  high_cor_ladies <- data.frame()
})

# 2. LASSO REGULARIZATION
cat("2. ALPINE LASSO REGULARIZATION:\n")
lasso_selected_ladies <- character(0)
tryCatch({
  set.seed(42)
  
  x_ladies <- as.matrix(train_ladies[all_features_ladies])
  y_ladies <- train_ladies$Pct_of_Max_Points
  
  if (any(!is.finite(x_ladies))) {
    warning("Non-finite values in alpine feature matrix for LASSO")
  }
  if (any(!is.finite(y_ladies))) {
    warning("Non-finite values in alpine target variable for LASSO")
  }
  
  cv_lasso_ladies <- cv.glmnet(x_ladies, y_ladies, alpha = 1, nfolds = 5)
  best_lambda_ladies <- cv_lasso_ladies$lambda.min
  lasso_coef_ladies <- coef(cv_lasso_ladies, s = best_lambda_ladies)
  
  lasso_selected_ladies <- rownames(lasso_coef_ladies)[which(lasso_coef_ladies != 0)][-1]
  
  if (length(lasso_selected_ladies) > 0) {
    cat("Alpine LASSO selected features:\n")
    for (feature in lasso_selected_ladies) {
      coef_val <- lasso_coef_ladies[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by alpine LASSO\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_ladies))
  
}, error = function(e) {
  cat("Error in alpine LASSO analysis:", e$message, "\n")
  lasso_selected_ladies <- character(0)
})

# 3. BORUTA FEATURE SELECTION
cat("3. ALPINE BORUTA FEATURE SELECTION:\n")
boruta_selected_ladies <- character(0)
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient alpine features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_ladies <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                           data = train_ladies, doTrace = 0)
    
    boruta_selected_ladies <- names(boruta_ladies$finalDecision)[boruta_ladies$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_ladies) > 0) {
      cat("Alpine Boruta confirmed features:\n")
      for (feature in boruta_selected_ladies) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by alpine Boruta\n")
    }
    
    tentative_ladies <- names(boruta_ladies$finalDecision)[boruta_ladies$finalDecision == "Tentative"]
    if (length(tentative_ladies) > 0) {
      cat("Alpine Boruta tentative features:\n")
      for (feature in tentative_ladies) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in alpine Boruta analysis:", e$message, "\n")
  boruta_selected_ladies <- character(0)
})

# 4. EXHAUSTIVE SEARCH
cat("4. ALPINE EXHAUSTIVE SEARCH:\n")
leaps_selected_ladies <- character(0)
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient alpine features for exhaustive search\n")
  } else if (length(all_features_ladies) > 8) {
    cat("Too many alpine features for exhaustive search - using best subset\n")
    leaps_ladies <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                              data = train_ladies, nvmax = min(8, length(all_features_ladies)))
  } else {
    leaps_ladies <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                              data = train_ladies, really.big = TRUE)
  }
  
  if (exists("leaps_ladies")) {
    summary_leaps_ladies <- summary(leaps_ladies)
    best_model_size <- which.max(summary_leaps_ladies$adjr2)
    leaps_selected_ladies <- names(which(summary_leaps_ladies$which[best_model_size, -1]))
    
    if (length(leaps_selected_ladies) > 0) {
      cat("Alpine exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_ladies) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_ladies$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by alpine exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine exhaustive search:", e$message, "\n")
  leaps_selected_ladies <- character(0)
})

# 5. CONSENSUS FEATURE SELECTION
cat("5. ALPINE CONSENSUS FEATURE SELECTION:\n")

all_selected_ladies <- c(lasso_selected_ladies, boruta_selected_ladies, leaps_selected_ladies)
if (length(all_selected_ladies) > 0) {
  feature_counts_ladies <- table(all_selected_ladies)
  consensus_ladies <- names(feature_counts_ladies)[feature_counts_ladies >= 2]
  
  if (length(consensus_ladies) > 0) {
    cat("Alpine consensus features (selected by 2+ methods):\n")
    for (feature in consensus_ladies) {
      count <- feature_counts_ladies[feature]
      methods <- c(
        if (feature %in% lasso_selected_ladies) "LASSO" else NULL,
        if (feature %in% boruta_selected_ladies) "Boruta" else NULL,
        if (feature %in% leaps_selected_ladies) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No alpine consensus features - using union of all methods\n")
    consensus_ladies <- unique(all_selected_ladies)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_ladies) && "Pct_of_Max_Points" %in% names(train_ladies)) {
    target_cors <- cor(train_ladies[all_features_ladies], train_ladies$Pct_of_Max_Points, use = "complete.obs")
    consensus_ladies <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_ladies))]
  } else {
    consensus_ladies <- all_features_ladies[1:min(3, length(all_features_ladies))]
  }
}

final_features_ladies <- consensus_ladies
cat(sprintf("Final alpine features for ladies: %s\n", paste(final_features_ladies, collapse = ", ")))

cat("\n=== ALPINE FEATURE SELECTION SUMMARY ===\n")
cat(sprintf("Men's final alpine features (%d): %s\n", length(final_features_men), paste(final_features_men, collapse = ", ")))
cat(sprintf("Ladies final alpine features (%d): %s\n", length(final_features_ladies), paste(final_features_ladies, collapse = ", ")))

# Store feature selection results for later use
feature_selection_results_men <- list(
  lasso = lasso_selected_men,
  boruta = boruta_selected_men,
  exhaustive = leaps_selected_men,
  final = final_features_men
)

feature_selection_results_ladies <- list(
  lasso = lasso_selected_ladies,
  boruta = boruta_selected_ladies,
  exhaustive = leaps_selected_ladies,
  final = final_features_ladies
)

cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION COMPLETE ===\n")
```

### GAM Model Building

```{r gam-model}
cat("=== GAM MODEL BUILDING & VALIDATION ===\n")

# Build GAM models using consensus-selected features with comprehensive validation

cat("\n--- GAM Model Construction ---\n")

# Validate inputs for GAM model building
if (!exists("final_features_men") || !exists("final_features_ladies")) {
  stop("Final features not defined - ensure feature selection completed successfully")
}

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure data preparation completed successfully")
}

cat(sprintf("Input validation: Men %d features, Ladies %d features\n", 
            length(final_features_men), length(final_features_ladies)))

cat(sprintf("Training data: Men %d rows, Ladies %d rows\n", 
            nrow(train_men), nrow(train_ladies)))

# Build GAM formula for Men using validated features
cat("\n--- Men's GAM Model ---\n")
men_gam_model <- NULL
tryCatch({
  if(length(final_features_men) > 0) {
    # Validate features exist in training data
    missing_features_men <- setdiff(final_features_men, names(train_men))
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's training data:", paste(missing_features_men, collapse = ", "), "\n")
      final_features_men <- intersect(final_features_men, names(train_men))
    }
    
    if (length(final_features_men) > 0) {
      smooth_terms_men <- paste("s(", final_features_men, ")", collapse = " + ")
      gam_formula_men <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_men))
      cat("Men's GAM Formula (Validated Features):\n")
      print(gam_formula_men)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_men) * min_obs_per_feature
      if (nrow(train_men) < required_obs) {
        warning(sprintf("Limited observations for men's GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_men), length(final_features_men), required_obs))
      }
      
      # Build GAM with error handling
      men_gam_model <- gam(gam_formula_men, data = train_men)
      cat(sprintf("✓ Men's GAM model built successfully with %d features\n", length(final_features_men)))
      
    } else {
      cat("No valid features for men's GAM - using fallback\n")
      stop("No valid features available")
    }
  } else {
    cat("No features selected for men - using fallback\n")
    stop("No features available")
  }
}, error = function(e) {
  cat("Error building men's GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_men <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_men))
  if (length(core_features_men) >= 2) {
    fallback_formula_men <- paste("Pct_of_Max_Points ~", paste("s(", core_features_men, ")", collapse = " + "))
    men_gam_model <- gam(as.formula(fallback_formula_men), data = train_men)
    final_features_men <- core_features_men
    cat("✓ Men's GAM fallback model built with core features\n")
  } else {
    stop("Cannot build men's GAM model - insufficient core features available")
  }
})

# Build GAM formula for Ladies using validated features
cat("\n--- Ladies GAM Model ---\n")
ladies_gam_model <- NULL
tryCatch({
  if(length(final_features_ladies) > 0) {
    # Validate features exist in training data
    missing_features_ladies <- setdiff(final_features_ladies, names(train_ladies))
    if (length(missing_features_ladies) > 0) {
      cat("Warning: Missing features in ladies training data:", paste(missing_features_ladies, collapse = ", "), "\n")
      final_features_ladies <- intersect(final_features_ladies, names(train_ladies))
    }
    
    if (length(final_features_ladies) > 0) {
      smooth_terms_ladies <- paste("s(", final_features_ladies, ")", collapse = " + ")
      gam_formula_ladies <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_ladies))
      cat("Ladies GAM Formula (Validated Features):\n")
      print(gam_formula_ladies)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_ladies) * min_obs_per_feature
      if (nrow(train_ladies) < required_obs) {
        warning(sprintf("Limited observations for ladies GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_ladies), length(final_features_ladies), required_obs))
      }
      
      # Build GAM with error handling
      ladies_gam_model <- gam(gam_formula_ladies, data = train_ladies)
      cat(sprintf("✓ Ladies GAM model built successfully with %d features\n", length(final_features_ladies)))
      
    } else {
      cat("No valid features for ladies GAM - using fallback\n")
      stop("No valid features available")
    }
  } else {
    cat("No features selected for ladies - using fallback\n")
    stop("No features available")
  }
}, error = function(e) {
  cat("Error building ladies GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_ladies <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_ladies))
  if (length(core_features_ladies) >= 2) {
    fallback_formula_ladies <- paste("Pct_of_Max_Points ~", paste("s(", core_features_ladies, ")", collapse = " + "))
    ladies_gam_model <- gam(as.formula(fallback_formula_ladies), data = train_ladies)
    final_features_ladies <- core_features_ladies
    cat("✓ Ladies GAM fallback model built with core features\n")
  } else {
    stop("Cannot build ladies GAM model - insufficient core features available")
  }
})

# Validate model objects were created
if (is.null(men_gam_model)) {
  stop("Failed to build men's GAM model")
}
if (is.null(ladies_gam_model)) {
  stop("Failed to build ladies GAM model")
}

# Model performance evaluation with validation
cat("\n=== GAM MODEL PERFORMANCE EVALUATION ===\n")

# Men's GAM Model Performance
cat("--- Men's GAM Model Performance ---\n")
tryCatch({
  men_summary <- summary(men_gam_model)
  
  # Validate summary components exist
  if (is.null(men_summary$dev.expl)) {
    warning("Men's GAM deviance explained not available")
    men_dev_expl <- NA
  } else {
    men_dev_expl <- men_summary$dev.expl * 100
  }
  
  if (is.null(men_summary$r.sq)) {
    warning("Men's GAM R-squared not available")
    men_r_sq <- NA
  } else {
    men_r_sq <- men_summary$r.sq
  }
  
  if (is.null(men_gam_model$gcv.ubre)) {
    warning("Men's GAM GCV score not available")
    men_gcv <- NA
  } else {
    men_gcv <- men_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", men_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", men_r_sq))
  cat(sprintf("GCV Score: %.4f\n", men_gcv))
  
  # Validate model performance
  if (!is.na(men_dev_expl) && men_dev_expl < 10) {
    warning("Men's GAM has very low deviance explained (<10%)")
  }
  if (!is.na(men_r_sq) && men_r_sq < 0.1) {
    warning("Men's GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(men_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(men_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating men's GAM performance:", e$message, "\n")
})

# Ladies GAM Model Performance
cat("\n--- Ladies GAM Model Performance ---\n")
tryCatch({
  ladies_summary <- summary(ladies_gam_model)
  
  # Validate summary components exist
  if (is.null(ladies_summary$dev.expl)) {
    warning("Ladies GAM deviance explained not available")
    ladies_dev_expl <- NA
  } else {
    ladies_dev_expl <- ladies_summary$dev.expl * 100
  }
  
  if (is.null(ladies_summary$r.sq)) {
    warning("Ladies GAM R-squared not available")
    ladies_r_sq <- NA
  } else {
    ladies_r_sq <- ladies_summary$r.sq
  }
  
  if (is.null(ladies_gam_model$gcv.ubre)) {
    warning("Ladies GAM GCV score not available")
    ladies_gcv <- NA
  } else {
    ladies_gcv <- ladies_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", ladies_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", ladies_r_sq))
  cat(sprintf("GCV Score: %.4f\n", ladies_gcv))
  
  # Validate model performance
  if (!is.na(ladies_dev_expl) && ladies_dev_expl < 10) {
    warning("Ladies GAM has very low deviance explained (<10%)")
  }
  if (!is.na(ladies_r_sq) && ladies_r_sq < 0.1) {
    warning("Ladies GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(ladies_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(ladies_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating ladies GAM performance:", e$message, "\n")
})

# Feature importance from GAM (edf values) with validation
cat("\n--- Feature Importance Analysis ---\n")

# Men's Feature Importance
cat("Men's GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(men_summary$s.table) && nrow(men_summary$s.table) > 0) {
    men_edf <- men_summary$s.table[,"edf"]
    names(men_edf) <- rownames(men_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(men_edf))) {
      warning("Some men's GAM EDF values are NA")
      men_edf <- men_edf[!is.na(men_edf)]
    }
    
    if (length(men_edf) > 0) {
      edf_sorted <- sort(men_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features (high EDF suggests non-linear relationship)
      high_edf_features <- names(men_edf[men_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for men's model\n")
    }
  } else {
    cat("No smooth terms in men's GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing men's feature importance:", e$message, "\n")
})

# Ladies Feature Importance
cat("Ladies GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(ladies_summary$s.table) && nrow(ladies_summary$s.table) > 0) {
    ladies_edf <- ladies_summary$s.table[,"edf"]
    names(ladies_edf) <- rownames(ladies_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(ladies_edf))) {
      warning("Some ladies GAM EDF values are NA")
      ladies_edf <- ladies_edf[!is.na(ladies_edf)]
    }
    
    if (length(ladies_edf) > 0) {
      edf_sorted <- sort(ladies_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features
      high_edf_features <- names(ladies_edf[ladies_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for ladies model\n")
    }
  } else {
    cat("No smooth terms in ladies GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing ladies feature importance:", e$message, "\n")
})

# Model diagnostics with validation
cat("\n=== GAM MODEL DIAGNOSTICS ===\n")

# Men's GAM Model Diagnostics
cat("--- Men's GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_men <- gam.check(men_gam_model, sub.caption = "Men's GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_men)) {
    # Check for model convergence issues
    if ("converged" %in% names(men_gam_model) && !men_gam_model$converged) {
      warning("Men's GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(men_summary)) {
      basis_dims <- men_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Men's GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Men's GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating men's GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})

# Ladies GAM Model Diagnostics
cat("--- Ladies GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_ladies <- gam.check(ladies_gam_model, sub.caption = "Ladies GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_ladies)) {
    # Check for model convergence issues
    if ("converged" %in% names(ladies_gam_model) && !ladies_gam_model$converged) {
      warning("Ladies GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(ladies_summary)) {
      basis_dims <- ladies_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Ladies GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Ladies GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating ladies GAM diagnostics:", e$message, "\n")
})

# Reset plotting parameters
par(mfrow = c(1, 1))

# Predict for 2026 season using 2025 ELO values with comprehensive validation
cat("\n=== 2026 SEASON PREDICTIONS ===\n")

# Validate prediction data availability
cat("--- Prediction Data Preparation ---\n")

# Check for 2025 ELO data (end-of-season values)
men_2025 <- M_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

ladies_2025 <- L_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

# Rename columns to match GAM model expectations (Prev_* format)
cat("Renaming 2025 features to Prev_* format for GAM predictions...\n")

if (nrow(men_2025) > 0) {
  # First, remove existing Prev_* columns (which contain 2024 data)
  prev_cols_to_remove <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                          "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  existing_prev_cols <- intersect(prev_cols_to_remove, names(men_2025))
  if (length(existing_prev_cols) > 0) {
    cat("Removing existing Prev_* columns (2024 data):", paste(existing_prev_cols, collapse = ", "), "\n")
    men_2025 <- men_2025 %>% dplyr::select(-all_of(existing_prev_cols))
  }
  
  # Then rename current 2025 columns to Prev_* format
  men_2025 <- men_2025 %>%
    rename(
      Prev_Pelo = Pelo,
      Prev_Downhill = Downhill_Pelo,
      Prev_Super_G = `Super G_Pelo`,
      Prev_Giant_Slalom = `Giant Slalom_Pelo`,
      Prev_Slalom = Slalom_Pelo,
      Prev_Combined = Combined_Pelo,
      Prev_Tech = Tech_Pelo,
      Prev_Speed = Speed_Pelo,
      Prev_Pct_of_Max_Points = Pct_of_Max_Points
    )
}

if (nrow(ladies_2025) > 0) {
  # First, remove existing Prev_* columns (which contain 2024 data)
  prev_cols_to_remove <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                          "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  existing_prev_cols <- intersect(prev_cols_to_remove, names(ladies_2025))
  if (length(existing_prev_cols) > 0) {
    cat("Removing existing ladies Prev_* columns (2024 data):", paste(existing_prev_cols, collapse = ", "), "\n")
    ladies_2025 <- ladies_2025 %>% dplyr::select(-all_of(existing_prev_cols))
  }
  
  # Then rename current 2025 columns to Prev_* format
  ladies_2025 <- ladies_2025 %>%
    rename(
      Prev_Pelo = Pelo,
      Prev_Downhill = Downhill_Pelo,
      Prev_Super_G = `Super G_Pelo`,
      Prev_Giant_Slalom = `Giant Slalom_Pelo`,
      Prev_Slalom = Slalom_Pelo,
      Prev_Combined = Combined_Pelo,
      Prev_Tech = Tech_Pelo,
      Prev_Speed = Speed_Pelo,
      Prev_Pct_of_Max_Points = Pct_of_Max_Points
    )
}

# Apply quartile replacement to handle missing values in 2025 data
cat("Applying quartile replacement for missing values in 2025 prediction data...\n")

if (nrow(men_2025) > 0) {
  men_2025 <- men_2025 %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_Super_G = replace_na_with_quartile(Prev_Super_G),
      Prev_Giant_Slalom = replace_na_with_quartile(Prev_Giant_Slalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace_na_with_quartile(Prev_Pct_of_Max_Points)
    ) %>%
    ungroup()
}

if (nrow(ladies_2025) > 0) {
  ladies_2025 <- ladies_2025 %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_Super_G = replace_na_with_quartile(Prev_Super_G),
      Prev_Giant_Slalom = replace_na_with_quartile(Prev_Giant_Slalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace_na_with_quartile(Prev_Pct_of_Max_Points)
    ) %>%
    ungroup()
}

cat(sprintf("2025 prediction data (end-of-season): Men %d rows, Ladies %d rows\n", nrow(men_2025), nrow(ladies_2025)))


# Men's 2026 Predictions
cat("\n--- Men's 2026 Predictions ---\n")
men_pred_data <- NULL
if(nrow(men_2025) > 0) {
  tryCatch({
    # Validate features are available in 2025 data
    available_features_men <- intersect(final_features_men, names(men_2025))
    missing_features_men <- setdiff(final_features_men, names(men_2025))
    
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's 2025 data for prediction:", paste(missing_features_men, collapse = ", "), "\n")
    }
    
    if (length(available_features_men) > 0) {
      # Debug: Show exact GAM model input for Marcel Hirscher
      if ("Marcel Hirscher" %in% men_2025$Skier) {
        hirscher_idx <- which(men_2025$Skier == "Marcel Hirscher")
        cat("\n=== DEBUG: Marcel Hirscher GAM Model Input ===\n")
        cat("Selected features for GAM:", paste(final_features_men, collapse = ", "), "\n")
        hirscher_model_data <- men_2025[hirscher_idx, c("Skier", final_features_men), drop = FALSE]
        print(hirscher_model_data)
      }
      
      # Use only available features for prediction
      pred_2026_men <- predict(men_gam_model, newdata = men_2025, se.fit = TRUE)
      
      # Validate predictions
      if (any(!is.finite(pred_2026_men$fit))) {
        warning("Some men's 2026 predictions are non-finite")
        pred_2026_men$fit[!is.finite(pred_2026_men$fit)] <- NA
      }
      
      men_pred_data <- men_2025 %>%
        mutate(
          Predicted_Pct_2026 = pred_2026_men$fit,
          Prediction_SE = pred_2026_men$se.fit,
          Lower_CI = Predicted_Pct_2026 - 1.96 * Prediction_SE,
          Upper_CI = Predicted_Pct_2026 + 1.96 * Prediction_SE
        ) %>%
        filter(!is.na(Predicted_Pct_2026)) %>%
        # Rename back to original column names for statistical-odds section
        rename(
          Pelo = Prev_Pelo,
          Downhill_Pelo = Prev_Downhill,
          `Super G_Pelo` = Prev_Super_G,
          `Giant Slalom_Pelo` = Prev_Giant_Slalom,
          Slalom_Pelo = Prev_Slalom,
          Combined_Pelo = Prev_Combined,
          Tech_Pelo = Prev_Tech,
          Speed_Pelo = Prev_Speed,
          Pct_of_Max_Points = Prev_Pct_of_Max_Points
        ) %>%
        arrange(desc(Predicted_Pct_2026))
      
      cat(sprintf("✓ Men's 2026 predictions generated for %d athletes\n", nrow(men_pred_data)))
      cat(sprintf("Top predicted: %s (%.2f%% of max points)\n", 
                  men_pred_data$Skier[1], men_pred_data$Predicted_Pct_2026[1] * 100))
      
    } else {
      cat("No features available for men's 2026 predictions\n")
    }
  }, error = function(e) {
    cat("Error generating men's 2026 predictions:", e$message, "\n")
  })
} else {
  cat("No men's 2025 data available for 2026 predictions\n")
}

# Ladies 2026 Predictions
cat("\n--- Ladies 2026 Predictions ---\n")
ladies_pred_data <- NULL
if(nrow(ladies_2025) > 0) {
  tryCatch({
    # Validate features are available in 2025 data
    available_features_ladies <- intersect(final_features_ladies, names(ladies_2025))
    missing_features_ladies <- setdiff(final_features_ladies, names(ladies_2025))
    
    if (length(missing_features_ladies) > 0) {
      cat("Warning: Missing features in ladies 2025 data for prediction:", paste(missing_features_ladies, collapse = ", "), "\n")
    }
    
    if (length(available_features_ladies) > 0) {
      # Debug: Show exact GAM model input for Lara Colturi
      if ("Lara Colturi" %in% ladies_2025$Skier) {
        colturi_idx <- which(ladies_2025$Skier == "Lara Colturi")
        cat("\n=== DEBUG: Lara Colturi GAM Model Input ===\n")
        cat("Selected features for GAM:", paste(final_features_ladies, collapse = ", "), "\n")
        colturi_model_data <- ladies_2025[colturi_idx, c("Skier", final_features_ladies), drop = FALSE]
        print(colturi_model_data)
      }
      
      # Use only available features for prediction
      pred_2026_ladies <- predict(ladies_gam_model, newdata = ladies_2025, se.fit = TRUE)
      
      # Validate predictions
      if (any(!is.finite(pred_2026_ladies$fit))) {
        warning("Some ladies 2026 predictions are non-finite")
        pred_2026_ladies$fit[!is.finite(pred_2026_ladies$fit)] <- NA
      }
      
      ladies_pred_data <- ladies_2025 %>%
        mutate(
          Predicted_Pct_2026 = pred_2026_ladies$fit,
          Prediction_SE = pred_2026_ladies$se.fit,
          Lower_CI = Predicted_Pct_2026 - 1.96 * Prediction_SE,
          Upper_CI = Predicted_Pct_2026 + 1.96 * Prediction_SE
        ) %>%
        filter(!is.na(Predicted_Pct_2026)) %>%
        # Rename back to original column names for statistical-odds section
        rename(
          Pelo = Prev_Pelo,
          Downhill_Pelo = Prev_Downhill,
          `Super G_Pelo` = Prev_Super_G,
          `Giant Slalom_Pelo` = Prev_Giant_Slalom,
          Slalom_Pelo = Prev_Slalom,
          Combined_Pelo = Prev_Combined,
          Tech_Pelo = Prev_Tech,
          Speed_Pelo = Prev_Speed,
          Pct_of_Max_Points = Prev_Pct_of_Max_Points
        ) %>%
        arrange(desc(Predicted_Pct_2026))
      
      cat(sprintf("✓ Ladies 2026 predictions generated for %d athletes\n", nrow(ladies_pred_data)))
      cat(sprintf("Top predicted: %s (%.2f%% of max points)\n", 
                  ladies_pred_data$Skier[1], ladies_pred_data$Predicted_Pct_2026[1] * 100))
      
    } else {
      cat("No features available for ladies 2026 predictions\n")
    }
  }, error = function(e) {
    cat("Error generating ladies 2026 predictions:", e$message, "\n")
  })
} else {
  cat("No ladies 2025 data available for 2026 predictions\n")
}

# Export predictions to Excel
cat("\n=== EXPORTING PREDICTIONS TO EXCEL ===\n")

tryCatch({
  # Check initial prediction data status
  cat("DEBUG: Checking prediction data availability...\n")
  cat(sprintf("DEBUG: men_pred_data exists: %s\n", exists("men_pred_data")))
  cat(sprintf("DEBUG: ladies_pred_data exists: %s\n", exists("ladies_pred_data")))
  
  if (exists("men_pred_data")) {
    cat(sprintf("DEBUG: men_pred_data is null: %s\n", is.null(men_pred_data)))
    if (!is.null(men_pred_data)) {
      cat(sprintf("DEBUG: men_pred_data rows: %d\n", nrow(men_pred_data)))
      cat(sprintf("DEBUG: men_pred_data columns: %s\n", paste(names(men_pred_data), collapse = ", ")))
    }
  }
  
  if (exists("ladies_pred_data")) {
    cat(sprintf("DEBUG: ladies_pred_data is null: %s\n", is.null(ladies_pred_data)))
    if (!is.null(ladies_pred_data)) {
      cat(sprintf("DEBUG: ladies_pred_data rows: %d\n", nrow(ladies_pred_data)))
      cat(sprintf("DEBUG: ladies_pred_data columns: %s\n", paste(names(ladies_pred_data), collapse = ", ")))
    }
  }
  
  # Create excel365 directory if it doesn't exist
  cat("DEBUG: Creating excel365 directory...\n")
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  } else {
    cat("excel365 directory already exists\n")
  }
  
  # Initialize workbook variables
  men_worldcup <- NULL
  ladies_worldcup <- NULL
  
  # Prepare Men's World Cup Predictions
  cat("DEBUG: Processing men's predictions...\n")
  if (!is.null(men_pred_data) && nrow(men_pred_data) > 0) {
    cat("DEBUG: Men's data validation passed, processing...\n")
    
    tryCatch({
      cat("DEBUG: Starting men's data selection and transformation...\n")
      men_worldcup <- men_pred_data %>%
        dplyr::select(Skier, Nation, Predicted_Pct_2026, 
                      Pct_of_Max_Points, Pelo, Tech_Pelo, Speed_Pelo) %>%
        mutate(
          `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2),
          `2025 Pct of Max Points` = round(Pct_of_Max_Points * 100, 2),
          `Current Overall ELO` = round(Pelo, 0),
          `Current Tech ELO` = round(Tech_Pelo, 0),
          `Current Speed ELO` = round(Speed_Pelo, 0)
        ) %>%
        dplyr::select(Skier, Nation, `Predicted Percent 2026`, `2025 Pct of Max Points`,
                      `Current Overall ELO`, `Current Tech ELO`, `Current Speed ELO`) %>%
        arrange(desc(`Predicted Percent 2026`))
      
      cat(sprintf("DEBUG: Men's data transformation completed. Rows: %d\n", nrow(men_worldcup)))
      
      # Create Excel workbook for men
      cat("DEBUG: Creating men's Excel workbook...\n")
      men_wb <- createWorkbook()
      addWorksheet(men_wb, "Men_Predictions_2026")
      writeData(men_wb, "Men_Predictions_2026", men_worldcup, startRow = 1, startCol = 1)
      
      cat("DEBUG: Adding styles to men's workbook...\n")
      # Style headers
      addStyle(men_wb, "Men_Predictions_2026", 
               createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
               rows = 1, cols = 1:ncol(men_worldcup))
      setColWidths(men_wb, "Men_Predictions_2026", cols = 1:ncol(men_worldcup), widths = "auto")
      
      # Save men's workbook
      cat("DEBUG: Saving men's Excel file...\n")
      men_output_file <- "excel365/Men_WorldCup_Predictions_2026.xlsx"
      saveWorkbook(men_wb, men_output_file, overwrite = TRUE)
      
      cat(sprintf("✓ Men's Excel file saved: %s\n", men_output_file))
      cat(sprintf("Men's export: %d athletes, Top predicted: %s (%.2f%%)\n", 
                  nrow(men_worldcup), men_worldcup$Skier[1], men_worldcup$`Predicted Percent 2026`[1]))
                  
    }, error = function(e) {
      cat(sprintf("DEBUG ERROR in men's processing: %s\n", e$message))
      cat(sprintf("DEBUG ERROR traceback: %s\n", paste(traceback(), collapse = "\n")))
      stop(e)
    })
  } else {
    cat("DEBUG: Men's data not available or empty\n")
  }
  
  # Prepare Ladies World Cup Predictions  
  cat("DEBUG: Processing ladies predictions...\n")
  if (!is.null(ladies_pred_data) && nrow(ladies_pred_data) > 0) {
    cat("DEBUG: Ladies data validation passed, processing...\n")
    
    tryCatch({
      cat("DEBUG: Starting ladies data selection and transformation...\n")
      ladies_worldcup <- ladies_pred_data %>%
        dplyr::select(Skier, Nation, Predicted_Pct_2026,
                      Pct_of_Max_Points, Pelo, Tech_Pelo, Speed_Pelo) %>%
        mutate(
          `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2),
          `2025 Pct of Max Points` = round(Pct_of_Max_Points * 100, 2),
          `Current Overall ELO` = round(Pelo, 0),
          `Current Tech ELO` = round(Tech_Pelo, 0),
          `Current Speed ELO` = round(Speed_Pelo, 0)
        ) %>%
        dplyr::select(Skier, Nation, `Predicted Percent 2026`, `2025 Pct of Max Points`,
                      `Current Overall ELO`, `Current Tech ELO`, `Current Speed ELO`) %>%
        arrange(desc(`Predicted Percent 2026`))
      
      cat(sprintf("DEBUG: Ladies data transformation completed. Rows: %d\n", nrow(ladies_worldcup)))
      
      # Create Excel workbook for ladies
      cat("DEBUG: Creating ladies Excel workbook...\n")
      ladies_wb <- createWorkbook()
      addWorksheet(ladies_wb, "Ladies_Predictions_2026")
      writeData(ladies_wb, "Ladies_Predictions_2026", ladies_worldcup, startRow = 1, startCol = 1)
      
      cat("DEBUG: Adding styles to ladies workbook...\n")
      # Style headers
      addStyle(ladies_wb, "Ladies_Predictions_2026", 
               createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
               rows = 1, cols = 1:ncol(ladies_worldcup))
      setColWidths(ladies_wb, "Ladies_Predictions_2026", cols = 1:ncol(ladies_worldcup), widths = "auto")
      
      # Save ladies workbook
      cat("DEBUG: Saving ladies Excel file...\n")
      ladies_output_file <- "excel365/Ladies_WorldCup_Predictions_2026.xlsx"
      saveWorkbook(ladies_wb, ladies_output_file, overwrite = TRUE)
      
      cat(sprintf("✓ Ladies Excel file saved: %s\n", ladies_output_file))
      cat(sprintf("Ladies export: %d athletes, Top predicted: %s (%.2f%%)\n", 
                  nrow(ladies_worldcup), ladies_worldcup$Skier[1], ladies_worldcup$`Predicted Percent 2026`[1]))
                  
    }, error = function(e) {
      cat(sprintf("DEBUG ERROR in ladies processing: %s\n", e$message))
      cat(sprintf("DEBUG ERROR traceback: %s\n", paste(traceback(), collapse = "\n")))
      stop(e)
    })
  } else {
    cat("DEBUG: Ladies data not available or empty\n")
  }
  
  # Final validation
  cat("DEBUG: Final validation...\n")
  men_rows <- if(!is.null(men_worldcup)) nrow(men_worldcup) else 0
  ladies_rows <- if(!is.null(ladies_worldcup)) nrow(ladies_worldcup) else 0
  
  cat(sprintf("DEBUG: Final counts - Men: %d, Ladies: %d\n", men_rows, ladies_rows))
  
  if (men_rows == 0 && ladies_rows == 0) {
    cat("No prediction data available for Excel export\n")
  }
  
}, error = function(e) {
  cat("ERROR in Excel export main block:", e$message, "\n")
  cat("ERROR traceback:", paste(traceback(), collapse = "\n"), "\n")
  print(e)
})

cat("\n✓ 2026 season predictions completed\n")
```

### Odds Setup and Calculations

```{r odds-setup}
cat("=== ODDS SETUP & VALIDATION ===\n")

# Validate training data availability for odds calculations
cat("\n--- Training Data Validation for Odds ---\n")

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure previous sections completed successfully")
}

if (nrow(train_men) == 0) {
  stop("Men's training data is empty")
}
if (nrow(train_ladies) == 0) {
  stop("Ladies training data is empty") 
}

cat(sprintf("Training data for odds: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Validate required columns exist
required_odds_cols <- c("Pct_of_Max_Points", "Season")
missing_men_cols <- setdiff(required_odds_cols, names(train_men))
missing_ladies_cols <- setdiff(required_odds_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop(sprintf("Men's training data missing required columns for odds: %s", paste(missing_men_cols, collapse = ", ")))
}
if (length(missing_ladies_cols) > 0) {
  stop(sprintf("Ladies training data missing required columns for odds: %s", paste(missing_ladies_cols, collapse = ", ")))
}

# Add Place column based on rankings within each season with validation
cat("\n--- Season Ranking Calculation ---\n")

tryCatch({
  df_place <- train_men %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
  
  cat(sprintf("✓ Men's place rankings calculated: %d rows\n", nrow(df_place)))
}, error = function(e) {
  stop("Failed to calculate men's place rankings: ", e$message)
})

tryCatch({
  df_place_ladies <- train_ladies %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
    
  cat(sprintf("✓ Ladies place rankings calculated: %d rows\n", nrow(df_place_ladies)))
}, error = function(e) {
  stop("Failed to calculate ladies place rankings: ", e$message)
})

# Validate Place column creation
place_na_men <- sum(is.na(df_place$Place))
place_na_ladies <- sum(is.na(df_place_ladies$Place))

if (place_na_men > 0) {
  warning(sprintf("Men's Place column has %d NA values", place_na_men))
}
if (place_na_ladies > 0) {
  warning(sprintf("Ladies Place column has %d NA values", place_na_ladies))
}

# Validate ranking ranges
men_place_range <- range(df_place$Place, na.rm = TRUE)
ladies_place_range <- range(df_place_ladies$Place, na.rm = TRUE)

cat(sprintf("Men's Place range: %d - %d\n", men_place_range[1], men_place_range[2]))
cat(sprintf("Ladies Place range: %d - %d\n", ladies_place_range[1], ladies_place_range[2]))

# Debug and validate season rankings
cat("\n--- Season Ranking Validation ---\n")

# Check ladies data distribution
cat("Ladies Pct_of_Max_Points distribution:\n")
ladies_pct_summary <- summary(train_ladies$Pct_of_Max_Points)
print(ladies_pct_summary)

# Validate no negative or extreme values
if (any(train_ladies$Pct_of_Max_Points < 0, na.rm = TRUE)) {
  warning("Ladies data contains negative Pct_of_Max_Points values")
}
if (any(train_ladies$Pct_of_Max_Points > 2, na.rm = TRUE)) {
  warning("Ladies data contains very high Pct_of_Max_Points values (>200%)")
}

cat("Ladies Place distribution:\n")
ladies_place_table <- table(df_place_ladies$Place)
print(head(ladies_place_table, 10))

cat("Ladies seasons distribution:\n")
ladies_season_table <- table(df_place_ladies$Season)
print(ladies_season_table)

# Check for balanced season representation
if (any(ladies_season_table < 5)) {
  seasons_low_n <- names(ladies_season_table[ladies_season_table < 5])
  warning(sprintf("Ladies seasons with <5 observations: %s", paste(seasons_low_n, collapse = ", ")))
}

# Sample rankings validation
cat("Sample ladies season rankings (first 15):\n")
sample_rankings <- df_place_ladies %>% 
  arrange(Season, Place) %>% 
  dplyr::select(Season, Skier, Pct_of_Max_Points, Place) %>%
  head(15)
print(sample_rankings)

# Create categorical outcomes for different cutoffs with validation
cat("\n--- Categorical Outcome Creation ---\n")

tryCatch({
  df_place <- df_place %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Men's categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create men's categorical outcomes: ", e$message)
})

tryCatch({
  df_place_ladies <- df_place_ladies %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Ladies categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create ladies categorical outcomes: ", e$message)
})

# Validate categorical outcome creation
cat("\n--- Categorical Outcome Validation ---\n")

# Check TopThree creation for ladies
cat("Ladies Place vs TopThree validation:\n")
topthree_crosstab <- table(df_place_ladies$Place, df_place_ladies$TopThree, useNA = "always")
print(topthree_crosstab[1:min(10, nrow(topthree_crosstab)), ])

# Validate factor levels
expected_levels <- c("0", "1")
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")

for (target in targets) {
  men_levels <- levels(df_place[[target]])
  ladies_levels <- levels(df_place_ladies[[target]])
  
  if (!all(expected_levels %in% men_levels)) {
    warning(sprintf("Men's %s missing expected levels: %s", target, paste(setdiff(expected_levels, men_levels), collapse = ", ")))
  }
  if (!all(expected_levels %in% ladies_levels)) {
    warning(sprintf("Ladies %s missing expected levels: %s", target, paste(setdiff(expected_levels, ladies_levels), collapse = ", ")))
  }
  
  # Check for class imbalance
  men_table <- table(df_place[[target]])
  ladies_table <- table(df_place_ladies[[target]])
  
  men_minority_pct <- min(men_table) / sum(men_table) * 100
  ladies_minority_pct <- min(ladies_table) / sum(ladies_table) * 100
  
  cat(sprintf("%s class balance: Men %.1f%% minority, Ladies %.1f%% minority\n", 
              target, men_minority_pct, ladies_minority_pct))
  
  if (men_minority_pct < 5) {
    warning(sprintf("Men's %s has severe class imbalance (<5%% minority class)", target))
  }
  if (ladies_minority_pct < 5) {
    warning(sprintf("Ladies %s has severe class imbalance (<5%% minority class)", target))
  }
}

# Sample TopThree values
cat("First 20 ladies Place and TopThree values:\n")
sample_topthree <- df_place_ladies %>% 
  dplyr::select(Skier, Season, Place, TopThree) %>% 
  head(20)
print(sample_topthree)

# Prepare 2025 prediction data with validation
cat("\n--- 2025 Prediction Data Preparation ---\n")

# Validate prediction data exists
if (!exists("men_pred_data") || is.null(men_pred_data)) {
  warning("Men's 2026 prediction data not available from previous section")
  men_pred_data <- data.frame()
}
if (!exists("ladies_pred_data") || is.null(ladies_pred_data)) {
  warning("Ladies 2026 prediction data not available from previous section") 
  ladies_pred_data <- data.frame()
}

# Men's prediction data preparation
pred_data_men <- NULL
if (nrow(men_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (alpine-specific)
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Downhill_Pelo", "Super G_Pelo", 
                           "Giant Slalom_Pelo", "Slalom_Pelo", "Combined_Pelo", 
                           "Tech_Pelo", "Speed_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(men_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(men_pred_data))
    
    cat(sprintf("Men's prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing men's prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_men <- men_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (alpine-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Downhill" = "Downhill_Pelo", 
                     "Prev_Super_G" = "Super G_Pelo", "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
                     "Prev_Slalom" = "Slalom_Pelo", "Prev_Combined" = "Combined_Pelo", 
                     "Prev_Tech" = "Tech_Pelo", "Prev_Speed" = "Speed_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "Nation")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_men)) {
          names(pred_data_men)[names(pred_data_men) == rename_map[old_name]] <- old_name
        }
      }
      
      # Handle column names with spaces by converting to underscores
      if ("Super G_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Super G_Pelo"] <- "Prev_Super_G"
      }
      if ("Giant Slalom_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Giant Slalom_Pelo"] <- "Prev_Giant_Slalom"
      }
      
      cat(sprintf("✓ Men's prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_men), ncol(pred_data_men)))
    } else {
      warning("Insufficient columns for men's prediction data preparation")
      pred_data_men <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing men's prediction data:", e$message, "\n")
    pred_data_men <- data.frame()
  })
} else {
  cat("No men's prediction data available\n")
  pred_data_men <- data.frame()
}

# Ladies prediction data preparation  
pred_data_ladies <- NULL
if (nrow(ladies_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (alpine-specific)
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Downhill_Pelo", "Super G_Pelo", 
                           "Giant Slalom_Pelo", "Slalom_Pelo", "Combined_Pelo", 
                           "Tech_Pelo", "Speed_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(ladies_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(ladies_pred_data))
    
    cat(sprintf("Ladies prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing ladies prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_ladies <- ladies_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (alpine-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Downhill" = "Downhill_Pelo", 
                     "Prev_Super_G" = "Super G_Pelo", "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
                     "Prev_Slalom" = "Slalom_Pelo", "Prev_Combined" = "Combined_Pelo", 
                     "Prev_Tech" = "Tech_Pelo", "Prev_Speed" = "Speed_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "Nation")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_ladies)) {
          names(pred_data_ladies)[names(pred_data_ladies) == rename_map[old_name]] <- old_name
        }
      }
      
      # Handle column names with spaces by converting to underscores
      if ("Super G_Pelo" %in% names(pred_data_ladies)) {
        names(pred_data_ladies)[names(pred_data_ladies) == "Super G_Pelo"] <- "Prev_Super_G"
      }
      if ("Giant Slalom_Pelo" %in% names(pred_data_ladies)) {
        names(pred_data_ladies)[names(pred_data_ladies) == "Giant Slalom_Pelo"] <- "Prev_Giant_Slalom"
      }
      
      cat(sprintf("✓ Ladies prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_ladies), ncol(pred_data_ladies)))
    } else {
      warning("Insufficient columns for ladies prediction data preparation")
      pred_data_ladies <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing ladies prediction data:", e$message, "\n")
    pred_data_ladies <- data.frame()
  })
} else {
  cat("No ladies prediction data available\n")
  pred_data_ladies <- data.frame()
}

cat("\n✓ Odds setup and validation completed\n")
```

### Feature Selection for Odds Models

```{r non-ml-feat}
cat("=== FEATURE SELECTION FOR ODDS MODELS & VALIDATION ===\n")

# Load required libraries with validation
cat("\n--- Library Loading ---\n")
tryCatch({
  library(leaps)
  cat("✓ leaps library loaded\n")
}, error = function(e) {
  stop("Failed to load leaps library: ", e$message)
})

tryCatch({
  library(caret)
  cat("✓ caret library loaded\n")
}, error = function(e) {
  stop("Failed to load caret library: ", e$message)
})

# Validate input data availability
cat("\n--- Input Data Validation ---\n")

if (!exists("df_place") || !exists("df_place_ladies")) {
  stop("Training data with places not available - ensure odds-setup section completed successfully")
}

if (nrow(df_place) == 0) {
  stop("Men's training data with places is empty")
}
if (nrow(df_place_ladies) == 0) {
  stop("Ladies training data with places is empty")
}

cat(sprintf("Training data with outcomes: Men %d rows, Ladies %d rows\n", nrow(df_place), nrow(df_place_ladies)))

# Define and validate features for alpine odds models
cat("\n--- Alpine Feature Definition & Validation ---\n")

features <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
              "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")

# Check feature availability in training data
men_available_features <- intersect(features, names(df_place))
ladies_available_features <- intersect(features, names(df_place_ladies))

cat(sprintf("Men's available alpine features: %d/%d\n", length(men_available_features), length(features)))
cat(sprintf("Ladies available alpine features: %d/%d\n", length(ladies_available_features), length(features)))

men_missing_features <- setdiff(features, men_available_features)
ladies_missing_features <- setdiff(features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing alpine features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing alpine features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from ladies training data")
}

# Update feature lists to only include available features
features_men <- men_available_features
features_ladies <- ladies_available_features

if (length(features_men) < 3) {
  stop("Insufficient alpine features for men's odds modeling (need at least 3)")
}
if (length(features_ladies) < 3) {
  stop("Insufficient alpine features for ladies odds modeling (need at least 3)")
}

# Function to evaluate binary logistic model with validation
evaluate_glm <- function(feature_set, data, target, gender_label = "Unknown") {
  tryCatch({
    # Validate inputs
    if (length(feature_set) == 0) {
      return(Inf)
    }
    
    # Check if features exist in data
    missing_features <- setdiff(feature_set, names(data))
    if (length(missing_features) > 0) {
      return(Inf)
    }
    
    # Check if target exists and has variation
    if (!target %in% names(data)) {
      return(Inf)
    }
    
    target_table <- table(data[[target]])
    if (length(target_table) < 2 || any(target_table < 5)) {
      return(Inf)  # Skip if not enough levels or insufficient observations
    }
    
    # Build and evaluate model
    formula_str <- as.formula(paste(target, "~", paste(feature_set, collapse = " + ")))
    model <- glm(formula_str, family = binomial, data = data)
    
    # Validate model convergence
    if (!model$converged) {
      return(Inf)
    }
    
    aic_value <- AIC(model)
    
    # Validate AIC value
    if (!is.finite(aic_value)) {
      return(Inf)
    }
    
    return(aic_value)
  }, error = function(e) {
    return(Inf)
  })
}

# Exhaustive feature search function with validation
exhaustive_feature_search <- function(target, data_df, gender_label, available_features) {
  cat(sprintf("Searching %s alpine features for %s...\n", gender_label, target))
  
  # Validate inputs
  if (!target %in% names(data_df)) {
    cat(sprintf("Target %s not found in %s data\n", target, gender_label))
    return(list(features = character(0), aic = Inf))
  }
  
  if (length(available_features) < 2) {
    cat(sprintf("Insufficient alpine features for %s %s search\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  }
  
  best_aic <- Inf
  best_features <- NULL
  total_combinations <- 0
  successful_models <- 0
  
  # Search through feature combinations (2-5 features)
  max_features <- min(5, length(available_features))
  
  for(i in 2:max_features) {
    if (i > length(available_features)) break
    
    combinations <- combn(available_features, i, simplify = FALSE)
    total_combinations <- total_combinations + length(combinations)
    
    for(feature_set in combinations) {
      aic <- evaluate_glm(feature_set, data_df, target, gender_label)
      if(is.finite(aic)) {
        successful_models <- successful_models + 1
        if(aic < best_aic) {
          best_aic <- aic
          best_features <- feature_set
        }
      }
    }
  }
  
  cat(sprintf("  Tested %d combinations, %d successful models\n", total_combinations, successful_models))
  
  if (is.null(best_features)) {
    cat(sprintf("  No successful models found for %s %s\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  } else {
    cat(sprintf("  Best %s %s alpine features: %s (AIC: %.2f)\n", 
                gender_label, target, paste(best_features, collapse = ", "), best_aic))
  }
  
  return(list(features = best_features, aic = best_aic))
}

# Debug and validate data structure
cat("\n--- Data Structure Validation ---\n")

# Check target variable distributions
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")
for (target in targets) {
  if (target %in% names(df_place)) {
    men_table <- table(df_place[[target]])
    cat(sprintf("Men's %s distribution: %s\n", target, paste(names(men_table), men_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Men's %s target not found", target))
  }
  
  if (target %in% names(df_place_ladies)) {
    ladies_table <- table(df_place_ladies[[target]])
    cat(sprintf("Ladies %s distribution: %s\n", target, paste(names(ladies_table), ladies_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Ladies %s target not found", target))
  }
}

cat(sprintf("Men's data dimensions: %d rows × %d columns\n", nrow(df_place), ncol(df_place)))
cat(sprintf("Ladies data dimensions: %d rows × %d columns\n", nrow(df_place_ladies), ncol(df_place_ladies)))

# Validate sufficient data for modeling
min_obs_per_class <- 10
for (target in targets) {
  if (target %in% names(df_place)) {
    men_min_class <- min(table(df_place[[target]]))
    if (men_min_class < min_obs_per_class) {
      warning(sprintf("Men's %s has insufficient minority class observations (%d < %d)", 
                     target, men_min_class, min_obs_per_class))
    }
  }
  
  if (target %in% names(df_place_ladies)) {
    ladies_min_class <- min(table(df_place_ladies[[target]]))
    if (ladies_min_class < min_obs_per_class) {
      warning(sprintf("Ladies %s has insufficient minority class observations (%d < %d)", 
                     target, ladies_min_class, min_obs_per_class))
    }
  }
}

# Perform exhaustive feature search with validation
cat("\n=== EXHAUSTIVE ALPINE FEATURE SEARCH ===\n")

# Initialize result storage
best_features_odds_men <- list()
best_features_odds_ladies <- list()

# Men's alpine feature search
cat("\n--- Men's Alpine Feature Search ---\n")
for(target in targets) {
  if (target %in% names(df_place)) {
    result <- exhaustive_feature_search(target, df_place, "Men's", features_men)
    best_features_odds_men[[target]] <- result
  } else {
    cat(sprintf("Skipping men's %s - target not available\n", target))
    best_features_odds_men[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Ladies alpine feature search  
cat("\n--- Ladies Alpine Feature Search ---\n")
for(target in targets) {
  if (target %in% names(df_place_ladies)) {
    result <- exhaustive_feature_search(target, df_place_ladies, "Ladies", features_ladies)
    best_features_odds_ladies[[target]] <- result
  } else {
    cat(sprintf("Skipping ladies %s - target not available\n", target))
    best_features_odds_ladies[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Validate search results
cat("\n--- Alpine Feature Search Validation ---\n")

for(target in targets) {
  men_result <- best_features_odds_men[[target]]
  ladies_result <- best_features_odds_ladies[[target]]
  
  cat(sprintf("%s alpine results:\n", target))
  
  if (length(men_result$features) > 0) {
    cat(sprintf("  Men: %s (AIC: %.2f)\n", paste(men_result$features, collapse = ", "), men_result$aic))
  } else {
    cat("  Men: No successful alpine model found\n")
  }
  
  if (length(ladies_result$features) > 0) {
    cat(sprintf("  Ladies: %s (AIC: %.2f)\n", paste(ladies_result$features, collapse = ", "), ladies_result$aic))
  } else {
    cat("  Ladies: No successful alpine model found\n")
  }
}

# Check for any successful models
successful_men_targets <- sum(sapply(best_features_odds_men, function(x) length(x$features) > 0))
successful_ladies_targets <- sum(sapply(best_features_odds_ladies, function(x) length(x$features) > 0))

cat(sprintf("Successful alpine models: Men %d/%d targets, Ladies %d/%d targets\n", 
            successful_men_targets, length(targets), successful_ladies_targets, length(targets)))

if (successful_men_targets == 0) {
  warning("No successful men's alpine odds models found")
}
if (successful_ladies_targets == 0) {
  warning("No successful ladies alpine odds models found")
}

# Maintain backwards compatibility
best_features_odds <- best_features_odds_men

cat("\n✓ Alpine feature selection for odds models completed\n")

# Set unified prediction data for backwards compatibility  
if (nrow(pred_data_men) > 0) {
  pred_data <- pred_data_men
  cat("Using men's alpine prediction data as default for backwards compatibility\n")
} else if (nrow(pred_data_ladies) > 0) {
  pred_data <- pred_data_ladies
  cat("Using ladies alpine prediction data as fallback default\n")
} else {
  pred_data <- data.frame()
  warning("No alpine prediction data available for odds calculations")
}

# Final validation summary
cat("\n--- Final Alpine Prediction Data Summary ---\n")
if (exists("pred_data") && nrow(pred_data) > 0) {
  cat(sprintf("✓ Unified pred_data created: %d rows, %d columns\n", nrow(pred_data), ncol(pred_data)))
  cat("Available features:", paste(names(pred_data), collapse = ", "), "\n")
} else {
  warning("No unified prediction data available")
}
```

### Statistical Odds Models

```{r statistical-odds}
cat("=== STATISTICAL ODDS VALIDATION ===\n")

# Input validation for feature sets
if (!exists("best_features_odds_men") || !is.list(best_features_odds_men)) {
  stop("best_features_odds_men object not found or invalid")
}
if (!exists("best_features_odds_ladies") || !is.list(best_features_odds_ladies)) {
  stop("best_features_odds_ladies object not found or invalid")
}

# Required outcome categories
required_outcomes <- c("Win", "TopThree", "Top5", "Top10", "Top30")
missing_men <- setdiff(required_outcomes, names(best_features_odds_men))
missing_ladies <- setdiff(required_outcomes, names(best_features_odds_ladies))

if (length(missing_men) > 0) {
  stop("Missing outcome categories in men's features: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing outcome categories in ladies features: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required outcome categories present\n")

tryCatch({
  # Use best features from exhaustive search for men
  win_features_men <- best_features_odds_men[["Win"]]$features
  topthree_features_men <- best_features_odds_men[["TopThree"]]$features
  top5_features_men <- best_features_odds_men[["Top5"]]$features
  top10_features_men <- best_features_odds_men[["Top10"]]$features
  top30_features_men <- best_features_odds_men[["Top30"]]$features
  
  # Validate men's features
  if (length(win_features_men) == 0) stop("No features found for men's Win")
  if (length(topthree_features_men) == 0) stop("No features found for men's TopThree")
  if (length(top5_features_men) == 0) stop("No features found for men's Top5")
  if (length(top10_features_men) == 0) stop("No features found for men's Top10")
  if (length(top30_features_men) == 0) stop("No features found for men's Top30")
  
  cat("Men's feature counts - Win:", length(win_features_men), 
      "Top3:", length(topthree_features_men),
      "Top5:", length(top5_features_men), 
      "Top10:", length(top10_features_men), 
      "Top30:", length(top30_features_men), "\n")
  
}, error = function(e) {
  stop("Error extracting men's features: ", e$message)
})

tryCatch({
  # Use best features from exhaustive search for ladies
  win_features_ladies <- best_features_odds_ladies[["Win"]]$features
  topthree_features_ladies <- best_features_odds_ladies[["TopThree"]]$features
  top5_features_ladies <- best_features_odds_ladies[["Top5"]]$features
  top10_features_ladies <- best_features_odds_ladies[["Top10"]]$features
  top30_features_ladies <- best_features_odds_ladies[["Top30"]]$features
  
  # Validate ladies features
  if (length(win_features_ladies) == 0) stop("No features found for ladies Win")
  if (length(topthree_features_ladies) == 0) stop("No features found for ladies TopThree")
  if (length(top5_features_ladies) == 0) stop("No features found for ladies Top5")
  if (length(top10_features_ladies) == 0) stop("No features found for ladies Top10")
  if (length(top30_features_ladies) == 0) stop("No features found for ladies Top30")
  
  cat("Ladies feature counts - Win:", length(win_features_ladies), 
      "Top3:", length(topthree_features_ladies), 
      "Top5:", length(top5_features_ladies), 
      "Top10:", length(top10_features_ladies), 
      "Top30:", length(top30_features_ladies), "\n")
  
}, error = function(e) {
  stop("Error extracting ladies features: ", e$message)
})

# Create formulas with validation
cat("\n--- Formula Creation ---\n")
tryCatch({
  # Create formulas for men's models
  win_formula_men <- as.formula(paste("Win ~", paste(win_features_men, collapse = " + ")))
  topthree_formula_men <- as.formula(paste("TopThree ~", paste(topthree_features_men, collapse = " + ")))
  top5_formula_men <- as.formula(paste("Top5 ~", paste(top5_features_men, collapse = " + ")))
  top10_formula_men <- as.formula(paste("Top10 ~", paste(top10_features_men, collapse = " + ")))
  top30_formula_men <- as.formula(paste("Top30 ~", paste(top30_features_men, collapse = " + ")))
  
  # Validate formula creation
  if (!inherits(win_formula_men, "formula")) stop("Failed to create Win formula for men")
  if (!inherits(topthree_formula_men, "formula")) stop("Failed to create TopThree formula for men")
  if (!inherits(top5_formula_men, "formula")) stop("Failed to create Top5 formula for men")
  if (!inherits(top10_formula_men, "formula")) stop("Failed to create Top10 formula for men")
  if (!inherits(top30_formula_men, "formula")) stop("Failed to create Top30 formula for men")
  
  cat("✓ Men's formulas created successfully\n")
  
}, error = function(e) {
  stop("Error creating men's formulas: ", e$message)
})

tryCatch({
  # Create formulas for ladies models
  win_formula_ladies <- as.formula(paste("Win ~", paste(win_features_ladies, collapse = " + ")))
  topthree_formula_ladies <- as.formula(paste("TopThree ~", paste(topthree_features_ladies, collapse = " + ")))
  top5_formula_ladies <- as.formula(paste("Top5 ~", paste(top5_features_ladies, collapse = " + ")))
  top10_formula_ladies <- as.formula(paste("Top10 ~", paste(top10_features_ladies, collapse = " + ")))
  top30_formula_ladies <- as.formula(paste("Top30 ~", paste(top30_features_ladies, collapse = " + ")))
  
  # Validate formula creation
  if (!inherits(win_formula_ladies, "formula")) stop("Failed to create Win formula for ladies")
  if (!inherits(topthree_formula_ladies, "formula")) stop("Failed to create TopThree formula for ladies")
  if (!inherits(top5_formula_ladies, "formula")) stop("Failed to create Top5 formula for ladies")
  if (!inherits(top10_formula_ladies, "formula")) stop("Failed to create Top10 formula for ladies")
  if (!inherits(top30_formula_ladies, "formula")) stop("Failed to create Top30 formula for ladies")
  
  cat("✓ Ladies formulas created successfully\n")
  
}, error = function(e) {
  stop("Error creating ladies formulas: ", e$message)
})

print("=== MEN'S OPTIMIZED ALPINE MODEL FORMULAS ===")
print(win_formula_men)
print(topthree_formula_men)
print(top5_formula_men)
print(top10_formula_men)
print(top30_formula_men)

print("=== LADIES OPTIMIZED ALPINE MODEL FORMULAS ===")
print(win_formula_ladies)
print(topthree_formula_ladies)
print(top5_formula_ladies)
print(top10_formula_ladies)
print(top30_formula_ladies)

# Maintain backwards compatibility - use men's formulas for unified model training
win_features <- win_features_men
topthree_features <- topthree_features_men
top5_features <- top5_features_men
top10_features <- top10_features_men
top30_features <- top30_features_men
win_formula <- win_formula_men
topthree_formula <- topthree_formula_men
top5_formula <- top5_formula_men
top10_formula <- top10_formula_men
top30_formula <- top30_formula_men

# Validate data availability for modeling
cat("\n--- Model Training Data Validation ---\n")
if (!exists("df_place") || !is.data.frame(df_place)) {
  stop("df_place dataset not found or invalid")
}
if (nrow(df_place) == 0) {
  stop("df_place dataset is empty")
}

# Check for required target variables
required_targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")
missing_targets <- setdiff(required_targets, names(df_place))
if (length(missing_targets) > 0) {
  stop("Missing target variables in df_place: ", paste(missing_targets, collapse = ", "))
}

# Validate target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place[[target]], useNA = "always")
  cat("Target", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for target ", target, " - model may be unstable")
  }
}

# Fit models with optimal feature sets and validation
cat("\n--- Model Training ---\n")
tryCatch({
  win_model <- glm(win_formula, family = binomial, data = df_place)
  
  # Validate model convergence
  if (!win_model$converged) {
    warning("Win model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(win_model)))) {
    warning("Win model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Win model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Win model: ", e$message)
})

tryCatch({
  topthree_model <- glm(topthree_formula, family = binomial, data = df_place)
  
  # Validate model convergence
  if (!topthree_model$converged) {
    warning("TopThree model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(topthree_model)))) {
    warning("TopThree model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ TopThree model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting TopThree model: ", e$message)
})

tryCatch({
  top5_model <- glm(top5_formula, family = binomial, data = df_place)
  
  if (!top5_model$converged) warning("Top5 model did not converge")
  if (any(is.na(coef(top5_model)))) warning("Top5 model has NA coefficients")
  cat("✓ Top5 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top5 model: ", e$message)
})

tryCatch({
  top10_model <- glm(top10_formula, family = binomial, data = df_place)
  
  if (!top10_model$converged) warning("Top10 model did not converge")
  if (any(is.na(coef(top10_model)))) warning("Top10 model has NA coefficients")
  cat("✓ Top10 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top10 model: ", e$message)
})

tryCatch({
  top30_model <- glm(top30_formula, family = binomial, data = df_place)
  
  if (!top30_model$converged) warning("Top30 model did not converge")
  if (any(is.na(coef(top30_model)))) warning("Top30 model has NA coefficients")
  cat("✓ Top30 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top30 model: ", e$message)
})

# Model diagnostics
cat("\n--- Model Diagnostics ---\n")
models <- list(
  Win = win_model,
  TopThree = topthree_model,
  Top5 = top5_model,
  Top10 = top10_model,
  Top30 = top30_model
)

for (model_name in names(models)) {
  model <- models[[model_name]]
  cat(sprintf("\n%s Model Summary:\n", model_name))
  
  # AIC
  cat(sprintf("  AIC: %.2f\n", AIC(model)))
  
  # Deviance
  cat(sprintf("  Residual Deviance: %.2f\n", deviance(model)))
  
  # Pseudo R-squared (McFadden)
  null_deviance <- model$null.deviance
  residual_deviance <- model$deviance
  pseudo_r2 <- 1 - (residual_deviance / null_deviance)
  cat(sprintf("  Pseudo R²: %.3f\n", pseudo_r2))
  
  # Check for perfect separation issues
  fitted_probs <- fitted(model)
  if (any(fitted_probs == 0) || any(fitted_probs == 1)) {
    warning(sprintf("%s model may have perfect separation issues", model_name))
  }
}

# ========== 2026 PREDICTIONS ==========
cat("\n=== GENERATING 2026 ALPINE PREDICTIONS ===\n")

# Validate prediction dataset
if (!exists("pred_data") || !is.data.frame(pred_data)) {
  stop("pred_data dataset not found or invalid")
}
if (nrow(pred_data) == 0) {
  stop("pred_data dataset is empty")
}

cat("Prediction data contains", nrow(pred_data), "alpine skiers\n")

# Debug: Show statistical-odds input data for key athletes
if ("Marcel Hirscher" %in% pred_data$Skier) {
  hirscher_idx <- which(pred_data$Skier == "Marcel Hirscher")
  cat("\n=== DEBUG: Marcel Hirscher Statistical-Odds Input ===\n")
  print(pred_data[hirscher_idx, ])
}

# Generate predictions with comprehensive validation
tryCatch({
  win_probs <- predict(win_model, pred_data, type = "response")
  
  # Validate Win predictions
  if (any(is.na(win_probs))) {
    warning("NA predictions detected for Win - ", sum(is.na(win_probs)), " out of ", length(win_probs))
  }
  if (any(win_probs < 0 | win_probs > 1, na.rm = TRUE)) {
    warning("Invalid probability values for Win (outside 0-1 range)")
  }
  
  cat("✓ Win predictions generated - Range: [", round(min(win_probs, na.rm = TRUE), 4), ", ", 
      round(max(win_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Win predictions: ", e$message)
})

tryCatch({
  top3_probs <- predict(topthree_model, pred_data, type = "response")
  
  # Validate TopThree predictions
  if (any(is.na(top3_probs))) {
    warning("NA predictions detected for TopThree - ", sum(is.na(top3_probs)), " out of ", length(top3_probs))
  }
  if (any(top3_probs < 0 | top3_probs > 1, na.rm = TRUE)) {
    warning("Invalid probability values for TopThree (outside 0-1 range)")
  }
  
  cat("✓ TopThree predictions generated - Range: [", round(min(top3_probs, na.rm = TRUE), 4), ", ", 
      round(max(top3_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating TopThree predictions: ", e$message)
})

tryCatch({
  top5_probs <- predict(top5_model, pred_data, type = "response")
  
  if (any(is.na(top5_probs))) warning("NA predictions for Top5")
  if (any(top5_probs < 0 | top5_probs > 1, na.rm = TRUE)) warning("Invalid Top5 probabilities")
  
  cat("✓ Top5 predictions generated - Range: [", round(min(top5_probs, na.rm = TRUE), 4), ", ", 
      round(max(top5_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top5 predictions: ", e$message)
})

tryCatch({
  top10_probs <- predict(top10_model, pred_data, type = "response")
  
  if (any(is.na(top10_probs))) warning("NA predictions for Top10")
  if (any(top10_probs < 0 | top10_probs > 1, na.rm = TRUE)) warning("Invalid Top10 probabilities")
  
  cat("✓ Top10 predictions generated - Range: [", round(min(top10_probs, na.rm = TRUE), 4), ", ", 
      round(max(top10_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top10 predictions: ", e$message)
})

tryCatch({
  top30_probs <- predict(top30_model, pred_data, type = "response")
  
  if (any(is.na(top30_probs))) warning("NA predictions for Top30")
  if (any(top30_probs < 0 | top30_probs > 1, na.rm = TRUE)) warning("Invalid Top30 probabilities")
  
  cat("✓ Top30 predictions generated - Range: [", round(min(top30_probs, na.rm = TRUE), 4), ", ", 
      round(max(top30_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top30 predictions: ", e$message)
})

# ========== NORMALIZATION FOR MEN'S ALPINE ODDS ==========
cat("\n--- Normalizing Alpine Probabilities ---\n")

# Function for simple proportional scaling to cap maximum probability
simple_scale <- function(probs, max_prob = 0.95) {
  # Handle edge cases
  if (length(probs) == 0) return(probs)
  if (all(is.na(probs))) return(probs)
  
  max_current <- max(probs, na.rm = TRUE)
  if (max_current <= max_prob) return(probs)
  
  # Scale all probabilities proportionally so max becomes max_prob
  scaling_factor <- max_prob / max_current
  return(probs * scaling_factor)
}

# Function for proportional scaling with simple maximum compression
proportional_scale <- function(probs, target_sum, max_prob = 0.95) {
  # Handle edge cases
  if (length(probs) == 0) return(probs)
  if (sum(probs, na.rm = TRUE) == 0) return(probs)
  
  # First apply proportional scaling to achieve target sum
  scaled_probs <- (probs / sum(probs, na.rm = TRUE)) * target_sum
  
  # Then apply simple scaling to cap maximum at max_prob
  final_probs <- simple_scale(scaled_probs, max_prob)
  
  return(final_probs)
}

# Normalize probabilities with proportional scaling and simple maximum compression
# Win probabilities should sum to 100% (1.0), max individual 95%
win_probs_normalized <- proportional_scale(win_probs, 1.0, 0.95)

# Top3 probabilities should sum to 300% (3.0), max individual 95%
top3_probs_normalized <- proportional_scale(top3_probs, 3.0, 0.95)

# Top5 probabilities should sum to 500% (5.0), max individual 95%  
top5_probs_normalized <- proportional_scale(top5_probs, 5.0, 0.95)

# Top10 probabilities should sum to 1000% (10.0), max individual 95%
top10_probs_normalized <- proportional_scale(top10_probs, 10.0, 0.95)

# Top30 probabilities should sum to 3000% (30.0), max individual 95%
top30_probs_normalized <- proportional_scale(top30_probs, 30.0, 0.95)

cat("Alpine normalization applied:\n")
cat("Win probs sum:", round(sum(win_probs_normalized, na.rm = TRUE), 3), "(target: 1.0)\n")
cat("Top3 probs sum:", round(sum(top3_probs_normalized, na.rm = TRUE), 3), "(target: 3.0)\n")
cat("Top5 probs sum:", round(sum(top5_probs_normalized, na.rm = TRUE), 3), "(target: 5.0)\n")
cat("Top10 probs sum:", round(sum(top10_probs_normalized, na.rm = TRUE), 3), "(target: 10.0)\n")
cat("Top30 probs sum:", round(sum(top30_probs_normalized, na.rm = TRUE), 3), "(target: 30.0)\n")

# Create results dataframe with validation
cat("\n--- Alpine Results DataFrame Creation ---\n")

# Validate required columns in pred_data
required_id_cols <- c("Skier", "Nation")
missing_id_cols <- setdiff(required_id_cols, names(pred_data))
if (length(missing_id_cols) > 0) {
  stop("Missing identification columns in pred_data: ", paste(missing_id_cols, collapse = ", "))
}

tryCatch({
  # Create results dataframe with all probabilities (USING NORMALIZED VALUES)
  results <- data.frame(
    Skier = pred_data$Skier,
    Nation = pred_data$Nation,
    Top3_Prob = top3_probs_normalized,  # Normalized Top3 probability
    Win_Prob = win_probs_normalized,    # Normalized win probability
    Second_Prob = win_probs_normalized, # Normalized (same as win for approximation)
    Third_Prob = win_probs_normalized,  # Normalized (same as win for approximation)
    Top5_Prob = top5_probs_normalized,  # Normalized Top5 probability
    Top10_Prob = top10_probs_normalized, # Normalized Top10 probability
    Top30_Prob = top30_probs_normalized, # Normalized Top30 probability
    Outside_Prob = 1 - (top30_probs_normalized / 30.0)  # Adjusted for normalization
  )
  
  # Validate results dataframe
  if (nrow(results) == 0) stop("Results dataframe is empty")
  if (any(is.na(results$Skier))) warning("Missing skier names in results")
  
  # Check probability consistency
  invalid_prob_consistency <- sum(results$Top3_Prob > results$Top5_Prob | 
                                  results$Top5_Prob > results$Top10_Prob | 
                                  results$Top10_Prob > results$Top30_Prob, na.rm = TRUE)
  
  if (invalid_prob_consistency > 0) {
    warning("Probability inconsistency detected in ", invalid_prob_consistency, " cases (P(smaller) > P(larger))")
  }
  
  cat("✓ Alpine results dataframe created with", nrow(results), "skiers\n")
  cat("Probability ranges - Top3: [", round(min(results$Top3_Prob, na.rm = TRUE), 4), ", ", 
      round(max(results$Top3_Prob, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error creating results dataframe: ", e$message)
})

# Calculate decimal and American odds with validation
cat("\n--- Alpine Odds Calculation ---\n")
tryCatch({
  results <- results %>%
    mutate(
      Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
      Win_American_Odds = ifelse(Win_Prob >= 0.5,
                                -Win_Prob/(1-Win_Prob) * 100,
                                (1-Win_Prob)/Win_Prob * 100),
      Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
      Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                                 -Top3_Prob/(1-Top3_Prob) * 100,
                                 (1-Top3_Prob)/Top3_Prob * 100),
      Top5_Decimal_Odds = ifelse(Top5_Prob > 0, 1 / Top5_Prob, Inf),
      Top5_American_Odds = ifelse(Top5_Prob >= 0.5,
                                 -Top5_Prob/(1-Top5_Prob) * 100,
                                 (1-Top5_Prob)/Top5_Prob * 100),
      Top10_Decimal_Odds = ifelse(Top10_Prob > 0, 1 / Top10_Prob, Inf),
      Top10_American_Odds = ifelse(Top10_Prob >= 0.5,
                                  -Top10_Prob/(1-Top10_Prob) * 100,
                                  (1-Top10_Prob)/Top10_Prob * 100),
      Top30_Decimal_Odds = ifelse(Top30_Prob > 0, 1 / Top30_Prob, Inf),
      Top30_American_Odds = ifelse(Top30_Prob >= 0.5,
                                  -Top30_Prob/(1-Top30_Prob) * 100,
                                  (1-Top30_Prob)/Top30_Prob * 100)
    ) %>%
    # Format probabilities and odds with validation
    mutate(
      Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
      Second_Prob = ifelse(is.na(Second_Prob), "N/A", sprintf("%.1f%%", Second_Prob * 100)),
      Third_Prob = ifelse(is.na(Third_Prob), "N/A", sprintf("%.1f%%", Third_Prob * 100)),
      Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
      Top5_Prob = ifelse(is.na(Top5_Prob), "N/A", sprintf("%.1f%%", Top5_Prob * 100)),
      Top10_Prob = ifelse(is.na(Top10_Prob), "N/A", sprintf("%.1f%%", Top10_Prob * 100)),
      Top30_Prob = ifelse(is.na(Top30_Prob), "N/A", sprintf("%.1f%%", Top30_Prob * 100)),
      Outside_Prob = ifelse(is.na(Outside_Prob), "N/A", sprintf("%.1f%%", Outside_Prob * 100)),
      
      # Round decimal odds with Inf handling
      Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                               ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
      Top3_Decimal_Odds = ifelse(is.infinite(Top3_Decimal_Odds), 999.99, 
                                ifelse(Top3_Decimal_Odds > 999.99, 999.99, round(Top3_Decimal_Odds, 2))),
      Top5_Decimal_Odds = ifelse(is.infinite(Top5_Decimal_Odds), 999.99, 
                                ifelse(Top5_Decimal_Odds > 999.99, 999.99, round(Top5_Decimal_Odds, 2))),
      Top10_Decimal_Odds = ifelse(is.infinite(Top10_Decimal_Odds), 999.99, 
                                 ifelse(Top10_Decimal_Odds > 999.99, 999.99, round(Top10_Decimal_Odds, 2))),
      Top30_Decimal_Odds = ifelse(is.infinite(Top30_Decimal_Odds), 999.99, 
                                 ifelse(Top30_Decimal_Odds > 999.99, 999.99, round(Top30_Decimal_Odds, 2))),
      
      # Format American odds with validation
      Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                                ifelse(Win_American_Odds > 0, 
                                      sprintf("+%.0f", round(Win_American_Odds, 0)),
                                      sprintf("%.0f", round(Win_American_Odds, 0)))),
      Top3_American_Odds = ifelse(is.na(Top3_American_Odds) | is.infinite(Top3_American_Odds), "N/A",
                                 ifelse(Top3_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top3_American_Odds, 0)),
                                       sprintf("%.0f", round(Top3_American_Odds, 0)))),
      Top5_American_Odds = ifelse(is.na(Top5_American_Odds) | is.infinite(Top5_American_Odds), "N/A",
                                 ifelse(Top5_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top5_American_Odds, 0)),
                                       sprintf("%.0f", round(Top5_American_Odds, 0)))),
      Top10_American_Odds = ifelse(is.na(Top10_American_Odds) | is.infinite(Top10_American_Odds), "N/A",
                                  ifelse(Top10_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top10_American_Odds, 0)),
                                        sprintf("%.0f", round(Top10_American_Odds, 0)))),
      Top30_American_Odds = ifelse(is.na(Top30_American_Odds) | is.infinite(Top30_American_Odds), "N/A",
                                  ifelse(Top30_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top30_American_Odds, 0)),
                                        sprintf("%.0f", round(Top30_American_Odds, 0))))
    )
  
  # Validate sorting and arrange results
  numeric_win_probs <- as.numeric(sub("%", "", results$Win_Prob))
  if (any(is.na(numeric_win_probs))) {
    warning("Some Win_Prob values could not be converted to numeric for sorting")
  }
  
  results <- results %>% arrange(desc(numeric_win_probs))
  
  cat("✓ Alpine odds calculation and formatting completed\n")
  
}, error = function(e) {
  stop("Error calculating alpine odds: ", e$message)
})

cat("\n--- Alpine Final Results Summary ---\n")
cat("Total alpine skiers with odds:", nrow(results), "\n")
cat("Skiers with valid Win probabilities:", sum(results$Win_Prob != "N/A"), "\n")
cat("Highest win probability:", max(numeric_win_probs, na.rm = TRUE), "%\n")

print("=== 2026 MEN'S ALPINE SEASON ODDS ===")
print("Top 10 Men's Alpine Season Winner Odds:")
print(results %>% 
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      head(10))

print("Top 10 Men's Alpine Podium Finish Odds:")
print(results %>% 
      arrange(desc(as.numeric(sub("%", "", Top3_Prob)))) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      head(10))

print("Top 10 Men's Alpine Top-10 Finish Odds:")
print(results %>% 
      arrange(desc(as.numeric(sub("%", "", Top10_Prob)))) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      head(10))

# Store men's results with validation
tryCatch({
  results_men <- results
  
  # Final validation
  if (nrow(results_men) == 0) stop("No results to store")
  if (all(results_men$Win_Prob == "N/A")) warning("All win probabilities are N/A")
  
  cat("✓ Men's alpine results stored successfully with", nrow(results_men), "skiers\n")
  
}, error = function(e) {
  stop("Error storing men's alpine results: ", e$message)
})

# Export Men's Alpine Odds to Excel
cat("\n=== EXPORTING MEN'S ALPINE ODDS TO EXCEL ===\n")

tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  if (!is.null(results_men) && nrow(results_men) > 0) {
    # Prepare data with numeric probabilities for proper sorting
    men_odds_export <- results_men %>%
      mutate(
        # Convert probability percentages to numeric for proper handling
        Win_Prob_Numeric = as.numeric(gsub("%", "", Win_Prob)),
        Top3_Prob_Numeric = as.numeric(gsub("%", "", Top3_Prob)),
        Top10_Prob_Numeric = as.numeric(gsub("%", "", Top10_Prob)),
        Top30_Prob_Numeric = as.numeric(gsub("%", "", Top30_Prob)),
        # Convert decimal odds to numeric for proper handling
        Win_Decimal_Numeric = as.numeric(Win_Decimal_Odds),
        Top3_Decimal_Numeric = as.numeric(Top3_Decimal_Odds),
        Top10_Decimal_Numeric = as.numeric(Top10_Decimal_Odds),
        Top30_Decimal_Numeric = as.numeric(Top30_Decimal_Odds)
      ) %>%
      # Create separate tables for each outcome
      arrange(desc(Win_Prob_Numeric))
    
    # Create separate Excel files for each outcome type
    
    # Win odds file
    win_data <- men_odds_export %>%
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(
        "Win Prob" = Win_Prob,
        "Win Decimal Odds" = Win_Decimal_Odds,
        "Win American Odds" = Win_American_Odds
      )
    
    win_wb <- createWorkbook()
    addWorksheet(win_wb, "Men Alpine Win Odds 2026")
    writeData(win_wb, "Men Alpine Win Odds 2026", win_data, startRow = 1, startCol = 1)
    addStyle(win_wb, "Men Alpine Win Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(win_data))
    setColWidths(win_wb, "Men Alpine Win Odds 2026", cols = 1:ncol(win_data), widths = "auto")
    saveWorkbook(win_wb, "excel365/Men_Win_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 3 odds file
    top3_data <- men_odds_export %>%
      arrange(desc(Top3_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(
        "Top 3 Prob" = Top3_Prob,
        "Top 3 Decimal Odds" = Top3_Decimal_Odds,
        "Top 3 American Odds" = Top3_American_Odds
      )
    
    top3_wb <- createWorkbook()
    addWorksheet(top3_wb, "Men Alpine Top 3 Odds 2026")
    writeData(top3_wb, "Men Alpine Top 3 Odds 2026", top3_data, startRow = 1, startCol = 1)
    addStyle(top3_wb, "Men Alpine Top 3 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top3_data))
    setColWidths(top3_wb, "Men Alpine Top 3 Odds 2026", cols = 1:ncol(top3_data), widths = "auto")
    saveWorkbook(top3_wb, "excel365/Men_Top3_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 10 odds file
    top10_data <- men_odds_export %>%
      arrange(desc(Top10_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(
        "Top 10 Prob" = Top10_Prob,
        "Top 10 Decimal Odds" = Top10_Decimal_Odds,
        "Top 10 American Odds" = Top10_American_Odds
      )
    
    top10_wb <- createWorkbook()
    addWorksheet(top10_wb, "Men Alpine Top 10 Odds 2026")
    writeData(top10_wb, "Men Alpine Top 10 Odds 2026", top10_data, startRow = 1, startCol = 1)
    addStyle(top10_wb, "Men Alpine Top 10 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top10_data))
    setColWidths(top10_wb, "Men Alpine Top 10 Odds 2026", cols = 1:ncol(top10_data), widths = "auto")
    saveWorkbook(top10_wb, "excel365/Men_Top10_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 30 odds file
    top30_data <- men_odds_export %>%
      arrange(desc(Top30_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top30_Prob, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(
        "Top 30 Prob" = Top30_Prob,
        "Top 30 Decimal Odds" = Top30_Decimal_Odds,
        "Top 30 American Odds" = Top30_American_Odds
      )
    
    top30_wb <- createWorkbook()
    addWorksheet(top30_wb, "Men Alpine Top 30 Odds 2026")
    writeData(top30_wb, "Men Alpine Top 30 Odds 2026", top30_data, startRow = 1, startCol = 1)
    addStyle(top30_wb, "Men Alpine Top 30 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top30_data))
    setColWidths(top30_wb, "Men Alpine Top 30 Odds 2026", cols = 1:ncol(top30_data), widths = "auto")
    saveWorkbook(top30_wb, "excel365/Men_Top30_Odds_2026.xlsx", overwrite = TRUE)
    
    cat("✓ Men's alpine odds Excel files saved:\n")
    cat("  - excel365/Men_Win_Odds_2026.xlsx\n")
    cat("  - excel365/Men_Top3_Odds_2026.xlsx\n") 
    cat("  - excel365/Men_Top10_Odds_2026.xlsx\n")
    cat("  - excel365/Men_Top30_Odds_2026.xlsx\n")
    cat(sprintf("Men's alpine odds export: %d athletes across 4 separate files\n", nrow(men_odds_export)))
    
  } else {
    cat("No men's alpine odds data available for export\n")
  }
  
}, error = function(e) {
  cat("Error exporting men's alpine odds to Excel:", e$message, "\n")
})
```

### Ladies Season Odds

```{r ladies-odds}
cat("=== LADIES ODDS VALIDATION ===\n")

# Validate ladies-specific formulas exist
if (!exists("win_formula_ladies") || !inherits(win_formula_ladies, "formula")) {
  stop("win_formula_ladies not found or invalid")
}
if (!exists("topthree_formula_ladies") || !inherits(topthree_formula_ladies, "formula")) {
  stop("topthree_formula_ladies not found or invalid")
}
if (!exists("top5_formula_ladies") || !inherits(top5_formula_ladies, "formula")) {
  stop("top5_formula_ladies not found or invalid")
}
if (!exists("top10_formula_ladies") || !inherits(top10_formula_ladies, "formula")) {
  stop("top10_formula_ladies not found or invalid")
}
if (!exists("top30_formula_ladies") || !inherits(top30_formula_ladies, "formula")) {
  stop("top30_formula_ladies not found or invalid")
}
cat("✓ All ladies formulas validated\n")

# Validate ladies training data
cat("\n--- Ladies Model Training Data Validation ---\n")
if (!exists("df_place_ladies") || !is.data.frame(df_place_ladies)) {
  stop("df_place_ladies dataset not found or invalid")
}
if (nrow(df_place_ladies) == 0) {
  stop("df_place_ladies dataset is empty")
}

# Check for required target variables in ladies data
required_targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")
missing_targets <- setdiff(required_targets, names(df_place_ladies))
if (length(missing_targets) > 0) {
  stop("Missing target variables in df_place_ladies: ", paste(missing_targets, collapse = ", "))
}

# Validate ladies target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place_ladies[[target]], useNA = "always")
  cat("Ladies", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for ladies ", target, " - model may be unstable")
  }
}

cat("Ladies training data:", nrow(df_place_ladies), "observations\n")

# Fit ladies models with validation
cat("\n--- Ladies Model Training ---\n")
tryCatch({
  win_model_ladies <- glm(win_formula_ladies, family = binomial, data = df_place_ladies)
  
  # Validate model convergence
  if (!win_model_ladies$converged) {
    warning("Ladies Win model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(win_model_ladies)))) {
    warning("Ladies Win model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Ladies Win model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Win model: ", e$message)
})

tryCatch({
  topthree_model_ladies <- glm(topthree_formula_ladies, family = binomial, data = df_place_ladies)
  
  # Validate model convergence
  if (!topthree_model_ladies$converged) {
    warning("Ladies TopThree model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(topthree_model_ladies)))) {
    warning("Ladies TopThree model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Ladies TopThree model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies TopThree model: ", e$message)
})

tryCatch({
  top5_model_ladies <- glm(top5_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top5_model_ladies$converged) warning("Ladies Top5 model did not converge")
  if (any(is.na(coef(top5_model_ladies)))) warning("Ladies Top5 model has NA coefficients")
  cat("✓ Ladies Top5 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top5 model: ", e$message)
})

tryCatch({
  top10_model_ladies <- glm(top10_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top10_model_ladies$converged) warning("Ladies Top10 model did not converge")
  if (any(is.na(coef(top10_model_ladies)))) warning("Ladies Top10 model has NA coefficients")
  cat("✓ Ladies Top10 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top10 model: ", e$message)
})

tryCatch({
  top30_model_ladies <- glm(top30_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top30_model_ladies$converged) warning("Ladies Top30 model did not converge")
  if (any(is.na(coef(top30_model_ladies)))) warning("Ladies Top30 model has NA coefficients")
  cat("✓ Ladies Top30 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top30 model: ", e$message)
})

# Validate ladies prediction data
cat("\n--- Ladies Prediction Data Validation ---\n")
if (!exists("pred_data_ladies") || !is.data.frame(pred_data_ladies)) {
  stop("pred_data_ladies dataset not found or invalid")
}
if (nrow(pred_data_ladies) == 0) {
  stop("pred_data_ladies dataset is empty")
}

# Check for required features in ladies prediction data
all_required_features <- unique(c(topthree_features_ladies, top5_features_ladies, top10_features_ladies, top30_features_ladies))
missing_pred_features <- setdiff(all_required_features, names(pred_data_ladies))
if (length(missing_pred_features) > 0) {
  warning("Missing features in ladies prediction data: ", paste(missing_pred_features, collapse = ", "))
}

cat("Ladies prediction dataset has", nrow(pred_data_ladies), "observations and", ncol(pred_data_ladies), "variables\n")

# Debug: Show ladies statistical-odds input data for key athletes
if ("Lara Colturi" %in% pred_data_ladies$Skier) {
  colturi_idx <- which(pred_data_ladies$Skier == "Lara Colturi")
  cat("\n=== DEBUG: Lara Colturi Ladies Statistical-Odds Input ===\n")
  print(pred_data_ladies[colturi_idx, ])
}

# Get predicted probabilities for ladies with validation
cat("\n--- Ladies Model Predictions ---\n")
tryCatch({
  win_probs_ladies <- predict(win_model_ladies, pred_data_ladies, type = "response")
  
  # Validate predictions
  if (any(is.na(win_probs_ladies))) {
    warning("NA predictions detected for ladies Win - ", sum(is.na(win_probs_ladies)), " out of ", length(win_probs_ladies))
  }
  if (any(win_probs_ladies < 0 | win_probs_ladies > 1, na.rm = TRUE)) {
    warning("Invalid probability values for ladies Win (outside 0-1 range)")
  }
  
  cat("✓ Ladies Win predictions generated - Range: [", round(min(win_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(win_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Win predictions: ", e$message)
})

tryCatch({
  top3_probs_ladies <- predict(topthree_model_ladies, pred_data_ladies, type = "response")
  
  # Validate predictions
  if (any(is.na(top3_probs_ladies))) {
    warning("NA predictions detected for ladies TopThree - ", sum(is.na(top3_probs_ladies)), " out of ", length(top3_probs_ladies))
  }
  if (any(top3_probs_ladies < 0 | top3_probs_ladies > 1, na.rm = TRUE)) {
    warning("Invalid probability values for ladies TopThree (outside 0-1 range)")
  }
  
  cat("✓ Ladies TopThree predictions generated - Range: [", round(min(top3_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top3_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies TopThree predictions: ", e$message)
})

tryCatch({
  top5_probs_ladies <- predict(top5_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top5_probs_ladies))) warning("NA predictions for ladies Top5")
  if (any(top5_probs_ladies < 0 | top5_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top5 probabilities")
  
  cat("✓ Ladies Top5 predictions generated - Range: [", round(min(top5_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top5_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top5 predictions: ", e$message)
})

tryCatch({
  top10_probs_ladies <- predict(top10_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top10_probs_ladies))) warning("NA predictions for ladies Top10")
  if (any(top10_probs_ladies < 0 | top10_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top10 probabilities")
  
  cat("✓ Ladies Top10 predictions generated - Range: [", round(min(top10_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top10_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top10 predictions: ", e$message)
})

tryCatch({
  top30_probs_ladies <- predict(top30_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top30_probs_ladies))) warning("NA predictions for ladies Top30")
  if (any(top30_probs_ladies < 0 | top30_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top30 probabilities")
  
  cat("✓ Ladies Top30 predictions generated - Range: [", round(min(top30_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top30_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top30 predictions: ", e$message)
})

# ========== NORMALIZATION FOR LADIES ODDS ==========
cat("\n--- Normalizing Ladies Probabilities ---\n")

# Use the same proportional scaling function as men's odds
# (Function already defined above in men's section)

# Normalize ladies probabilities with proportional scaling and simple maximum compression
# Win probabilities should sum to 100% (1.0), max individual 95%
win_probs_normalized_ladies <- proportional_scale(win_probs_ladies, 1.0, 0.95)
second_probs_normalized_ladies <- win_probs_normalized_ladies
third_probs_normalized_ladies <- win_probs_normalized_ladies

# Top3 probabilities should sum to 300% (3.0), max individual 95%
top3_probs_normalized_ladies <- proportional_scale(top3_probs_ladies, 3.0, 0.95)

# Top5 probabilities should sum to 500% (5.0), max individual 95%
top5_probs_normalized_ladies <- proportional_scale(top5_probs_ladies, 5.0, 0.95)

# Top10 probabilities should sum to 1000% (10.0), max individual 95%
top10_probs_normalized_ladies <- proportional_scale(top10_probs_ladies, 10.0, 0.95)

# Top30 probabilities should sum to 3000% (30.0), max individual 95%
top30_probs_normalized_ladies <- proportional_scale(top30_probs_ladies, 30.0, 0.95)

cat("Ladies Normalization applied:\n")
cat("Win probs sum:", round(sum(win_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 1.0)\n")
cat("Top3 probs sum:", round(sum(top3_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 3.0)\n")
cat("Top5 probs sum:", round(sum(top5_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 5.0)\n")
cat("Top10 probs sum:", round(sum(top10_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 10.0)\n")
cat("Top30 probs sum:", round(sum(top30_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 30.0)\n")

# Create ladies results dataframe with validation
cat("\n--- Ladies Results DataFrame Creation ---\n")

# Validate required columns in pred_data_ladies
required_id_cols <- c("Skier", "Nation")
missing_id_cols <- setdiff(required_id_cols, names(pred_data_ladies))
if (length(missing_id_cols) > 0) {
  stop("Missing identification columns in pred_data_ladies: ", paste(missing_id_cols, collapse = ", "))
}

tryCatch({
  # Create ladies results dataframe with all probabilities (USING NORMALIZED VALUES)
  # Note: Since TopThree is now binary, we don't have separate win/second/third probs
  results_ladies <- data.frame(
    Skier = pred_data_ladies$Skier,
    Nation = pred_data_ladies$Nation,
    Top3_Prob = top3_probs_normalized_ladies,    # Normalized Top3 probability
    Win_Prob = win_probs_normalized_ladies,      # Normalized win probability
    Second_Prob = second_probs_normalized_ladies, # Normalized second probability
    Third_Prob = third_probs_normalized_ladies,  # Normalized third probability
    Top5_Prob = top5_probs_normalized_ladies,    # Normalized Top5 probability
    Top10_Prob = top10_probs_normalized_ladies,  # Normalized Top10 probability
    Top30_Prob = top30_probs_normalized_ladies,  # Normalized Top30 probability
    Outside_Prob = 1 - (top30_probs_normalized_ladies / 30.0)  # Adjusted for normalization
  )
  
  # Validate ladies results dataframe
  if (nrow(results_ladies) == 0) stop("Ladies results dataframe is empty")
  if (any(is.na(results_ladies$Skier))) warning("Missing skier names in ladies results")
  
  # Check probability consistency for ladies
  invalid_prob_consistency <- sum(results_ladies$Top3_Prob > results_ladies$Top5_Prob | 
                                  results_ladies$Top5_Prob > results_ladies$Top10_Prob | 
                                  results_ladies$Top10_Prob > results_ladies$Top30_Prob, na.rm = TRUE)
  
  if (invalid_prob_consistency > 0) {
    warning("Probability inconsistency detected in ", invalid_prob_consistency, " ladies cases (P(smaller) > P(larger))")
  }
  
  cat("✓ Ladies results dataframe created with", nrow(results_ladies), "skiers\n")
  cat("Ladies probability ranges - Top3: [", round(min(results_ladies$Top3_Prob, na.rm = TRUE), 4), ", ", 
      round(max(results_ladies$Top3_Prob, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error creating ladies results dataframe: ", e$message)
})

# Calculate ladies decimal and American odds with validation
cat("\n--- Ladies Odds Calculation ---\n")
tryCatch({
  results_ladies <- results_ladies %>%
    mutate(
      Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
      Win_American_Odds = ifelse(Win_Prob >= 0.5,
                                -Win_Prob/(1-Win_Prob) * 100,
                                (1-Win_Prob)/Win_Prob * 100),
      Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
      Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                                 -Top3_Prob/(1-Top3_Prob) * 100,
                                 (1-Top3_Prob)/Top3_Prob * 100),
      Top5_Decimal_Odds = ifelse(Top5_Prob > 0, 1 / Top5_Prob, Inf),
      Top5_American_Odds = ifelse(Top5_Prob >= 0.5,
                                 -Top5_Prob/(1-Top5_Prob) * 100,
                                 (1-Top5_Prob)/Top5_Prob * 100),
      Top10_Decimal_Odds = ifelse(Top10_Prob > 0, 1 / Top10_Prob, Inf),
      Top10_American_Odds = ifelse(Top10_Prob >= 0.5,
                                  -Top10_Prob/(1-Top10_Prob) * 100,
                                  (1-Top10_Prob)/Top10_Prob * 100),
      Top30_Decimal_Odds = ifelse(Top30_Prob > 0, 1 / Top30_Prob, Inf),
      Top30_American_Odds = ifelse(Top30_Prob >= 0.5,
                                  -Top30_Prob/(1-Top30_Prob) * 100,
                                  (1-Top30_Prob)/Top30_Prob * 100)
    ) %>%
    # Format ladies probabilities and odds with validation
    mutate(
      Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
      Second_Prob = ifelse(is.na(Second_Prob), "N/A", sprintf("%.1f%%", Second_Prob * 100)),
      Third_Prob = ifelse(is.na(Third_Prob), "N/A", sprintf("%.1f%%", Third_Prob * 100)),
      Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
      Top5_Prob = ifelse(is.na(Top5_Prob), "N/A", sprintf("%.1f%%", Top5_Prob * 100)),
      Top10_Prob = ifelse(is.na(Top10_Prob), "N/A", sprintf("%.1f%%", Top10_Prob * 100)),
      Top30_Prob = ifelse(is.na(Top30_Prob), "N/A", sprintf("%.1f%%", Top30_Prob * 100)),
      Outside_Prob = ifelse(is.na(Outside_Prob), "N/A", sprintf("%.1f%%", Outside_Prob * 100)),
      
      # Round ladies decimal odds with Inf handling
      Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                               ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
      Top3_Decimal_Odds = ifelse(is.infinite(Top3_Decimal_Odds), 999.99, 
                                ifelse(Top3_Decimal_Odds > 999.99, 999.99, round(Top3_Decimal_Odds, 2))),
      Top5_Decimal_Odds = ifelse(is.infinite(Top5_Decimal_Odds), 999.99, 
                                ifelse(Top5_Decimal_Odds > 999.99, 999.99, round(Top5_Decimal_Odds, 2))),
      Top10_Decimal_Odds = ifelse(is.infinite(Top10_Decimal_Odds), 999.99, 
                                 ifelse(Top10_Decimal_Odds > 999.99, 999.99, round(Top10_Decimal_Odds, 2))),
      Top30_Decimal_Odds = ifelse(is.infinite(Top30_Decimal_Odds), 999.99, 
                                 ifelse(Top30_Decimal_Odds > 999.99, 999.99, round(Top30_Decimal_Odds, 2))),
      
      # Format ladies American odds with validation
      Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                                ifelse(Win_American_Odds > 0, 
                                      sprintf("+%.0f", round(Win_American_Odds, 0)),
                                      sprintf("%.0f", round(Win_American_Odds, 0)))),
      Top3_American_Odds = ifelse(is.na(Top3_American_Odds) | is.infinite(Top3_American_Odds), "N/A",
                                 ifelse(Top3_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top3_American_Odds, 0)),
                                       sprintf("%.0f", round(Top3_American_Odds, 0)))),
      Top5_American_Odds = ifelse(is.na(Top5_American_Odds) | is.infinite(Top5_American_Odds), "N/A",
                                 ifelse(Top5_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top5_American_Odds, 0)),
                                       sprintf("%.0f", round(Top5_American_Odds, 0)))),
      Top10_American_Odds = ifelse(is.na(Top10_American_Odds) | is.infinite(Top10_American_Odds), "N/A",
                                  ifelse(Top10_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top10_American_Odds, 0)),
                                        sprintf("%.0f", round(Top10_American_Odds, 0)))),
      Top30_American_Odds = ifelse(is.na(Top30_American_Odds) | is.infinite(Top30_American_Odds), "N/A",
                                  ifelse(Top30_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top30_American_Odds, 0)),
                                        sprintf("%.0f", round(Top30_American_Odds, 0))))
    )
  
  # Validate ladies sorting and arrange results
  numeric_win_probs_ladies <- as.numeric(sub("%", "", results_ladies$Win_Prob))
  if (any(is.na(numeric_win_probs_ladies))) {
    warning("Some ladies Win_Prob values could not be converted to numeric for sorting")
  }
  
  results_ladies <- results_ladies %>% arrange(desc(numeric_win_probs_ladies))
  
  cat("✓ Ladies odds calculation and formatting completed\n")
  
}, error = function(e) {
  stop("Error calculating ladies odds: ", e$message)
})

cat("\n--- Ladies Final Results Summary ---\n")
cat("Total ladies with odds:", nrow(results_ladies), "\n")
cat("Ladies with valid Win probabilities:", sum(results_ladies$Win_Prob != "N/A"), "\n")
cat("Highest ladies win probability:", max(numeric_win_probs_ladies, na.rm = TRUE), "%\n")

print("=== 2026 LADIES ALPINE SEASON ODDS ===")
print("Top 10 Ladies Season Winner Odds:")
print(results_ladies %>% 
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      head(10))

print("Top 10 Ladies Podium Finish Odds:")
print(results_ladies %>% 
      arrange(desc(as.numeric(sub("%", "", Top3_Prob)))) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      head(10))

print("Top 10 Ladies Top-10 Finish Odds:")
print(results_ladies %>% 
      arrange(desc(as.numeric(sub("%", "", Top10_Prob)))) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      head(10))

# Store ladies results with validation
tryCatch({
  # Final validation before storage
  if (nrow(results_ladies) == 0) stop("No ladies results to store")
  if (all(results_ladies$Win_Prob == "N/A")) warning("All ladies win probabilities are N/A")
  
  cat("✓ Ladies results stored successfully with", nrow(results_ladies), "skiers\n")
  
}, error = function(e) {
  stop("Error storing ladies results: ", e$message)
})

# Export Ladies Odds to Excel
cat("\n=== EXPORTING LADIES ALPINE ODDS TO EXCEL ===\n")
tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  if (!is.null(results_ladies) && nrow(results_ladies) > 0) {
    # Prepare data with numeric probabilities for proper sorting
    ladies_odds_export <- results_ladies %>%
      mutate(
        # Convert probability percentages to numeric for proper handling
        Win_Prob_Numeric = as.numeric(gsub("%", "", Win_Prob)),
        Top3_Prob_Numeric = as.numeric(gsub("%", "", Top3_Prob)),
        Top10_Prob_Numeric = as.numeric(gsub("%", "", Top10_Prob)),
        Top30_Prob_Numeric = as.numeric(gsub("%", "", Top30_Prob)),
        # Convert decimal odds to numeric for proper handling
        Win_Decimal_Numeric = as.numeric(Win_Decimal_Odds),
        Top3_Decimal_Numeric = as.numeric(Top3_Decimal_Odds),
        Top10_Decimal_Numeric = as.numeric(Top10_Decimal_Odds),
        Top30_Decimal_Numeric = as.numeric(Top30_Decimal_Odds)
      ) %>%
      # Create separate tables for each outcome
      arrange(desc(Win_Prob_Numeric))
    
    # Create separate Excel files for each outcome type
    
    # Win odds file
    win_data <- ladies_odds_export %>%
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(
        "Win Prob" = Win_Prob,
        "Win Decimal Odds" = Win_Decimal_Odds,
        "Win American Odds" = Win_American_Odds
      )
    
    win_wb <- createWorkbook()
    addWorksheet(win_wb, "Ladies Alpine Win Odds 2026")
    writeData(win_wb, "Ladies Alpine Win Odds 2026", win_data, startRow = 1, startCol = 1)
    addStyle(win_wb, "Ladies Alpine Win Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(win_data))
    setColWidths(win_wb, "Ladies Alpine Win Odds 2026", cols = 1:ncol(win_data), widths = "auto")
    saveWorkbook(win_wb, "excel365/Ladies_Win_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 3 odds file
    top3_data <- ladies_odds_export %>%
      arrange(desc(Top3_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(
        "Top 3 Prob" = Top3_Prob,
        "Top 3 Decimal Odds" = Top3_Decimal_Odds,
        "Top 3 American Odds" = Top3_American_Odds
      )
    
    top3_wb <- createWorkbook()
    addWorksheet(top3_wb, "Ladies Alpine Top 3 Odds 2026")
    writeData(top3_wb, "Ladies Alpine Top 3 Odds 2026", top3_data, startRow = 1, startCol = 1)
    addStyle(top3_wb, "Ladies Alpine Top 3 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top3_data))
    setColWidths(top3_wb, "Ladies Alpine Top 3 Odds 2026", cols = 1:ncol(top3_data), widths = "auto")
    saveWorkbook(top3_wb, "excel365/Ladies_Top3_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 10 odds file
    top10_data <- ladies_odds_export %>%
      arrange(desc(Top10_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(
        "Top 10 Prob" = Top10_Prob,
        "Top 10 Decimal Odds" = Top10_Decimal_Odds,
        "Top 10 American Odds" = Top10_American_Odds
      )
    
    top10_wb <- createWorkbook()
    addWorksheet(top10_wb, "Ladies Alpine Top 10 Odds 2026")
    writeData(top10_wb, "Ladies Alpine Top 10 Odds 2026", top10_data, startRow = 1, startCol = 1)
    addStyle(top10_wb, "Ladies Alpine Top 10 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top10_data))
    setColWidths(top10_wb, "Ladies Alpine Top 10 Odds 2026", cols = 1:ncol(top10_data), widths = "auto")
    saveWorkbook(top10_wb, "excel365/Ladies_Top10_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 30 odds file
    top30_data <- ladies_odds_export %>%
      arrange(desc(Top30_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top30_Prob, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(
        "Top 30 Prob" = Top30_Prob,
        "Top 30 Decimal Odds" = Top30_Decimal_Odds,
        "Top 30 American Odds" = Top30_American_Odds
      )
    
    top30_wb <- createWorkbook()
    addWorksheet(top30_wb, "Ladies Alpine Top 30 Odds 2026")
    writeData(top30_wb, "Ladies Alpine Top 30 Odds 2026", top30_data, startRow = 1, startCol = 1)
    addStyle(top30_wb, "Ladies Alpine Top 30 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top30_data))
    setColWidths(top30_wb, "Ladies Alpine Top 30 Odds 2026", cols = 1:ncol(top30_data), widths = "auto")
    saveWorkbook(top30_wb, "excel365/Ladies_Top30_Odds_2026.xlsx", overwrite = TRUE)
    
    cat("✓ Ladies alpine odds Excel files saved:\n")
    cat("  - excel365/Ladies_Win_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top3_Odds_2026.xlsx\n") 
    cat("  - excel365/Ladies_Top10_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top30_Odds_2026.xlsx\n")
    cat(sprintf("Ladies alpine odds export: %d athletes across 4 separate files\n", nrow(ladies_odds_export)))
    
  } else {
    cat("No ladies alpine odds data available for export\n")
  }
  
}, error = function(e) {
  cat("Error exporting ladies alpine odds to Excel:", e$message, "\n")
})
```

### Breakthrough Analysis

```{r breakout-identifier}
cat("=== BREAKTHROUGH ANALYSIS VALIDATION ===\n")

# Validate training data availability
if (!exists("train_men") || !is.data.frame(train_men)) {
  stop("train_men dataset not found or invalid")
}
if (!exists("train_ladies") || !is.data.frame(train_ladies)) {
  stop("train_ladies dataset not found or invalid")
}

if (nrow(train_men) == 0) stop("train_men dataset is empty")
if (nrow(train_ladies) == 0) stop("train_ladies dataset is empty")

cat("Training data validated - Men:", nrow(train_men), "observations, Ladies:", nrow(train_ladies), "observations\n")

# Validate required columns for breakthrough analysis
required_breakthrough_cols <- c("Skier", "Nation", "Season", "Pct_of_Max_Points", "Age")
missing_men_cols <- setdiff(required_breakthrough_cols, names(train_men))
missing_ladies_cols <- setdiff(required_breakthrough_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop("Missing required columns in train_men: ", paste(missing_men_cols, collapse = ", "))
}
if (length(missing_ladies_cols) > 0) {
  stop("Missing required columns in train_ladies: ", paste(missing_ladies_cols, collapse = ", "))
}
cat("✓ All required columns present in both datasets\n")

# Validate Pct_of_Max_Points data quality
cat("\n--- Data Quality Validation ---\n")

# Men's data validation
men_invalid_pct <- sum(is.na(train_men$Pct_of_Max_Points) | 
                      train_men$Pct_of_Max_Points < 0 | 
                      train_men$Pct_of_Max_Points > 1 | 
                      !is.finite(train_men$Pct_of_Max_Points))

ladies_invalid_pct <- sum(is.na(train_ladies$Pct_of_Max_Points) | 
                         train_ladies$Pct_of_Max_Points < 0 | 
                         train_ladies$Pct_of_Max_Points > 1 | 
                         !is.finite(train_ladies$Pct_of_Max_Points))

cat("Men's invalid Pct_of_Max_Points values:", men_invalid_pct, "\n")
cat("Ladies invalid Pct_of_Max_Points values:", ladies_invalid_pct, "\n")

if (men_invalid_pct > nrow(train_men) * 0.1) {
  warning("More than 10% of men's Pct_of_Max_Points values are invalid")
}
if (ladies_invalid_pct > nrow(train_ladies) * 0.1) {
  warning("More than 10% of ladies Pct_of_Max_Points values are invalid")
}

# Identify historical top performers with validation
cat("\n--- Historical Top Performers Analysis ---\n")

tryCatch({
  top_performers_men <- train_men %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.2,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_men) == 0) {
    warning("No men's breakthrough performers found with >20% points")
  } else {
    cat("✓ Men's breakthrough performers identified:", nrow(top_performers_men), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying men's top performers: ", e$message)
})

tryCatch({
  top_performers_ladies <- train_ladies %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.2,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_ladies) == 0) {
    warning("No ladies breakthrough performers found with >20% points")
  } else {
    cat("✓ Ladies breakthrough performers identified:", nrow(top_performers_ladies), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying ladies top performers: ", e$message)
})

# Summary statistics with validation
tryCatch({
  unique_men_breakthroughs <- length(unique(top_performers_men$Skier))
  unique_ladies_breakthroughs <- length(unique(top_performers_ladies$Skier))
  
  cat("✓ Analysis completed successfully\n")
  cat("Men's breakthrough entries:", nrow(top_performers_men), "\n")
  cat("Ladies breakthrough entries:", nrow(top_performers_ladies), "\n")
  
  print("=== MEN'S HISTORICAL BREAKTHROUGH PERFORMERS (>20% of max points) ===")
  print(paste("Unique men's breakthrough skiers:", unique_men_breakthroughs))
  
  if (nrow(top_performers_men) > 0) {
    print("Recent men's breakthrough examples:")
    recent_men <- top_performers_men %>%
      arrange(desc(Season), desc(Pct_of_Max_Points))
    print(recent_men)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_men$Age))) {
      cat("Men's breakthrough age range:", 
          round(min(top_performers_men$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_men$Age, na.rm = TRUE), 1), "\n")
      cat("Men's mean breakthrough age:", 
          round(mean(top_performers_men$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No men's breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in men's breakthrough summary: ", e$message)
})

tryCatch({
  print("=== LADIES HISTORICAL BREAKTHROUGH PERFORMERS (>20% of max points) ===")
  print(paste("Unique ladies breakthrough skiers:", unique_ladies_breakthroughs))
  
  if (nrow(top_performers_ladies) > 0) {
    print("Recent ladies breakthrough examples:")
    recent_ladies <- top_performers_ladies %>%
      arrange(desc(Season), desc(Pct_of_Max_Points))
    print(recent_ladies)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_ladies$Age))) {
      cat("Ladies breakthrough age range:", 
          round(min(top_performers_ladies$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
      cat("Ladies mean breakthrough age:", 
          round(mean(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No ladies breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in ladies breakthrough summary: ", e$message)
})
```

### Breakthrough Feature Selection

```{r feat-select-break}
# Load required libraries for breakthrough analysis
tryCatch({
  library(caret)
  library(ranger)
  library(pROC)
  cat("✓ Required libraries loaded successfully\n")
}, error = function(e) {
  stop("Error loading required libraries: ", e$message)
})

# Enhanced function to evaluate predictor importance for breakthrough prediction
evaluate_breakthrough_predictors <- function(df, predictors) {
  cat("\n--- Breakthrough Predictor Evaluation ---\n")
  
  # Input validation
  if (!is.data.frame(df)) stop("Input df is not a data frame")
  if (nrow(df) == 0) stop("Input dataframe is empty")
  if (is.null(predictors) || length(predictors) == 0) stop("No predictors provided")
  
  # Validate predictors exist in dataframe
  missing_predictors <- setdiff(predictors, names(df))
  if (length(missing_predictors) > 0) {
    warning("Missing predictors: ", paste(missing_predictors, collapse = ", "))
    predictors <- intersect(predictors, names(df))
  }
  
  if (length(predictors) == 0) stop("No valid predictors remain after filtering")
  cat("Using", length(predictors), "predictors for breakthrough analysis\n")
  
  # Prepare data with validation and adaptive age filtering
  tryCatch({
    # First, try broader age range to get sufficient breakthrough cases
    initial_data <- df %>%
      mutate(
        # Define breakthrough as achieving >20% in this season
        Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.2),
        Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                 labels = c("No", "Yes")),
        Age = as.numeric(Age)
      ) %>%
      filter(!is.na(Will_Breakthrough),
             !is.na(Pct_of_Max_Points),
             !is.na(Age)) %>%
      dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
      na.omit()
    
    # Check breakthrough distribution across age ranges
    breakthrough_by_age <- initial_data %>%
      filter(Will_Breakthrough == "Yes") %>%
      summarise(
        n_breakthroughs = n(),
        min_age = min(Age, na.rm = TRUE),
        max_age = max(Age, na.rm = TRUE),
        mean_age = mean(Age, na.rm = TRUE)
      )
    
    cat("Initial breakthrough cases found:", breakthrough_by_age$n_breakthroughs, "\n")
    if (breakthrough_by_age$n_breakthroughs > 0) {
      cat("Breakthrough age range:", round(breakthrough_by_age$min_age, 1), "-", round(breakthrough_by_age$max_age, 1), "\n")
    }
    
    # If still too few cases, try lower breakthrough threshold
    if (breakthrough_by_age$n_breakthroughs < 5) {
      cat("Very few breakthrough cases at 20% threshold, trying 10% threshold\n")
      initial_data <- df %>%
        mutate(
          # Lower threshold for breakthrough (10%)
          Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.1),
          Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                   labels = c("No", "Yes")),
          Age = as.numeric(Age)
        ) %>%
        filter(!is.na(Will_Breakthrough),
               !is.na(Pct_of_Max_Points),
               !is.na(Age)) %>%
        dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
        na.omit()
      
      # Recalculate breakthrough stats
      breakthrough_by_age <- initial_data %>%
        filter(Will_Breakthrough == "Yes") %>%
        summarise(
          n_breakthroughs = n(),
          min_age = min(Age, na.rm = TRUE),
          max_age = max(Age, na.rm = TRUE),
          mean_age = mean(Age, na.rm = TRUE)
        )
      
      cat("Breakthrough cases at 10% threshold:", breakthrough_by_age$n_breakthroughs, "\n")
    }
    
    # Use all ages for model training (no age restrictions for breakthrough potential)
    cat("Using all ages for breakthrough model training (no age restrictions)\n")
    
    model_data <- initial_data %>%
      dplyr::select(Will_Breakthrough, all_of(predictors))
    
    # Impute missing values with first quartile (using existing function)
    cat("\n--- Missing Data Imputation ---\n")
    for (pred in predictors) {
      if (pred %in% names(model_data)) {
        initial_nas <- sum(is.na(model_data[[pred]]))
        if (initial_nas > 0) {
          cat(sprintf("Imputing %d missing values in %s\n", initial_nas, pred))
          model_data[[pred]] <- replace_na_with_quartile(model_data[[pred]], pred)
          final_nas <- sum(is.na(model_data[[pred]]))
          cat(sprintf("  %s: %d -> %d NAs after imputation\n", pred, initial_nas, final_nas))
        }
      }
    }
    
    cat("✓ Data preparation completed\n")
    
  }, error = function(e) {
    stop("Error in data preparation: ", e$message)
  })
  
  print("Breakthrough data dimensions after filtering:")
  print(dim(model_data))
  
  # Validate class distribution
  breakthrough_dist <- table(model_data$Will_Breakthrough, useNA = "always")
  print("Breakthrough distribution:")
  print(breakthrough_dist)
  
  # Check for class imbalance with adaptive thresholds
  min_class_size <- min(breakthrough_dist[breakthrough_dist > 0])  # Exclude NA count
  breakthrough_count <- breakthrough_dist[["Yes"]]
  no_breakthrough_count <- breakthrough_dist[["No"]]
  
  cat("Breakthrough cases (Yes):", breakthrough_count, "\n")
  cat("Non-breakthrough cases (No):", no_breakthrough_count, "\n")
  
  # Adaptive validation based on data availability
  if (min_class_size < 2) {
    stop("Insufficient data for model training - need at least 2 cases per class")
  } else if (min_class_size < 5) {
    warning("Very few cases in minority class (", min_class_size, ") - model may be unstable")
  } else if (breakthrough_count < 10) {
    warning("Few breakthrough cases (", breakthrough_count, ") - consider this when interpreting results")
  }
  
  # Calculate class imbalance ratio
  imbalance_ratio <- max(breakthrough_count, no_breakthrough_count) / min(breakthrough_count, no_breakthrough_count)
  if (imbalance_ratio > 20) {
    warning("Severe class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  } else if (imbalance_ratio > 10) {
    warning("Moderate class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  }
  
  # Validate examples with error handling
  tryCatch({
    print("Sample breakthrough cases (Will_Breakthrough = Yes):")
    breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "Yes") %>% 
      head(10)
    
    if(nrow(breakthrough_examples) > 0) {
      print(breakthrough_examples)
      cat("✓ Breakthrough examples validated\n")
    } else {
      warning("No breakthrough examples found in filtered data!")
    }
    
  }, error = function(e) {
    warning("Error displaying breakthrough examples: ", e$message)
  })
  
  tryCatch({
    print("Sample non-breakthrough cases (Will_Breakthrough = No):")
    non_breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "No") %>% 
      head(10)
    
    if(nrow(non_breakthrough_examples) > 0) {
      print(non_breakthrough_examples)
      cat("✓ Non-breakthrough examples validated\n")
    } else {
      warning("No non-breakthrough examples found!")
    }
    
  }, error = function(e) {
    warning("Error displaying non-breakthrough examples: ", e$message)
  })
  
  # Cross-validation setup with adaptive parameters
  tryCatch({
    # Adaptive CV parameters based on data size
    if (nrow(model_data) < 50) {
      cv_method <- "LOOCV"  # Leave-one-out for very small datasets
      cv_number <- NULL
    } else if (nrow(model_data) < 200) {
      cv_method <- "cv"
      cv_number <- 5  # 5-fold for small datasets
    } else {
      cv_method <- "cv"
      cv_number <- 10  # 10-fold for larger datasets
    }
    
    if (cv_method == "LOOCV") {
      ctrl <- trainControl(method = "LOOCV", classProbs = TRUE, summaryFunction = twoClassSummary)
      cat("Using Leave-One-Out Cross-Validation\n")
    } else {
      ctrl <- trainControl(method = cv_method, number = cv_number, classProbs = TRUE, summaryFunction = twoClassSummary)
      cat("Using", cv_number, "-fold Cross-Validation\n")
    }
    
  }, error = function(e) {
    stop("Error setting up cross-validation: ", e$message)
  })
  
  # Train logistic model with validation
  tryCatch({
    breakthrough_formula <- as.formula(paste("Will_Breakthrough ~", paste(predictors, collapse = " + ")))
    cat("Training logistic regression model with", length(predictors), "predictors\n")
    
    logistic_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "glm",
      family = "binomial",
      trControl = ctrl,
      metric = "ROC"
    )
    
    cat("✓ Logistic regression model trained\n")
    
    # Extract coefficient importance
    logistic_coefs <- summary(logistic_model$finalModel)$coefficients
    logistic_importance <- abs(logistic_coefs[-1, "Estimate"])  # Exclude intercept
    names(logistic_importance) <- rownames(logistic_coefs)[-1]
    
  }, error = function(e) {
    stop("Error training logistic regression: ", e$message)
  })
  
  # Train Random Forest with validation
  tryCatch({
    cat("Training Random Forest model for variable importance\n")
    
    rf_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "ranger",
      trControl = ctrl,
      importance = 'impurity',
      metric = "ROC"
    )
    
    cat("✓ Random Forest model trained\n")
    
    # Extract variable importance
    rf_importance <- rf_model$finalModel$variable.importance
    
  }, error = function(e) {
    warning("Error training Random Forest - using logistic regression only: ", e$message)
    rf_model <- NULL
    rf_importance <- NULL
  })
  
  # Combine and rank importance scores with validation
  tryCatch({
    if (!is.null(rf_importance)) {
      # Normalize importance scores to 0-1 scale
      logistic_norm <- (logistic_importance - min(logistic_importance)) / 
                      (max(logistic_importance) - min(logistic_importance))
      rf_norm <- (rf_importance - min(rf_importance)) / 
                 (max(rf_importance) - min(rf_importance))
      
      # Combine scores (equal weighting)
      common_vars <- intersect(names(logistic_norm), names(rf_norm))
      combined_importance <- (logistic_norm[common_vars] + rf_norm[common_vars]) / 2
      
      # Create comprehensive importance dataframe
      importance_df <- data.frame(
        Variable = common_vars,
        Logistic_Importance = logistic_norm[common_vars],
        RF_Importance = rf_norm[common_vars],
        Combined_Importance = combined_importance,
        stringsAsFactors = FALSE
      ) %>%
        arrange(desc(Combined_Importance))
      
      cat("✓ Combined importance scores calculated\n")
      
    } else {
      # Use only logistic regression importance
      importance_df <- data.frame(
        Variable = names(logistic_importance),
        Logistic_Importance = logistic_importance,
        RF_Importance = NA,
        Combined_Importance = logistic_importance,
        stringsAsFactors = FALSE
      ) %>%
        arrange(desc(Combined_Importance))
      
      cat("✓ Logistic-only importance scores calculated\n")
    }
    
  }, error = function(e) {
    stop("Error calculating variable importance: ", e$message)
  })
  
  # Model performance comparison with validation
  tryCatch({
    models_list <- list(Logistic = logistic_model)
    if (!is.null(rf_model)) {
      models_list$RandomForest <- rf_model
    }
    
    model_comparison <- resamples(models_list)
    performance_summary <- summary(model_comparison)
    
    cat("✓ Model performance comparison completed\n")
    
  }, error = function(e) {
    warning("Error in model comparison: ", e$message)
    model_comparison <- NULL
    performance_summary <- NULL
  })
  
  # Select top predictors with validation
  tryCatch({
    # Select top predictors (up to 5, or fewer if not enough predictors)
    n_top <- min(5, nrow(importance_df))
    top_predictors <- importance_df$Variable[1:n_top]
    
    cat("✓ Top", n_top, "predictors selected\n")
    
    # Train reduced model with only top predictors
    if (n_top >= 2) {  # Need at least 2 predictors for meaningful model
      reduced_formula <- as.formula(paste("Will_Breakthrough ~", paste(top_predictors, collapse = " + ")))
      
      reduced_model <- train(
        reduced_formula,
        data = model_data,
        method = "glm",
        family = "binomial",
        trControl = ctrl,
        metric = "ROC"
      )
      
      cat("✓ Reduced model with top predictors trained\n")
      
      # Add coefficient direction validation for breakthrough prediction
      cat("\n--- Alpine Breakthrough Model Coefficient Validation ---\n")
      tryCatch({
        # Get logistic regression coefficients
        logistic_coefs <- summary(reduced_model$finalModel)$coefficients
        
        # Expected positive coefficients for breakthrough prediction (alpine specific)
        expected_positive_vars <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                                    "Prev_Slalom", "Prev_Pct_of_Max_Points")
        expected_negative_vars <- c("Age")  # Younger athletes more likely to breakthrough
        
        cat("=== DEBUG: Predictor Values Used ===\n")
        for (var in top_predictors) {
          if (var %in% names(model_data)) {
            vals <- model_data[[var]]
            cat(sprintf("%s: min=%.3f, max=%.3f, mean=%.3f, na_count=%d\n", 
                       var, min(vals, na.rm=TRUE), max(vals, na.rm=TRUE), 
                       mean(vals, na.rm=TRUE), sum(is.na(vals))))
          }
        }
        
        # Check coefficient directions
        for (var in top_predictors) {
          if (var %in% rownames(logistic_coefs)) {
            coef_value <- logistic_coefs[var, "Estimate"]
            coef_pvalue <- logistic_coefs[var, "Pr(>|z|)"]
            
            # Check if coefficient direction matches expectation
            if (var %in% expected_positive_vars) {
              if (coef_value > 0) {
                cat("✓", var, "has positive coefficient (", round(coef_value, 4), ") - VALID for breakthrough prediction\n")
              } else {
                cat("⚠️  WARNING:", var, "has negative coefficient (", round(coef_value, 4), ") - unexpected for breakthrough prediction\n")
              }
            } else if (var %in% expected_negative_vars) {
              if (coef_value < 0) {
                cat("✓", var, "has negative coefficient (", round(coef_value, 4), ") - VALID for breakthrough prediction\n")
              } else {
                cat("⚠️  WARNING:", var, "has positive coefficient (", round(coef_value, 4), ") - unexpected for breakthrough prediction\n")
              }
            } else {
              # For other variables, include regardless of direction but note it
              cat("?", var, "has coefficient (", round(coef_value, 4), ") - included (direction not specified)\n")
            }
            
            # Also check statistical significance
            if (coef_pvalue > 0.1) {
              cat("  NOTE:", var, "p-value =", round(coef_pvalue, 4), "(not significant at 0.1 level)\n")
            }
          }
        }
        
        # Implement intelligent model selection to find best model with correct coefficient directions
        cat("\n--- Intelligent Model Selection for Correct Coefficient Directions ---\n")
        
        # Define core predictors we want to prioritize
        core_predictors <- c("Age", "Prev_Pct_of_Max_Points")
        available_predictors <- intersect(top_predictors, names(model_data))
        
        # Function to check if all coefficients have correct directions
        check_coefficient_directions <- function(model_coefs, predictors_used) {
          all_correct <- TRUE
          for (var in predictors_used) {
            if (var %in% rownames(model_coefs)) {
              coef_value <- model_coefs[var, "Estimate"]
              if (var %in% expected_positive_vars && coef_value <= 0) {
                all_correct <- FALSE
              } else if (var %in% expected_negative_vars && coef_value >= 0) {
                all_correct <- FALSE
              }
            }
          }
          return(all_correct)
        }
        
        best_model <- NULL
        best_predictors <- NULL
        best_roc <- 0
        best_directions_correct <- FALSE
        
        # Try different combinations, starting with simpler models
        for (n_predictors in 2:min(6, length(available_predictors))) {
          # Always include Age if available
          if ("Age" %in% available_predictors) {
            remaining_predictors <- setdiff(available_predictors, "Age")
            
            # Try combinations that include Age
            if (n_predictors > 1 && length(remaining_predictors) >= (n_predictors - 1)) {
              combinations <- combn(remaining_predictors, n_predictors - 1, simplify = FALSE)
              
              for (combo in combinations[1:min(20, length(combinations))]) {  # Limit to 20 combinations
                test_predictors <- c("Age", combo)
                
                tryCatch({
                  test_formula <- as.formula(paste("Will_Breakthrough ~", paste(test_predictors, collapse = " + ")))
                  
                  test_model <- train(
                    test_formula,
                    data = model_data,
                    method = "glm",
                    family = "binomial",
                    trControl = ctrl,
                    metric = "ROC"
                  )
                  
                  test_roc <- max(test_model$results$ROC, na.rm = TRUE)
                  test_coefs <- summary(test_model$finalModel)$coefficients
                  directions_correct <- check_coefficient_directions(test_coefs, test_predictors)
                  
                  # Prioritize models with correct directions, then by ROC
                  is_better <- FALSE
                  if (directions_correct && !best_directions_correct) {
                    is_better <- TRUE  # First model with correct directions
                  } else if (directions_correct && best_directions_correct && test_roc > best_roc) {
                    is_better <- TRUE  # Better ROC among models with correct directions
                  } else if (!directions_correct && !best_directions_correct && test_roc > best_roc) {
                    is_better <- TRUE  # Better ROC when no good directions found yet
                  }
                  
                  if (is_better) {
                    best_model <- test_model
                    best_predictors <- test_predictors
                    best_roc <- test_roc
                    best_directions_correct <- directions_correct
                    
                    cat("New best model found:", paste(test_predictors, collapse = ", "), 
                        "ROC:", round(test_roc, 3), 
                        "Directions:", ifelse(directions_correct, "✓ Correct", "✗ Wrong"), "\n")
                  }
                  
                }, error = function(e) {
                  # Skip combinations that fail
                })
              }
            }
          }
        }
        
        # Use the best model found
        if (!is.null(best_model)) {
          reduced_model <- best_model
          top_predictors <- best_predictors
          
          cat("\n--- Final Selected Model ---\n")
          cat("Selected predictors:", paste(best_predictors, collapse = ", "), "\n")
          cat("Model ROC:", round(best_roc, 3), "\n")
          cat("All coefficients correct direction:", ifelse(best_directions_correct, "✓ Yes", "✗ No"), "\n")
          
          # Show final coefficients
          final_coefs <- summary(best_model$finalModel)$coefficients
          cat("\nFinal model coefficients:\n")
          for (var in best_predictors) {
            if (var %in% rownames(final_coefs)) {
              coef_value <- final_coefs[var, "Estimate"]
              coef_pvalue <- final_coefs[var, "Pr(>|z|)"]
              direction_ok <- ""
              if (var %in% expected_positive_vars) {
                direction_ok <- ifelse(coef_value > 0, "✓", "✗")
              } else if (var %in% expected_negative_vars) {
                direction_ok <- ifelse(coef_value < 0, "✓", "✗")
              }
              cat(sprintf("  %s %s: coef=%.4f, p=%.4f\n", direction_ok, var, coef_value, coef_pvalue))
            }
          }
        } else {
          cat("No valid model found - keeping original\n")
        }
        
      }, error = function(e) {
        cat("Error in alpine breakthrough coefficient validation:", e$message, "\n")
      })
    } else {
      warning("Too few predictors for reduced model")
      reduced_model <- logistic_model
    }
    
  }, error = function(e) {
    warning("Error creating reduced model: ", e$message)
    top_predictors <- predictors[1:min(3, length(predictors))]  # Fallback
    reduced_model <- logistic_model
  })
  
  # Return comprehensive results
  return(list(
    importance = importance_df,
    top_predictors = top_predictors,
    full_model = logistic_model,
    reduced_model = reduced_model,
    rf_model = rf_model,
    model_comparison = model_comparison,
    performance = performance_summary,
    data_summary = list(
      n_observations = nrow(model_data),
      n_breakthrough = breakthrough_count,
      n_no_breakthrough = no_breakthrough_count,
      age_cutoff = "No age restriction"
    )
  ))
}

cat("\n--- Breakthrough Predictor Setup ---\n")

tryCatch({
  # Extract previous season features and age for men 
  
  men_prev_features <- names(train_men)[grep("^Prev_", names(train_men))]
  breakthrough_predictors_men <- c(men_prev_features, "Age")
  breakthrough_predictors_men <- breakthrough_predictors_men[!is.na(breakthrough_predictors_men)]
  
  # Validate men's predictors
  if (length(breakthrough_predictors_men) == 0) {
    stop("No valid predictors found for men's breakthrough analysis")
  }
  
  # Check which predictors actually exist in the data
  available_men_predictors <- intersect(breakthrough_predictors_men, names(train_men))
  if (length(available_men_predictors) < length(breakthrough_predictors_men)) {
    missing_men <- setdiff(breakthrough_predictors_men, available_men_predictors)
    warning("Missing men's predictors: ", paste(missing_men, collapse = ", "))
    breakthrough_predictors_men <- available_men_predictors
  }
  
  cat("✓ Men's breakthrough predictors validated:", length(breakthrough_predictors_men), "features\n")
  
}, error = function(e) {
  stop("Error setting up men's breakthrough predictors: ", e$message)
})

tryCatch({
  # Extract previous season features and age for ladies
  ladies_prev_features <- names(train_ladies)[grep("^Prev_", names(train_ladies))]
  breakthrough_predictors_ladies <- c(ladies_prev_features, "Age")
  breakthrough_predictors_ladies <- breakthrough_predictors_ladies[!is.na(breakthrough_predictors_ladies)]
  
  # Validate ladies predictors
  if (length(breakthrough_predictors_ladies) == 0) {
    stop("No valid predictors found for ladies breakthrough analysis")
  }
  
  # Check which predictors actually exist in the data
  available_ladies_predictors <- intersect(breakthrough_predictors_ladies, names(train_ladies))
  if (length(available_ladies_predictors) < length(breakthrough_predictors_ladies)) {
    missing_ladies <- setdiff(breakthrough_predictors_ladies, available_ladies_predictors)
    warning("Missing ladies predictors: ", paste(missing_ladies, collapse = ", "))
    breakthrough_predictors_ladies <- available_ladies_predictors
  }
  
  cat("✓ Ladies breakthrough predictors validated:", length(breakthrough_predictors_ladies), "features\n")
  
}, error = function(e) {
  stop("Error setting up ladies breakthrough predictors: ", e$message)
})

print("Available men's breakthrough predictors:")
print(breakthrough_predictors_men)

print("Available ladies breakthrough predictors:")
print(breakthrough_predictors_ladies)

# Run breakthrough analysis for men with validation
cat("\n--- Men's Breakthrough Analysis Execution ---\n")
print("=== MEN'S BREAKTHROUGH ANALYSIS ===")

tryCatch({
  breakthrough_analysis_men <- evaluate_breakthrough_predictors(train_men, breakthrough_predictors_men)
  
  # Validate results
  if (is.null(breakthrough_analysis_men)) {
    stop("Men's breakthrough analysis returned NULL")
  }
  
  required_components <- c("importance", "top_predictors", "model_comparison")
  missing_components <- setdiff(required_components, names(breakthrough_analysis_men))
  if (length(missing_components) > 0) {
    warning("Missing components in men's analysis: ", paste(missing_components, collapse = ", "))
  }
  
  cat("✓ Men's breakthrough analysis completed successfully\n")
  
}, error = function(e) {
  stop("Error in men's breakthrough analysis: ", e$message)
})

# Display men's results with validation
tryCatch({
  print("Men's Breakthrough Predictor Importance Summary:")
  if (!is.null(breakthrough_analysis_men$importance) && nrow(breakthrough_analysis_men$importance) > 0) {
    print(breakthrough_analysis_men$importance)
  } else {
    warning("No importance scores available for men's analysis")
  }
  
  print("Men's Top Predictors for Breakthrough:")
  if (!is.null(breakthrough_analysis_men$top_predictors) && length(breakthrough_analysis_men$top_predictors) > 0) {
    print(breakthrough_analysis_men$top_predictors)
  } else {
    warning("No top predictors available for men's analysis")
  }
  
  if (!is.null(breakthrough_analysis_men$model_comparison)) {
    print("Men's Model Performance Comparison:")
    print(breakthrough_analysis_men$performance)
  }
  
}, error = function(e) {
  warning("Error displaying men's results: ", e$message)
})

# Run breakthrough analysis for ladies with validation
cat("\n--- Ladies Breakthrough Analysis Execution ---\n")
print("=== LADIES BREAKTHROUGH ANALYSIS ===")

tryCatch({
  breakthrough_analysis_ladies <- evaluate_breakthrough_predictors(train_ladies, breakthrough_predictors_ladies)
  
  # Validate results
  if (is.null(breakthrough_analysis_ladies)) {
    stop("Ladies breakthrough analysis returned NULL")
  }
  
  required_components <- c("importance", "top_predictors", "model_comparison")
  missing_components <- setdiff(required_components, names(breakthrough_analysis_ladies))
  if (length(missing_components) > 0) {
    warning("Missing components in ladies analysis: ", paste(missing_components, collapse = ", "))
  }
  
  cat("✓ Ladies breakthrough analysis completed successfully\n")
  
}, error = function(e) {
  stop("Error in ladies breakthrough analysis: ", e$message)
})

# Display ladies results with validation
tryCatch({
  print("Ladies Breakthrough Predictor Importance Summary:")
  if (!is.null(breakthrough_analysis_ladies$importance) && nrow(breakthrough_analysis_ladies$importance) > 0) {
    print(breakthrough_analysis_ladies$importance)
  } else {
    warning("No importance scores available for ladies analysis")
  }
  
  print("Ladies Top Predictors for Breakthrough:")
  if (!is.null(breakthrough_analysis_ladies$top_predictors) && length(breakthrough_analysis_ladies$top_predictors) > 0) {
    print(breakthrough_analysis_ladies$top_predictors)
  } else {
    warning("No top predictors available for ladies analysis")
  }
  
  if (!is.null(breakthrough_analysis_ladies$model_comparison)) {
    print("Ladies Model Performance Comparison:")
    print(breakthrough_analysis_ladies$performance)
  }
  
}, error = function(e) {
  warning("Error displaying ladies results: ", e$message)
})
```

### 2026 Breakthrough Predictions

```{r big-break}
cat("=== 2026 BREAKTHROUGH PREDICTIONS VALIDATION ===\n")

# Enhanced function to predict 2026 breakthrough candidates
predict_2026_breakthroughs <- function(current_data, breakthrough_model, top_predictors) {
  cat("\n--- 2026 Breakthrough Prediction Function ---\n")
  
  # Input validation
  if (!is.data.frame(current_data)) stop("current_data is not a data frame")
  if (nrow(current_data) == 0) stop("current_data is empty")
  if (is.null(breakthrough_model)) stop("breakthrough_model is NULL")
  if (is.null(top_predictors) || length(top_predictors) == 0) stop("No top_predictors provided")
  
  cat("Input validation passed\n")
  cat("Using", length(top_predictors), "top predictors for breakthrough prediction\n")
  
  # Define mapping from prev variables to current Elo variables with validation
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Sprint" = "Sprint_Pelo", 
    "Prev_Distance" = "Distance_Pelo",
    "Prev_Mass_Start" = "Mass_Start_Pelo",
    "Prev_Individual" = "Individual_Pelo",
    "Prev_Pursuit" = "Pursuit_Pelo",
    "Prev_Overall" = "Overall_Pelo",
    "Age" = "Age"
  )
  
  # Validate required columns exist in current_data
  required_cols <- c("Skier", "Nation", "Season", "Age", "Pct_of_Max_Points")
  missing_cols <- setdiff(required_cols, names(current_data))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in current_data: ", paste(missing_cols, collapse = ", "))
  }
  
  print("Using breakthrough predictors:")
  print(top_predictors)
  
  # Career history analysis with validation
  cat("\n--- Career History Analysis ---\n")
  
  # Get 2025 data for potential breakthrough candidates
  tryCatch({
    # Focus on 2025 season as the most recent complete season
    season_2025_data <- current_data %>%
      filter(Season == 2025) %>%
      group_by(Skier) %>%
      arrange(desc(Season)) %>%
      slice(1) %>%  # Take most recent entry for each skier in 2025
      ungroup()
    
    if (nrow(season_2025_data) == 0) {
      stop("No 2025 season data found")
    }
    
    cat("✓ 2025 season data identified:", nrow(season_2025_data), "skiers\n")
    
  }, error = function(e) {
    stop("Error accessing 2025 season data: ", e$message)
  })
  
  # Identify breakthrough candidates with validation
  tryCatch({
    # Define breakthrough candidates: those who haven't yet achieved 20% in their CAREER
    # First, calculate career maximum performance for each skier across ALL seasons
    career_max_performance <- current_data %>%
      filter(!is.na(Pct_of_Max_Points)) %>%
      group_by(Skier) %>%
      summarise(
        Career_Max_Pct = max(Pct_of_Max_Points, na.rm = TRUE),
        .groups = 'drop'
      )
    
    # Then get the most recent season data and filter based on career maximum
    current_candidates <- season_2025_data %>%
      filter(
        !is.na(Age),
        !is.na(Pct_of_Max_Points),
        Pct_of_Max_Points > 0.01   # Must have some competitive results in recent season
      ) %>%
      group_by(Skier) %>%
      arrange(desc(Season)) %>%
      slice(1) %>%  # Take most recent season for each skier (should be 2025)
      ungroup() %>%
      # Join with career maximum performance
      left_join(career_max_performance, by = "Skier") %>%
      # Filter out those who have EVER achieved 20% or more in their career
      filter(
        !is.na(Career_Max_Pct),
        Career_Max_Pct < 0.2  # Haven't achieved 20% breakthrough in their ENTIRE CAREER
      )
    
    # Validate candidate data
    if (nrow(current_candidates) == 0) {
      stop("No breakthrough candidates found for 2025")
    }
    
    # Check for data quality issues in candidates
    na_age_count <- sum(is.na(current_candidates$Age))
    na_pct_count <- sum(is.na(current_candidates$Pct_of_Max_Points))
    
    if (na_age_count > 0) {
      warning("Found ", na_age_count, " candidates with missing age data")
    }
    if (na_pct_count > 0) {
      warning("Found ", na_pct_count, " candidates with missing performance data")
    }
    
    cat("✓ Breakthrough candidates identified:", nrow(current_candidates), "\n")
    
  }, error = function(e) {
    stop("Error identifying breakthrough candidates: ", e$message)
  })
  
  # Top candidates analysis with validation
  tryCatch({
    print("Top 2025 performers among breakthrough candidates:")
    top_candidates <- current_candidates %>% 
      filter(!is.na(Pct_of_Max_Points)) %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points) %>% 
      arrange(desc(Pct_of_Max_Points)) %>% 
      head(15)
    
    if (nrow(top_candidates) > 0) {
      print(top_candidates)
      cat("✓ Top candidates validated\n")
    } else {
      warning("No valid top candidates found")
    }
    
  }, error = function(e) {
    warning("Error analyzing top candidates: ", e$message)
  })
  
  # Age distribution analysis with validation
  tryCatch({
    age_summary <- current_candidates %>%
      filter(!is.na(Age)) %>%
      summarise(
        min_age = min(Age),
        max_age = max(Age),
        mean_age = round(mean(Age), 1),
        median_age = median(Age),
        n_under_25 = sum(Age <= 25)
      )
    
    print("Breakthrough candidates age distribution:")
    print(age_summary)
    
    cat("Candidates under 25:", age_summary$n_under_25, "out of", nrow(current_candidates), "\n")
    
  }, error = function(e) {
    warning("Error analyzing age distribution: ", e$message)
  })
  
  # Prepare prediction data with validation
  tryCatch({
    cat("\n--- Prediction Data Preparation ---\n")
    
    # Create prediction dataset by mapping current Elo variables to previous variables
    prediction_data <- current_candidates
    
    # Map current variables to "previous" variables for model prediction
    for (prev_var in names(predictor_mapping)) {
      current_var <- predictor_mapping[[prev_var]]
      
      if (current_var %in% names(prediction_data)) {
        prediction_data[[prev_var]] <- prediction_data[[current_var]]
      } else {
        warning("Current variable ", current_var, " not found in data")
        prediction_data[[prev_var]] <- NA
      }
    }
    
    # Validate prediction data quality
    prediction_cols_available <- intersect(top_predictors, names(prediction_data))
    missing_pred_cols <- setdiff(top_predictors, names(prediction_data))
    
    if (length(missing_pred_cols) > 0) {
      warning("Missing prediction columns: ", paste(missing_pred_cols, collapse = ", "))
    }
    
    cat("Available prediction columns:", length(prediction_cols_available), "out of", length(top_predictors), "\n")
    
    # Check for NA values in key predictors
    for (pred_col in prediction_cols_available) {
      na_count <- sum(is.na(prediction_data[[pred_col]]))
      if (na_count > 0) {
        cat("Warning: ", na_count, " NA values in predictor", pred_col, "\n")
      }
    }
    
    cat("✓ Prediction data prepared with", nrow(prediction_data), "candidates\n")
    
  }, error = function(e) {
    stop("Error preparing prediction data: ", e$message)
  })
  
  # Generate breakthrough predictions with validation
  tryCatch({
    cat("\n--- Generating Breakthrough Predictions ---\n")
    
    # Validate predictors are available for model
    missing_predictors <- setdiff(top_predictors, names(prediction_data))
    if (length(missing_predictors) > 0) {
      warning("Missing predictors for model prediction: ", paste(missing_predictors, collapse = ", "))
    }
    
    # Debug: Show breakthrough model input for key athletes
    if ("Marcel Hirscher" %in% prediction_data$Skier) {
      hirscher_idx <- which(prediction_data$Skier == "Marcel Hirscher")
      cat("\n=== DEBUG: Marcel Hirscher Breakthrough Model Input ===\n")
      cat("Top predictors used:", paste(top_predictors, collapse = ", "), "\n")
      hirscher_breakthrough_data <- prediction_data[hirscher_idx, c("Skier", top_predictors), drop = FALSE]
      print(hirscher_breakthrough_data)
    }
    
    if ("Lara Colturi" %in% prediction_data$Skier) {
      colturi_idx <- which(prediction_data$Skier == "Lara Colturi")
      cat("\n=== DEBUG: Lara Colturi Breakthrough Model Input ===\n")
      cat("Top predictors used:", paste(top_predictors, collapse = ", "), "\n")
      colturi_breakthrough_data <- prediction_data[colturi_idx, c("Skier", top_predictors), drop = FALSE]
      print(colturi_breakthrough_data)
    }
    
    # Make breakthrough predictions
    breakthrough_probs <- predict(breakthrough_model,
                                 newdata = prediction_data,
                                 type = "prob")
    
    # Validate prediction results
    if (is.null(breakthrough_probs)) {
      stop("Model prediction returned NULL")
    }
    if (nrow(breakthrough_probs) != nrow(prediction_data)) {
      stop("Prediction result row count mismatch")
    }
    if (!"Yes" %in% names(breakthrough_probs)) {
      stop("Missing 'Yes' probability column in predictions")
    }
    if (any(is.na(breakthrough_probs$Yes))) {
      warning("NA values detected in breakthrough probabilities")
    }
    
    cat("✓ Breakthrough predictions generated for", nrow(breakthrough_probs), "candidates\n")
    
  }, error = function(e) {
    stop("Error generating breakthrough predictions: ", e$message)
  })
  
  # Prediction analysis with validation
  tryCatch({
    yes_probs <- breakthrough_probs[,"Yes"]
    
    # Validate probability values
    if (any(is.na(yes_probs))) {
      warning("Found NA values in breakthrough probabilities")
    }
    
    if (any(yes_probs < 0 | yes_probs > 1, na.rm = TRUE)) {
      warning("Found invalid probability values (outside 0-1 range)")
    }
    
    print("Distribution of breakthrough probabilities:")
    print(summary(yes_probs))
    
    max_prob <- max(yes_probs, na.rm = TRUE)
    high_prob_count <- sum(yes_probs > 0.1, na.rm = TRUE)
    medium_prob_count <- sum(yes_probs > 0.05, na.rm = TRUE)
    
    cat("Highest breakthrough probability:", round(max_prob * 100, 1), "%\n")
    cat("Candidates with >10% breakthrough probability:", high_prob_count, "\n")
    cat("Candidates with >5% breakthrough probability:", medium_prob_count, "\n")
    
  }, error = function(e) {
    warning("Error analyzing predictions: ", e$message)
  })
  
  # Create results dataframe with validation
  tryCatch({
    cat("\n--- Creating Results DataFrame ---\n")
    
    # Ensure we have required predictors for output
    available_predictors <- intersect(top_predictors, names(prediction_data))
    
    results <- prediction_data %>%
      dplyr::select(Skier, Nation, Age, all_of(available_predictors), Pct_of_Max_Points) %>%
      mutate(
        Breakthrough_Prob = breakthrough_probs[,"Yes"],
        Points_To_Threshold = pmax(0, 0.2 - Pct_of_Max_Points, na.rm = TRUE),
        Likelihood = case_when(
          is.na(Breakthrough_Prob) ~ "Unknown",
          Breakthrough_Prob >= 0.6 ~ "Very High",
          Breakthrough_Prob >= 0.4 ~ "High", 
          Breakthrough_Prob >= 0.2 ~ "Moderate",
          Breakthrough_Prob >= 0.1 ~ "Low",
          TRUE ~ "Very Low"
        )
      ) %>%
      arrange(desc(Breakthrough_Prob))
    
    # Create age-filtered subset for young prospects
    under25_results <- results %>%
      filter(Age <= 25) %>%
      arrange(desc(Breakthrough_Prob))
    
    # Validate results
    if (nrow(results) == 0) {
      stop("No results generated")
    }
    
    cat("✓ Results created with", nrow(results), "total candidates\n")
    cat("Young prospects (≤25):", nrow(under25_results), "candidates\n")
    
    # Summary statistics
    valid_probs <- sum(!is.na(results$Breakthrough_Prob))
    cat("Valid predictions:", valid_probs, "out of", nrow(results), "\n")
    
    if (valid_probs > 0) {
      mean_prob <- mean(results$Breakthrough_Prob, na.rm = TRUE)
      cat("Mean breakthrough probability:", round(mean_prob * 100, 1), "%\n")
    }
    
  }, error = function(e) {
    stop("Error creating results: ", e$message)
  })
  
  # Return comprehensive results with validation
  tryCatch({
    return_obj <- list(
      all_candidates = results,
      under25_candidates = under25_results,
      summary = list(
        total_candidates = nrow(results),
        young_candidates = nrow(under25_results),
        mean_probability = mean(results$Breakthrough_Prob, na.rm = TRUE),
        max_probability = max(results$Breakthrough_Prob, na.rm = TRUE),
        high_potential_count = sum(results$Breakthrough_Prob > 0.3, na.rm = TRUE)
      ),
      predictors_used = available_predictors
    )
    
    cat("✓ Return object created successfully\n")
    return(return_obj)
    
  }, error = function(e) {
    stop("Error creating return object: ", e$message)
  })
}

# Execute breakthrough predictions with validation
cat("\n--- 2026 Breakthrough Prediction Execution ---\n")

# Make 2026 breakthrough predictions for men
tryCatch({
  cat("Generating men's breakthrough predictions\n")
  
  # Validate inputs
  if (is.null(breakthrough_analysis_men$reduced_model)) {
    stop("Men's breakthrough model is NULL")
  }
  if (is.null(breakthrough_analysis_men$top_predictors) || length(breakthrough_analysis_men$top_predictors) == 0) {
    stop("Men's top predictors are NULL or empty")
  }
  
  breakthrough_predictions_men <- predict_2026_breakthroughs(
    train_men,  # Use full training data to check career history
    breakthrough_analysis_men$reduced_model,
    breakthrough_analysis_men$top_predictors
  )
  
  # Validate results
  if (is.null(breakthrough_predictions_men)) {
    stop("Men's breakthrough predictions returned NULL")
  }
  
  cat("✓ Men's breakthrough predictions completed\n")
  
}, error = function(e) {
  stop("Error generating men's breakthrough predictions: ", e$message)
})

# Make 2026 breakthrough predictions for ladies
tryCatch({
  cat("Generating ladies breakthrough predictions\n")
  
  # Validate inputs
  if (is.null(breakthrough_analysis_ladies$reduced_model)) {
    stop("Ladies breakthrough model is NULL")
  }
  if (is.null(breakthrough_analysis_ladies$top_predictors) || length(breakthrough_analysis_ladies$top_predictors) == 0) {
    stop("Ladies top predictors are NULL or empty")
  }
  
  breakthrough_predictions_ladies <- predict_2026_breakthroughs(
    train_ladies,  # Use full training data to check career history
    breakthrough_analysis_ladies$reduced_model,
    breakthrough_analysis_ladies$top_predictors
  )
  
  # Validate results
  if (is.null(breakthrough_predictions_ladies)) {
    stop("Ladies breakthrough predictions returned NULL")
  }
  
  cat("✓ Ladies breakthrough predictions completed\n")
  
}, error = function(e) {
  stop("Error generating ladies breakthrough predictions: ", e$message)
})

print("=== 2026 MEN'S BREAKTHROUGH PREDICTIONS (ALL CANDIDATES) ===")
print("Top 15 Men's Breakthrough Candidates:")
print(breakthrough_predictions_men$all_candidates %>%
      head(15) %>%
      dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
      mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))

print("=== 2026 LADIES BREAKTHROUGH PREDICTIONS (ALL CANDIDATES) ===")  
print("Top 15 Ladies Breakthrough Candidates:")
print(breakthrough_predictions_ladies$all_candidates %>%
      head(15) %>%
      dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
      mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))

print("=== BREAKTHROUGH PREDICTION SUMMARY ===")
print("Men's Breakthrough Summary:")
print(breakthrough_predictions_men$summary)

print("Ladies Breakthrough Summary:")
print(breakthrough_predictions_ladies$summary)

print("Men's Breakthrough Likelihood Summary (All):")
print(table(breakthrough_predictions_men$all_candidates$Likelihood))
print("Men's Breakthrough Likelihood Summary (Under 25):")
print(table(breakthrough_predictions_men$under25_candidates$Likelihood))

print("Ladies Breakthrough Likelihood Summary (All):")
print(table(breakthrough_predictions_ladies$all_candidates$Likelihood))
print("Ladies Breakthrough Likelihood Summary (Under 25):")
print(table(breakthrough_predictions_ladies$under25_candidates$Likelihood))

# High-potential breakthrough candidates for men
high_potential_men <- breakthrough_predictions_men$all_candidates %>%
  filter(Breakthrough_Prob >= 0.3) %>%
  arrange(desc(Breakthrough_Prob))

if(nrow(high_potential_men) > 0) {
  print("High-Potential Men's Breakthrough Candidates (≥30% probability):")
  print(high_potential_men %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No men's skiers with ≥30% breakthrough probability identified")
}

# High-potential breakthrough candidates for ladies
high_potential_ladies <- breakthrough_predictions_ladies$all_candidates %>%
  filter(Breakthrough_Prob >= 0.3) %>%
  arrange(desc(Breakthrough_Prob))

if(nrow(high_potential_ladies) > 0) {
  print("High-Potential Ladies Breakthrough Candidates (≥30% probability):")
  print(high_potential_ladies %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No ladies skiers with ≥30% breakthrough probability identified")
}

# Young breakthrough prospects (age ≤ 25) - using dedicated under25 dataframes
young_prospects_men <- breakthrough_predictions_men$under25_candidates %>%
  arrange(desc(Breakthrough_Prob)) %>%
  head(10)

if(nrow(young_prospects_men) > 0) {
  print("=== TOP YOUNG MEN'S BREAKTHROUGH PROSPECTS (Age ≤ 25) ===")
  print(young_prospects_men %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No young men's breakthrough prospects identified")
}

# Young breakthrough prospects (age ≤ 25) for ladies  
young_prospects_ladies <- breakthrough_predictions_ladies$under25_candidates %>%
  arrange(desc(Breakthrough_Prob)) %>%
  head(10)

if(nrow(young_prospects_ladies) > 0) {
  print("=== TOP YOUNG LADIES BREAKTHROUGH PROSPECTS (Age ≤ 25) ===")
  print(young_prospects_ladies %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No young ladies breakthrough prospects identified")
}

# Create Excel workbooks for breakthrough candidates
library(openxlsx)

# Men's breakthrough candidates workbook
men_breakthrough_workbook <- breakthrough_predictions_men$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob,
    Likelihood
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1)
  ) %>%
  arrange(desc(`Breakthrough Prob`))

# Ladies breakthrough candidates workbook  
ladies_breakthrough_workbook <- breakthrough_predictions_ladies$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob,
    Likelihood
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1)
  ) %>%
  arrange(desc(`Breakthrough Prob`))

# Create comparative analysis with historical breakthroughs
cat("\n=== HISTORICAL BREAKTHROUGH COMPARISON ===\n")

# Function to apply breakthrough model to historical data
predict_historical_breakthrough <- function(historical_data, breakthrough_model, top_predictors) {
  
  # Define mapping from prev variables to current Elo variables
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Downhill" = "Downhill_Pelo",
    "Prev_Super_G" = "Super G_Pelo", 
    "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
    "Prev_Slalom" = "Slalom_Pelo",
    "Prev_Combined" = "Combined_Pelo",
    "Prev_Tech" = "Tech_Pelo",
    "Prev_Speed" = "Speed_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points"
  )
  
  # Create prediction dataset by mapping current values to prev_ names
  prediction_data <- historical_data
  
  for(prev_var in names(predictor_mapping)) {
    if(prev_var %in% top_predictors) {
      current_var <- predictor_mapping[prev_var]
      if(current_var %in% names(historical_data)) {
        prediction_data[[prev_var]] <- prediction_data[[current_var]]
      }
    }
  }
  
  # Handle missing values with median imputation
  for(pred in top_predictors) {
    if(pred %in% names(prediction_data)) {
      na_count <- sum(is.na(prediction_data[[pred]]))
      if(na_count > 0) {
        pred_median <- median(prediction_data[[pred]], na.rm = TRUE)
        if(is.na(pred_median)) {
          pred_median <- 0
        }
        prediction_data[[pred]] <- ifelse(is.na(prediction_data[[pred]]),
                                        pred_median,
                                        prediction_data[[pred]])
      }
    }
  }
  
  # Make predictions
  tryCatch({
    breakthrough_probs <- predict(breakthrough_model,
                                 newdata = prediction_data,
                                 type = "prob")
    return(breakthrough_probs[,"Yes"])
  }, error = function(e) {
    warning("Error predicting historical breakthroughs: ", e$message)
    return(rep(0.5, nrow(prediction_data)))  # Default to 50% if prediction fails
  })
}

# Get historical breakthroughs for men
# Find skiers who achieved their first 20%+ season during our data period
first_year <- min(train_men$Season, na.rm = TRUE)
cat("First year in data:", first_year, "\n")

genuine_breakthroughs_men <- train_men %>%
  filter(!is.na(Pct_of_Max_Points), 
         !is.na(Skier),
         !is.na(Season),
         !is.na(Age)) %>%
  group_by(Skier) %>%
  arrange(Season) %>%
  mutate(
    ever_above_20 = any(Pct_of_Max_Points >= 0.2),
    first_season = min(Season),
    first_breakthrough_season = min(Season[Pct_of_Max_Points > 0.2]),
    # Only consider seasons BEFORE the breakthrough as "early" for comparison
    early_performance = ifelse(Season < first_breakthrough_season, Pct_of_Max_Points, NA),
    max_early_performance = max(early_performance, na.rm = TRUE)
  ) %>%
  filter(
    ever_above_20,  # Must have achieved ≥20% at some point
    !is.infinite(max_early_performance),  # Must have early season data
    max_early_performance < 0.2,  # Was not already above 20% in early seasons
    Pct_of_Max_Points >= 0.2  # This is a breakthrough season (≥20%)
  ) %>%
  slice(1) %>%  # Take first breakthrough season
  ungroup()

cat("Men with genuine breakthroughs (≥20%):", nrow(genuine_breakthroughs_men), "\n")

# Apply current model to historical men's data using PREVIOUS season data
historical_breakthroughs_men <- data.frame()
if(nrow(genuine_breakthroughs_men) > 0) {
  # Get the season before breakthrough for each skier to make fair predictions
  historical_men_prev_season <- genuine_breakthroughs_men %>%
    dplyr::select(Skier, breakthrough_season = Season, breakthrough_pct = Pct_of_Max_Points) %>%
    mutate(prev_season = breakthrough_season - 1) %>%
    left_join(
      train_men %>%
        dplyr::select(Skier, Season, everything()),
      by = c("Skier" = "Skier", "prev_season" = "Season")
    ) %>%
    filter(!is.na(Pct_of_Max_Points))  # Only keep cases where we have previous season data
  
  if(nrow(historical_men_prev_season) > 0) {
    historical_men_probs <- predict_historical_breakthrough(
      historical_men_prev_season,
      breakthrough_analysis_men$reduced_model,
      breakthrough_analysis_men$top_predictors
    )
    
    historical_breakthroughs_men <- historical_men_prev_season %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Pre-Breakthrough Pct` = Pct_of_Max_Points,
        breakthrough_pct,
        Season = breakthrough_season
      ) %>%
      mutate(
        `Pre-Breakthrough Pct` = round(`Pre-Breakthrough Pct` * 100, 1),
        `Breakthrough Result` = round(breakthrough_pct * 100, 1),
        `Predicted Prob` = round(historical_men_probs * 100, 1),
        Type = "Historical Success"
      )
    
    cat("Historical men's breakthroughs with predictions:", nrow(historical_breakthroughs_men), "\n")
  }
}

# Get historical breakthroughs for ladies
genuine_breakthroughs_ladies <- train_ladies %>%
  filter(!is.na(Pct_of_Max_Points), 
         !is.na(Skier),
         !is.na(Season),
         !is.na(Age)) %>%
  group_by(Skier) %>%
  arrange(Season) %>%
  mutate(
    ever_above_20 = any(Pct_of_Max_Points >= 0.2),
    first_season = min(Season),
    first_breakthrough_season = min(Season[Pct_of_Max_Points > 0.2]),
    # Only consider seasons BEFORE the breakthrough as "early" for comparison
    early_performance = ifelse(Season < first_breakthrough_season, Pct_of_Max_Points, NA),
    max_early_performance = max(early_performance, na.rm = TRUE)
  ) %>%
  filter(
    ever_above_20,  # Must have achieved ≥20% at some point
    !is.infinite(max_early_performance),  # Must have early season data
    max_early_performance < 0.2,  # Was not already above 20% in early seasons
    Pct_of_Max_Points >= 0.2  # This is a breakthrough season (≥20%)
  ) %>%
  slice(1) %>%  # Take first breakthrough season
  ungroup()

cat("Ladies with genuine breakthroughs (≥20%):", nrow(genuine_breakthroughs_ladies), "\n")

# Apply current model to historical ladies data using PREVIOUS season data
historical_breakthroughs_ladies <- data.frame()
if(nrow(genuine_breakthroughs_ladies) > 0) {
  # Get the season before breakthrough for each skier to make fair predictions
  historical_ladies_prev_season <- genuine_breakthroughs_ladies %>%
    dplyr::select(Skier, breakthrough_season = Season, breakthrough_pct = Pct_of_Max_Points) %>%
    mutate(prev_season = breakthrough_season - 1) %>%
    left_join(
      train_ladies %>%
        dplyr::select(Skier, Season, everything()),
      by = c("Skier" = "Skier", "prev_season" = "Season")
    ) %>%
    filter(!is.na(Pct_of_Max_Points))  # Only keep cases where we have previous season data
  
  if(nrow(historical_ladies_prev_season) > 0) {
    historical_ladies_probs <- predict_historical_breakthrough(
      historical_ladies_prev_season,
      breakthrough_analysis_ladies$reduced_model,
      breakthrough_analysis_ladies$top_predictors
    )
    
    historical_breakthroughs_ladies <- historical_ladies_prev_season %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Pre-Breakthrough Pct` = Pct_of_Max_Points,
        breakthrough_pct,
        Season = breakthrough_season
      ) %>%
      mutate(
        `Pre-Breakthrough Pct` = round(`Pre-Breakthrough Pct` * 100, 1),
        `Breakthrough Result` = round(breakthrough_pct * 100, 1),
        `Predicted Prob` = round(historical_ladies_probs * 100, 1),
        Type = "Historical Success"
      )
    
    cat("Historical ladies breakthroughs with predictions:", nrow(historical_breakthroughs_ladies), "\n")
  }
}

# Add current year predictions for comparison
current_men_predictions <- breakthrough_predictions_men$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pre-Breakthrough Pct` = Pct_of_Max_Points,
    `Predicted Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pre-Breakthrough Pct` = round(`Pre-Breakthrough Pct` * 100, 1),
    `Breakthrough Result` = NA,  # Unknown - this is a prediction
    `Predicted Prob` = round(`Predicted Prob` * 100, 1),
    Season = 2026,
    Type = "2026 Prediction"
  ) %>%
  arrange(desc(`Predicted Prob`)) %>%
  head(15)  # Top 15 current predictions

current_ladies_predictions <- breakthrough_predictions_ladies$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pre-Breakthrough Pct` = Pct_of_Max_Points,
    `Predicted Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pre-Breakthrough Pct` = round(`Pre-Breakthrough Pct` * 100, 1),
    `Breakthrough Result` = NA,  # Unknown - this is a prediction
    `Predicted Prob` = round(`Predicted Prob` * 100, 1),
    Season = 2026,
    Type = "2026 Prediction"
  ) %>%
  arrange(desc(`Predicted Prob`)) %>%
  head(15)  # Top 15 current predictions

# Combine historical and current data for comparison
comparative_men <- bind_rows(historical_breakthroughs_men, current_men_predictions) %>%
  arrange(desc(`Predicted Prob`), Season) %>%
  dplyr::select(Name, Nation, Age, `Pre-Breakthrough Pct`, `Breakthrough Result`, 
                `Predicted Prob`, Season, Type)

comparative_ladies <- bind_rows(historical_breakthroughs_ladies, current_ladies_predictions) %>%
  arrange(desc(`Predicted Prob`), Season) %>%
  dplyr::select(Name, Nation, Age, `Pre-Breakthrough Pct`, `Breakthrough Result`, 
                `Predicted Prob`, Season, Type)

print("=== HISTORICAL VS 2026 BREAKTHROUGH COMPARISON (MEN) ===")
print(comparative_men)

print("=== HISTORICAL VS 2026 BREAKTHROUGH COMPARISON (LADIES) ===")
print(comparative_ladies)

# Export to Excel with error handling
tryCatch({
  # Ensure output directory exists
  output_dir <- "excel365"
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Write men's breakthrough candidates
  men_file <- file.path(output_dir, "mens_breakthrough_candidates_2026.xlsx")
  write.xlsx(men_breakthrough_workbook, men_file, rowNames = FALSE)
  cat("✓ Men's alpine breakthrough candidates saved to:", men_file, "\n")
  
  # Write ladies breakthrough candidates
  ladies_file <- file.path(output_dir, "ladies_breakthrough_candidates_2026.xlsx")
  write.xlsx(ladies_breakthrough_workbook, ladies_file, rowNames = FALSE)
  cat("✓ Ladies alpine breakthrough candidates saved to:", ladies_file, "\n")
  
  # Write comparative analysis files
  comparative_men_file <- file.path(output_dir, "mens_breakthrough_comparison_historical_vs_2026.xlsx")
  write.xlsx(comparative_men, comparative_men_file, rowNames = FALSE)
  cat("✓ Men's historical comparison saved to:", comparative_men_file, "\n")
  
  comparative_ladies_file <- file.path(output_dir, "ladies_breakthrough_comparison_historical_vs_2026.xlsx")
  write.xlsx(comparative_ladies, comparative_ladies_file, rowNames = FALSE)
  cat("✓ Ladies historical comparison saved to:", comparative_ladies_file, "\n")
  
  cat("Breakthrough analysis exported:", nrow(men_breakthrough_workbook), "men and", 
      nrow(ladies_breakthrough_workbook), "ladies candidates\n")
  
}, error = function(e) {
  cat("Error exporting breakthrough candidates to Excel:", e$message, "\n")
})
```

### Age-Adjusted 2026 Predictions

```{r df82}
cat("=== DF82 COMPREHENSIVE DATASET VALIDATION ===\n")

# Enhanced function to replace NAs with the first quartile within each group
replace_na_with_quartile <- function(x) {
  tryCatch({
    if (length(x) == 0) {
      warning("Empty vector passed to replace_na_with_quartile")
      return(numeric(0))
    }
    
    # Remove NAs to calculate quartile
    non_na_values <- x[!is.na(x)]
    
    if (length(non_na_values) == 0) {
      # All values are NA
      return(rep(0, length(x)))
    }
    
    # Calculate first quartile
    q1 <- quantile(non_na_values, 0.25, na.rm = TRUE)
    
    # Replace NAs with first quartile
    result <- ifelse(is.na(x), q1, x)
    return(result)
    
  }, error = function(e) {
    warning("Error in replace_na_with_quartile: ", e$message, " - using 0 as fallback")
    return(ifelse(is.na(x), 0, x))
  })
}

# Create comprehensive df82-style dataset for age analysis
cat("Creating comprehensive alpine dataset (df82 style)\n")

# Process men's alpine data following df82 methodology
cat("\n--- Men's Alpine Data Processing ---\n")

tryCatch({
  # Validate input data
  if (!exists("M_elo")) stop("M_elo data not found")
  if (nrow(M_elo) == 0) stop("M_elo data is empty")
  
  # Validate required columns exist
  required_cols <- c("Skier", "Nation", "Season", "Age", "Pct_of_Max_Points")
  missing_cols <- setdiff(required_cols, names(M_elo))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in M_elo: ", paste(missing_cols, collapse = ", "))
  }
  
  # Check for ELO columns
  elo_cols <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
               "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")
  available_elo_cols <- intersect(elo_cols, names(M_elo))
  
  if (length(available_elo_cols) == 0) {
    stop("No ELO columns found in M_elo")
  }
  
  cat("Available ELO columns:", length(available_elo_cols), "\n")
  cat("✓ Input validation passed for men's alpine data\n")
  
  df82_men <- M_elo %>%
    # Filter for seasons with sufficient data
    filter(Season >= 1981) %>%
    # Remove any invalid entries
    filter(!is.na(Skier), 
           !is.na(Season),
           !is.na(Age)) %>%
    # Arrange by season and skier
    arrange(Skier, Season) %>%
    # Group by skier and season to get season-end values
    group_by(Skier, Season) %>%
    arrange(desc(Season)) %>%
    slice(1) %>%  # Take the last entry for each skier in each season
    ungroup()
  
  # Validate processed data
  if (nrow(df82_men) == 0) stop("No data remaining after men's processing")
  
  # Check for data quality issues
  invalid_age <- sum(is.na(df82_men$Age) | df82_men$Age < 10 | df82_men$Age > 60)
  if (invalid_age > 0) {
    warning("Found ", invalid_age, " invalid Age values in men's data")
  }
  
  invalid_pct <- sum(is.na(df82_men$Pct_of_Max_Points) | 
                    df82_men$Pct_of_Max_Points < 0 | 
                    df82_men$Pct_of_Max_Points > 2)
  if (invalid_pct > 0) {
    warning("Found ", invalid_pct, " invalid Pct_of_Max_Points values in men's data")
  }
  
  cat("✓ Men's alpine data processing completed:", nrow(df82_men), "observations\n")
  
}, error = function(e) {
  stop("Error processing men's alpine data: ", e$message)
})

# Create ELO dataframe with previous season values for men
cat("\n--- Men's Alpine ELO Dataframe Creation ---\n")

tryCatch({
  # Validate df82_men exists and has required columns
  if (!exists("df82_men")) stop("df82_men not found")
  if (nrow(df82_men) == 0) stop("df82_men is empty")
  
  # Check available ELO columns
  elo_cols_to_check <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                        "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")
  available_elos <- intersect(elo_cols_to_check, names(df82_men))
  
  if (length(available_elos) == 0) {
    stop("No ELO columns available for processing")
  }
  
  cat("Processing ELO columns:", paste(available_elos, collapse = ", "), "\n")
  
  elo_df82 <- df82_men %>%
    arrange(Skier, Season) %>%
    group_by(Skier) %>%
    mutate(
      # Create previous season ELO values
      Prev_Pelo = lag(Pelo),
      Prev_Downhill = lag(Downhill_Pelo),
      Prev_SuperG = lag(`Super G_Pelo`),
      Prev_GiantSlalom = lag(`Giant Slalom_Pelo`),
      Prev_Slalom = lag(Slalom_Pelo),
      Prev_Combined = lag(Combined_Pelo),
      Prev_Tech = lag(Tech_Pelo),
      Prev_Speed = lag(Speed_Pelo),
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points),
      Prev_Age = lag(Age)
    ) %>%
    ungroup() %>%
    filter(Season > 1981)  # Need at least one previous season
  
  # Validate ELO dataframe
  if (nrow(elo_df82) == 0) stop("No data remaining after ELO processing")
  
  # Check for excessive missing values in previous season data
  prev_cols <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", 
                "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  
  for (col in prev_cols) {
    if (col %in% names(elo_df82)) {
      na_count <- sum(is.na(elo_df82[[col]]))
      na_pct <- (na_count / nrow(elo_df82)) * 100
      if (na_pct > 75) {
        warning("High missing data (", round(na_pct, 1), "%) in column: ", col)
      }
    }
  }
  
  cat("✓ Men's alpine ELO dataframe created:", nrow(elo_df82), "observations\n")
  cat("Unique skiers:", length(unique(elo_df82$Skier)), "\n")
  cat("Season range:", min(elo_df82$Season), "to", max(elo_df82$Season), "\n")
  
}, error = function(e) {
  stop("Error creating men's alpine ELO dataframe: ", e$message)
})

# Handle missing values in previous season data with validation
cat("\n--- Men's Alpine Missing Value Imputation ---\n")

tryCatch({
  # Validate elo_df82 exists
  if (!exists("elo_df82")) stop("elo_df82 not found")
  if (nrow(elo_df82) == 0) stop("elo_df82 is empty")
  
  # Count missing values before imputation
  prev_vars <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", 
                "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  
  missing_before <- sapply(prev_vars, function(var) {
    if (var %in% names(elo_df82)) {
      sum(is.na(elo_df82[[var]]))
    } else {
      0
    }
  })
  
  cat("Missing values before imputation:\n")
  for (i in seq_along(missing_before)) {
    if (missing_before[i] > 0) {
      cat("-", names(missing_before)[i], ":", missing_before[i], "\n")
    }
  }
  
  df82_final <- elo_df82 %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_SuperG = replace_na_with_quartile(Prev_SuperG),
      Prev_GiantSlalom = replace_na_with_quartile(Prev_GiantSlalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate final data
  if (nrow(df82_final) == 0) stop("No data remaining after missing value imputation")
  
  # Count missing values after imputation
  missing_after <- sapply(prev_vars, function(var) {
    if (var %in% names(df82_final)) {
      sum(is.na(df82_final[[var]]))
    } else {
      0
    }
  })
  
  # Check if imputation was successful
  remaining_missing <- sum(missing_after)
  if (remaining_missing > 0) {
    warning("Still have ", remaining_missing, " missing values after imputation")
  }
  
  # Validate data ranges
  numeric_cols <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                   "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed")
  
  for (col in numeric_cols) {
    if (col %in% names(df82_final)) {
      invalid_vals <- sum(!is.finite(df82_final[[col]]) | df82_final[[col]] < 0, na.rm = TRUE)
      if (invalid_vals > 0) {
        warning("Found ", invalid_vals, " invalid values in ", col)
      }
    }
  }
  
  cat("✓ Men's alpine missing value imputation completed\n")
  cat("Final dataset:", nrow(df82_final), "observations\n")
  
}, error = function(e) {
  stop("Error handling missing values in men's alpine data: ", e$message)
})

# Process ladies alpine data with same methodology
cat("\n--- Ladies Alpine Data Processing ---\n")

tryCatch({
  # Validate input data
  if (!exists("L_elo")) stop("L_elo data not found")
  if (nrow(L_elo) == 0) stop("L_elo data is empty")
  
  # Validate required columns exist
  required_cols <- c("Skier", "Nation", "Season", "Age", "Pct_of_Max_Points")
  missing_cols <- setdiff(required_cols, names(L_elo))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in L_elo: ", paste(missing_cols, collapse = ", "))
  }
  
  # Check for ELO columns
  elo_cols <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
               "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")
  available_elo_cols <- intersect(elo_cols, names(L_elo))
  
  if (length(available_elo_cols) == 0) {
    stop("No ELO columns found in L_elo")
  }
  
  cat("Available ladies ELO columns:", length(available_elo_cols), "\n")
  cat("✓ Input validation passed for ladies alpine data\n")
  
  df82_ladies <- L_elo %>%
    # Filter for seasons with sufficient data
    filter(Season >= 1981) %>%
    # Remove any invalid entries
    filter(!is.na(Skier), 
           !is.na(Season),
           !is.na(Age)) %>%
    # Arrange by season and skier
    arrange(Skier, Season) %>%
    # Group by skier and season to get season-end values
    group_by(Skier, Season) %>%
    arrange(desc(Season)) %>%
    slice(1) %>%  # Take the last entry for each skier in each season
    ungroup()
  
  # Validate processed data
  if (nrow(df82_ladies) == 0) stop("No data remaining after ladies processing")
  
  # Check for data quality issues
  invalid_age <- sum(is.na(df82_ladies$Age) | df82_ladies$Age < 10 | df82_ladies$Age > 60)
  if (invalid_age > 0) {
    warning("Found ", invalid_age, " invalid Age values in ladies data")
  }
  
  invalid_pct <- sum(is.na(df82_ladies$Pct_of_Max_Points) | 
                    df82_ladies$Pct_of_Max_Points < 0 | 
                    df82_ladies$Pct_of_Max_Points > 2)
  if (invalid_pct > 0) {
    warning("Found ", invalid_pct, " invalid Pct_of_Max_Points values in ladies data")
  }
  
  cat("✓ Ladies alpine data processing completed:", nrow(df82_ladies), "observations\n")
  
}, error = function(e) {
  stop("Error processing ladies alpine data: ", e$message)
})

# Create ladies ELO dataframe with previous season values
cat("\n--- Ladies Alpine ELO Dataframe Creation ---\n")

tryCatch({
  # Validate df82_ladies exists and has required columns
  if (!exists("df82_ladies")) stop("df82_ladies not found")
  if (nrow(df82_ladies) == 0) stop("df82_ladies is empty")
  
  # Check available ELO columns
  elo_cols_to_check <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                        "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")
  available_elos <- intersect(elo_cols_to_check, names(df82_ladies))
  
  if (length(available_elos) == 0) {
    stop("No ELO columns available for ladies processing")
  }
  
  cat("Processing ladies ELO columns:", paste(available_elos, collapse = ", "), "\n")
  
  elo_df82_ladies <- df82_ladies %>%
    arrange(Skier, Season) %>%
    group_by(Skier) %>%
    mutate(
      # Create previous season ELO values
      Prev_Pelo = lag(Pelo),
      Prev_Downhill = lag(Downhill_Pelo),
      Prev_SuperG = lag(`Super G_Pelo`),
      Prev_GiantSlalom = lag(`Giant Slalom_Pelo`),
      Prev_Slalom = lag(Slalom_Pelo),
      Prev_Combined = lag(Combined_Pelo),
      Prev_Tech = lag(Tech_Pelo),
      Prev_Speed = lag(Speed_Pelo),
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points),
      Prev_Age = lag(Age)
    ) %>%
    ungroup() %>%
    filter(Season > 1981)  # Need at least one previous season
  
  # Validate ELO dataframe
  if (nrow(elo_df82_ladies) == 0) stop("No data remaining after ladies ELO processing")
  
  # Check for excessive missing values in previous season data
  prev_cols <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", 
                "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  
  for (col in prev_cols) {
    if (col %in% names(elo_df82_ladies)) {
      na_count <- sum(is.na(elo_df82_ladies[[col]]))
      na_pct <- (na_count / nrow(elo_df82_ladies)) * 100
      if (na_pct > 75) {
        warning("High missing data (", round(na_pct, 1), "%) in column: ", col)
      }
    }
  }
  
  cat("✓ Ladies alpine ELO dataframe created:", nrow(elo_df82_ladies), "observations\n")
  cat("Unique skiers:", length(unique(elo_df82_ladies$Skier)), "\n")
  cat("Season range:", min(elo_df82_ladies$Season), "to", max(elo_df82_ladies$Season), "\n")
  
}, error = function(e) {
  stop("Error creating ladies alpine ELO dataframe: ", e$message)
})

# Handle missing values in previous season data for ladies with validation
cat("\n--- Ladies Alpine Missing Value Imputation ---\n")

tryCatch({
  # Validate elo_df82_ladies exists
  if (!exists("elo_df82_ladies")) stop("elo_df82_ladies not found")
  if (nrow(elo_df82_ladies) == 0) stop("elo_df82_ladies is empty")
  
  # Count missing values before imputation
  prev_vars <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", 
                "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  
  missing_before <- sapply(prev_vars, function(var) {
    if (var %in% names(elo_df82_ladies)) {
      sum(is.na(elo_df82_ladies[[var]]))
    } else {
      0
    }
  })
  
  cat("Missing values before imputation:\n")
  for (i in seq_along(missing_before)) {
    if (missing_before[i] > 0) {
      cat("-", names(missing_before)[i], ":", missing_before[i], "\n")
    }
  }
  
  df82_final_ladies <- elo_df82_ladies %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_SuperG = replace_na_with_quartile(Prev_SuperG),
      Prev_GiantSlalom = replace_na_with_quartile(Prev_GiantSlalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate final data
  if (nrow(df82_final_ladies) == 0) stop("No data remaining after ladies missing value imputation")
  
  # Count missing values after imputation
  missing_after <- sapply(prev_vars, function(var) {
    if (var %in% names(df82_final_ladies)) {
      sum(is.na(df82_final_ladies[[var]]))
    } else {
      0
    }
  })
  
  # Check if imputation was successful
  remaining_missing <- sum(missing_after)
  if (remaining_missing > 0) {
    warning("Still have ", remaining_missing, " missing values after imputation")
  }
  
  # Validate data ranges
  numeric_cols <- c("Prev_Pelo", "Prev_Downhill", "Prev_SuperG", 
                   "Prev_GiantSlalom", "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed")
  
  for (col in numeric_cols) {
    if (col %in% names(df82_final_ladies)) {
      invalid_vals <- sum(!is.finite(df82_final_ladies[[col]]) | df82_final_ladies[[col]] < 0, na.rm = TRUE)
      if (invalid_vals > 0) {
        warning("Found ", invalid_vals, " invalid values in ", col)
      }
    }
  }
  
  cat("✓ Ladies alpine missing value imputation completed\n")
  cat("Final dataset:", nrow(df82_final_ladies), "observations\n")
  
}, error = function(e) {
  stop("Error handling missing values in ladies alpine data: ", e$message)
})

# Final validation and summary reporting
cat("\n--- Final DF82 Alpine Dataset Summary ---\n")

tryCatch({
  # Validate final datasets exist
  if (!exists("df82_final")) stop("df82_final not found")
  if (!exists("df82_final_ladies")) stop("df82_final_ladies not found")
  
  # Men's dataset summary
  if (nrow(df82_final) > 0) {
    cat("Men's comprehensive alpine dataset:", nrow(df82_final), "observations\n")
    cat("Men's seasons covered:", min(df82_final$Season), "to", max(df82_final$Season), "\n")
    cat("Unique men's alpine skiers:", length(unique(df82_final$Skier)), "\n")
    
    # Sample of recent data
    recent_men <- df82_final %>%
      filter(Season >= 2020) %>%
      arrange(desc(Season), desc(Pelo)) %>%
      head(10)
    
    if (nrow(recent_men) > 0) {
      cat("Sample recent men's data (2020+):\n")
      print(recent_men %>% 
            dplyr::select(Skier, Nation, Season, Age, Pelo, Pct_of_Max_Points))
    }
  } else {
    warning("Men's final alpine dataset is empty")
  }
  
  # Ladies dataset summary
  if (nrow(df82_final_ladies) > 0) {
    cat("Ladies comprehensive alpine dataset:", nrow(df82_final_ladies), "observations\n")
    cat("Ladies seasons covered:", min(df82_final_ladies$Season), "to", max(df82_final_ladies$Season), "\n")
    cat("Unique ladies alpine skiers:", length(unique(df82_final_ladies$Skier)), "\n")
    
    # Sample of recent data
    recent_ladies <- df82_final_ladies %>%
      filter(Season >= 2020) %>%
      arrange(desc(Season), desc(Pelo)) %>%
      head(10)
    
    if (nrow(recent_ladies) > 0) {
      cat("Sample recent ladies data (2020+):\n")
      print(recent_ladies %>% 
            dplyr::select(Skier, Nation, Season, Age, Pelo, Pct_of_Max_Points))
    }
  } else {
    warning("Ladies final alpine dataset is empty")
  }
  
  cat("✓ DF82 alpine dataset creation completed successfully\n")
  
}, error = function(e) {
  stop("Error in final DF82 alpine validation: ", e$message)
})
```

### Age-Based Performance Analysis

```{r age-exploration}
cat("=== ALPINE AGE EXPLORATION VALIDATION ===\n")

# Simple GAM-based age prediction function adapted for alpine skiing
predict_elo_with_age_gam <- function(df, min_exp = 20) {
  cat("\n--- GAM-based Age Prediction Function ---\n")
  
  # Filter data
  gam_data <- df %>%
    filter(!is.na(Age), Age >= 15, Age <= 40) %>%
    filter(Exp >= min_exp) %>%
    filter(!is.na(Prev_Pelo), !is.na(Pelo)) %>%
    filter(Prev_Pelo > 0, Pelo > 0)
  
  cat("GAM training data:", nrow(gam_data), "observations\n")
  
  # Fit GAM models for key alpine ELO types
  gam_models <- list()
  
  # Pelo GAM (overall alpine rating)
  if (nrow(gam_data) >= 50) {
    tryCatch({
      pelo_gam <- gam(Pelo ~ s(Age) + s(Prev_Pelo), data = gam_data)
      gam_models$Pelo <- pelo_gam
      cat("✓ Pelo GAM fitted - R²:", round(summary(pelo_gam)$r.sq, 3), "\n")
    }, error = function(e) cat("✗ Pelo GAM failed:", e$message, "\n"))
    
    # Downhill GAM
    if (sum(!is.na(gam_data$Downhill_Pelo) & !is.na(gam_data$Prev_Downhill)) >= 50) {
      tryCatch({
        downhill_gam <- gam(Downhill_Pelo ~ s(Age) + s(Prev_Downhill), data = gam_data)
        gam_models$Downhill <- downhill_gam
        cat("✓ Downhill GAM fitted - R²:", round(summary(downhill_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Downhill GAM failed:", e$message, "\n"))
    }
    
    # Super G GAM
    if (sum(!is.na(gam_data$`Super G_Pelo`) & !is.na(gam_data$Prev_SuperG)) >= 50) {
      tryCatch({
        superg_gam <- gam(`Super G_Pelo` ~ s(Age) + s(Prev_SuperG), data = gam_data)
        gam_models$SuperG <- superg_gam
        cat("✓ Super G GAM fitted - R²:", round(summary(superg_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Super G GAM failed:", e$message, "\n"))
    }
    
    # Giant Slalom GAM
    if (sum(!is.na(gam_data$`Giant Slalom_Pelo`) & !is.na(gam_data$Prev_GiantSlalom)) >= 50) {
      tryCatch({
        gs_gam <- gam(`Giant Slalom_Pelo` ~ s(Age) + s(Prev_GiantSlalom), data = gam_data)
        gam_models$GiantSlalom <- gs_gam
        cat("✓ Giant Slalom GAM fitted - R²:", round(summary(gs_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Giant Slalom GAM failed:", e$message, "\n"))
    }
    
    # Slalom GAM
    if (sum(!is.na(gam_data$Slalom_Pelo) & !is.na(gam_data$Prev_Slalom)) >= 50) {
      tryCatch({
        slalom_gam <- gam(Slalom_Pelo ~ s(Age) + s(Prev_Slalom), data = gam_data)
        gam_models$Slalom <- slalom_gam
        cat("✓ Slalom GAM fitted - R²:", round(summary(slalom_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Slalom GAM failed:", e$message, "\n"))
    }
    
    # Technical disciplines GAM (Slalom + Giant Slalom)
    if (sum(!is.na(gam_data$Tech_Pelo) & !is.na(gam_data$Prev_Tech)) >= 50) {
      tryCatch({
        tech_gam <- gam(Tech_Pelo ~ s(Age) + s(Prev_Tech), data = gam_data)
        gam_models$Tech <- tech_gam
        cat("✓ Tech GAM fitted - R²:", round(summary(tech_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Tech GAM failed:", e$message, "\n"))
    }
    
    # Speed disciplines GAM (Downhill + Super G)
    if (sum(!is.na(gam_data$Speed_Pelo) & !is.na(gam_data$Prev_Speed)) >= 50) {
      tryCatch({
        speed_gam <- gam(Speed_Pelo ~ s(Age) + s(Prev_Speed), data = gam_data)
        gam_models$Speed <- speed_gam
        cat("✓ Speed GAM fitted - R²:", round(summary(speed_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Speed GAM failed:", e$message, "\n"))
    }
  }
  
  # Create prediction function
  predict_age_elos <- function(age, prev_pelo, prev_downhill = NULL, prev_superg = NULL, 
                              prev_giantslalom = NULL, prev_slalom = NULL, 
                              prev_tech = NULL, prev_speed = NULL) {
    predictions <- list()
    
    # Predict Pelo
    if ("Pelo" %in% names(gam_models) && !is.na(prev_pelo) && prev_pelo > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Pelo = prev_pelo)
        predictions$Predicted_Pelo <- max(0, predict(gam_models$Pelo, pred_data))
      }, error = function(e) {
        predictions$Predicted_Pelo <- prev_pelo  # Fallback
      })
    } else {
      predictions$Predicted_Pelo <- prev_pelo
    }
    
    # Predict Downhill
    if ("Downhill" %in% names(gam_models) && !is.na(prev_downhill) && prev_downhill > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Downhill = prev_downhill)
        predictions$Predicted_Downhill <- max(0, predict(gam_models$Downhill, pred_data))
      }, error = function(e) {
        predictions$Predicted_Downhill <- prev_downhill  # Fallback
      })
    } else {
      predictions$Predicted_Downhill <- prev_downhill
    }
    
    # Predict Super G
    if ("SuperG" %in% names(gam_models) && !is.na(prev_superg) && prev_superg > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_SuperG = prev_superg)
        predictions$Predicted_SuperG <- max(0, predict(gam_models$SuperG, pred_data))
      }, error = function(e) {
        predictions$Predicted_SuperG <- prev_superg  # Fallback
      })
    } else {
      predictions$Predicted_SuperG <- prev_superg
    }
    
    # Predict Giant Slalom
    if ("GiantSlalom" %in% names(gam_models) && !is.na(prev_giantslalom) && prev_giantslalom > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_GiantSlalom = prev_giantslalom)
        predictions$Predicted_GiantSlalom <- max(0, predict(gam_models$GiantSlalom, pred_data))
      }, error = function(e) {
        predictions$Predicted_GiantSlalom <- prev_giantslalom  # Fallback
      })
    } else {
      predictions$Predicted_GiantSlalom <- prev_giantslalom
    }
    
    # Predict Slalom
    if ("Slalom" %in% names(gam_models) && !is.na(prev_slalom) && prev_slalom > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Slalom = prev_slalom)
        predictions$Predicted_Slalom <- max(0, predict(gam_models$Slalom, pred_data))
      }, error = function(e) {
        predictions$Predicted_Slalom <- prev_slalom  # Fallback
      })
    } else {
      predictions$Predicted_Slalom <- prev_slalom
    }
    
    # Predict Tech
    if ("Tech" %in% names(gam_models) && !is.na(prev_tech) && prev_tech > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Tech = prev_tech)
        predictions$Predicted_Tech <- max(0, predict(gam_models$Tech, pred_data))
      }, error = function(e) {
        predictions$Predicted_Tech <- prev_tech  # Fallback
      })
    } else {
      predictions$Predicted_Tech <- prev_tech
    }
    
    # Predict Speed
    if ("Speed" %in% names(gam_models) && !is.na(prev_speed) && prev_speed > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Speed = prev_speed)
        predictions$Predicted_Speed <- max(0, predict(gam_models$Speed, pred_data))
      }, error = function(e) {
        predictions$Predicted_Speed <- prev_speed  # Fallback
      })
    } else {
      predictions$Predicted_Speed <- prev_speed
    }
    
    return(predictions)
  }
  
  cat("✓ GAM age prediction function created with", length(gam_models), "models\n")
  
  return(list(
    gam_models = gam_models,
    predict_function = predict_age_elos,
    training_data = gam_data
  ))
}

# GAM-based age progression analysis using data-driven smooth curves
# Fit GAM models for each alpine ELO type: Current_ELO ~ s(Age) + s(Previous_ELO)
analyze_elo_progression_by_age_gam <- function(df, min_exp = 20) {
  
  cat("\n--- GAM-based Age Progression Analysis Function ---\n")
  
  # Input validation
  tryCatch({
    if (!is.data.frame(df)) stop("Input 'df' is not a data frame")
    if (nrow(df) == 0) stop("Input dataframe is empty")
    if (!is.numeric(min_exp) || min_exp < 0) stop("min_exp must be a non-negative number")
    
    # Check for required columns (alpine skiing specific)
    required_cols <- c("Age", "Exp", "Pelo", "Prev_Pelo", "Downhill_Pelo", "Prev_Downhill",
                      "Super G_Pelo", "Prev_SuperG", "Giant Slalom_Pelo", "Prev_GiantSlalom",
                      "Slalom_Pelo", "Prev_Slalom", "Combined_Pelo", "Prev_Combined",
                      "Tech_Pelo", "Prev_Tech", "Speed_Pelo", "Prev_Speed")
    
    missing_cols <- setdiff(required_cols, names(df))
    if (length(missing_cols) > 0) {
      cat("Note: Some alpine ELO columns not found:", paste(missing_cols, collapse = ", "), "\n")
    }
    
    # Validate data quality
    na_age <- sum(is.na(df$Age))
    na_exp <- sum(is.na(df$Exp))
    
    if (na_age > nrow(df) * 0.5) {
      stop("More than 50% of Age values are missing")
    }
    if (na_exp > nrow(df) * 0.5) {
      stop("More than 50% of Exp values are missing")
    }
    
    cat("✓ Input validation passed\n")
    cat("Dataset size:", nrow(df), "observations\n")
    cat("Missing Age values:", na_age, "\n")
    cat("Missing Exp values:", na_exp, "\n")
    
  }, error = function(e) {
    stop("Input validation failed: ", e$message)
  })
  
  # All alpine ELO rating types to analyze
  elo_types <- list(
    "Pelo" = c("Pelo", "Prev_Pelo"),
    "Downhill_Pelo" = c("Downhill_Pelo", "Prev_Downhill"),
    "Super G_Pelo" = c("Super G_Pelo", "Prev_SuperG"), 
    "Giant Slalom_Pelo" = c("Giant Slalom_Pelo", "Prev_GiantSlalom"),
    "Slalom_Pelo" = c("Slalom_Pelo", "Prev_Slalom"),
    "Combined_Pelo" = c("Combined_Pelo", "Prev_Combined"),
    "Tech_Pelo" = c("Tech_Pelo", "Prev_Tech"),
    "Speed_Pelo" = c("Speed_Pelo", "Prev_Speed")
  )
  
  # Final validation and return
  tryCatch({
    result_list <- list(
      data = df
    )
    
    # Validate return components
    if (is.null(result_list$data) || nrow(result_list$data) == 0) {
      stop("Input dataframe is NULL or empty")
    }
    
    cat("\n✓ Alpine age analysis data preparation completed successfully\n")
    cat("Total observations:", nrow(result_list$data), "\n")
    
    return(result_list)
    
  }, error = function(e) {
    stop("Error creating return object: ", e$message)
  })
}

# Run GAM-based age progression analysis on comprehensive alpine datasets with validation
cat("\n=== MEN'S ALPINE GAM-BASED AGE PROGRESSION ANALYSIS ===\n")

tryCatch({
  # Validate input data exists
  if (!exists("df82_final")) stop("df82_final dataset not found")
  if (nrow(df82_final) == 0) stop("df82_final dataset is empty")
  
  age_analysis_men <- predict_elo_with_age_gam(df82_final)
  
  # Validate results
  if (is.null(age_analysis_men)) stop("Age analysis returned NULL for men")
  
  # Display GAM model information
  if (!is.null(age_analysis_men$gam_models) && length(age_analysis_men$gam_models) > 0) {
    cat("\nMen's alpine GAM-based ELO prediction models:\n")
    for (model_name in names(age_analysis_men$gam_models)) {
      model <- age_analysis_men$gam_models[[model_name]]
      cat(sprintf("- %s GAM: R² = %.3f, Training obs = %d\n", 
                  model_name, summary(model)$r.sq, nrow(model$model)))
    }
  } else {
    cat("No GAM models available for men\n")
  }
  
  cat("\nMen's alpine GAM age analysis summary:\n")
  cat("- Training observations:", nrow(age_analysis_men$training_data), "\n")
  cat("- GAM models fitted:", length(age_analysis_men$gam_models), "\n")
  
}, error = function(e) {
  stop("Error in men's alpine age progression analysis: ", e$message)
})

cat("\n=== LADIES ALPINE GAM-BASED AGE PROGRESSION ANALYSIS ===\n")

tryCatch({
  # Validate input data exists
  if (!exists("df82_final_ladies")) stop("df82_final_ladies dataset not found")
  if (nrow(df82_final_ladies) == 0) stop("df82_final_ladies dataset is empty")
  
  age_analysis_ladies <- predict_elo_with_age_gam(df82_final_ladies)
  
  # Validate results
  if (is.null(age_analysis_ladies)) stop("Age analysis returned NULL for ladies")
  
  # Display GAM model information
  if (!is.null(age_analysis_ladies$gam_models) && length(age_analysis_ladies$gam_models) > 0) {
    cat("\nLadies alpine GAM-based ELO prediction models:\n")
    for (model_name in names(age_analysis_ladies$gam_models)) {
      model <- age_analysis_ladies$gam_models[[model_name]]
      cat(sprintf("- %s GAM: R² = %.3f, Training obs = %d\n", 
                  model_name, summary(model)$r.sq, nrow(model$model)))
    }
  } else {
    cat("No GAM models available for ladies\n")
  }
  
  cat("\nLadies alpine GAM age analysis summary:\n")
  cat("- Training observations:", nrow(age_analysis_ladies$training_data), "\n")
  cat("- GAM models fitted:", length(age_analysis_ladies$gam_models), "\n")
  
}, error = function(e) {
  stop("Error in ladies alpine age progression analysis: ", e$message)
})

# Use men's analysis for backwards compatibility in subsequent sections with validation
tryCatch({
  if (!exists("age_analysis_men") || is.null(age_analysis_men)) {
    stop("Men's age analysis not available for backwards compatibility")
  }
  
  age_analysis <- age_analysis_men
  cat("\n✓ Alpine age analysis stored for backwards compatibility\n")
  
}, error = function(e) {
  warning("Could not set backwards compatibility: ", e$message)
  age_analysis <- NULL
})
```

### GAM-Based Age-Adjusted 2026 Predictions

```{r age-adjusted-2025}
cat("=== ALPINE GAM-BASED AGE-ADJUSTED 2025 VALIDATION ===\n")

# Calculate GAM-based age-adjusted predictions for 2026 using 2025 alpine ELO values
cat("\nAlpine GAM-Based Age-Adjusted 2026 Predictions\n")

# Extract GAM prediction functions from analysis with validation
tryCatch({
  # Validate age_analysis exists and has required structure
  if (!exists("age_analysis")) stop("age_analysis not found")
  if (is.null(age_analysis)) stop("age_analysis is NULL")
  if (!"predict_function" %in% names(age_analysis)) {
    stop("predict_function not found in age_analysis")
  }
  
  # Extract GAM prediction function
  age_prediction_function <- age_analysis$predict_function
  
  # Validate GAM prediction function
  if (is.null(age_prediction_function)) stop("No GAM prediction function available")
  if (!is.function(age_prediction_function)) stop("age_prediction_function is not a function")
  
  cat("✓ Alpine GAM age prediction function extracted\n")
  
}, error = function(e) {
  stop("Error extracting alpine GAM age factors: ", e$message)
})

# Enhanced GAM-based prediction function with validation for alpine skiing
predict_2026_with_gam_age_adjustment <- function(current_data, gam_predict_func) {
  
  cat("\n--- Alpine GAM-Based Age Adjustment Prediction Function ---\n")
  
  # Input validation
  tryCatch({
    if (!is.data.frame(current_data)) stop("current_data is not a data frame")
    if (nrow(current_data) == 0) stop("current_data is empty")
    if (!is.function(gam_predict_func)) stop("gam_predict_func is not a function")
    
    # Check for required columns in current_data (alpine specific)
    required_cols <- c("Age", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                      "Slalom_Pelo", "Tech_Pelo", "Speed_Pelo", "Combined_Pelo", 
                      "Pelo", "Skier", "Nation", "Pct_of_Max_Points")
    missing_cols <- setdiff(required_cols, names(current_data))
    if (length(missing_cols) > 0) {
      cat("Note: Some alpine columns not found:", paste(missing_cols, collapse = ", "), "\n")
    }
    
    cat("✓ Alpine input validation passed\n")
    
  }, error = function(e) {
    stop("Alpine input validation failed: ", e$message)
  })
  
  # Data processing with validation for alpine disciplines
  tryCatch({
    # Check for missing age data before processing
    missing_age_count <- sum(is.na(current_data$Age))
    if (missing_age_count > 0) {
      warning("Found ", missing_age_count, " missing Age values in current_data")
    }
    
    predictions <- current_data %>%
      rowwise() %>%
      mutate(
        # Debug: Show age adjustment model input for Marcel Hirscher and Lara Colturi
        debug_age_input = {
          if (Skier %in% c("Marcel Hirscher", "Lara Colturi")) {
            cat("\n=== DEBUG: Age Adjustment Model Input for", Skier, "===\n")
            cat("Age:", Age, "\n")
            cat("Pelo:", Pelo, "\n")
            cat("Downhill_Pelo:", if("Downhill_Pelo" %in% names(.)) Downhill_Pelo else "NULL", "\n")
            cat("Super G_Pelo:", if("Super G_Pelo" %in% names(.)) `Super G_Pelo` else "NULL", "\n")
            cat("Giant Slalom_Pelo:", if("Giant Slalom_Pelo" %in% names(.)) `Giant Slalom_Pelo` else "NULL", "\n")
            cat("Slalom_Pelo:", if("Slalom_Pelo" %in% names(.)) Slalom_Pelo else "NULL", "\n")
            cat("Tech_Pelo:", if("Tech_Pelo" %in% names(.)) Tech_Pelo else "NULL", "\n")
            cat("Speed_Pelo:", if("Speed_Pelo" %in% names(.)) Speed_Pelo else "NULL", "\n")
            cat("=== End Debug Input ===\n\n")
          }
          TRUE
        },
        
        # Use GAM predictions for age-adjusted alpine ELO values
        gam_predictions = list(gam_predict_func(
          Age, 
          Pelo, 
          if("Downhill_Pelo" %in% names(.)) Downhill_Pelo else NULL,
          if("Super G_Pelo" %in% names(.)) `Super G_Pelo` else NULL,
          if("Giant Slalom_Pelo" %in% names(.)) `Giant Slalom_Pelo` else NULL,
          if("Slalom_Pelo" %in% names(.)) Slalom_Pelo else NULL,
          if("Tech_Pelo" %in% names(.)) Tech_Pelo else NULL,
          if("Speed_Pelo" %in% names(.)) Speed_Pelo else NULL
        )),
        
        # Debug: Show age adjustment model output for Marcel Hirscher and Lara Colturi
        debug_age_output = {
          if (Skier %in% c("Marcel Hirscher", "Lara Colturi")) {
            cat("\n=== DEBUG: Age Adjustment Model Output for", Skier, "===\n")
            cat("GAM Predictions Structure:\n")
            print(str(gam_predictions))
            if (!is.null(gam_predictions$Predicted_Pelo)) {
              cat("Predicted_Pelo:", gam_predictions$Predicted_Pelo, "\n")
            }
            if (!is.null(gam_predictions$Predicted_Downhill)) {
              cat("Predicted_Downhill:", gam_predictions$Predicted_Downhill, "\n")
            }
            if (!is.null(gam_predictions$Predicted_SuperG)) {
              cat("Predicted_SuperG:", gam_predictions$Predicted_SuperG, "\n")
            }
            if (!is.null(gam_predictions$Predicted_GiantSlalom)) {
              cat("Predicted_GiantSlalom:", gam_predictions$Predicted_GiantSlalom, "\n")
            }
            if (!is.null(gam_predictions$Predicted_Slalom)) {
              cat("Predicted_Slalom:", gam_predictions$Predicted_Slalom, "\n")
            }
            if (!is.null(gam_predictions$Predicted_Tech)) {
              cat("Predicted_Tech:", gam_predictions$Predicted_Tech, "\n")
            }
            if (!is.null(gam_predictions$Predicted_Speed)) {
              cat("Predicted_Speed:", gam_predictions$Predicted_Speed, "\n")
            }
            cat("=== End Debug Output ===\n\n")
          }
          TRUE
        },
        
        # Extract GAM predictions with fallback to current values
        Predicted_Pelo_2026 = ifelse(!is.null(gam_predictions$Predicted_Pelo) && 
                                     is.finite(gam_predictions$Predicted_Pelo), 
                                     gam_predictions$Predicted_Pelo, Pelo),
        Predicted_Downhill_2026 = ifelse(!is.null(gam_predictions$Predicted_Downhill) && 
                                        is.finite(gam_predictions$Predicted_Downhill), 
                                        gam_predictions$Predicted_Downhill, 
                                        if("Downhill_Pelo" %in% names(.)) Downhill_Pelo else Pelo),
        Predicted_SuperG_2026 = ifelse(!is.null(gam_predictions$Predicted_SuperG) && 
                                      is.finite(gam_predictions$Predicted_SuperG), 
                                      gam_predictions$Predicted_SuperG, 
                                      if("Super G_Pelo" %in% names(.)) `Super G_Pelo` else Pelo),
        Predicted_GiantSlalom_2026 = ifelse(!is.null(gam_predictions$Predicted_GiantSlalom) && 
                                           is.finite(gam_predictions$Predicted_GiantSlalom), 
                                           gam_predictions$Predicted_GiantSlalom, 
                                           if("Giant Slalom_Pelo" %in% names(.)) `Giant Slalom_Pelo` else Pelo),
        Predicted_Slalom_2026 = ifelse(!is.null(gam_predictions$Predicted_Slalom) && 
                                      is.finite(gam_predictions$Predicted_Slalom), 
                                      gam_predictions$Predicted_Slalom, 
                                      if("Slalom_Pelo" %in% names(.)) Slalom_Pelo else Pelo),
        Predicted_Tech_2026 = ifelse(!is.null(gam_predictions$Predicted_Tech) && 
                                    is.finite(gam_predictions$Predicted_Tech), 
                                    gam_predictions$Predicted_Tech, 
                                    if("Tech_Pelo" %in% names(.)) Tech_Pelo else Pelo),
        Predicted_Speed_2026 = ifelse(!is.null(gam_predictions$Predicted_Speed) && 
                                     is.finite(gam_predictions$Predicted_Speed), 
                                     gam_predictions$Predicted_Speed, 
                                     if("Speed_Pelo" %in% names(.)) Speed_Pelo else Pelo),
        
        # Alpine skiing age progression category
        Age_Category = case_when(
          is.na(Age) ~ "Unknown",
          Age <= 23 ~ "Young (≤23)",
          Age <= 27 ~ "Prime (24-27)", 
          Age <= 31 ~ "Peak (28-31)",
          Age <= 35 ~ "Mature (32-35)",
          TRUE ~ "Veteran (36+)"
        )
      ) %>%
      ungroup() %>%
      dplyr::select(Skier, Nation, Age, Age_Category, 
             Pelo, Predicted_Pelo_2026,
             contains("Downhill_Pelo"), contains("Predicted_Downhill_2026"),
             contains("Super G_Pelo"), contains("Predicted_SuperG_2026"),
             contains("Giant Slalom_Pelo"), contains("Predicted_GiantSlalom_2026"),
             contains("Slalom_Pelo"), contains("Predicted_Slalom_2026"),
             contains("Tech_Pelo"), contains("Predicted_Tech_2026"),
             contains("Speed_Pelo"), contains("Predicted_Speed_2026"),
             Pct_of_Max_Points, -gam_predictions, -debug_age_input, -debug_age_output)
    
    # Validate predictions
    if (nrow(predictions) == 0) stop("No predictions generated")
    
    # Check for invalid predictions
    invalid_predictions <- sum(!is.finite(predictions$Predicted_Pelo_2026), na.rm = TRUE)
    if (invalid_predictions > 0) {
      warning("Generated ", invalid_predictions, " invalid predictions")
    }
    
    # Check for predictions that are similar to current values (minimal age effect)
    minimal_change <- sum(abs(predictions$Predicted_Pelo_2026 - predictions$Pelo) < 10, na.rm = TRUE)
    if (minimal_change > 0) {
      cat(minimal_change, " alpine athletes have minimal GAM age adjustment (<10 ELO points)\n")
    }
    
    cat("✓ Alpine GAM-based age-adjusted predictions generated:", nrow(predictions), "athletes\n")
    
    return(predictions)
    
  }, error = function(e) {
    stop("Error generating alpine predictions: ", e$message)
  })
}

# Apply GAM-based age adjustments to 2025 alpine data with validation
cat("\n--- Alpine GAM-Based Age Adjustment Execution ---\n")

tryCatch({
  # Validate input data exists
  if (!exists("men_pred_data")) {
    stop("men_pred_data not found")
  }
  if (!exists("age_prediction_function")) {
    stop("age_prediction_function not found") 
  }
  if (nrow(men_pred_data) == 0) {
    stop("men_pred_data is empty")
  }
  
  # Apply GAM-based age adjustments
  age_adjusted_predictions <- predict_2026_with_gam_age_adjustment(men_pred_data, age_prediction_function)
  
  # Validate results
  if (is.null(age_adjusted_predictions)) stop("Alpine GAM age adjustment function returned NULL")
  if (nrow(age_adjusted_predictions) == 0) stop("No alpine GAM age-adjusted predictions generated")
  
  # Display top predictions with validation
  cat("\nTop 15 Alpine GAM Age-Adjusted 2026 Predictions:\n")
  tryCatch({
    top_predictions <- age_adjusted_predictions %>%
      arrange(desc(Predicted_Pelo_2026)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(Predicted_Pelo_2026 - Pelo, 0)
      ) %>%
      head(15)
    
    if (nrow(top_predictions) > 0) {
      print(top_predictions)
    } else {
      cat("No alpine predictions to display\n")
    }
  }, error = function(e) {
    warning("Error displaying top alpine predictions: ", e$message)
  })
  
  # Identify biggest improvers with validation (GAM predicted increase > 0)
  cat("\nBiggest Expected Alpine Improvers (GAM Age Adjustment > 0):\n")
  tryCatch({
    improvers <- age_adjusted_predictions %>%
      mutate(GAM_Change = Predicted_Pelo_2026 - Pelo) %>%
      filter(!is.na(GAM_Change), GAM_Change > 0) %>%
      arrange(desc(GAM_Change)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026, GAM_Change) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(GAM_Change, 0)
      ) %>%
      head(10)
    
    if (nrow(improvers) > 0) {
      print(improvers)
    } else {
      cat("No alpine improvers found with GAM age predictions\n")
    }
  }, error = function(e) {
    warning("Error analyzing alpine improvers: ", e$message)
  })
  
  # Identify biggest decliners with validation (GAM predicted decrease < 0)
  cat("\nBiggest Expected Alpine Decliners (GAM Age Adjustment < 0):\n")
  tryCatch({
    decliners <- age_adjusted_predictions %>%
      mutate(GAM_Change = Predicted_Pelo_2026 - Pelo) %>%
      filter(!is.na(GAM_Change), GAM_Change < 0) %>%
      arrange(GAM_Change) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026, GAM_Change) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(GAM_Change, 0)
      ) %>%
      head(10)
    
    if (nrow(decliners) > 0) {
      print(decliners)
    } else {
      cat("No alpine decliners found with GAM age predictions\n")
    }
  }, error = function(e) {
    warning("Error analyzing alpine decliners: ", e$message)
  })
  
  cat("✓ Alpine GAM-based age adjustment analysis completed successfully\n")
  
}, error = function(e) {
  cat("Alpine GAM-based age adjustment analysis failed: ", e$message, "\n")
  cat("Attempting to continue without alpine GAM age-adjusted predictions\n")
})


# LADIES ALPINE GAM-BASED AGE ADJUSTMENT
cat("\n=== LADIES ALPINE GAM-BASED AGE-ADJUSTED 2026 PREDICTIONS ===\n")

tryCatch({
  # Validate ladies prediction function exists
  if (!exists("age_analysis_ladies") || is.null(age_analysis_ladies)) {
    stop("Ladies alpine age analysis not found")
  }
  if (!"predict_function" %in% names(age_analysis_ladies)) {
    stop("Ladies predict_function not found in age_analysis_ladies")
  }
  
  # Extract ladies GAM prediction function
  age_prediction_function_ladies <- age_analysis_ladies$predict_function
  
  # Validate ladies prediction data
  if (!exists("ladies_pred_data") || is.null(ladies_pred_data) || nrow(ladies_pred_data) == 0) {
    stop("Ladies alpine prediction data not available")
  }
  
  # Apply GAM-based age adjustments to ladies
  age_adjusted_predictions_ladies <- predict_2026_with_gam_age_adjustment(ladies_pred_data, age_prediction_function_ladies)
  
  # Validate results
  if (is.null(age_adjusted_predictions_ladies)) stop("Ladies alpine GAM age adjustment function returned NULL")
  if (nrow(age_adjusted_predictions_ladies) == 0) stop("No ladies alpine GAM age-adjusted predictions generated")
  
  # Display top predictions
  cat("\nTop 15 Ladies Alpine GAM Age-Adjusted 2026 Predictions:\n")
  tryCatch({
    top_predictions_ladies <- age_adjusted_predictions_ladies %>%
      arrange(desc(Predicted_Pelo_2026)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(Predicted_Pelo_2026 - Pelo, 0)
      ) %>%
      head(15)
    
    if (nrow(top_predictions_ladies) > 0) {
      print(top_predictions_ladies)
    } else {
      cat("No ladies alpine predictions to display\n")
    }
  }, error = function(e) {
    warning("Error displaying ladies alpine top predictions: ", e$message)
  })
  
  cat("✓ Ladies alpine GAM-based age adjustment analysis completed successfully\n")
  
}, error = function(e) {
  cat("Ladies alpine GAM-based age adjustment analysis failed: ", e$message, "\n")
})


# EXCEL OUTPUTS FOR ALPINE AGE-ADJUSTED PREDICTIONS
cat("\n=== EXCEL OUTPUTS FOR ALPINE AGE-ADJUSTED PREDICTIONS ===\n")

tryCatch({
  # Create output directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
  }
  
  # Men's alpine age-adjusted predictions Excel output using Log-Transform GAM
  if (exists("age_adjusted_predictions") && !is.null(age_adjusted_predictions) && nrow(age_adjusted_predictions) > 0) {
    men_alpine_age_excel <- age_adjusted_predictions %>%
      mutate(
        # Use log-transform GAM predictions if available, otherwise original GAM
        `Log-Transform GAM Predicted Elo` = if(exists("log_predictor_men") && is.function(log_predictor_men)) {
          mapply(function(age, pelo) {
            tryCatch({
              round(log_predictor_men(age, pelo), 0)
            }, error = function(e) {
              round(Predicted_Pelo_2026, 0)  # Fallback to original
            })
          }, Age, Pelo, SIMPLIFY = TRUE)
        } else {
          round(Predicted_Pelo_2026, 0)  # Use existing GAM if log-transform not available
        },
        `Predicted Elo Change` = `Log-Transform GAM Predicted Elo` - round(Pelo, 0)
      ) %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Current Elo` = Pelo,
        `Predicted Elo 2026` = `Log-Transform GAM Predicted Elo`,
        `Predicted Elo Change`
      ) %>%
      mutate(
        `Current Elo` = round(`Current Elo`, 0)
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    men_alpine_age_file <- file.path("excel365", "mens_age_adjusted_predictions_2026.xlsx")
    write.xlsx(men_alpine_age_excel, men_alpine_age_file, rowNames = FALSE)
    cat("✓ Men's alpine age-adjusted predictions saved to:", men_alpine_age_file, "\n")
  }
  
  # Ladies alpine age-adjusted predictions Excel output using Log-Transform GAM
  if (exists("age_adjusted_predictions_ladies") && !is.null(age_adjusted_predictions_ladies) && nrow(age_adjusted_predictions_ladies) > 0) {
    ladies_alpine_age_excel <- age_adjusted_predictions_ladies %>%
      mutate(
        # Use log-transform GAM predictions if available, otherwise original GAM
        `Log-Transform GAM Predicted Elo` = if(exists("log_predictor_ladies") && is.function(log_predictor_ladies)) {
          mapply(function(age, pelo) {
            tryCatch({
              round(log_predictor_ladies(age, pelo), 0)
            }, error = function(e) {
              round(Predicted_Pelo_2026, 0)  # Fallback to original
            })
          }, Age, Pelo, SIMPLIFY = TRUE)
        } else {
          round(Predicted_Pelo_2026, 0)  # Use existing GAM if log-transform not available
        },
        `Predicted Elo Change` = `Log-Transform GAM Predicted Elo` - round(Pelo, 0)
      ) %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Current Elo` = Pelo,
        `Predicted Elo 2026` = `Log-Transform GAM Predicted Elo`,
        `Predicted Elo Change`
      ) %>%
      mutate(
        `Current Elo` = round(`Current Elo`, 0)
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    ladies_alpine_age_file <- file.path("excel365", "ladie_age_adjusted_predictions_2026.xlsx")
    write.xlsx(ladies_alpine_age_excel, ladies_alpine_age_file, rowNames = FALSE)
    cat("✓ Ladies alpine age-adjusted predictions saved to:", ladies_alpine_age_file, "\n")
  }
  
}, error = function(e) {
  warning("Error creating alpine Excel outputs: ", e$message)
})

cat("\n=== ALPINE GAM MODEL DIAGNOSTICS ===\n")

# Men's Alpine GAM Model Diagnostics
cat("--- Men's Alpine GAM Model Diagnostics ---\n")
tryCatch({
  if (exists("age_analysis_men") && !is.null(age_analysis_men) && 
      "gam_models" %in% names(age_analysis_men) && 
      "Pelo" %in% names(age_analysis_men$gam_models)) {
    
    men_alpine_gam_model <- age_analysis_men$gam_models$Pelo
    men_alpine_summary <- summary(men_alpine_gam_model)
    
    par(mfrow = c(2, 2))
    gam_check_men_alpine <- gam.check(men_alpine_gam_model, sub.caption = "Men's Alpine GAM Diagnostics")
    
    # Extract and validate diagnostic information
    if (!is.null(gam_check_men_alpine)) {
      # Check for model convergence issues
      if ("converged" %in% names(men_alpine_gam_model) && !men_alpine_gam_model$converged) {
        warning("Men's alpine GAM model did not converge properly")
      }
      
      # Check basis dimensions
      if ("s.table" %in% names(men_alpine_summary) && !is.null(men_alpine_summary$s.table)) {
        if ("k-index" %in% colnames(men_alpine_summary$s.table)) {
          basis_dims <- men_alpine_summary$s.table[,"k-index"]
          low_basis <- names(basis_dims[basis_dims < 0.1])
          if (length(low_basis) > 0) {
            warning(paste("Men's alpine GAM features with potentially insufficient basis dimensions:", 
                         paste(low_basis, collapse = ", ")))
          }
        }
      }
    }
    
    cat("✓ Men's alpine GAM diagnostic plots generated\n")
    cat("Men's alpine GAM R-squared:", round(men_alpine_summary$r.sq, 3), "\n")
    cat("Men's alpine GAM Deviance explained:", round(men_alpine_summary$dev.expl * 100, 1), "%\n")
    
  } else {
    cat("Men's alpine GAM model not available for diagnostics\n")
  }
  
}, error = function(e) {
  cat("Error generating men's alpine GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})

# Ladies Alpine GAM Model Diagnostics
cat("--- Ladies Alpine GAM Model Diagnostics ---\n")
tryCatch({
  if (exists("age_analysis_ladies") && !is.null(age_analysis_ladies) && 
      "gam_models" %in% names(age_analysis_ladies) && 
      "Pelo" %in% names(age_analysis_ladies$gam_models)) {
    
    ladies_alpine_gam_model <- age_analysis_ladies$gam_models$Pelo
    ladies_alpine_summary <- summary(ladies_alpine_gam_model)
    
    par(mfrow = c(2, 2))
    gam_check_ladies_alpine <- gam.check(ladies_alpine_gam_model, sub.caption = "Ladies Alpine GAM Diagnostics")
    
    # Extract and validate diagnostic information
    if (!is.null(gam_check_ladies_alpine)) {
      # Check for model convergence issues
      if ("converged" %in% names(ladies_alpine_gam_model) && !ladies_alpine_gam_model$converged) {
        warning("Ladies alpine GAM model did not converge properly")
      }
      
      # Check basis dimensions
      if ("s.table" %in% names(ladies_alpine_summary) && !is.null(ladies_alpine_summary$s.table)) {
        if ("k-index" %in% colnames(ladies_alpine_summary$s.table)) {
          basis_dims <- ladies_alpine_summary$s.table[,"k-index"]
          low_basis <- names(basis_dims[basis_dims < 0.1])
          if (length(low_basis) > 0) {
            warning(paste("Ladies alpine GAM features with potentially insufficient basis dimensions:", 
                         paste(low_basis, collapse = ", ")))
          }
        }
      }
    }
    
    cat("✓ Ladies alpine GAM diagnostic plots generated\n")
    cat("Ladies alpine GAM R-squared:", round(ladies_alpine_summary$r.sq, 3), "\n")
    cat("Ladies alpine GAM Deviance explained:", round(ladies_alpine_summary$dev.expl * 100, 1), "%\n")
    
  } else {
    cat("Ladies alpine GAM model not available for diagnostics\n")
  }
  
}, error = function(e) {
  cat("Error generating ladies alpine GAM diagnostics:", e$message, "\n")
})

# Reset plotting parameters
par(mfrow = c(1, 1))

cat("\n✓ Alpine GAM model diagnostics completed\n")

# LOG-TRANSFORM GAM MODEL FOR ALPINE SKIING (SOLVES HETEROSCEDASTICITY)
cat("\n=== ALPINE LOG-TRANSFORM GAM MODEL FOR TOP PERFORMER ISSUE ===\n")

library(mgcv)

# Log-transform GAM - proven to completely solve heteroscedasticity for alpine skiing
create_alpine_log_transform_gam <- function(df, data_name = "Unknown", min_exp = 20) {
  
  cat(sprintf("\n--- %s Alpine Log-Transform GAM ---\n", data_name))
  
  tryCatch({
    # Prepare training data
    gam_data <- df %>%
      filter(!is.na(Age), Age >= 15, Age <= 40) %>%
      filter(Exp >= min_exp) %>%
      filter(!is.na(Prev_Pelo), !is.na(Pelo)) %>%
      filter(Prev_Pelo > 0, Pelo > 0)
    
    if (nrow(gam_data) < 100) {
      stop(sprintf("Insufficient data for %s alpine log-transform GAM: %d rows", data_name, nrow(gam_data)))
    }
    
    cat(sprintf("Alpine training data: %d observations\n", nrow(gam_data)))
    
    # Create log-transform variables
    gam_data <- gam_data %>%
      mutate(
        log_prev_pelo = log(Prev_Pelo),
        log_pelo = log(Pelo)
      )
    
    # Fit log-transform GAM with proper validation
    log_gam_formula <- log_pelo ~ s(Age, k = 8) + s(log_prev_pelo, k = 10)
    
    log_gam_model <- gam(
      log_gam_formula,
      data = gam_data,
      family = gaussian(),
      method = "REML"
    )
    
    # Validate model convergence
    if (!log_gam_model$converged) {
      warning(sprintf("%s alpine log-transform GAM did not converge", data_name))
    }
    
    # Create prediction function
    log_predictor <- function(age, current_pelo) {
      if (is.na(age) || is.na(current_pelo) || current_pelo <= 0) {
        return(current_pelo)
      }
      
      pred_data <- data.frame(
        Age = age,
        log_prev_pelo = log(current_pelo)
      )
      
      log_pred <- predict(log_gam_model, newdata = pred_data, type = "response")
      return(exp(log_pred))
    }
    
    # Model diagnostics
    summary_stats <- summary(log_gam_model)
    cat(sprintf("✓ %s Alpine Log-Transform GAM R-squared: %.3f\n", data_name, summary_stats$r.sq))
    cat(sprintf("✓ %s Alpine Log-Transform GAM Deviance explained: %.1f%%\n", data_name, summary_stats$dev.expl * 100))
    
    return(list(
      model = log_gam_model,
      predictor = log_predictor,
      summary = summary_stats,
      data_name = data_name
    ))
    
  }, error = function(e) {
    cat(sprintf("Error creating %s alpine log-transform GAM: %s\n", data_name, e$message))
    return(NULL)
  })
}

# Create log-transform diagnostics function for alpine
create_alpine_log_transform_diagnostics <- function(log_gam_result, data_name) {
  
  if (is.null(log_gam_result) || is.null(log_gam_result$model)) {
    cat(sprintf("No %s alpine log-transform GAM model available for diagnostics\n", data_name))
    return()
  }
  
  cat(sprintf("\n--- %s Alpine Log-Transform GAM Diagnostics ---\n", data_name))
  
  tryCatch({
    par(mfrow = c(2, 2))
    gam.check(log_gam_result$model, sub.caption = sprintf("%s Alpine Log-Transform GAM", data_name))
    par(mfrow = c(1, 1))
    
    cat(sprintf("✓ %s Alpine Log-Transform GAM diagnostic plots generated\n", data_name))
    
  }, error = function(e) {
    cat(sprintf("Error generating %s alpine log-transform GAM diagnostics: %s\n", data_name, e$message))
    par(mfrow = c(1, 1))
  })
}

# Create alpine log-transform GAM models
if (exists("df82_final") && !is.null(df82_final) && nrow(df82_final) > 0) {
  log_gam_men <- create_alpine_log_transform_gam(df82_final, "Men")
  if (!is.null(log_gam_men)) {
    log_predictor_men <- log_gam_men$predictor
  }
}

if (exists("df82_final_ladies") && !is.null(df82_final_ladies) && nrow(df82_final_ladies) > 0) {
  log_gam_ladies <- create_alpine_log_transform_gam(df82_final_ladies, "Ladies")
  if (!is.null(log_gam_ladies)) {
    log_predictor_ladies <- log_gam_ladies$predictor
  }
}

# Run diagnostics for log-transform men's alpine model
if (exists("log_gam_men") && !is.null(log_gam_men)) {
  create_alpine_log_transform_diagnostics(log_gam_men, "Men")
}

# Run diagnostics for log-transform ladies alpine model
if (exists("log_gam_ladies") && !is.null(log_gam_ladies)) {
  create_alpine_log_transform_diagnostics(log_gam_ladies, "Ladies")
}

cat("\n✓ Alpine log-transform GAM diagnostics completed\n")
```