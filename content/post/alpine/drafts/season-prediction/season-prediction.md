# Alpine Skiing Season Prediction Script Documentation

This document provides detailed explanations of each section in the 2026 alpine skiing season prediction R script, explaining the purpose, implementation, and reasoning behind each component.

## Section: {r load-data} - Alpine Data Loading & Validation

### Purpose
This section is responsible for loading the core chronometer data files that contain race results for alpine skiing and performing comprehensive validation to ensure data quality and integrity before any analysis begins.

### Data Sources
The section loads two primary CSV files:
- **Men's data**: `/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/men_chrono.csv`
- **Ladies data**: `/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/ladies_chrono.csv`

These files contain chronological race data generated by the alpine ELO rating system pipeline, with each row representing a single race result for an alpine skier.

### Implementation Details

#### 1. File Existence Validation
```r
# Check if files exist before loading
men_file <- '/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/men_chrono.csv'
ladies_file <- '/Users/syverjohansen/ski/elo/python/alpine/polars/excel365/ladies_chrono.csv'

if (!file.exists(men_file)) stop("Men's alpine data file not found: ", men_file)
if (!file.exists(ladies_file)) stop("Ladies alpine data file not found: ", ladies_file)

cat("✓ Alpine data files exist\n")
```
**Purpose**: Ensures the alpine data files exist before attempting to load them. This prevents cryptic errors later and provides clear feedback if the alpine data pipeline hasn't run or files have been moved.

#### 2. Safe Data Loading with Error Handling
```r
tryCatch({
  M_chrono <- read_csv(men_file, show_col_types = FALSE)
  cat("✓ Men's alpine data loaded:", nrow(M_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load men's alpine data: ", e$message)
})

tryCatch({
  L_chrono <- read_csv(ladies_file, show_col_types = FALSE)
  cat("✓ Ladies alpine data loaded:", nrow(L_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load ladies alpine data: ", e$message)
})
```
**Purpose**: Uses `tryCatch()` to handle potential file corruption, permission issues, or formatting problems. The `show_col_types = FALSE` suppresses column type messages for cleaner output. Immediately reports the number of rows loaded for verification.

#### 3. Required Column Validation
```r
# Validate required columns exist
required_cols <- c("Skier", "Date", "Season", "Event", "Nation", "Distance", "Place", "Race", "ID")
missing_men <- setdiff(required_cols, names(M_chrono))
missing_ladies <- setdiff(required_cols, names(L_chrono))

if (length(missing_men) > 0) {
  stop("Missing required columns in men's alpine data: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing required columns in ladies alpine data: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required columns present in both alpine datasets\n")
```
**Purpose**: Validates that all essential columns are present in the loaded alpine data. These columns are critical for:
- **Skier**: Athlete identification
- **Date**: Race timing and chronological ordering
- **Season**: Season grouping for analysis
- **Event**: Race type classification (World Cup, etc.)
- **Nation**: Country representation
- **Distance**: Discipline classification in alpine skiing
- **Place**: Finishing position for points calculation
- **Race**: Race identifier within the dataset
- **ID**: Unique skier identifier for linking with other datasets

#### 4. Data Quality Validation

##### Empty Dataset Protection
```r
# Check for completely empty datasets
if (nrow(M_chrono) == 0) stop("Men's alpine dataset is empty")
if (nrow(L_chrono) == 0) stop("Ladies alpine dataset is empty")
```
**Purpose**: Prevents analysis from proceeding with empty datasets, which would cause downstream errors.

##### Place Column Validation
```r
# Check Place column (should be positive integers)
invalid_places_m <- sum(is.na(M_chrono$Place) | M_chrono$Place < 0 | !is.finite(M_chrono$Place))
invalid_places_l <- sum(is.na(L_chrono$Place) | L_chrono$Place < 0 | !is.finite(L_chrono$Place))

cat("Men's invalid Place values:", invalid_places_m, "\n")
cat("Ladies invalid Place values:", invalid_places_l, "\n")

if (invalid_places_m > nrow(M_chrono) * 0.1) {
  warning("More than 10% of men's Place values are invalid")
}
if (invalid_places_l > nrow(L_chrono) * 0.1) {
  warning("More than 10% of ladies Place values are invalid")
}
```
**Purpose**: Validates that finishing places are logical (positive integers). The 10% threshold allows for some data imperfections (DNS, DSQ, DNF) while flagging systematic data quality issues.

##### Skier Name Validation
```r
# Check for missing Skier names
missing_skiers_m <- sum(is.na(M_chrono$Skier) | M_chrono$Skier == "")
missing_skiers_l <- sum(is.na(L_chrono$Skier) | L_chrono$Skier == "")

cat("Men's missing skier names:", missing_skiers_m, "\n")
cat("Ladies missing skier names:", missing_skiers_l, "\n")

if (missing_skiers_m > nrow(M_chrono) * 0.05) {
  warning("More than 5% of men's skier names are missing")
}
if (missing_skiers_l > nrow(L_chrono) * 0.05) {
  warning("More than 5% of ladies skier names are missing")
}
```
**Purpose**: Ensures all race results can be attributed to specific athletes. Missing skier names would break the analysis pipeline. Uses a 5% threshold for skier name completeness.

##### Season Range Validation
```r
# Check Season range
season_range_m <- range(M_chrono$Season, na.rm = TRUE)
season_range_l <- range(L_chrono$Season, na.rm = TRUE)

cat("Men's season range:", season_range_m[1], "to", season_range_m[2], "\n")
cat("Ladies season range:", season_range_l[1], "to", season_range_l[2], "\n")

# Expected season range (adjust based on your data)
expected_min_season <- 2010
expected_max_season <- 2025

if (season_range_m[1] < expected_min_season || season_range_m[2] > expected_max_season) {
  warning("Men's season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}
if (season_range_l[1] < expected_min_season || season_range_l[2] > expected_max_season) {
  warning("Ladies season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}
```
**Purpose**: Validates that season data falls within expected ranges (2010-2025), helping identify data import issues or unexpected historical data.

##### Date Validation
```r
# Date validation
date_errors_m <- sum(is.na(M_chrono$Date))
date_errors_l <- sum(is.na(L_chrono$Date))

cat("Men's invalid dates:", date_errors_m, "\n")
cat("Ladies invalid dates:", date_errors_l, "\n")
```
**Purpose**: Validates that race dates are present, which is essential for chronological analysis and season grouping.

#### 5. Alpine Athlete Exclusion System
```r
# 2025 Retirements - Men
excluded_men <- c("Yannick Chabloz", "Sebastian Foss-Solevåg", "Nico Gauer", 
                  "Stefano Gross", "Boštjan Kline", "Urs Kryenbühl", 
                  "Stefan Luitz", "Adrian Meisen", "Reto Schmidiger", 
                  "Dominik Schwaiger", "Rasmus Windingstad")

# 2025 Retirements - Ladies  
excluded_ladies <- c("Michelle Niederwieser", "Roni Remme", "Charlotta Säfvenberg",
                     "Anna Schillinger", "Elena Stoffel", "Tamara Tippler",
                     "Vera Tschurtschenthaler", "Stephanie Venier")

cat("\n--- Alpine Athlete Exclusion ---\n")
cat("Excluding men:", paste(excluded_men, collapse = ", "), "\n")
cat("Excluding ladies:", paste(excluded_ladies, collapse = ", "), "\n")

# Count how many records will be excluded
excluded_count_m <- sum(M_chrono$Skier %in% excluded_men)
excluded_count_l <- sum(L_chrono$Skier %in% excluded_ladies)

cat("Men's records to exclude:", excluded_count_m, "\n")
cat("Ladies records to exclude:", excluded_count_l, "\n")
```
**Purpose**: Removes specific athletes from analysis who have retired or are inactive in 2025, ensuring predictions focus on active competitors for the 2026 season.

**Exclusion Tracking**: The system counts how many records will be excluded before performing the operation, providing transparency about the impact of exclusions.

#### 6. Exclusion Validation and Verification
```r
# Filter out excluded athletes from raw data
M_chrono_original_rows <- nrow(M_chrono)
L_chrono_original_rows <- nrow(L_chrono)

M_chrono <- M_chrono %>%
  filter(!Skier %in% excluded_men)

L_chrono <- L_chrono %>%
  filter(!Skier %in% excluded_ladies)

# Verify exclusion worked correctly
actual_excluded_m <- M_chrono_original_rows - nrow(M_chrono)
actual_excluded_l <- L_chrono_original_rows - nrow(L_chrono)

if (actual_excluded_m != excluded_count_m) {
  warning("Mismatch in men's exclusion: expected ", excluded_count_m, ", actual ", actual_excluded_m)
}
if (actual_excluded_l != excluded_count_l) {
  warning("Mismatch in ladies exclusion: expected ", excluded_count_l, ", actual ", actual_excluded_l)
}

cat("✓ Men's alpine data after exclusion:", nrow(M_chrono), "rows\n")
cat("✓ Ladies alpine data after exclusion:", nrow(L_chrono), "rows\n")
```
**Purpose**: Validates that the exclusion process worked correctly by comparing expected vs. actual excluded record counts. This ensures data integrity and catches any issues with the exclusion logic.

#### 7. Alpine World Cup Points System Setup
```r
# Alpine World Cup points mapping with validation
cat("\n--- Alpine Points System Validation ---\n")

# Standard alpine World Cup points (top 30 get points)
alpine_points <- c(100,80,60,50,45,40,36,32,29,26,24,22,20,18,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
```
**Purpose**: Establishes the official Alpine World Cup points system where only the top 30 finishers receive points, with winners receiving 100 points and decreasing amounts down to 1 point for 30th place.

**Alpine Points System Characteristics**:
- **Winner Premium**: 100 points for 1st place, 80 for 2nd (20-point gap rewards victories)
- **Limited Scoring**: Only top 30 athletes score points (more exclusive than some other sports)
- **Standard Structure**: Consistent across all alpine disciplines

### Alpine-Specific Design Considerations

#### Points System Differences
Alpine skiing uses a single, standardized points system across all disciplines:
- **Uniform Structure**: Same points (100-80-60-50...) regardless of whether it's Downhill, Slalom, Giant Slalom, Super G, or Combined
- **Limited Scoring Positions**: Only top 30 receive points (creates competitive pressure)
- **High Winner Premium**: Large gap between 1st and 2nd place rewards race victories

#### Data Quality Thresholds
The validation uses sport-appropriate thresholds:
- **Place Values**: 10% tolerance for invalid places (accounts for DNF/DSQ common in alpine)
- **Skier Names**: 5% tolerance for missing names (stricter than place tolerance)
- **Season Range**: 2010-2025 (modern alpine World Cup era)

#### Exclusion Strategy
The exclusion system targets:
- **2025 Retirements**: Athletes who retired after the 2025 season
- **Active Competition Focus**: Ensures predictions are relevant for athletes likely to compete in 2026
- **Comprehensive Coverage**: Separate lists for men and ladies account for different retirement patterns

### Error Handling and Robustness
- **File Validation**: Confirms alpine data files exist and are accessible
- **Column Validation**: Ensures all required fields for alpine analysis are present
- **Data Quality Monitoring**: Uses sport-appropriate thresholds for data quality metrics
- **Exclusion Validation**: Verifies athlete exclusions worked as expected
- **Comprehensive Logging**: Provides detailed feedback on each validation step

This alpine data loading section provides a robust foundation for all subsequent alpine skiing analysis, ensuring data quality and establishing the analytical framework specific to alpine racing's competitive structure and points system.

## Section: {r process-data} - Alpine Data Processing & Feature Engineering

### Purpose
This section implements comprehensive data processing and feature engineering specifically designed for alpine skiing performance analysis. It transforms raw chronometer data into analysis-ready datasets with alpine-specific metrics, cumulative performance tracking, and validation checks.

### Implementation Details

#### 1. Core Processing Function: `process_alpine_chrono_data()`
The section centers around a robust processing function tailored for alpine skiing data:

```r
process_alpine_chrono_data <- function(chrono_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Processing %s Alpine Data ---\n", data_name))
  
  # Input validation
  if (nrow(chrono_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  # Check for required columns before processing
  required_cols <- c("Event", "Nation", "Place", "Distance", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(chrono_df))
  if (length(missing_cols) > 0) {
    stop(sprintf("Missing required columns in %s alpine data: %s", data_name, paste(missing_cols, collapse = ", ")))
  }
  
  original_rows <- nrow(chrono_df)
  cat(sprintf("Input: %d rows\n", original_rows))
}
```

**Purpose**: Provides a specialized framework for processing alpine skiing data that handles the sport's unique competitive structure and points system.

**Key Features**:
- **Parameterized Processing**: Accepts data name for detailed logging
- **Input Validation**: Ensures data integrity before processing
- **Column Validation**: Verifies all required fields are present
- **Progress Tracking**: Reports processing steps with row counts

#### 2. Alpine Points Assignment and Validation
```r
# Add Alpine World Cup points
cat("Adding Alpine World Cup points...\n")
df <- chrono_df %>%
  mutate(Points = map_int(Place, ~ get_alpine_points(.x, alpine_points)))

# Validate points assignment
points_na <- sum(is.na(df$Points))
points_negative <- sum(df$Points < 0, na.rm = TRUE)

if (points_na > 0) {
  warning(sprintf("%s: %d rows have NA points", data_name, points_na))
}
if (points_negative > 0) {
  warning(sprintf("%s: %d rows have negative points", data_name, points_negative))
}

cat(sprintf("Alpine points range: %d - %d\n", min(df$Points, na.rm = TRUE), max(df$Points, na.rm = TRUE)))
```

**Purpose**: Applies the Alpine World Cup points system to race results and validates the assignment process.

**Points Assignment Logic**:
- Uses `get_alpine_points()` function to safely assign points based on placement
- Awards 100 points for 1st place down to 1 point for 30th place
- Returns 0 points for placements outside top 30
- Handles edge cases (NA, negative, or invalid placements)

**Validation Features**:
- Checks for NA points assignments
- Identifies negative points (should not occur)
- Reports points range for verification

#### 3. Event Filtering and Competition Focus
```r
# Count events before filtering
event_counts_before <- table(df$Event)
cat("Events before filtering:\n")
print(event_counts_before)

# Filter for relevant alpine events (only World Cup and Offseason)
cat("Filtering for relevant alpine events (World Cup, Offseason)...\n")
relevant_events <- c("World Cup", "Offseason")

df <- df %>%
  filter(Event %in% relevant_events) %>%
  arrange(Date, Race, Place) %>%
  group_by(ID, Season) %>%
  mutate(
    Cumulative_Points = cumsum(Points),
    Races_in_Season = n()
  ) %>%
  ungroup()

filtered_rows <- nrow(df)
cat(sprintf("After alpine event filtering: %d rows (removed %d rows)\n", filtered_rows, original_rows - filtered_rows))

# Count events after filtering
event_counts_after <- table(df$Event)
cat("Alpine events after filtering:\n")
print(event_counts_after)
```

**Purpose**: Focuses analysis on the most relevant competitions for performance prediction while tracking filtering impact.

**Event Filtering Logic**:
- **World Cup**: Primary elite alpine racing circuit
- **Offseason**: Summer and training competitions
- **Exclusions**: Removes lower-level competitions that are less predictive

**Feature Engineering**:
- **Cumulative_Points**: Running total of points earned within each season
- **Races_in_Season**: Count of races participated in each season
- **Date Ordering**: Ensures chronological processing for cumulative calculations

#### 4. Cumulative Points Calculation Validation
```r
# Validate cumulative points calculation
invalid_cumulative <- df %>%
  group_by(ID, Season) %>%
  mutate(expected_cumulative = cumsum(Points)) %>%
  ungroup() %>%
  filter(Cumulative_Points != expected_cumulative) %>%
  nrow()

if (invalid_cumulative > 0) {
  warning(sprintf("%s: %d rows have incorrect cumulative points", data_name, invalid_cumulative))
} else {
  cat("✓ Cumulative points calculation validated\n")
}
```

**Purpose**: Validates that cumulative points are calculated correctly by comparing against expected values.

**Validation Method**:
- Recalculates cumulative points independently
- Compares against stored cumulative values
- Identifies any discrepancies in the calculation
- Ensures data integrity for downstream analysis

#### 5. Alpine Discipline Analysis
```r
# Alpine doesn't have team events like cross-country, but check for any unusual distances
cat("Checking alpine disciplines...\n")
discipline_counts <- table(df$Distance)
cat("Alpine disciplines:\n")
print(discipline_counts)
```

**Purpose**: Analyzes the distribution of alpine disciplines to ensure comprehensive coverage and identify any data anomalies.

**Alpine Discipline Context**:
- **Individual Events Only**: Unlike cross-country, alpine has no team events
- **Multiple Disciplines**: Downhill, Super G, Giant Slalom, Slalom, Combined
- **Distance Field Usage**: The Distance field contains discipline information in alpine data

#### 6. Maximum Points Calculation and Percentage Metrics
```r
# Calculate maximum possible points per season 
cat("Calculating maximum possible alpine points per season...\n")
max_points_per_season <- df %>%
  group_by(Season, Date, Race) %>%
  summarise(Max_Race_Points = max(Points), .groups = 'drop') %>%
  group_by(Season) %>%
  summarise(Max_Points = sum(Max_Race_Points), .groups = 'drop')

# Validate max points calculation
if (nrow(max_points_per_season) == 0) {
  stop(sprintf("%s: No seasons found for alpine max points calculation", data_name))
}

# Check for seasons with zero max points
zero_max_seasons <- max_points_per_season %>% filter(Max_Points == 0)
if (nrow(zero_max_seasons) > 0) {
  warning(sprintf("%s: %d alpine seasons have zero max points", data_name, nrow(zero_max_seasons)))
  print(zero_max_seasons)
}

cat(sprintf("Alpine max points range by season: %d - %d\n", 
            min(max_points_per_season$Max_Points), max(max_points_per_season$Max_Points)))
```

**Purpose**: Calculates the theoretical maximum points possible in each season to enable performance percentage calculations.

**Maximum Points Logic**:
- **Race-Level Maximum**: Finds highest points awarded in each race (typically 100 for winners)
- **Season Aggregation**: Sums maximum points across all races in each season
- **Validation**: Ensures all seasons have positive maximum points

**Performance Standardization**: Enables comparison across different seasons with varying numbers of races.

#### 7. Performance Percentage Calculation and Validation
```r
# Join max points and calculate percentage
cat("Calculating percentage of maximum alpine points...\n")
before_join <- nrow(df)

df <- df %>%
  left_join(max_points_per_season, by = "Season") %>%
  mutate(Pct_of_Max_Points = Cumulative_Points / Max_Points)

after_join <- nrow(df)
if (before_join != after_join) {
  warning(sprintf("%s: Row count changed during alpine max points join: %d -> %d", data_name, before_join, after_join))
}

# Validate percentage calculations
pct_na <- sum(is.na(df$Pct_of_Max_Points))
pct_negative <- sum(df$Pct_of_Max_Points < 0, na.rm = TRUE)
pct_over_one <- sum(df$Pct_of_Max_Points > 1, na.rm = TRUE)

if (pct_na > 0) {
  warning(sprintf("%s: %d rows have NA percentage of max alpine points", data_name, pct_na))
}
if (pct_negative > 0) {
  warning(sprintf("%s: %d rows have negative percentage of max alpine points", data_name, pct_negative))
}
if (pct_over_one > 0) {
  warning(sprintf("%s: %d rows have percentage > 100%% of max alpine points", data_name, pct_over_one))
}

cat(sprintf("Alpine percentage range: %.3f - %.3f\n", 
            min(df$Pct_of_Max_Points, na.rm = TRUE), max(df$Pct_of_Max_Points, na.rm = TRUE)))
```

**Purpose**: Creates standardized performance metrics by calculating what percentage of maximum possible points each athlete achieved.

**Percentage Calculation**:
- **Formula**: (Cumulative Points / Season Max Points)
- **Range**: 0.0 (no points) to 1.0 (won every race)
- **Standardization**: Enables comparison across different season lengths

**Validation Checks**:
- **Row Count**: Ensures join operation doesn't change data size
- **NA Values**: Identifies missing percentage calculations
- **Range**: Validates percentages are between 0 and 1
- **Logical Constraints**: Flags impossible values (negative or >100%)

#### 8. Final Validation and Summary Statistics
```r
# Final validation checks
cat("\n--- Final Alpine Validation ---\n")

# Check for required columns in output
expected_output_cols <- c("Points", "Cumulative_Points", "Races_in_Season", "Max_Points", "Pct_of_Max_Points")
missing_output_cols <- setdiff(expected_output_cols, names(df))
if (length(missing_output_cols) > 0) {
  stop(sprintf("%s: Missing expected alpine output columns: %s", data_name, paste(missing_output_cols, collapse = ", ")))
}

# Summary statistics
cat(sprintf("✓ Alpine processing complete for %s\n", data_name))
cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(df), 100 * nrow(df) / original_rows))
cat(sprintf("Unique alpine skiers: %d\n", length(unique(df$Skier))))
cat(sprintf("Alpine seasons covered: %d (%s - %s)\n", 
            length(unique(df$Season)), min(df$Season), max(df$Season)))
cat(sprintf("Average alpine races per season per skier: %.1f\n", mean(df$Races_in_Season)))
```

**Purpose**: Provides final validation and comprehensive summary of the processed alpine data.

**Output Validation**:
- **Required Columns**: Ensures all expected columns are present
- **Data Completeness**: Reports final data size and retention rate
- **Coverage Metrics**: Summarizes unique skiers and season coverage
- **Racing Activity**: Reports average participation rates

#### 9. Cross-Dataset Processing and Validation
```r
# Process both alpine datasets with validation
cat("\n=== PROCESSING MEN'S ALPINE DATA ===\n")
tryCatch({
  M_processed <- process_alpine_chrono_data(M_chrono, "Men's")
}, error = function(e) {
  stop("Failed to process men's alpine data: ", e$message)
})

cat("\n=== PROCESSING LADIES ALPINE DATA ===\n")
tryCatch({
  L_processed <- process_alpine_chrono_data(L_chrono, "Ladies")
}, error = function(e) {
  stop("Failed to process ladies alpine data: ", e$message)
})

# Cross-validation between alpine datasets
cat("\n=== CROSS-DATASET ALPINE VALIDATION ===\n")

# Compare season ranges
men_seasons <- sort(unique(M_processed$Season))
ladies_seasons <- sort(unique(L_processed$Season))

cat("Men's alpine seasons:", paste(range(men_seasons), collapse = " - "), "(", length(men_seasons), "seasons )\n")
cat("Ladies alpine seasons:", paste(range(ladies_seasons), collapse = " - "), "(", length(ladies_seasons), "seasons )\n")

# Check for season overlap
common_seasons <- intersect(men_seasons, ladies_seasons)
cat("Common alpine seasons:", length(common_seasons), "\n")

if (length(common_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine data")
}
```

**Purpose**: Applies processing to both men's and women's alpine data and validates consistency between datasets.

**Cross-Validation Features**:
- **Parallel Processing**: Applies same function to both datasets
- **Error Handling**: Isolates processing errors to specific datasets
- **Season Coverage**: Compares temporal coverage between datasets
- **Overlap Analysis**: Ensures adequate common data for comparative analysis

#### 10. Star Athlete Validation Testing
```r
# Test with star athletes to validate processing
cat("\n=== ALPINE STAR ATHLETE VALIDATION ===\n")

# Test Marco Odermatt (men)
odermatt_data <- M_processed %>% 
  filter(Skier == "Marco Odermatt") %>%
  arrange(Season, Date)

if (nrow(odermatt_data) > 0) {
  cat("✓ Marco Odermatt found in men's data\n")
  cat(sprintf("  Seasons: %s - %s\n", min(odermatt_data$Season), max(odermatt_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(odermatt_data)))
  cat(sprintf("  Career points: %d\n", sum(odermatt_data$Points)))
  
  # Show recent season performance
  recent_season <- max(odermatt_data$Season)
  recent_data <- odermatt_data %>% filter(Season == recent_season)
  cat(sprintf("  %d season: %d races, %d points, %.1f%% of max\n", 
              recent_season, nrow(recent_data), sum(recent_data$Points),
              max(recent_data$Pct_of_Max_Points) * 100))
} else {
  warning("Marco Odermatt not found in men's alpine data")
}
```

**Purpose**: Validates processing accuracy using known high-performing athletes as test cases.

**Validation Athletes**:
- **Marco Odermatt**: Top men's alpine skier for validation
- **Mikaela Shiffrin**: Top women's alpine skier for validation

**Test Metrics**:
- **Data Presence**: Confirms star athletes are found in processed data
- **Career Span**: Validates reasonable season coverage
- **Performance Metrics**: Checks points and percentage calculations
- **Recent Performance**: Validates latest season data

### Alpine-Specific Design Considerations

#### Single Points System
Alpine skiing uses one consistent points system:
- **Uniform Application**: Same points structure across all disciplines
- **Top 30 Scoring**: Only top 30 finishers receive points
- **Winner Premium**: 100 points for victory vs. 80 for second place

#### Event Hierarchy
Processing focuses on performance-relevant competitions:
- **World Cup**: Primary elite circuit (highest priority)
- **Offseason**: Training and summer competitions (secondary priority)
- **Lower Levels**: Excluded to focus on predictive competitions

#### Performance Standardization
Percentage calculations account for alpine skiing characteristics:
- **Variable Schedules**: Athletes compete in different numbers of races
- **Discipline Specialization**: Some athletes focus on specific disciplines
- **Season Length Variation**: Different seasons may have different race calendars

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data structure and completeness
- **Processing Validation**: Validates each step of feature engineering and calculation
- **Cross-Dataset Consistency**: Ensures consistent processing across men's and women's data
- **Star Athlete Testing**: Uses known high performers to validate processing accuracy
- **Comprehensive Logging**: Detailed progress reporting and diagnostic output

This alpine data processing section provides a robust foundation for subsequent analysis, creating standardized performance metrics while preserving the unique characteristics of alpine skiing competition and its points system.

## Section: {r elo-prep} - Alpine ELO Data Preparation & Feature Engineering

### Purpose
This section prepares alpine ELO (rating system) data for machine learning models by filtering offseason data, creating lagged features for previous season performance, and implementing comprehensive missing value treatment specific to alpine skiing's multi-discipline structure.

### Implementation Details

#### 1. Missing Value Helper Function
```r
# Helper function for quartile replacement (handles NAs by replacing with 1st quartile within season)
replace_na_with_quartile <- function(x, var_name) {
  if (all(is.na(x))) {
    warning(sprintf("All values NA for %s in this season - using global mean", var_name))
    return(rep(mean(x, na.rm = TRUE), length(x)))
  }
  
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  if (is.na(q1)) {
    warning(sprintf("Cannot calculate quartile for %s - using mean", var_name))
    q1 <- mean(x, na.rm = TRUE)
  }
  
  return(replace(x, is.na(x), q1))
}
```

**Purpose**: Provides robust missing value imputation using first quartile values within each season, with fallback strategies for edge cases.

**Imputation Strategy**:
- **Primary Method**: Uses first quartile (25th percentile) within season
- **Fallback 1**: If all values are NA in season, uses global mean
- **Fallback 2**: If quartile calculation fails, uses season mean
- **Conservative Approach**: First quartile provides conservative estimates for missing ELO ratings

#### 2. Core ELO Preparation Function
```r
prepare_alpine_elo_data <- function(processed_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Preparing %s Alpine ELO Data ---\n", data_name))
  
  # Input validation
  if (nrow(processed_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  original_rows <- nrow(processed_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Check for offseason data
  offseason_count <- sum(processed_df$Event == "Offseason", na.rm = TRUE)
  cat(sprintf("Offseason events available: %d\n", offseason_count))
  
  if (offseason_count == 0) {
    stop(sprintf("%s: No offseason data found for alpine ELO preparation", data_name))
  }
}
```

**Purpose**: Establishes the framework for alpine ELO data preparation with comprehensive validation.

**Key Validation Steps**:
- **Empty Dataset Check**: Ensures data is available for processing
- **Offseason Data Requirement**: Validates presence of offseason data (essential for ELO preparation)
- **Progress Tracking**: Reports input data size and availability

#### 3. Alpine ELO Column Validation
```r
# Check for required alpine ELO columns before processing
required_elo_cols <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                       "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")

available_elo_cols <- intersect(required_elo_cols, names(processed_df))
missing_elo_cols <- setdiff(required_elo_cols, names(processed_df))

cat(sprintf("Available alpine ELO columns: %d/%d\n", length(available_elo_cols), length(required_elo_cols)))
if (length(missing_elo_cols) > 0) {
  cat("Missing alpine ELO columns:", paste(missing_elo_cols, collapse = ", "), "\n")
  warning(sprintf("%s: Missing some alpine ELO columns - proceeding with available columns", data_name))
}
```

**Purpose**: Validates availability of alpine-specific ELO rating columns and handles graceful degradation if some are missing.

**Alpine ELO Structure**:
- **Pelo**: Overall alpine ELO rating
- **Downhill_Pelo**: Downhill-specific ELO rating
- **Super G_Pelo**: Super G-specific ELO rating
- **Giant Slalom_Pelo**: Giant Slalom-specific ELO rating
- **Slalom_Pelo**: Slalom-specific ELO rating
- **Combined_Pelo**: Combined event ELO rating
- **Tech_Pelo**: Technical disciplines (Slalom, Giant Slalom) aggregate ELO
- **Speed_Pelo**: Speed disciplines (Downhill, Super G) aggregate ELO

**Flexible Processing**: Continues with available columns if some ELO ratings are missing.

#### 4. Offseason Data Filtering and Lag Feature Creation
```r
# Filter for offseason data and create previous season ELO values
cat("Filtering for offseason data and creating lag features...\n")

elo_df <- processed_df %>%
  filter(Event == "Offseason") %>%
  arrange(ID, Season)

filtered_rows <- nrow(elo_df)
cat(sprintf("After offseason filter: %d rows (%.1f%% of input)\n", 
            filtered_rows, 100 * filtered_rows / original_rows))

if (filtered_rows == 0) {
  stop(sprintf("%s: No rows remaining after offseason filtering", data_name))
}

# Create lag features for alpine disciplines with validation
cat("Creating alpine discipline lag features...\n")

elo_df <- elo_df %>%
  group_by(ID) %>%
  mutate(
    Prev_Pelo = if("Pelo" %in% names(.)) lag(Pelo) else NA_real_,
    Prev_Downhill = if("Downhill_Pelo" %in% names(.)) lag(Downhill_Pelo) else NA_real_,
    Prev_Super_G = if("Super G_Pelo" %in% names(.)) lag(`Super G_Pelo`) else NA_real_,
    Prev_Giant_Slalom = if("Giant Slalom_Pelo" %in% names(.)) lag(`Giant Slalom_Pelo`) else NA_real_,
    Prev_Slalom = if("Slalom_Pelo" %in% names(.)) lag(Slalom_Pelo) else NA_real_,
    Prev_Combined = if("Combined_Pelo" %in% names(.)) lag(Combined_Pelo) else NA_real_,
    Prev_Tech = if("Tech_Pelo" %in% names(.)) lag(Tech_Pelo) else NA_real_,
    Prev_Speed = if("Speed_Pelo" %in% names(.)) lag(Speed_Pelo) else NA_real_,
    Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
  ) %>%
  ungroup()
```

**Purpose**: Extracts offseason data and creates lagged features representing previous season performance across all alpine disciplines.

**Offseason Focus**: 
- **End-of-Season Snapshot**: Offseason data represents final ELO ratings after season completion
- **Predictive Features**: Previous season ELO ratings serve as predictors for next season performance
- **Clean Temporal Ordering**: Arranges by athlete ID and season for proper lag calculation

**Lag Feature Engineering**:
- **Previous Overall Rating**: `Prev_Pelo` for general alpine ability
- **Discipline-Specific Ratings**: Previous ELO for each alpine discipline
- **Aggregate Category Ratings**: Previous Technical and Speed ELO ratings
- **Performance Percentage**: Previous season's percentage of maximum points achieved

#### 5. Season Filtering and Validation
```r
# Apply season filter
cat("Applying season filter (> 2015)...\n")
before_season_filter <- nrow(elo_df)

elo_df <- elo_df %>%
  filter(Season > 2015)

after_season_filter <- nrow(elo_df)
cat(sprintf("After season filter: %d rows (removed %d rows from ≤2015)\n", 
            after_season_filter, before_season_filter - after_season_filter))

if (after_season_filter == 0) {
  stop(sprintf("%s: No rows remaining after alpine season filtering (>2015)", data_name))
}

# Validate season range
season_range <- range(elo_df$Season, na.rm = TRUE)
cat(sprintf("Final alpine season range: %.0f - %.0f\n", season_range[1], season_range[2]))
```

**Purpose**: Focuses analysis on modern alpine skiing era (post-2015) to ensure ELO ratings reflect current competitive dynamics.

**Season Filter Rationale**:
- **Modern Era Focus**: 2016+ represents current alpine skiing competitive structure
- **ELO System Stability**: Ensures ELO ratings have stabilized and are reliable
- **Equipment and Rule Consistency**: Reduces impact of equipment changes and rule modifications
- **Data Quality**: More recent data has better quality and completeness

#### 6. Comprehensive Missing Value Treatment
```r
# Handle missing values by replacing with quartiles within each season
cat("\n--- Alpine ELO Missing Value Treatment ---\n")

# Count NAs before treatment
if (length(created_lag_features) > 0) {
  available_lag_features <- intersect(created_lag_features, names(elo_df))
  if (length(available_lag_features) > 0) {
    na_summary_before <- elo_df[available_lag_features] %>%
      summarise_all(~ sum(is.na(.))) %>%
      gather(variable, na_count) %>%
      filter(na_count > 0)
  }
}

if (nrow(na_summary_before) > 0) {
  cat("Alpine ELO NAs before treatment:\n")
  print(na_summary_before)
} else {
  cat("No NAs found in alpine lag features\n")
}

# Apply quartile replacement by season for alpine disciplines
cat("Applying quartile replacement by season for alpine disciplines...\n")

elo_df <- elo_df %>%
  group_by(Season) %>%
  mutate(
    Prev_Downhill = if("Prev_Downhill" %in% names(.)) replace_na_with_quartile(Prev_Downhill, "Prev_Downhill") else Prev_Downhill,
    Prev_Super_G = if("Prev_Super_G" %in% names(.)) replace_na_with_quartile(Prev_Super_G, "Prev_Super_G") else Prev_Super_G,
    Prev_Giant_Slalom = if("Prev_Giant_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Giant_Slalom, "Prev_Giant_Slalom") else Prev_Giant_Slalom,
    Prev_Slalom = if("Prev_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Slalom, "Prev_Slalom") else Prev_Slalom,
    Prev_Combined = if("Prev_Combined" %in% names(.)) replace_na_with_quartile(Prev_Combined, "Prev_Combined") else Prev_Combined,
    Prev_Tech = if("Prev_Tech" %in% names(.)) replace_na_with_quartile(Prev_Tech, "Prev_Tech") else Prev_Tech,
    Prev_Speed = if("Prev_Speed" %in% names(.)) replace_na_with_quartile(Prev_Speed, "Prev_Speed") else Prev_Speed,
    Prev_Pelo = if("Prev_Pelo" %in% names(.)) replace_na_with_quartile(Prev_Pelo, "Prev_Pelo") else Prev_Pelo,
    Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
  ) %>%
  ungroup()
```

**Purpose**: Implements sophisticated missing value imputation that respects alpine skiing's competitive context and seasonal variations.

**Season-Based Imputation Strategy**:
- **Within-Season Context**: Replaces missing ELO values using quartiles within the same season
- **Conservative Estimates**: First quartile provides conservative performance estimates
- **Discipline-Specific Treatment**: Each alpine discipline gets independent imputation
- **Performance Points Special Case**: Missing performance percentages set to 0 (indicating no previous season success)

**Quality Assurance**:
- **Before/After Comparison**: Tracks missing value counts before and after treatment
- **Validation Reporting**: Reports remaining missing values if any exist
- **Error Handling**: Warns if imputation is incomplete

#### 7. Final Data Quality Validation
```r
# Final validation checks
cat("\n--- Final Alpine ELO Validation ---\n")

# Check for infinite values
numeric_cols <- select_if(elo_df, is.numeric) %>% names()
if (length(numeric_cols) > 0) {
  inf_check <- elo_df[numeric_cols] %>%
    summarise_all(~ sum(!is.finite(.))) %>%
    gather(variable, inf_count) %>%
    filter(inf_count > 0)
}

if (nrow(inf_check) > 0) {
  cat("Infinite values found in alpine ELO data:\n")
  print(inf_check)
  warning(sprintf("%s: Contains infinite values", data_name))
} else {
  cat("✓ No infinite values detected in alpine ELO data\n")
}

# Validate key relationships for alpine
if ("Age" %in% names(elo_df)) {
  age_issues <- elo_df %>%
    filter(Age < 15 | Age > 50) %>%
    nrow()
  
  if (age_issues > 0) {
    warning(sprintf("%s: %d rows with unusual ages (<15 or >50)", data_name, age_issues))
  }
  
  cat(sprintf("Alpine skier age range: %.0f - %.0f\n", min(elo_df$Age, na.rm = TRUE), max(elo_df$Age, na.rm = TRUE)))
}
```

**Purpose**: Performs comprehensive final validation to ensure data quality and logical consistency.

**Validation Checks**:
- **Infinite Value Detection**: Identifies any infinite or NaN values that could break models
- **Age Range Validation**: Ensures athlete ages are within reasonable bounds (15-50 years)
- **Finite Value Verification**: Confirms all numeric values are finite and usable

**Quality Standards**:
- **Model Readiness**: Ensures data is ready for machine learning algorithms
- **Logical Consistency**: Validates that data relationships make sense
- **Error Prevention**: Catches data quality issues before they affect downstream analysis

#### 8. Cross-Dataset Processing and Analysis
```r
# Prepare alpine ELO data for both men and ladies with comprehensive validation
cat("\n=== PREPARING MEN'S ALPINE ELO DATA ===\n")
tryCatch({
  M_elo <- prepare_alpine_elo_data(M_processed, "Men's")
}, error = function(e) {
  stop("Failed to prepare men's alpine ELO data: ", e$message)
})

cat("\n=== PREPARING LADIES ALPINE ELO DATA ===\n")
tryCatch({
  L_elo <- prepare_alpine_elo_data(L_processed, "Ladies")
}, error = function(e) {
  stop("Failed to prepare ladies alpine ELO data: ", e$message)
})

# Cross-validation between alpine ELO datasets
cat("\n=== CROSS-DATASET ALPINE ELO VALIDATION ===\n")

# Compare season ranges
men_elo_seasons <- sort(unique(M_elo$Season))
ladies_elo_seasons <- sort(unique(L_elo$Season))

cat("Men's alpine ELO seasons:", paste(range(men_elo_seasons), collapse = " - "), "(", length(men_elo_seasons), "seasons )\n")
cat("Ladies alpine ELO seasons:", paste(range(ladies_elo_seasons), collapse = " - "), "(", length(ladies_elo_seasons), "seasons )\n")

# Check for season overlap
common_elo_seasons <- intersect(men_elo_seasons, ladies_elo_seasons)
cat("Common alpine ELO seasons:", length(common_elo_seasons), "\n")

if (length(common_elo_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine ELO data")
}
```

**Purpose**: Applies ELO preparation to both men's and women's data with comprehensive cross-validation.

**Processing Features**:
- **Parallel Processing**: Applies same preparation function to both datasets
- **Error Isolation**: Isolates processing errors to specific datasets
- **Season Coverage Comparison**: Validates temporal coverage between men's and women's data
- **Overlap Analysis**: Ensures adequate common seasons for comparative modeling

#### 9. Alpine ELO Distribution Analysis
```r
# Validate alpine ELO distributions
cat("\n--- Alpine ELO Distribution Analysis ---\n")

# Check ELO ranges for men
if ("Prev_Pelo" %in% names(M_elo)) {
  men_pelo_range <- range(M_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Men's Prev_Pelo range: %.0f - %.0f\n", men_pelo_range[1], men_pelo_range[2]))
}

if ("Prev_Tech" %in% names(M_elo)) {
  men_tech_range <- range(M_elo$Prev_Tech, na.rm = TRUE)
  cat(sprintf("Men's Prev_Tech range: %.0f - %.0f\n", men_tech_range[1], men_tech_range[2]))
}

if ("Prev_Speed" %in% names(M_elo)) {
  men_speed_range <- range(M_elo$Prev_Speed, na.rm = TRUE)
  cat(sprintf("Men's Prev_Speed range: %.0f - %.0f\n", men_speed_range[1], men_speed_range[2]))
}
```

**Purpose**: Analyzes ELO rating distributions to validate data quality and identify potential issues.

**Distribution Analysis**:
- **Overall Alpine ELO**: General alpine skiing ability ratings
- **Technical Disciplines**: Slalom and Giant Slalom combined ratings
- **Speed Disciplines**: Downhill and Super G combined ratings
- **Range Validation**: Ensures ELO ranges are reasonable and consistent

### Alpine ELO-Specific Design Considerations

#### Multi-Discipline ELO Structure
Alpine skiing's unique characteristic is having separate ELO ratings for each discipline:
- **Individual Discipline Ratings**: Separate ELO for Downhill, Super G, Giant Slalom, Slalom, Combined
- **Aggregate Category Ratings**: Technical (Slalom + Giant Slalom) and Speed (Downhill + Super G)
- **Overall Alpine Rating**: General alpine skiing ability across all disciplines

#### Offseason Data Focus
ELO preparation specifically targets offseason data:
- **End-of-Season Ratings**: Represents final ELO after all season races completed
- **Stable Performance Indicators**: ELO ratings have stabilized by offseason
- **Predictive Value**: End-of-season ratings are most predictive of next season performance

#### Conservative Missing Value Treatment
The quartile-based imputation strategy:
- **Conservative Estimates**: First quartile provides conservative performance expectations
- **Season-Aware**: Imputation respects seasonal competitive context
- **Discipline-Specific**: Each alpine discipline gets independent treatment
- **Graceful Degradation**: Handles edge cases with appropriate fallback strategies

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data availability and structure
- **ELO Column Validation**: Flexible handling of missing discipline-specific ELO columns
- **Missing Value Monitoring**: Detailed tracking of missing value treatment effectiveness
- **Cross-Dataset Consistency**: Ensures consistent processing across men's and women's data
- **Distribution Validation**: Analyzes ELO distributions for quality assurance

This alpine ELO preparation section creates a robust foundation for machine learning models by providing clean, validated, and properly engineered features that respect alpine skiing's multi-discipline competitive structure and seasonal dynamics.

## Section: {r comprehensive-feature-selection} - Alpine Feature Selection & Model Optimization

### Purpose
This section implements comprehensive feature selection for alpine skiing season prediction using multiple statistical and machine learning methods. It identifies the most predictive alpine-specific features across all disciplines and creates robust consensus-based feature sets for both men's and women's modeling.

### Implementation Details

#### 1. Training Data Preparation and Validation
```r
cat("=== COMPREHENSIVE ALPINE FEATURE SELECTION & VALIDATION ===\n")

# Input validation for alpine ELO datasets
if (nrow(M_elo) == 0) {
  stop("Men's alpine ELO dataset is empty")
}
if (nrow(L_elo) == 0) {
  stop("Ladies alpine ELO dataset is empty")
}

cat(sprintf("Input alpine datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))

# Prepare training data - include more historical seasons to capture early breakthroughs
# Use data from 2016+ to include breakthrough seasons in alpine
cat("Filtering alpine training data (2016-2025, non-NA Pct_of_Max_Points)...\n")

# Check available seasons before filtering
men_seasons_available <- sort(unique(M_elo$Season))
ladies_seasons_available <- sort(unique(L_elo$Season))

cat(sprintf("Men's alpine available seasons: %s\n", paste(range(men_seasons_available), collapse = " - ")))
cat(sprintf("Ladies alpine available seasons: %s\n", paste(range(ladies_seasons_available), collapse = " - ")))

# Apply training filters with validation
train_men <- M_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

train_ladies <- L_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))
```

**Purpose**: Establishes comprehensive training datasets with validated temporal coverage for alpine skiing feature selection.

**Training Data Strategy**:
- **Historical Coverage**: Uses 2016-2025 data to capture full range of alpine performance patterns
- **Target Variable Validation**: Ensures non-missing percentage of maximum points for supervised learning
- **Season Range Validation**: Confirms adequate temporal coverage for robust feature selection
- **Breakthrough Inclusion**: 2016+ timeframe captures early career breakthroughs in alpine skiing

**Quality Assurance**:
- **Empty Dataset Protection**: Prevents feature selection with insufficient data
- **Season Coverage Reporting**: Validates temporal span of training data
- **Model Robustness Check**: Warns if fewer than 3 seasons available

#### 2. Alpine Feature Definition and Availability Validation
```r
# Define and validate potential alpine features
cat("\n--- Alpine Feature Validation ---\n")

all_features <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                  "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", 
                  "Prev_Pct_of_Max_Points", "Age")

# Check feature availability in alpine training datasets
men_available_features <- intersect(all_features, names(train_men))
ladies_available_features <- intersect(all_features, names(train_ladies))

cat(sprintf("Men's available alpine features: %d/%d\n", length(men_available_features), length(all_features)))
cat(sprintf("Ladies available alpine features: %d/%d\n", length(ladies_available_features), length(all_features)))

# Report missing features
men_missing_features <- setdiff(all_features, men_available_features)
ladies_missing_features <- setdiff(all_features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing alpine features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing alpine features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from ladies training data")
}
```

**Purpose**: Validates availability of alpine-specific predictive features and handles graceful degradation for missing features.

**Alpine Feature Set**:
- **Overall Alpine Performance**: `Prev_Pelo` (previous season overall ELO)
- **Individual Discipline ELOs**: `Prev_Downhill`, `Prev_Super_G`, `Prev_Giant_Slalom`, `Prev_Slalom`, `Prev_Combined`
- **Discipline Category ELOs**: `Prev_Tech` (technical disciplines), `Prev_Speed` (speed disciplines)
- **Performance History**: `Prev_Pct_of_Max_Points` (previous season success rate)
- **Athlete Demographics**: `Age` (current age for experience modeling)

**Flexible Processing**:
- **Graceful Degradation**: Continues with available features if some are missing
- **Minimum Threshold**: Requires at least 3 features for meaningful feature selection
- **Cross-Gender Validation**: Ensures consistent feature availability across men's and women's data

#### 3. Data Quality Validation for Feature Selection
```r
# Validate alpine feature data quality
cat("\n--- Alpine Feature Data Quality Checks ---\n")

# Check for missing values in alpine features
men_feature_na_counts <- sapply(train_men[all_features_men], function(x) sum(is.na(x)))
ladies_feature_na_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(is.na(x)))

if (any(men_feature_na_counts > 0)) {
  cat("Men's alpine features with NAs:\n")
  print(men_feature_na_counts[men_feature_na_counts > 0])
  warning("Men's alpine training data contains missing values in features")
}

# Check for infinite values
men_feature_inf_counts <- sapply(train_men[all_features_men], function(x) sum(!is.finite(x)))
ladies_feature_inf_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(!is.finite(x)))

# Check target variable quality
men_target_na <- sum(is.na(train_men$Pct_of_Max_Points))
ladies_target_na <- sum(is.na(train_ladies$Pct_of_Max_Points))

cat(sprintf("Alpine target variable ranges: Men %.3f-%.3f, Ladies %.3f-%.3f\n",
            min(train_men$Pct_of_Max_Points, na.rm = TRUE), max(train_men$Pct_of_Max_Points, na.rm = TRUE),
            min(train_ladies$Pct_of_Max_Points, na.rm = TRUE), max(train_ladies$Pct_of_Max_Points, na.rm = TRUE)))
```

**Purpose**: Ensures data quality standards necessary for reliable feature selection across alpine skiing datasets.

**Quality Validation Checks**:
- **Missing Value Detection**: Identifies features with incomplete data that could bias selection
- **Infinite Value Detection**: Finds numerical issues that could break feature selection algorithms
- **Target Variable Validation**: Ensures target variable (percentage of maximum points) has valid range
- **Cross-Dataset Consistency**: Validates data quality across men's and women's datasets

#### 4. Multi-Method Feature Selection Framework

##### 4a. Correlation Analysis
```r
# 1. CORRELATION ANALYSIS with validation
cat("1. ALPINE CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for correlation analysis\n")
    cor_matrix_men <- NULL
    high_cor_men <- data.frame()
  } else {
    cor_matrix_men <- cor(train_men[all_features_men], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_men))) {
      warning("Alpine correlation matrix contains NA values")
    }
    
    high_cor_men <- which(abs(cor_matrix_men) > 0.7 & upper.tri(cor_matrix_men), arr.ind = TRUE)
    if(nrow(high_cor_men) > 0) {
      cat("High alpine correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_men)) {
        row_name <- rownames(cor_matrix_men)[high_cor_men[i,1]]
        col_name <- colnames(cor_matrix_men)[high_cor_men[i,2]]
        cor_val <- cor_matrix_men[high_cor_men[i,1], high_cor_men[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high alpine correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine correlation analysis:", e$message, "\n")
  cor_matrix_men <- NULL
  high_cor_men <- data.frame()
})
```

**Purpose**: Identifies multicollinearity among alpine features and establishes baseline correlation patterns.

**Correlation Analysis Features**:
- **Multicollinearity Detection**: Identifies features with |r| > 0.7 that may cause modeling issues
- **Alpine-Specific Patterns**: Reveals relationships between different alpine disciplines
- **Quality Assurance**: Validates correlation matrix integrity and handles edge cases
- **Baseline Establishment**: Provides correlation foundation for other selection methods

##### 4b. LASSO Regularization
```r
# 2. LASSO REGULARIZATION with validation
cat("2. ALPINE LASSO REGULARIZATION:\n")
lasso_selected_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_men <- as.matrix(train_men[all_features_men])
  y_men <- train_men$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_men))) {
    warning("Non-finite values in alpine feature matrix for LASSO")
  }
  if (any(!is.finite(y_men))) {
    warning("Non-finite values in alpine target variable for LASSO")
  }
  
  cv_lasso_men <- cv.glmnet(x_men, y_men, alpha = 1, nfolds = 5)
  best_lambda_men <- cv_lasso_men$lambda.min
  lasso_coef_men <- coef(cv_lasso_men, s = best_lambda_men)
  
  lasso_selected_men <- rownames(lasso_coef_men)[which(lasso_coef_men != 0)][-1]  # Remove intercept
  
  if (length(lasso_selected_men) > 0) {
    cat("Alpine LASSO selected features:\n")
    for (feature in lasso_selected_men) {
      coef_val <- lasso_coef_men[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by alpine LASSO (may indicate weak predictors)\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_men))
  
}, error = function(e) {
  cat("Error in alpine LASSO analysis:", e$message, "\n")
  lasso_selected_men <- character(0)
})
```

**Purpose**: Uses L1 regularization to identify alpine features that contribute most to prediction accuracy while preventing overfitting.

**LASSO Selection Features**:
- **Automatic Feature Selection**: LASSO naturally selects most predictive alpine features
- **Overfitting Prevention**: L1 regularization reduces model complexity for alpine data
- **Cross-Validation**: 5-fold CV optimizes lambda parameter for alpine-specific patterns
- **Coefficient Reporting**: Shows feature importance magnitude and direction
- **Reproducibility**: Fixed random seed ensures consistent results across runs

##### 4c. Boruta Feature Selection
```r
# 3. BORUTA FEATURE SELECTION with validation
cat("3. ALPINE BORUTA FEATURE SELECTION:\n")
boruta_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_men <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                         data = train_men, doTrace = 0)
    
    boruta_selected_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_men) > 0) {
      cat("Alpine Boruta confirmed features:\n")
      for (feature in boruta_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by alpine Boruta\n")
    }
    
    # Check for tentative features
    tentative_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Tentative"]
    if (length(tentative_men) > 0) {
      cat("Alpine Boruta tentative features:\n")
      for (feature in tentative_men) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in alpine Boruta analysis:", e$message, "\n")
  boruta_selected_men <- character(0)
})
```

**Purpose**: Uses random forest-based all-relevant feature selection to identify all alpine features that have genuine predictive value.

**Boruta Selection Features**:
- **All-Relevant Selection**: Identifies all genuinely useful alpine features, not just best subset
- **Statistical Rigor**: Uses permutation testing to validate feature importance against random chance
- **Random Forest Foundation**: Leverages ensemble method strengths for alpine data patterns
- **Tentative Feature Handling**: Provides uncertainty quantification for borderline alpine features
- **Robust to Interactions**: Captures complex relationships between alpine disciplines

##### 4d. Exhaustive Search
```r
# 4. EXHAUSTIVE SEARCH with validation
cat("4. ALPINE EXHAUSTIVE SEARCH:\n")
leaps_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for exhaustive search\n")
  } else if (length(all_features_men) > 8) {
    cat("Too many alpine features for exhaustive search - using best subset\n")
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, nvmax = min(8, length(all_features_men)))
  } else {
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, really.big = TRUE)
  }
  
  if (exists("leaps_men")) {
    summary_leaps_men <- summary(leaps_men)
    best_model_size <- which.max(summary_leaps_men$adjr2)
    leaps_selected_men <- names(which(summary_leaps_men$which[best_model_size, -1]))  # Remove intercept
    
    if (length(leaps_selected_men) > 0) {
      cat("Alpine exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_men$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by alpine exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine exhaustive search:", e$message, "\n")
  leaps_selected_men <- character(0)
})
```

**Purpose**: Performs exhaustive search for optimal alpine feature combinations using adjusted R-squared optimization.

**Exhaustive Search Features**:
- **Optimal Subset Identification**: Finds best alpine feature combination for linear prediction
- **Adjusted R² Optimization**: Balances model fit with complexity for alpine data
- **Computational Efficiency**: Limits search to 8 features when full search impractical
- **Model Size Reporting**: Provides transparency about selected model complexity
- **Linear Relationship Focus**: Optimized for linear relationships in alpine performance data

#### 5. Consensus Feature Selection and Final Integration
```r
# 5. CONSENSUS FEATURE SELECTION
cat("5. ALPINE CONSENSUS FEATURE SELECTION:\n")

all_selected_men <- c(lasso_selected_men, boruta_selected_men, leaps_selected_men)
if (length(all_selected_men) > 0) {
  feature_counts_men <- table(all_selected_men)
  consensus_men <- names(feature_counts_men)[feature_counts_men >= 2]  # Features selected by 2+ methods
  
  if (length(consensus_men) > 0) {
    cat("Alpine consensus features (selected by 2+ methods):\n")
    for (feature in consensus_men) {
      count <- feature_counts_men[feature]
      methods <- c(
        if (feature %in% lasso_selected_men) "LASSO" else NULL,
        if (feature %in% boruta_selected_men) "Boruta" else NULL,
        if (feature %in% leaps_selected_men) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No alpine consensus features - using union of all methods\n")
    consensus_men <- unique(all_selected_men)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_men) && "Pct_of_Max_Points" %in% names(train_men)) {
    target_cors <- cor(train_men[all_features_men], train_men$Pct_of_Max_Points, use = "complete.obs")
    consensus_men <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_men))]
  } else {
    consensus_men <- all_features_men[1:min(3, length(all_features_men))]
  }
}

final_features_men <- consensus_men
cat(sprintf("Final alpine features for men: %s\n", paste(final_features_men, collapse = ", ")))
```

**Purpose**: Integrates results from multiple feature selection methods to create robust, consensus-based feature sets for alpine skiing prediction.

**Consensus Strategy**:
- **Multi-Method Integration**: Combines LASSO, Boruta, and exhaustive search results
- **Robust Selection**: Prioritizes features selected by 2+ methods for reliability
- **Fallback Mechanisms**: Uses union of methods or correlation-based selection when consensus fails
- **Method Transparency**: Reports which methods selected each consensus feature
- **Quality Assurance**: Ensures at least some features selected for model building

#### 6. Cross-Gender Feature Selection Replication
The same comprehensive feature selection process is applied to women's alpine data:

```r
cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION FOR LADIES ===\n")

# Repeat the same process for ladies with alpine-specific adaptations
# 1. CORRELATION ANALYSIS
# 2. LASSO REGULARIZATION  
# 3. BORUTA FEATURE SELECTION
# 4. EXHAUSTIVE SEARCH
# 5. CONSENSUS FEATURE SELECTION
```

**Purpose**: Ensures consistent and thorough feature selection across both men's and women's alpine skiing datasets.

**Cross-Gender Consistency**:
- **Parallel Processing**: Applies identical methodology to both datasets
- **Gender-Specific Optimization**: Allows for different optimal feature sets between men's and women's alpine skiing
- **Comparative Analysis**: Enables comparison of feature importance patterns across genders
- **Independent Validation**: Validates feature selection robustness across different athlete populations

#### 7. Feature Selection Results Storage and Summary
```r
cat("\n=== ALPINE FEATURE SELECTION SUMMARY ===\n")
cat(sprintf("Men's final alpine features (%d): %s\n", length(final_features_men), paste(final_features_men, collapse = ", ")))
cat(sprintf("Ladies final alpine features (%d): %s\n", length(final_features_ladies), paste(final_features_ladies, collapse = ", ")))

# Store feature selection results for later use
feature_selection_results_men <- list(
  lasso = lasso_selected_men,
  boruta = boruta_selected_men,
  exhaustive = leaps_selected_men,
  final = final_features_men
)

feature_selection_results_ladies <- list(
  lasso = lasso_selected_ladies,
  boruta = boruta_selected_ladies,
  exhaustive = leaps_selected_ladies,
  final = final_features_ladies
)

cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION COMPLETE ===\n")
```

**Purpose**: Summarizes feature selection results and stores detailed outcomes for subsequent modeling and analysis.

**Results Documentation**:
- **Final Feature Sets**: Reports consensus features for both men's and women's alpine skiing
- **Method-Specific Results**: Preserves individual method results for analysis and debugging
- **Structured Storage**: Organizes results in lists for programmatic access in downstream modeling
- **Comprehensive Summary**: Provides clear overview of feature selection outcomes

### Alpine Feature Selection Design Considerations

#### Multi-Discipline Feature Space
Alpine skiing's unique feature requirements:
- **Discipline-Specific ELOs**: Individual ratings for Downhill, Super G, Giant Slalom, Slalom, Combined
- **Aggregate Category Features**: Technical vs Speed discipline groupings
- **Performance History**: Previous season success metrics and trend indicators
- **Demographic Factors**: Age and experience considerations

#### Method Complementarity
The multi-method approach leverages different selection strengths:
- **LASSO**: Linear relationship optimization with automatic feature selection
- **Boruta**: All-relevant features with statistical rigor and interaction capture
- **Exhaustive Search**: Optimal subset identification for linear prediction
- **Consensus Integration**: Robust feature sets through method agreement

#### Alpine-Specific Adaptations
- **Season-Aware Training**: Uses 2016-2025 timeframe for modern alpine competitive dynamics
- **Discipline Balance**: Ensures representation across alpine's diverse competitive structure
- **Performance Standardization**: Works with percentage of maximum points for cross-season comparability
- **Gender-Specific Optimization**: Allows for different optimal features between men's and women's alpine skiing

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data availability and quality
- **Method-Specific Validation**: Individual error handling for each selection method
- **Consensus Robustness**: Multiple fallback strategies when consensus fails
- **Cross-Dataset Consistency**: Parallel processing ensures consistent methodology
- **Results Documentation**: Detailed tracking of selection outcomes and method performance

This alpine feature selection section creates optimized, statistically validated feature sets that capture the most predictive aspects of alpine skiing performance while maintaining robustness across different modeling approaches and athlete populations.

## Section: {r gam-model} - Alpine GAM Model Building & Prediction

### Purpose
This section builds Generalized Additive Models (GAM) for alpine skiing season prediction using consensus-selected features, validates model performance, and generates 2026 season predictions with comprehensive error handling and diagnostic evaluation.

### Implementation Details

#### 1. GAM Model Construction and Input Validation
```r
cat("=== GAM MODEL BUILDING & VALIDATION ===\n")

# Build GAM models using consensus-selected features with comprehensive validation
cat("\n--- GAM Model Construction ---\n")

# Validate inputs for GAM model building
if (!exists("final_features_men") || !exists("final_features_ladies")) {
  stop("Final features not defined - ensure feature selection completed successfully")
}

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure data preparation completed successfully")
}

cat(sprintf("Input validation: Men %d features, Ladies %d features\n", 
            length(final_features_men), length(final_features_ladies)))

cat(sprintf("Training data: Men %d rows, Ladies %d rows\n", 
            nrow(train_men), nrow(train_ladies)))
```

**Purpose**: Establishes comprehensive validation framework for GAM model construction using alpine-specific consensus features.

**Input Validation Features**:
- **Feature Availability Check**: Ensures consensus feature selection completed successfully
- **Training Data Validation**: Confirms processed training data is available for modeling
- **Data Size Reporting**: Reports feature counts and training dataset sizes for both genders
- **Dependency Verification**: Validates that prerequisite processing steps completed successfully

#### 2. Men's GAM Model Construction with Robust Error Handling
```r
# Build GAM formula for Men using validated features
cat("\n--- Men's GAM Model ---\n")
men_gam_model <- NULL
tryCatch({
  if(length(final_features_men) > 0) {
    # Validate features exist in training data
    missing_features_men <- setdiff(final_features_men, names(train_men))
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's training data:", paste(missing_features_men, collapse = ", "), "\n")
      final_features_men <- intersect(final_features_men, names(train_men))
    }
    
    if (length(final_features_men) > 0) {
      smooth_terms_men <- paste("s(", final_features_men, ")", collapse = " + ")
      gam_formula_men <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_men))
      cat("Men's GAM Formula (Validated Features):\n")
      print(gam_formula_men)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_men) * min_obs_per_feature
      if (nrow(train_men) < required_obs) {
        warning(sprintf("Limited observations for men's GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_men), length(final_features_men), required_obs))
      }
      
      # Build GAM with error handling
      men_gam_model <- gam(gam_formula_men, data = train_men)
      cat(sprintf("✓ Men's GAM model built successfully with %d features\n", length(final_features_men)))
    }
  }
}, error = function(e) {
  cat("Error building men's GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_men <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_men))
  if (length(core_features_men) >= 2) {
    fallback_formula_men <- paste("Pct_of_Max_Points ~", paste("s(", core_features_men, ")", collapse = " + "))
    men_gam_model <- gam(as.formula(fallback_formula_men), data = train_men)
    final_features_men <- core_features_men
    cat("✓ Men's GAM fallback model built with core features\n")
  } else {
    stop("Cannot build men's GAM model - insufficient core features available")
  }
})
```

**Purpose**: Constructs robust GAM models for men's alpine skiing with comprehensive error handling and fallback strategies.

**GAM Construction Features**:
- **Feature Validation**: Confirms selected features exist in training data before model building
- **Formula Generation**: Creates GAM formula with smooth terms for non-linear relationships
- **Data Sufficiency Check**: Validates adequate observations per feature (10:1 ratio recommended)
- **Smooth Term Integration**: Uses `s()` notation for capturing non-linear alpine performance relationships
- **Robust Error Handling**: Implements fallback to core alpine features when consensus features fail

**Fallback Strategy**:
- **Core Features**: Falls back to proven alpine predictors (Prev_Pct_of_Max_Points, Prev_Pelo, Prev_Tech, Prev_Speed)
- **Minimum Requirements**: Requires at least 2 core features for fallback model
- **Graceful Degradation**: Ensures model building succeeds even with limited feature availability

#### 3. Ladies GAM Model Construction with Parallel Processing
```r
# Build GAM formula for Ladies using validated features
cat("\n--- Ladies GAM Model ---\n")
ladies_gam_model <- NULL
tryCatch({
  if(length(final_features_ladies) > 0) {
    # Validate features exist in training data
    missing_features_ladies <- setdiff(final_features_ladies, names(train_ladies))
    if (length(missing_features_ladies) > 0) {
      cat("Warning: Missing features in ladies training data:", paste(missing_features_ladies, collapse = ", "), "\n")
      final_features_ladies <- intersect(final_features_ladies, names(train_ladies))
    }
    
    if (length(final_features_ladies) > 0) {
      smooth_terms_ladies <- paste("s(", final_features_ladies, ")", collapse = " + ")
      gam_formula_ladies <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_ladies))
      cat("Ladies GAM Formula (Validated Features):\n")
      print(gam_formula_ladies)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_ladies) * min_obs_per_feature
      if (nrow(train_ladies) < required_obs) {
        warning(sprintf("Limited observations for ladies GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_ladies), length(final_features_ladies), required_obs))
      }
      
      # Build GAM with error handling
      ladies_gam_model <- gam(gam_formula_ladies, data = train_ladies)
      cat(sprintf("✓ Ladies GAM model built successfully with %d features\n", length(final_features_ladies)))
    }
  }
}, error = function(e) {
  cat("Error building ladies GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_ladies <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_ladies))
  if (length(core_features_ladies) >= 2) {
    fallback_formula_ladies <- paste("Pct_of_Max_Points ~", paste("s(", core_features_ladies, ")", collapse = " + "))
    ladies_gam_model <- gam(as.formula(fallback_formula_ladies), data = train_ladies)
    final_features_ladies <- core_features_ladies
    cat("✓ Ladies GAM fallback model built with core features\n")
  } else {
    stop("Cannot build ladies GAM model - insufficient core features available")
  }
})
```

**Purpose**: Constructs women's alpine GAM models using identical methodology to ensure cross-gender consistency and robustness.

**Parallel Processing Benefits**:
- **Consistent Methodology**: Uses same validation and construction process as men's models
- **Gender-Specific Optimization**: Allows for different optimal features between men's and women's alpine skiing
- **Independent Validation**: Validates model construction robustness across different athlete populations
- **Comparative Analysis**: Enables comparison of model performance patterns across genders

#### 4. Comprehensive GAM Model Performance Evaluation
```r
# Model performance evaluation with validation
cat("\n=== GAM MODEL PERFORMANCE EVALUATION ===\n")

# Men's GAM Model Performance
cat("--- Men's GAM Model Performance ---\n")
tryCatch({
  men_summary <- summary(men_gam_model)
  
  # Validate summary components exist
  if (is.null(men_summary$dev.expl)) {
    warning("Men's GAM deviance explained not available")
    men_dev_expl <- NA
  } else {
    men_dev_expl <- men_summary$dev.expl * 100
  }
  
  if (is.null(men_summary$r.sq)) {
    warning("Men's GAM R-squared not available")
    men_r_sq <- NA
  } else {
    men_r_sq <- men_summary$r.sq
  }
  
  if (is.null(men_gam_model$gcv.ubre)) {
    warning("Men's GAM GCV score not available")
    men_gcv <- NA
  } else {
    men_gcv <- men_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", men_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", men_r_sq))
  cat(sprintf("GCV Score: %.4f\n", men_gcv))
  
  # Validate model performance
  if (!is.na(men_dev_expl) && men_dev_expl < 10) {
    warning("Men's GAM has very low deviance explained (<10%)")
  }
  if (!is.na(men_r_sq) && men_r_sq < 0.1) {
    warning("Men's GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(men_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(men_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating men's GAM performance:", e$message, "\n")
})
```

**Purpose**: Provides comprehensive evaluation of GAM model performance using multiple alpine-specific metrics.

**Performance Metrics**:
- **Deviance Explained**: Measures how much variance the model explains in alpine performance data
- **Adjusted R-squared**: Accounts for model complexity in goodness-of-fit assessment
- **GCV Score**: Generalized Cross-Validation score for model selection and validation
- **Effective Degrees of Freedom**: Measures model complexity for alpine feature relationships

**Quality Validation**:
- **Performance Thresholds**: Warns if deviance explained <10% or R-squared <0.1
- **Component Validation**: Ensures all performance metrics are available and valid
- **Model Complexity Assessment**: Reports observations and effective degrees of freedom

#### 5. Feature Importance Analysis Through Effective Degrees of Freedom
```r
# Feature importance from GAM (edf values) with validation
cat("\n--- Feature Importance Analysis ---\n")

# Men's Feature Importance
cat("Men's GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(men_summary$s.table) && nrow(men_summary$s.table) > 0) {
    men_edf <- men_summary$s.table[,"edf"]
    names(men_edf) <- rownames(men_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(men_edf))) {
      warning("Some men's GAM EDF values are NA")
      men_edf <- men_edf[!is.na(men_edf)]
    }
    
    if (length(men_edf) > 0) {
      edf_sorted <- sort(men_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features (high EDF suggests non-linear relationship)
      high_edf_features <- names(men_edf[men_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for men's model\n")
    }
  } else {
    cat("No smooth terms in men's GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing men's feature importance:", e$message, "\n")
})
```

**Purpose**: Analyzes feature importance in alpine GAM models using Effective Degrees of Freedom to understand non-linear relationships.

**EDF Analysis Features**:
- **Non-linearity Detection**: High EDF values (>3) indicate strong non-linear relationships in alpine performance
- **Feature Ranking**: Sorts features by complexity to identify most important alpine predictors
- **Complexity Assessment**: EDF ≈1 suggests linear relationship, higher values indicate more complex curves
- **Alpine-Specific Interpretation**: Helps understand which alpine disciplines show non-linear performance patterns

#### 6. Comprehensive GAM Model Diagnostics
```r
# Model diagnostics with validation
cat("\n=== GAM MODEL DIAGNOSTICS ===\n")

# Men's GAM Model Diagnostics
cat("--- Men's GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_men <- gam.check(men_gam_model, sub.caption = "Men's GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_men)) {
    # Check for model convergence issues
    if ("converged" %in% names(men_gam_model) && !men_gam_model$converged) {
      warning("Men's GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(men_summary)) {
      basis_dims <- men_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Men's GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Men's GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating men's GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})
```

**Purpose**: Generates comprehensive diagnostic plots and validates GAM model assumptions for alpine skiing data.

**Diagnostic Features**:
- **Residual Analysis**: QQ plots and residual vs fitted plots for assumption validation
- **Convergence Validation**: Checks if GAM optimization converged properly for alpine data
- **Basis Dimension Assessment**: Validates smooth function basis dimensions are adequate
- **Visual Diagnostics**: Four-panel diagnostic plots for comprehensive model validation

#### 7. 2026 Season Prediction Framework
```r
# Predict for 2026 season using 2025 ELO values with comprehensive validation
cat("\n=== 2026 SEASON PREDICTIONS ===\n")

# Validate prediction data availability
cat("--- Prediction Data Preparation ---\n")

# Check for 2025 ELO data (end-of-season values)
men_2025 <- M_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

ladies_2025 <- L_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

# Rename columns to match GAM model expectations (Prev_* format)
cat("Renaming 2025 features to Prev_* format for GAM predictions...\n")
```

**Purpose**: Establishes comprehensive framework for generating 2026 alpine skiing season predictions using trained GAM models.

**Prediction Data Preparation**:
- **End-of-Season ELO**: Uses most recent 2025 ELO ratings as predictors for 2026 performance
- **Feature Alignment**: Renames 2025 ELO columns to match GAM model expected format (Prev_*)
- **Data Validation**: Ensures prediction data availability and quality before GAM prediction
- **Temporal Consistency**: Maintains proper time ordering for prediction validity

#### 8. Data Preprocessing for 2026 Predictions
```r
if (nrow(men_2025) > 0) {
  # First, remove existing Prev_* columns (which contain 2024 data)
  prev_cols_to_remove <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                          "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  existing_prev_cols <- intersect(prev_cols_to_remove, names(men_2025))
  if (length(existing_prev_cols) > 0) {
    cat("Removing existing Prev_* columns (2024 data):", paste(existing_prev_cols, collapse = ", "), "\n")
    men_2025 <- men_2025 %>% dplyr::select(-all_of(existing_prev_cols))
  }
  
  # Then rename current 2025 columns to Prev_* format
  men_2025 <- men_2025 %>%
    rename(
      Prev_Pelo = Pelo,
      Prev_Downhill = Downhill_Pelo,
      Prev_Super_G = `Super G_Pelo`,
      Prev_Giant_Slalom = `Giant Slalom_Pelo`,
      Prev_Slalom = Slalom_Pelo,
      Prev_Combined = Combined_Pelo,
      Prev_Tech = Tech_Pelo,
      Prev_Speed = Speed_Pelo,
      Prev_Pct_of_Max_Points = Pct_of_Max_Points
    )
}

# Apply quartile replacement to handle missing values in 2025 data
cat("Applying quartile replacement for missing values in 2025 prediction data...\n")

if (nrow(men_2025) > 0) {
  men_2025 <- men_2025 %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_Super_G = replace_na_with_quartile(Prev_Super_G),
      Prev_Giant_Slalom = replace_na_with_quartile(Prev_Giant_Slalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace_na_with_quartile(Prev_Pct_of_Max_Points)
    ) %>%
    ungroup()
}
```

**Purpose**: Implements robust data preprocessing for 2026 predictions with comprehensive missing value handling.

**Preprocessing Steps**:
- **Legacy Data Removal**: Removes outdated Prev_* columns containing 2024 data
- **Feature Renaming**: Converts 2025 ELO ratings to Prev_* format for GAM model compatibility
- **Missing Value Imputation**: Applies conservative quartile-based imputation for missing alpine ELO values
- **Discipline-Specific Treatment**: Handles missing values for each alpine discipline independently

#### 9. GAM-Based 2026 Prediction Generation
```r
# Men's 2026 Predictions
cat("\n--- Men's 2026 Predictions ---\n")
men_pred_data <- NULL
if(nrow(men_2025) > 0) {
  tryCatch({
    # Validate features are available in 2025 data
    available_features_men <- intersect(final_features_men, names(men_2025))
    missing_features_men <- setdiff(final_features_men, names(men_2025))
    
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's 2025 data for prediction:", paste(missing_features_men, collapse = ", "), "\n")
    }
    
    if (length(available_features_men) > 0) {
      # Debug: Show exact GAM model input for Marcel Hirscher
      if ("Marcel Hirscher" %in% men_2025$Skier) {
        hirscher_idx <- which(men_2025$Skier == "Marcel Hirscher")
        cat("\n=== DEBUG: Marcel Hirscher GAM Model Input ===\n")
        cat("Selected features for GAM:", paste(final_features_men, collapse = ", "), "\n")
        hirscher_model_data <- men_2025[hirscher_idx, c("Skier", final_features_men), drop = FALSE]
        print(hirscher_model_data)
      }
      
      # Use only available features for prediction
      pred_2026_men <- predict(men_gam_model, newdata = men_2025, se.fit = TRUE)
      
      # Validate predictions
      if (any(!is.finite(pred_2026_men$fit))) {
        warning("Some men's 2026 predictions are non-finite")
        pred_2026_men$fit[!is.finite(pred_2026_men$fit)] <- NA
      }
      
      men_pred_data <- men_2025 %>%
        mutate(
          Predicted_Pct_2026 = pred_2026_men$fit,
          Prediction_SE = pred_2026_men$se.fit,
          Lower_CI = Predicted_Pct_2026 - 1.96 * Prediction_SE,
          Upper_CI = Predicted_Pct_2026 + 1.96 * Prediction_SE
        ) %>%
        filter(!is.na(Predicted_Pct_2026)) %>%
        arrange(desc(Predicted_Pct_2026))
      
      cat(sprintf("✓ Men's 2026 predictions generated for %d athletes\n", nrow(men_pred_data)))
      cat(sprintf("Top predicted: %s (%.2f%% of max points)\n", 
                  men_pred_data$Skier[1], men_pred_data$Predicted_Pct_2026[1] * 100))
    }
  }, error = function(e) {
    cat("Error generating men's 2026 predictions:", e$message, "\n")
  })
}
```

**Purpose**: Generates 2026 season predictions with confidence intervals and comprehensive validation.

**Prediction Features**:
- **Feature Validation**: Ensures required features are available in 2025 prediction data
- **Debug Output**: Provides detailed model input for star athletes (Marcel Hirscher, Lara Colturi)
- **Uncertainty Quantification**: Generates standard errors and 95% confidence intervals
- **Prediction Validation**: Checks for non-finite predictions and handles gracefully
- **Results Ranking**: Sorts predictions by expected performance for easy interpretation

### Alpine GAM-Specific Design Considerations

#### Non-Linear Relationship Modeling
GAM models excel at capturing alpine skiing's complex performance patterns:
- **Smooth Functions**: Use spline smoothing to model non-linear relationships between ELO ratings and performance
- **Discipline Interactions**: Capture complex relationships between different alpine disciplines
- **Performance Curves**: Model diminishing returns and threshold effects in alpine performance
- **Age Effects**: Capture non-linear age-performance relationships in alpine skiing

#### Alpine-Specific Model Validation
- **EDF Interpretation**: High EDF values indicate complex non-linear relationships specific to alpine disciplines
- **Convergence Monitoring**: Ensures GAM optimization converges properly for alpine data patterns
- **Basis Dimension Validation**: Confirms adequate flexibility for modeling alpine performance curves
- **Cross-Gender Consistency**: Validates model construction robustness across different athlete populations

#### Prediction Robustness
- **Feature Alignment**: Ensures 2025 ELO data properly formatted for GAM prediction
- **Missing Value Handling**: Conservative quartile-based imputation maintains prediction reliability
- **Uncertainty Quantification**: Confidence intervals provide prediction reliability assessment
- **Star Athlete Debugging**: Detailed output for high-profile athletes ensures prediction transparency

### Error Handling and Quality Assurance
- **Comprehensive Input Validation**: Validates all prerequisites before GAM construction
- **Robust Fallback Strategies**: Core feature fallbacks ensure model building succeeds
- **Performance Monitoring**: Multiple metrics assess model quality and reliability
- **Prediction Validation**: Extensive checks ensure prediction quality and interpretability
- **Diagnostic Integration**: Built-in diagnostic plots validate model assumptions

This alpine GAM modeling section creates sophisticated, non-linear prediction models that capture the complex relationships inherent in alpine skiing performance while maintaining robustness and providing comprehensive uncertainty quantification for 2026 season predictions.

## Section: {r odds-setup} - Alpine Odds Framework & Categorical Outcome Preparation

### Purpose
This section establishes the comprehensive framework for odds calculation in alpine skiing by creating categorical performance outcomes, validating ranking systems, and preparing prediction data for statistical odds modeling across multiple performance thresholds.

### Implementation Details

#### 1. Training Data Validation for Odds Calculation
```r
cat("=== ODDS SETUP & VALIDATION ===\n")

# Validate training data availability for odds calculations
cat("\n--- Training Data Validation for Odds ---\n")

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure previous sections completed successfully")
}

if (nrow(train_men) == 0) {
  stop("Men's training data is empty")
}
if (nrow(train_ladies) == 0) {
  stop("Ladies training data is empty") 
}

cat(sprintf("Training data for odds: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Validate required columns exist
required_odds_cols <- c("Pct_of_Max_Points", "Season")
missing_men_cols <- setdiff(required_odds_cols, names(train_men))
missing_ladies_cols <- setdiff(required_odds_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop(sprintf("Men's training data missing required columns for odds: %s", paste(missing_men_cols, collapse = ", ")))
}
if (length(missing_ladies_cols) > 0) {
  stop(sprintf("Ladies training data missing required columns for odds: %s", paste(missing_ladies_cols, collapse = ", ")))
}
```

**Purpose**: Validates comprehensive training data availability and quality for alpine skiing odds calculation framework.

**Data Validation Features**:
- **Training Data Existence**: Confirms processed training data is available from previous sections
- **Empty Dataset Protection**: Prevents odds calculation with insufficient data
- **Required Column Validation**: Ensures essential variables (Pct_of_Max_Points, Season) are present
- **Cross-Gender Validation**: Validates data availability for both men's and women's alpine skiing

**Quality Assurance**:
- **Data Size Reporting**: Reports training dataset sizes for transparency
- **Dependency Verification**: Ensures prerequisite processing steps completed successfully
- **Error Prevention**: Stops processing if critical data components are missing

#### 2. Season-Based Ranking System Implementation
```r
# Add Place column based on rankings within each season with validation
cat("\n--- Season Ranking Calculation ---\n")

tryCatch({
  df_place <- train_men %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
  
  cat(sprintf("✓ Men's place rankings calculated: %d rows\n", nrow(df_place)))
}, error = function(e) {
  stop("Failed to calculate men's place rankings: ", e$message)
})

tryCatch({
  df_place_ladies <- train_ladies %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
    
  cat(sprintf("✓ Ladies place rankings calculated: %d rows\n", nrow(df_place_ladies)))
}, error = function(e) {
  stop("Failed to calculate ladies place rankings: ", e$message)
})

# Validate Place column creation
place_na_men <- sum(is.na(df_place$Place))
place_na_ladies <- sum(is.na(df_place_ladies$Place))

if (place_na_men > 0) {
  warning(sprintf("Men's Place column has %d NA values", place_na_men))
}
if (place_na_ladies > 0) {
  warning(sprintf("Ladies Place column has %d NA values", place_na_ladies))
}

# Validate ranking ranges
men_place_range <- range(df_place$Place, na.rm = TRUE)
ladies_place_range <- range(df_place_ladies$Place, na.rm = TRUE)

cat(sprintf("Men's Place range: %d - %d\n", men_place_range[1], men_place_range[2]))
cat(sprintf("Ladies Place range: %d - %d\n", ladies_place_range[1], ladies_place_range[2]))
```

**Purpose**: Implements robust season-based ranking system that creates competitive context for alpine skiing odds calculation.

**Ranking System Features**:
- **Season-Based Rankings**: Rankings calculated within each season to account for competitive context
- **Performance-Based Ordering**: Uses negative Pct_of_Max_Points for descending order (best performers ranked 1st)
- **Tie Handling**: Uses "min" method for consistent tie-breaking in alpine performance rankings
- **Cross-Gender Processing**: Applies identical ranking methodology to both men's and women's data

**Validation Framework**:
- **Missing Value Detection**: Identifies and reports any NA values in ranking calculations
- **Range Validation**: Confirms ranking ranges are logical (starting from 1)
- **Error Handling**: Robust error handling ensures ranking calculation succeeds or fails gracefully

#### 3. Comprehensive Season Ranking Validation
```r
# Debug and validate season rankings
cat("\n--- Season Ranking Validation ---\n")

# Check ladies data distribution
cat("Ladies Pct_of_Max_Points distribution:\n")
ladies_pct_summary <- summary(train_ladies$Pct_of_Max_Points)
print(ladies_pct_summary)

# Validate no negative or extreme values
if (any(train_ladies$Pct_of_Max_Points < 0, na.rm = TRUE)) {
  warning("Ladies data contains negative Pct_of_Max_Points values")
}
if (any(train_ladies$Pct_of_Max_Points > 2, na.rm = TRUE)) {
  warning("Ladies data contains very high Pct_of_Max_Points values (>200%)")
}

cat("Ladies Place distribution:\n")
ladies_place_table <- table(df_place_ladies$Place)
print(head(ladies_place_table, 10))

cat("Ladies seasons distribution:\n")
ladies_season_table <- table(df_place_ladies$Season)
print(ladies_season_table)

# Check for balanced season representation
if (any(ladies_season_table < 5)) {
  seasons_low_n <- names(ladies_season_table[ladies_season_table < 5])
  warning(sprintf("Ladies seasons with <5 observations: %s", paste(seasons_low_n, collapse = ", ")))
}

# Sample rankings validation
cat("Sample ladies season rankings (first 15):\n")
sample_rankings <- df_place_ladies %>% 
  arrange(Season, Place) %>% 
  dplyr::select(Season, Skier, Pct_of_Max_Points, Place) %>%
  head(15)
print(sample_rankings)
```

**Purpose**: Provides comprehensive validation of alpine skiing ranking system quality and distribution characteristics.

**Validation Components**:
- **Performance Distribution Analysis**: Examines Pct_of_Max_Points distribution for data quality
- **Extreme Value Detection**: Identifies negative or unrealistically high performance values
- **Ranking Distribution**: Analyzes place distribution to understand competitive structure
- **Season Balance Assessment**: Ensures adequate representation across all alpine skiing seasons
- **Sample Validation**: Provides concrete examples of ranking calculation results

**Quality Checks**:
- **Data Range Validation**: Confirms performance percentages are within expected bounds (0-200%)
- **Season Representation**: Warns about seasons with insufficient data (<5 observations)
- **Ranking Logic Verification**: Shows sample rankings to validate correct ordering

#### 4. Categorical Outcome Framework Creation
```r
# Create categorical outcomes for different cutoffs with validation
cat("\n--- Categorical Outcome Creation ---\n")

tryCatch({
  df_place <- df_place %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Men's categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create men's categorical outcomes: ", e$message)
})

tryCatch({
  df_place_ladies <- df_place_ladies %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Ladies categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create ladies categorical outcomes: ", e$message)
})
```

**Purpose**: Creates comprehensive categorical outcome framework for alpine skiing odds calculation across multiple performance thresholds.

**Categorical Outcome Structure**:
- **Win**: Season victory (Place <= 1) - captures championship-level performance
- **TopThree**: Podium finish (Place <= 3) - represents elite consistency in alpine skiing
- **Top5**: Elite performance (Place <= 5) - broader elite tier for alpine competitive analysis
- **Top10**: Strong performance (Place <= 10) - competitive alpine skiing threshold
- **Top30**: Points-scoring finish (Place <= 30) - alpine World Cup points eligibility

**Alpine-Specific Considerations**:
- **Championship Focus**: Win category captures seasonal dominance in alpine skiing
- **Podium Emphasis**: TopThree aligns with alpine skiing's podium ceremony tradition
- **Points Threshold**: Top30 corresponds to alpine World Cup points system (top 30 score points)
- **Factor Encoding**: Binary factors (0/1) enable logistic regression modeling for odds calculation

#### 5. Comprehensive Categorical Outcome Validation
```r
# Validate categorical outcome creation
cat("\n--- Categorical Outcome Validation ---\n")

# Check TopThree creation for ladies
cat("Ladies Place vs TopThree validation:\n")
topthree_crosstab <- table(df_place_ladies$Place, df_place_ladies$TopThree, useNA = "always")
print(topthree_crosstab[1:min(10, nrow(topthree_crosstab)), ])

# Validate factor levels
expected_levels <- c("0", "1")
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")

for (target in targets) {
  men_levels <- levels(df_place[[target]])
  ladies_levels <- levels(df_place_ladies[[target]])
  
  if (!all(expected_levels %in% men_levels)) {
    warning(sprintf("Men's %s missing expected levels: %s", target, paste(setdiff(expected_levels, men_levels), collapse = ", ")))
  }
  if (!all(expected_levels %in% ladies_levels)) {
    warning(sprintf("Ladies %s missing expected levels: %s", target, paste(setdiff(expected_levels, ladies_levels), collapse = ", ")))
  }
  
  # Check for class imbalance
  men_table <- table(df_place[[target]])
  ladies_table <- table(df_place_ladies[[target]])
  
  men_minority_pct <- min(men_table) / sum(men_table) * 100
  ladies_minority_pct <- min(ladies_table) / sum(ladies_table) * 100
  
  cat(sprintf("%s class balance: Men %.1f%% minority, Ladies %.1f%% minority\n", 
              target, men_minority_pct, ladies_minority_pct))
  
  if (men_minority_pct < 5) {
    warning(sprintf("Men's %s has severe class imbalance (<5%% minority class)", target))
  }
  if (ladies_minority_pct < 5) {
    warning(sprintf("Ladies %s has severe class imbalance (<5%% minority class)", target))
  }
}

# Sample TopThree values
cat("First 20 ladies Place and TopThree values:\n")
sample_topthree <- df_place_ladies %>% 
  dplyr::select(Skier, Season, Place, TopThree) %>% 
  head(20)
print(sample_topthree)
```

**Purpose**: Provides comprehensive validation of categorical outcome creation and identifies potential modeling challenges.

**Validation Framework**:
- **Cross-Tabulation Analysis**: Validates that categorical outcomes align correctly with place rankings
- **Factor Level Verification**: Ensures all categorical outcomes have expected binary levels (0, 1)
- **Class Balance Assessment**: Identifies class imbalance that could affect odds modeling quality
- **Sample Verification**: Provides concrete examples to validate categorical outcome logic

**Class Imbalance Monitoring**:
- **Severe Imbalance Detection**: Warns when minority class <5% (could cause modeling issues)
- **Cross-Gender Comparison**: Compares class balance between men's and women's alpine skiing
- **Performance Threshold Analysis**: Shows how class balance varies across different performance thresholds

#### 6. Prediction Data Preparation for Odds Calculation
```r
# Prepare 2025 prediction data with validation
cat("\n--- 2025 Prediction Data Preparation ---\n")

# Validate prediction data exists
if (!exists("men_pred_data") || is.null(men_pred_data)) {
  warning("Men's 2026 prediction data not available from previous section")
  men_pred_data <- data.frame()
}
if (!exists("ladies_pred_data") || is.null(ladies_pred_data)) {
  warning("Ladies 2026 prediction data not available from previous section") 
  ladies_pred_data <- data.frame()
}

# Men's prediction data preparation
pred_data_men <- NULL
if (nrow(men_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (alpine-specific)
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Downhill_Pelo", "Super G_Pelo", 
                           "Giant Slalom_Pelo", "Slalom_Pelo", "Combined_Pelo", 
                           "Tech_Pelo", "Speed_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(men_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(men_pred_data))
    
    cat(sprintf("Men's prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing men's prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_men <- men_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (alpine-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Downhill" = "Downhill_Pelo", 
                     "Prev_Super_G" = "Super G_Pelo", "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
                     "Prev_Slalom" = "Slalom_Pelo", "Prev_Combined" = "Combined_Pelo", 
                     "Prev_Tech" = "Tech_Pelo", "Prev_Speed" = "Speed_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "Nation")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_men)) {
          names(pred_data_men)[names(pred_data_men) == rename_map[old_name]] <- old_name
        }
      }
      
      # Handle column names with spaces by converting to underscores
      if ("Super G_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Super G_Pelo"] <- "Prev_Super_G"
      }
      if ("Giant Slalom_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Giant Slalom_Pelo"] <- "Prev_Giant_Slalom"
      }
      
      cat(sprintf("✓ Men's prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_men), ncol(pred_data_men)))
    } else {
      warning("Insufficient columns for men's prediction data preparation")
      pred_data_men <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing men's prediction data:", e$message, "\n")
    pred_data_men <- data.frame()
  })
} else {
  cat("No men's prediction data available\n")
  pred_data_men <- data.frame()
}
```

**Purpose**: Prepares 2026 prediction data for odds calculation by aligning feature names and validating data availability.

**Prediction Data Processing**:
- **Alpine-Specific Column Mapping**: Handles all alpine disciplines (Downhill, Super G, Giant Slalom, Slalom, Combined)
- **Feature Name Alignment**: Converts prediction data column names to match training data format
- **Space Handling**: Properly manages alpine discipline names containing spaces
- **Minimum Data Requirements**: Ensures at least 4 columns available for meaningful odds calculation

**Data Validation**:
- **Column Availability Assessment**: Reports available vs missing prediction columns
- **Graceful Degradation**: Continues processing with available columns when some are missing
- **Error Handling**: Robust error handling ensures prediction data preparation succeeds or fails gracefully

### Alpine Odds-Specific Design Considerations

#### Performance Threshold Framework
Alpine skiing odds framework uses sport-specific performance thresholds:
- **Championship Level**: Win category captures seasonal overall victory
- **Elite Consistency**: TopThree represents podium-level alpine performance
- **Competitive Tiers**: Top5, Top10, Top30 provide graduated performance levels
- **Points System Alignment**: Top30 threshold aligns with alpine World Cup points eligibility

#### Season-Based Ranking Context
Ranking system accounts for alpine skiing's competitive structure:
- **Seasonal Context**: Rankings calculated within seasons to account for varying competitive fields
- **Performance Standardization**: Uses percentage of maximum points for cross-season comparability
- **Tie-Breaking Consistency**: Standardized tie-breaking ensures reproducible rankings

#### Alpine-Specific Data Requirements
Odds framework handles alpine skiing's multi-discipline structure:
- **Discipline Coverage**: Accommodates all five alpine disciplines plus aggregate categories
- **ELO Integration**: Incorporates discipline-specific and overall ELO ratings
- **Feature Flexibility**: Handles missing disciplines gracefully while maintaining prediction capability

### Error Handling and Quality Assurance
- **Comprehensive Data Validation**: Validates training and prediction data availability and quality
- **Ranking System Verification**: Extensive validation of season-based ranking calculations
- **Categorical Outcome Validation**: Cross-tabulation and factor level verification
- **Class Balance Monitoring**: Identifies potential modeling challenges from class imbalance
- **Prediction Data Alignment**: Ensures feature name consistency between training and prediction data

This alpine odds setup section establishes a robust framework for odds calculation that respects alpine skiing's competitive structure while providing comprehensive validation and error handling to ensure reliable odds modeling across multiple performance thresholds.

### Implementation Details

#### 1. Core Processing Function: `process_alpine_chrono_data()`
The section centers around a robust processing function tailored for alpine skiing data:

```r
process_alpine_chrono_data <- function(chrono_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Processing %s Alpine Data ---\n", data_name))
  
  # Input validation
  if (nrow(chrono_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  # Check for required columns before processing
  required_cols <- c("Event", "Nation", "Place", "Distance", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(chrono_df))
  if (length(missing_cols) > 0) {
    stop(sprintf("Missing required columns in %s alpine data: %s", data_name, paste(missing_cols, collapse = ", ")))
  }
  
  original_rows <- nrow(chrono_df)
  cat(sprintf("Input: %d rows\n", original_rows))
}
```

**Purpose**: Provides a specialized framework for processing alpine skiing data that handles the sport's unique competitive structure and points system.

**Key Features**:
- **Parameterized Processing**: Accepts data name for detailed logging
- **Input Validation**: Ensures data integrity before processing
- **Column Validation**: Verifies all required fields are present
- **Progress Tracking**: Reports processing steps with row counts

#### 2. Alpine Points Assignment and Validation
```r
# Add Alpine World Cup points
cat("Adding Alpine World Cup points...\n")
df <- chrono_df %>%
  mutate(Points = map_int(Place, ~ get_alpine_points(.x, alpine_points)))

# Validate points assignment
points_na <- sum(is.na(df$Points))
points_negative <- sum(df$Points < 0, na.rm = TRUE)

if (points_na > 0) {
  warning(sprintf("%s: %d rows have NA points", data_name, points_na))
}
if (points_negative > 0) {
  warning(sprintf("%s: %d rows have negative points", data_name, points_negative))
}

cat(sprintf("Alpine points range: %d - %d\n", min(df$Points, na.rm = TRUE), max(df$Points, na.rm = TRUE)))
```

**Purpose**: Applies the Alpine World Cup points system to race results and validates the assignment process.

**Points Assignment Logic**:
- Uses `get_alpine_points()` function to safely assign points based on placement
- Awards 100 points for 1st place down to 1 point for 30th place
- Returns 0 points for placements outside top 30
- Handles edge cases (NA, negative, or invalid placements)

**Validation Features**:
- Checks for NA points assignments
- Identifies negative points (should not occur)
- Reports points range for verification

#### 3. Event Filtering and Competition Focus
```r
# Count events before filtering
event_counts_before <- table(df$Event)
cat("Events before filtering:\n")
print(event_counts_before)

# Filter for relevant alpine events (only World Cup and Offseason)
cat("Filtering for relevant alpine events (World Cup, Offseason)...\n")
relevant_events <- c("World Cup", "Offseason")

df <- df %>%
  filter(Event %in% relevant_events) %>%
  arrange(Date, Race, Place) %>%
  group_by(ID, Season) %>%
  mutate(
    Cumulative_Points = cumsum(Points),
    Races_in_Season = n()
  ) %>%
  ungroup()

filtered_rows <- nrow(df)
cat(sprintf("After alpine event filtering: %d rows (removed %d rows)\n", filtered_rows, original_rows - filtered_rows))

# Count events after filtering
event_counts_after <- table(df$Event)
cat("Alpine events after filtering:\n")
print(event_counts_after)
```

**Purpose**: Focuses analysis on the most relevant competitions for performance prediction while tracking filtering impact.

**Event Filtering Logic**:
- **World Cup**: Primary elite alpine racing circuit
- **Offseason**: Summer and training competitions
- **Exclusions**: Removes lower-level competitions that are less predictive

**Feature Engineering**:
- **Cumulative_Points**: Running total of points earned within each season
- **Races_in_Season**: Count of races participated in each season
- **Date Ordering**: Ensures chronological processing for cumulative calculations

#### 4. Cumulative Points Calculation Validation
```r
# Validate cumulative points calculation
invalid_cumulative <- df %>%
  group_by(ID, Season) %>%
  mutate(expected_cumulative = cumsum(Points)) %>%
  ungroup() %>%
  filter(Cumulative_Points != expected_cumulative) %>%
  nrow()

if (invalid_cumulative > 0) {
  warning(sprintf("%s: %d rows have incorrect cumulative points", data_name, invalid_cumulative))
} else {
  cat("✓ Cumulative points calculation validated\n")
}
```

**Purpose**: Validates that cumulative points are calculated correctly by comparing against expected values.

**Validation Method**:
- Recalculates cumulative points independently
- Compares against stored cumulative values
- Identifies any discrepancies in the calculation
- Ensures data integrity for downstream analysis

#### 5. Alpine Discipline Analysis
```r
# Alpine doesn't have team events like cross-country, but check for any unusual distances
cat("Checking alpine disciplines...\n")
discipline_counts <- table(df$Distance)
cat("Alpine disciplines:\n")
print(discipline_counts)
```

**Purpose**: Analyzes the distribution of alpine disciplines to ensure comprehensive coverage and identify any data anomalies.

**Alpine Discipline Context**:
- **Individual Events Only**: Unlike cross-country, alpine has no team events
- **Multiple Disciplines**: Downhill, Super G, Giant Slalom, Slalom, Combined
- **Distance Field Usage**: The Distance field contains discipline information in alpine data

#### 6. Maximum Points Calculation and Percentage Metrics
```r
# Calculate maximum possible points per season 
cat("Calculating maximum possible alpine points per season...\n")
max_points_per_season <- df %>%
  group_by(Season, Date, Race) %>%
  summarise(Max_Race_Points = max(Points), .groups = 'drop') %>%
  group_by(Season) %>%
  summarise(Max_Points = sum(Max_Race_Points), .groups = 'drop')

# Validate max points calculation
if (nrow(max_points_per_season) == 0) {
  stop(sprintf("%s: No seasons found for alpine max points calculation", data_name))
}

# Check for seasons with zero max points
zero_max_seasons <- max_points_per_season %>% filter(Max_Points == 0)
if (nrow(zero_max_seasons) > 0) {
  warning(sprintf("%s: %d alpine seasons have zero max points", data_name, nrow(zero_max_seasons)))
  print(zero_max_seasons)
}

cat(sprintf("Alpine max points range by season: %d - %d\n", 
            min(max_points_per_season$Max_Points), max(max_points_per_season$Max_Points)))
```

**Purpose**: Calculates the theoretical maximum points possible in each season to enable performance percentage calculations.

**Maximum Points Logic**:
- **Race-Level Maximum**: Finds highest points awarded in each race (typically 100 for winners)
- **Season Aggregation**: Sums maximum points across all races in each season
- **Validation**: Ensures all seasons have positive maximum points

**Performance Standardization**: Enables comparison across different seasons with varying numbers of races.

#### 7. Performance Percentage Calculation and Validation
```r
# Join max points and calculate percentage
cat("Calculating percentage of maximum alpine points...\n")
before_join <- nrow(df)

df <- df %>%
  left_join(max_points_per_season, by = "Season") %>%
  mutate(Pct_of_Max_Points = Cumulative_Points / Max_Points)

after_join <- nrow(df)
if (before_join != after_join) {
  warning(sprintf("%s: Row count changed during alpine max points join: %d -> %d", data_name, before_join, after_join))
}

# Validate percentage calculations
pct_na <- sum(is.na(df$Pct_of_Max_Points))
pct_negative <- sum(df$Pct_of_Max_Points < 0, na.rm = TRUE)
pct_over_one <- sum(df$Pct_of_Max_Points > 1, na.rm = TRUE)

if (pct_na > 0) {
  warning(sprintf("%s: %d rows have NA percentage of max alpine points", data_name, pct_na))
}
if (pct_negative > 0) {
  warning(sprintf("%s: %d rows have negative percentage of max alpine points", data_name, pct_negative))
}
if (pct_over_one > 0) {
  warning(sprintf("%s: %d rows have percentage > 100%% of max alpine points", data_name, pct_over_one))
}

cat(sprintf("Alpine percentage range: %.3f - %.3f\n", 
            min(df$Pct_of_Max_Points, na.rm = TRUE), max(df$Pct_of_Max_Points, na.rm = TRUE)))
```

**Purpose**: Creates standardized performance metrics by calculating what percentage of maximum possible points each athlete achieved.

**Percentage Calculation**:
- **Formula**: (Cumulative Points / Season Max Points)
- **Range**: 0.0 (no points) to 1.0 (won every race)
- **Standardization**: Enables comparison across different season lengths

**Validation Checks**:
- **Row Count**: Ensures join operation doesn't change data size
- **NA Values**: Identifies missing percentage calculations
- **Range**: Validates percentages are between 0 and 1
- **Logical Constraints**: Flags impossible values (negative or >100%)

#### 8. Final Validation and Summary Statistics
```r
# Final validation checks
cat("\n--- Final Alpine Validation ---\n")

# Check for required columns in output
expected_output_cols <- c("Points", "Cumulative_Points", "Races_in_Season", "Max_Points", "Pct_of_Max_Points")
missing_output_cols <- setdiff(expected_output_cols, names(df))
if (length(missing_output_cols) > 0) {
  stop(sprintf("%s: Missing expected alpine output columns: %s", data_name, paste(missing_output_cols, collapse = ", ")))
}

# Summary statistics
cat(sprintf("✓ Alpine processing complete for %s\n", data_name))
cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(df), 100 * nrow(df) / original_rows))
cat(sprintf("Unique alpine skiers: %d\n", length(unique(df$Skier))))
cat(sprintf("Alpine seasons covered: %d (%s - %s)\n", 
            length(unique(df$Season)), min(df$Season), max(df$Season)))
cat(sprintf("Average alpine races per season per skier: %.1f\n", mean(df$Races_in_Season)))
```

**Purpose**: Provides final validation and comprehensive summary of the processed alpine data.

**Output Validation**:
- **Required Columns**: Ensures all expected columns are present
- **Data Completeness**: Reports final data size and retention rate
- **Coverage Metrics**: Summarizes unique skiers and season coverage
- **Racing Activity**: Reports average participation rates

#### 9. Cross-Dataset Processing and Validation
```r
# Process both alpine datasets with validation
cat("\n=== PROCESSING MEN'S ALPINE DATA ===\n")
tryCatch({
  M_processed <- process_alpine_chrono_data(M_chrono, "Men's")
}, error = function(e) {
  stop("Failed to process men's alpine data: ", e$message)
})

cat("\n=== PROCESSING LADIES ALPINE DATA ===\n")
tryCatch({
  L_processed <- process_alpine_chrono_data(L_chrono, "Ladies")
}, error = function(e) {
  stop("Failed to process ladies alpine data: ", e$message)
})

# Cross-validation between alpine datasets
cat("\n=== CROSS-DATASET ALPINE VALIDATION ===\n")

# Compare season ranges
men_seasons <- sort(unique(M_processed$Season))
ladies_seasons <- sort(unique(L_processed$Season))

cat("Men's alpine seasons:", paste(range(men_seasons), collapse = " - "), "(", length(men_seasons), "seasons )\n")
cat("Ladies alpine seasons:", paste(range(ladies_seasons), collapse = " - "), "(", length(ladies_seasons), "seasons )\n")

# Check for season overlap
common_seasons <- intersect(men_seasons, ladies_seasons)
cat("Common alpine seasons:", length(common_seasons), "\n")

if (length(common_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine data")
}
```

**Purpose**: Applies processing to both men's and women's alpine data and validates consistency between datasets.

**Cross-Validation Features**:
- **Parallel Processing**: Applies same function to both datasets
- **Error Handling**: Isolates processing errors to specific datasets
- **Season Coverage**: Compares temporal coverage between datasets
- **Overlap Analysis**: Ensures adequate common data for comparative analysis

#### 10. Star Athlete Validation Testing
```r
# Test with star athletes to validate processing
cat("\n=== ALPINE STAR ATHLETE VALIDATION ===\n")

# Test Marco Odermatt (men)
odermatt_data <- M_processed %>% 
  filter(Skier == "Marco Odermatt") %>%
  arrange(Season, Date)

if (nrow(odermatt_data) > 0) {
  cat("✓ Marco Odermatt found in men's data\n")
  cat(sprintf("  Seasons: %s - %s\n", min(odermatt_data$Season), max(odermatt_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(odermatt_data)))
  cat(sprintf("  Career points: %d\n", sum(odermatt_data$Points)))
  
  # Show recent season performance
  recent_season <- max(odermatt_data$Season)
  recent_data <- odermatt_data %>% filter(Season == recent_season)
  cat(sprintf("  %d season: %d races, %d points, %.1f%% of max\n", 
              recent_season, nrow(recent_data), sum(recent_data$Points),
              max(recent_data$Pct_of_Max_Points) * 100))
} else {
  warning("Marco Odermatt not found in men's alpine data")
}
```

**Purpose**: Validates processing accuracy using known high-performing athletes as test cases.

**Validation Athletes**:
- **Marco Odermatt**: Top men's alpine skier for validation
- **Mikaela Shiffrin**: Top women's alpine skier for validation

**Test Metrics**:
- **Data Presence**: Confirms star athletes are found in processed data
- **Career Span**: Validates reasonable season coverage
- **Performance Metrics**: Checks points and percentage calculations
- **Recent Performance**: Validates latest season data

### Alpine-Specific Design Considerations

#### Single Points System
Alpine skiing uses one consistent points system:
- **Uniform Application**: Same points structure across all disciplines
- **Top 30 Scoring**: Only top 30 finishers receive points
- **Winner Premium**: 100 points for victory vs. 80 for second place

#### Event Hierarchy
Processing focuses on performance-relevant competitions:
- **World Cup**: Primary elite circuit (highest priority)
- **Offseason**: Training and summer competitions (secondary priority)
- **Lower Levels**: Excluded to focus on predictive competitions

#### Performance Standardization
Percentage calculations account for alpine skiing characteristics:
- **Variable Schedules**: Athletes compete in different numbers of races
- **Discipline Specialization**: Some athletes focus on specific disciplines
- **Season Length Variation**: Different seasons may have different race calendars

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data structure and completeness
- **Processing Validation**: Validates each step of feature engineering and calculation
- **Cross-Dataset Consistency**: Ensures consistent processing across men's and women's data
- **Star Athlete Testing**: Uses known high performers to validate processing accuracy
- **Comprehensive Logging**: Detailed progress reporting and diagnostic output

This alpine data processing section provides a robust foundation for subsequent analysis, creating standardized performance metrics while preserving the unique characteristics of alpine skiing competition and its points system.

## Section: {r elo-prep} - Alpine ELO Data Preparation & Feature Engineering

### Purpose
This section prepares alpine ELO (rating system) data for machine learning models by filtering offseason data, creating lagged features for previous season performance, and implementing comprehensive missing value treatment specific to alpine skiing's multi-discipline structure.

### Implementation Details

#### 1. Missing Value Helper Function
```r
# Helper function for quartile replacement (handles NAs by replacing with 1st quartile within season)
replace_na_with_quartile <- function(x, var_name) {
  if (all(is.na(x))) {
    warning(sprintf("All values NA for %s in this season - using global mean", var_name))
    return(rep(mean(x, na.rm = TRUE), length(x)))
  }
  
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  if (is.na(q1)) {
    warning(sprintf("Cannot calculate quartile for %s - using mean", var_name))
    q1 <- mean(x, na.rm = TRUE)
  }
  
  return(replace(x, is.na(x), q1))
}
```

**Purpose**: Provides robust missing value imputation using first quartile values within each season, with fallback strategies for edge cases.

**Imputation Strategy**:
- **Primary Method**: Uses first quartile (25th percentile) within season
- **Fallback 1**: If all values are NA in season, uses global mean
- **Fallback 2**: If quartile calculation fails, uses season mean
- **Conservative Approach**: First quartile provides conservative estimates for missing ELO ratings

#### 2. Core ELO Preparation Function
```r
prepare_alpine_elo_data <- function(processed_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Preparing %s Alpine ELO Data ---\n", data_name))
  
  # Input validation
  if (nrow(processed_df) == 0) {
    stop(sprintf("%s alpine dataset is empty", data_name))
  }
  
  original_rows <- nrow(processed_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Check for offseason data
  offseason_count <- sum(processed_df$Event == "Offseason", na.rm = TRUE)
  cat(sprintf("Offseason events available: %d\n", offseason_count))
  
  if (offseason_count == 0) {
    stop(sprintf("%s: No offseason data found for alpine ELO preparation", data_name))
  }
}
```

**Purpose**: Establishes the framework for alpine ELO data preparation with comprehensive validation.

**Key Validation Steps**:
- **Empty Dataset Check**: Ensures data is available for processing
- **Offseason Data Requirement**: Validates presence of offseason data (essential for ELO preparation)
- **Progress Tracking**: Reports input data size and availability

#### 3. Alpine ELO Column Validation
```r
# Check for required alpine ELO columns before processing
required_elo_cols <- c("Pelo", "Downhill_Pelo", "Super G_Pelo", "Giant Slalom_Pelo", 
                       "Slalom_Pelo", "Combined_Pelo", "Tech_Pelo", "Speed_Pelo")

available_elo_cols <- intersect(required_elo_cols, names(processed_df))
missing_elo_cols <- setdiff(required_elo_cols, names(processed_df))

cat(sprintf("Available alpine ELO columns: %d/%d\n", length(available_elo_cols), length(required_elo_cols)))
if (length(missing_elo_cols) > 0) {
  cat("Missing alpine ELO columns:", paste(missing_elo_cols, collapse = ", "), "\n")
  warning(sprintf("%s: Missing some alpine ELO columns - proceeding with available columns", data_name))
}
```

**Purpose**: Validates availability of alpine-specific ELO rating columns and handles graceful degradation if some are missing.

**Alpine ELO Structure**:
- **Pelo**: Overall alpine ELO rating
- **Downhill_Pelo**: Downhill-specific ELO rating
- **Super G_Pelo**: Super G-specific ELO rating
- **Giant Slalom_Pelo**: Giant Slalom-specific ELO rating
- **Slalom_Pelo**: Slalom-specific ELO rating
- **Combined_Pelo**: Combined event ELO rating
- **Tech_Pelo**: Technical disciplines (Slalom, Giant Slalom) aggregate ELO
- **Speed_Pelo**: Speed disciplines (Downhill, Super G) aggregate ELO

**Flexible Processing**: Continues with available columns if some ELO ratings are missing.

#### 4. Offseason Data Filtering and Lag Feature Creation
```r
# Filter for offseason data and create previous season ELO values
cat("Filtering for offseason data and creating lag features...\n")

elo_df <- processed_df %>%
  filter(Event == "Offseason") %>%
  arrange(ID, Season)

filtered_rows <- nrow(elo_df)
cat(sprintf("After offseason filter: %d rows (%.1f%% of input)\n", 
            filtered_rows, 100 * filtered_rows / original_rows))

if (filtered_rows == 0) {
  stop(sprintf("%s: No rows remaining after offseason filtering", data_name))
}

# Create lag features for alpine disciplines with validation
cat("Creating alpine discipline lag features...\n")

elo_df <- elo_df %>%
  group_by(ID) %>%
  mutate(
    Prev_Pelo = if("Pelo" %in% names(.)) lag(Pelo) else NA_real_,
    Prev_Downhill = if("Downhill_Pelo" %in% names(.)) lag(Downhill_Pelo) else NA_real_,
    Prev_Super_G = if("Super G_Pelo" %in% names(.)) lag(`Super G_Pelo`) else NA_real_,
    Prev_Giant_Slalom = if("Giant Slalom_Pelo" %in% names(.)) lag(`Giant Slalom_Pelo`) else NA_real_,
    Prev_Slalom = if("Slalom_Pelo" %in% names(.)) lag(Slalom_Pelo) else NA_real_,
    Prev_Combined = if("Combined_Pelo" %in% names(.)) lag(Combined_Pelo) else NA_real_,
    Prev_Tech = if("Tech_Pelo" %in% names(.)) lag(Tech_Pelo) else NA_real_,
    Prev_Speed = if("Speed_Pelo" %in% names(.)) lag(Speed_Pelo) else NA_real_,
    Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
  ) %>%
  ungroup()
```

**Purpose**: Extracts offseason data and creates lagged features representing previous season performance across all alpine disciplines.

**Offseason Focus**: 
- **End-of-Season Snapshot**: Offseason data represents final ELO ratings after season completion
- **Predictive Features**: Previous season ELO ratings serve as predictors for next season performance
- **Clean Temporal Ordering**: Arranges by athlete ID and season for proper lag calculation

**Lag Feature Engineering**:
- **Previous Overall Rating**: `Prev_Pelo` for general alpine ability
- **Discipline-Specific Ratings**: Previous ELO for each alpine discipline
- **Aggregate Category Ratings**: Previous Technical and Speed ELO ratings
- **Performance Percentage**: Previous season's percentage of maximum points achieved

#### 5. Season Filtering and Validation
```r
# Apply season filter
cat("Applying season filter (> 2015)...\n")
before_season_filter <- nrow(elo_df)

elo_df <- elo_df %>%
  filter(Season > 2015)

after_season_filter <- nrow(elo_df)
cat(sprintf("After season filter: %d rows (removed %d rows from ≤2015)\n", 
            after_season_filter, before_season_filter - after_season_filter))

if (after_season_filter == 0) {
  stop(sprintf("%s: No rows remaining after alpine season filtering (>2015)", data_name))
}

# Validate season range
season_range <- range(elo_df$Season, na.rm = TRUE)
cat(sprintf("Final alpine season range: %.0f - %.0f\n", season_range[1], season_range[2]))
```

**Purpose**: Focuses analysis on modern alpine skiing era (post-2015) to ensure ELO ratings reflect current competitive dynamics.

**Season Filter Rationale**:
- **Modern Era Focus**: 2016+ represents current alpine skiing competitive structure
- **ELO System Stability**: Ensures ELO ratings have stabilized and are reliable
- **Equipment and Rule Consistency**: Reduces impact of equipment changes and rule modifications
- **Data Quality**: More recent data has better quality and completeness

#### 6. Comprehensive Missing Value Treatment
```r
# Handle missing values by replacing with quartiles within each season
cat("\n--- Alpine ELO Missing Value Treatment ---\n")

# Count NAs before treatment
if (length(created_lag_features) > 0) {
  available_lag_features <- intersect(created_lag_features, names(elo_df))
  if (length(available_lag_features) > 0) {
    na_summary_before <- elo_df[available_lag_features] %>%
      summarise_all(~ sum(is.na(.))) %>%
      gather(variable, na_count) %>%
      filter(na_count > 0)
  }
}

if (nrow(na_summary_before) > 0) {
  cat("Alpine ELO NAs before treatment:\n")
  print(na_summary_before)
} else {
  cat("No NAs found in alpine lag features\n")
}

# Apply quartile replacement by season for alpine disciplines
cat("Applying quartile replacement by season for alpine disciplines...\n")

elo_df <- elo_df %>%
  group_by(Season) %>%
  mutate(
    Prev_Downhill = if("Prev_Downhill" %in% names(.)) replace_na_with_quartile(Prev_Downhill, "Prev_Downhill") else Prev_Downhill,
    Prev_Super_G = if("Prev_Super_G" %in% names(.)) replace_na_with_quartile(Prev_Super_G, "Prev_Super_G") else Prev_Super_G,
    Prev_Giant_Slalom = if("Prev_Giant_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Giant_Slalom, "Prev_Giant_Slalom") else Prev_Giant_Slalom,
    Prev_Slalom = if("Prev_Slalom" %in% names(.)) replace_na_with_quartile(Prev_Slalom, "Prev_Slalom") else Prev_Slalom,
    Prev_Combined = if("Prev_Combined" %in% names(.)) replace_na_with_quartile(Prev_Combined, "Prev_Combined") else Prev_Combined,
    Prev_Tech = if("Prev_Tech" %in% names(.)) replace_na_with_quartile(Prev_Tech, "Prev_Tech") else Prev_Tech,
    Prev_Speed = if("Prev_Speed" %in% names(.)) replace_na_with_quartile(Prev_Speed, "Prev_Speed") else Prev_Speed,
    Prev_Pelo = if("Prev_Pelo" %in% names(.)) replace_na_with_quartile(Prev_Pelo, "Prev_Pelo") else Prev_Pelo,
    Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
  ) %>%
  ungroup()
```

**Purpose**: Implements sophisticated missing value imputation that respects alpine skiing's competitive context and seasonal variations.

**Season-Based Imputation Strategy**:
- **Within-Season Context**: Replaces missing ELO values using quartiles within the same season
- **Conservative Estimates**: First quartile provides conservative performance estimates
- **Discipline-Specific Treatment**: Each alpine discipline gets independent imputation
- **Performance Points Special Case**: Missing performance percentages set to 0 (indicating no previous season success)

**Quality Assurance**:
- **Before/After Comparison**: Tracks missing value counts before and after treatment
- **Validation Reporting**: Reports remaining missing values if any exist
- **Error Handling**: Warns if imputation is incomplete

#### 7. Final Data Quality Validation
```r
# Final validation checks
cat("\n--- Final Alpine ELO Validation ---\n")

# Check for infinite values
numeric_cols <- select_if(elo_df, is.numeric) %>% names()
if (length(numeric_cols) > 0) {
  inf_check <- elo_df[numeric_cols] %>%
    summarise_all(~ sum(!is.finite(.))) %>%
    gather(variable, inf_count) %>%
    filter(inf_count > 0)
}

if (nrow(inf_check) > 0) {
  cat("Infinite values found in alpine ELO data:\n")
  print(inf_check)
  warning(sprintf("%s: Contains infinite values", data_name))
} else {
  cat("✓ No infinite values detected in alpine ELO data\n")
}

# Validate key relationships for alpine
if ("Age" %in% names(elo_df)) {
  age_issues <- elo_df %>%
    filter(Age < 15 | Age > 50) %>%
    nrow()
  
  if (age_issues > 0) {
    warning(sprintf("%s: %d rows with unusual ages (<15 or >50)", data_name, age_issues))
  }
  
  cat(sprintf("Alpine skier age range: %.0f - %.0f\n", min(elo_df$Age, na.rm = TRUE), max(elo_df$Age, na.rm = TRUE)))
}
```

**Purpose**: Performs comprehensive final validation to ensure data quality and logical consistency.

**Validation Checks**:
- **Infinite Value Detection**: Identifies any infinite or NaN values that could break models
- **Age Range Validation**: Ensures athlete ages are within reasonable bounds (15-50 years)
- **Finite Value Verification**: Confirms all numeric values are finite and usable

**Quality Standards**:
- **Model Readiness**: Ensures data is ready for machine learning algorithms
- **Logical Consistency**: Validates that data relationships make sense
- **Error Prevention**: Catches data quality issues before they affect downstream analysis

#### 8. Cross-Dataset Processing and Analysis
```r
# Prepare alpine ELO data for both men and ladies with comprehensive validation
cat("\n=== PREPARING MEN'S ALPINE ELO DATA ===\n")
tryCatch({
  M_elo <- prepare_alpine_elo_data(M_processed, "Men's")
}, error = function(e) {
  stop("Failed to prepare men's alpine ELO data: ", e$message)
})

cat("\n=== PREPARING LADIES ALPINE ELO DATA ===\n")
tryCatch({
  L_elo <- prepare_alpine_elo_data(L_processed, "Ladies")
}, error = function(e) {
  stop("Failed to prepare ladies alpine ELO data: ", e$message)
})

# Cross-validation between alpine ELO datasets
cat("\n=== CROSS-DATASET ALPINE ELO VALIDATION ===\n")

# Compare season ranges
men_elo_seasons <- sort(unique(M_elo$Season))
ladies_elo_seasons <- sort(unique(L_elo$Season))

cat("Men's alpine ELO seasons:", paste(range(men_elo_seasons), collapse = " - "), "(", length(men_elo_seasons), "seasons )\n")
cat("Ladies alpine ELO seasons:", paste(range(ladies_elo_seasons), collapse = " - "), "(", length(ladies_elo_seasons), "seasons )\n")

# Check for season overlap
common_elo_seasons <- intersect(men_elo_seasons, ladies_elo_seasons)
cat("Common alpine ELO seasons:", length(common_elo_seasons), "\n")

if (length(common_elo_seasons) == 0) {
  warning("No common seasons between men's and ladies alpine ELO data")
}
```

**Purpose**: Applies ELO preparation to both men's and women's data with comprehensive cross-validation.

**Processing Features**:
- **Parallel Processing**: Applies same preparation function to both datasets
- **Error Isolation**: Isolates processing errors to specific datasets
- **Season Coverage Comparison**: Validates temporal coverage between men's and women's data
- **Overlap Analysis**: Ensures adequate common seasons for comparative modeling

#### 9. Alpine ELO Distribution Analysis
```r
# Validate alpine ELO distributions
cat("\n--- Alpine ELO Distribution Analysis ---\n")

# Check ELO ranges for men
if ("Prev_Pelo" %in% names(M_elo)) {
  men_pelo_range <- range(M_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Men's Prev_Pelo range: %.0f - %.0f\n", men_pelo_range[1], men_pelo_range[2]))
}

if ("Prev_Tech" %in% names(M_elo)) {
  men_tech_range <- range(M_elo$Prev_Tech, na.rm = TRUE)
  cat(sprintf("Men's Prev_Tech range: %.0f - %.0f\n", men_tech_range[1], men_tech_range[2]))
}

if ("Prev_Speed" %in% names(M_elo)) {
  men_speed_range <- range(M_elo$Prev_Speed, na.rm = TRUE)
  cat(sprintf("Men's Prev_Speed range: %.0f - %.0f\n", men_speed_range[1], men_speed_range[2]))
}
```

**Purpose**: Analyzes ELO rating distributions to validate data quality and identify potential issues.

**Distribution Analysis**:
- **Overall Alpine ELO**: General alpine skiing ability ratings
- **Technical Disciplines**: Slalom and Giant Slalom combined ratings
- **Speed Disciplines**: Downhill and Super G combined ratings
- **Range Validation**: Ensures ELO ranges are reasonable and consistent

### Alpine ELO-Specific Design Considerations

#### Multi-Discipline ELO Structure
Alpine skiing's unique characteristic is having separate ELO ratings for each discipline:
- **Individual Discipline Ratings**: Separate ELO for Downhill, Super G, Giant Slalom, Slalom, Combined
- **Aggregate Category Ratings**: Technical (Slalom + Giant Slalom) and Speed (Downhill + Super G)
- **Overall Alpine Rating**: General alpine skiing ability across all disciplines

#### Offseason Data Focus
ELO preparation specifically targets offseason data:
- **End-of-Season Ratings**: Represents final ELO after all season races completed
- **Stable Performance Indicators**: ELO ratings have stabilized by offseason
- **Predictive Value**: End-of-season ratings are most predictive of next season performance

#### Conservative Missing Value Treatment
The quartile-based imputation strategy:
- **Conservative Estimates**: First quartile provides conservative performance expectations
- **Season-Aware**: Imputation respects seasonal competitive context
- **Discipline-Specific**: Each alpine discipline gets independent treatment
- **Graceful Degradation**: Handles edge cases with appropriate fallback strategies

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data availability and structure
- **ELO Column Validation**: Flexible handling of missing discipline-specific ELO columns
- **Missing Value Monitoring**: Detailed tracking of missing value treatment effectiveness
- **Cross-Dataset Consistency**: Ensures consistent processing across men's and women's data
- **Distribution Validation**: Analyzes ELO distributions for quality assurance

This alpine ELO preparation section creates a robust foundation for machine learning models by providing clean, validated, and properly engineered features that respect alpine skiing's multi-discipline competitive structure and seasonal dynamics.

## Section: {r comprehensive-feature-selection} - Alpine Feature Selection & Model Optimization

### Purpose
This section implements comprehensive feature selection for alpine skiing season prediction using multiple statistical and machine learning methods. It identifies the most predictive alpine-specific features across all disciplines and creates robust consensus-based feature sets for both men's and women's modeling.

### Implementation Details

#### 1. Training Data Preparation and Validation
```r
cat("=== COMPREHENSIVE ALPINE FEATURE SELECTION & VALIDATION ===\n")

# Input validation for alpine ELO datasets
if (nrow(M_elo) == 0) {
  stop("Men's alpine ELO dataset is empty")
}
if (nrow(L_elo) == 0) {
  stop("Ladies alpine ELO dataset is empty")
}

cat(sprintf("Input alpine datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))

# Prepare training data - include more historical seasons to capture early breakthroughs
# Use data from 2016+ to include breakthrough seasons in alpine
cat("Filtering alpine training data (2016-2025, non-NA Pct_of_Max_Points)...\n")

# Check available seasons before filtering
men_seasons_available <- sort(unique(M_elo$Season))
ladies_seasons_available <- sort(unique(L_elo$Season))

cat(sprintf("Men's alpine available seasons: %s\n", paste(range(men_seasons_available), collapse = " - ")))
cat(sprintf("Ladies alpine available seasons: %s\n", paste(range(ladies_seasons_available), collapse = " - ")))

# Apply training filters with validation
train_men <- M_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

train_ladies <- L_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))
```

**Purpose**: Establishes comprehensive training datasets with validated temporal coverage for alpine skiing feature selection.

**Training Data Strategy**:
- **Historical Coverage**: Uses 2016-2025 data to capture full range of alpine performance patterns
- **Target Variable Validation**: Ensures non-missing percentage of maximum points for supervised learning
- **Season Range Validation**: Confirms adequate temporal coverage for robust feature selection
- **Breakthrough Inclusion**: 2016+ timeframe captures early career breakthroughs in alpine skiing

**Quality Assurance**:
- **Empty Dataset Protection**: Prevents feature selection with insufficient data
- **Season Coverage Reporting**: Validates temporal span of training data
- **Model Robustness Check**: Warns if fewer than 3 seasons available

#### 2. Alpine Feature Definition and Availability Validation
```r
# Define and validate potential alpine features
cat("\n--- Alpine Feature Validation ---\n")

all_features <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                  "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", 
                  "Prev_Pct_of_Max_Points", "Age")

# Check feature availability in alpine training datasets
men_available_features <- intersect(all_features, names(train_men))
ladies_available_features <- intersect(all_features, names(train_ladies))

cat(sprintf("Men's available alpine features: %d/%d\n", length(men_available_features), length(all_features)))
cat(sprintf("Ladies available alpine features: %d/%d\n", length(ladies_available_features), length(all_features)))

# Report missing features
men_missing_features <- setdiff(all_features, men_available_features)
ladies_missing_features <- setdiff(all_features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing alpine features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing alpine features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some alpine features missing from ladies training data")
}
```

**Purpose**: Validates availability of alpine-specific predictive features and handles graceful degradation for missing features.

**Alpine Feature Set**:
- **Overall Alpine Performance**: `Prev_Pelo` (previous season overall ELO)
- **Individual Discipline ELOs**: `Prev_Downhill`, `Prev_Super_G`, `Prev_Giant_Slalom`, `Prev_Slalom`, `Prev_Combined`
- **Discipline Category ELOs**: `Prev_Tech` (technical disciplines), `Prev_Speed` (speed disciplines)
- **Performance History**: `Prev_Pct_of_Max_Points` (previous season success rate)
- **Athlete Demographics**: `Age` (current age for experience modeling)

**Flexible Processing**:
- **Graceful Degradation**: Continues with available features if some are missing
- **Minimum Threshold**: Requires at least 3 features for meaningful feature selection
- **Cross-Gender Validation**: Ensures consistent feature availability across men's and women's data

#### 3. Data Quality Validation for Feature Selection
```r
# Validate alpine feature data quality
cat("\n--- Alpine Feature Data Quality Checks ---\n")

# Check for missing values in alpine features
men_feature_na_counts <- sapply(train_men[all_features_men], function(x) sum(is.na(x)))
ladies_feature_na_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(is.na(x)))

if (any(men_feature_na_counts > 0)) {
  cat("Men's alpine features with NAs:\n")
  print(men_feature_na_counts[men_feature_na_counts > 0])
  warning("Men's alpine training data contains missing values in features")
}

# Check for infinite values
men_feature_inf_counts <- sapply(train_men[all_features_men], function(x) sum(!is.finite(x)))
ladies_feature_inf_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(!is.finite(x)))

# Check target variable quality
men_target_na <- sum(is.na(train_men$Pct_of_Max_Points))
ladies_target_na <- sum(is.na(train_ladies$Pct_of_Max_Points))

cat(sprintf("Alpine target variable ranges: Men %.3f-%.3f, Ladies %.3f-%.3f\n",
            min(train_men$Pct_of_Max_Points, na.rm = TRUE), max(train_men$Pct_of_Max_Points, na.rm = TRUE),
            min(train_ladies$Pct_of_Max_Points, na.rm = TRUE), max(train_ladies$Pct_of_Max_Points, na.rm = TRUE)))
```

**Purpose**: Ensures data quality standards necessary for reliable feature selection across alpine skiing datasets.

**Quality Validation Checks**:
- **Missing Value Detection**: Identifies features with incomplete data that could bias selection
- **Infinite Value Detection**: Finds numerical issues that could break feature selection algorithms
- **Target Variable Validation**: Ensures target variable (percentage of maximum points) has valid range
- **Cross-Dataset Consistency**: Validates data quality across men's and women's datasets

#### 4. Multi-Method Feature Selection Framework

##### 4a. Correlation Analysis
```r
# 1. CORRELATION ANALYSIS with validation
cat("1. ALPINE CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for correlation analysis\n")
    cor_matrix_men <- NULL
    high_cor_men <- data.frame()
  } else {
    cor_matrix_men <- cor(train_men[all_features_men], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_men))) {
      warning("Alpine correlation matrix contains NA values")
    }
    
    high_cor_men <- which(abs(cor_matrix_men) > 0.7 & upper.tri(cor_matrix_men), arr.ind = TRUE)
    if(nrow(high_cor_men) > 0) {
      cat("High alpine correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_men)) {
        row_name <- rownames(cor_matrix_men)[high_cor_men[i,1]]
        col_name <- colnames(cor_matrix_men)[high_cor_men[i,2]]
        cor_val <- cor_matrix_men[high_cor_men[i,1], high_cor_men[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high alpine correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine correlation analysis:", e$message, "\n")
  cor_matrix_men <- NULL
  high_cor_men <- data.frame()
})
```

**Purpose**: Identifies multicollinearity among alpine features and establishes baseline correlation patterns.

**Correlation Analysis Features**:
- **Multicollinearity Detection**: Identifies features with |r| > 0.7 that may cause modeling issues
- **Alpine-Specific Patterns**: Reveals relationships between different alpine disciplines
- **Quality Assurance**: Validates correlation matrix integrity and handles edge cases
- **Baseline Establishment**: Provides correlation foundation for other selection methods

##### 4b. LASSO Regularization
```r
# 2. LASSO REGULARIZATION with validation
cat("2. ALPINE LASSO REGULARIZATION:\n")
lasso_selected_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_men <- as.matrix(train_men[all_features_men])
  y_men <- train_men$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_men))) {
    warning("Non-finite values in alpine feature matrix for LASSO")
  }
  if (any(!is.finite(y_men))) {
    warning("Non-finite values in alpine target variable for LASSO")
  }
  
  cv_lasso_men <- cv.glmnet(x_men, y_men, alpha = 1, nfolds = 5)
  best_lambda_men <- cv_lasso_men$lambda.min
  lasso_coef_men <- coef(cv_lasso_men, s = best_lambda_men)
  
  lasso_selected_men <- rownames(lasso_coef_men)[which(lasso_coef_men != 0)][-1]  # Remove intercept
  
  if (length(lasso_selected_men) > 0) {
    cat("Alpine LASSO selected features:\n")
    for (feature in lasso_selected_men) {
      coef_val <- lasso_coef_men[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by alpine LASSO (may indicate weak predictors)\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_men))
  
}, error = function(e) {
  cat("Error in alpine LASSO analysis:", e$message, "\n")
  lasso_selected_men <- character(0)
})
```

**Purpose**: Uses L1 regularization to identify alpine features that contribute most to prediction accuracy while preventing overfitting.

**LASSO Selection Features**:
- **Automatic Feature Selection**: LASSO naturally selects most predictive alpine features
- **Overfitting Prevention**: L1 regularization reduces model complexity for alpine data
- **Cross-Validation**: 5-fold CV optimizes lambda parameter for alpine-specific patterns
- **Coefficient Reporting**: Shows feature importance magnitude and direction
- **Reproducibility**: Fixed random seed ensures consistent results across runs

##### 4c. Boruta Feature Selection
```r
# 3. BORUTA FEATURE SELECTION with validation
cat("3. ALPINE BORUTA FEATURE SELECTION:\n")
boruta_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_men <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                         data = train_men, doTrace = 0)
    
    boruta_selected_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_men) > 0) {
      cat("Alpine Boruta confirmed features:\n")
      for (feature in boruta_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by alpine Boruta\n")
    }
    
    # Check for tentative features
    tentative_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Tentative"]
    if (length(tentative_men) > 0) {
      cat("Alpine Boruta tentative features:\n")
      for (feature in tentative_men) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in alpine Boruta analysis:", e$message, "\n")
  boruta_selected_men <- character(0)
})
```

**Purpose**: Uses random forest-based all-relevant feature selection to identify all alpine features that have genuine predictive value.

**Boruta Selection Features**:
- **All-Relevant Selection**: Identifies all genuinely useful alpine features, not just best subset
- **Statistical Rigor**: Uses permutation testing to validate feature importance against random chance
- **Random Forest Foundation**: Leverages ensemble method strengths for alpine data patterns
- **Tentative Feature Handling**: Provides uncertainty quantification for borderline alpine features
- **Robust to Interactions**: Captures complex relationships between alpine disciplines

##### 4d. Exhaustive Search
```r
# 4. EXHAUSTIVE SEARCH with validation
cat("4. ALPINE EXHAUSTIVE SEARCH:\n")
leaps_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient alpine features for exhaustive search\n")
  } else if (length(all_features_men) > 8) {
    cat("Too many alpine features for exhaustive search - using best subset\n")
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, nvmax = min(8, length(all_features_men)))
  } else {
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, really.big = TRUE)
  }
  
  if (exists("leaps_men")) {
    summary_leaps_men <- summary(leaps_men)
    best_model_size <- which.max(summary_leaps_men$adjr2)
    leaps_selected_men <- names(which(summary_leaps_men$which[best_model_size, -1]))  # Remove intercept
    
    if (length(leaps_selected_men) > 0) {
      cat("Alpine exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_men$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by alpine exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in alpine exhaustive search:", e$message, "\n")
  leaps_selected_men <- character(0)
})
```

**Purpose**: Performs exhaustive search for optimal alpine feature combinations using adjusted R-squared optimization.

**Exhaustive Search Features**:
- **Optimal Subset Identification**: Finds best alpine feature combination for linear prediction
- **Adjusted R² Optimization**: Balances model fit with complexity for alpine data
- **Computational Efficiency**: Limits search to 8 features when full search impractical
- **Model Size Reporting**: Provides transparency about selected model complexity
- **Linear Relationship Focus**: Optimized for linear relationships in alpine performance data

#### 5. Consensus Feature Selection and Final Integration
```r
# 5. CONSENSUS FEATURE SELECTION
cat("5. ALPINE CONSENSUS FEATURE SELECTION:\n")

all_selected_men <- c(lasso_selected_men, boruta_selected_men, leaps_selected_men)
if (length(all_selected_men) > 0) {
  feature_counts_men <- table(all_selected_men)
  consensus_men <- names(feature_counts_men)[feature_counts_men >= 2]  # Features selected by 2+ methods
  
  if (length(consensus_men) > 0) {
    cat("Alpine consensus features (selected by 2+ methods):\n")
    for (feature in consensus_men) {
      count <- feature_counts_men[feature]
      methods <- c(
        if (feature %in% lasso_selected_men) "LASSO" else NULL,
        if (feature %in% boruta_selected_men) "Boruta" else NULL,
        if (feature %in% leaps_selected_men) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No alpine consensus features - using union of all methods\n")
    consensus_men <- unique(all_selected_men)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_men) && "Pct_of_Max_Points" %in% names(train_men)) {
    target_cors <- cor(train_men[all_features_men], train_men$Pct_of_Max_Points, use = "complete.obs")
    consensus_men <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_men))]
  } else {
    consensus_men <- all_features_men[1:min(3, length(all_features_men))]
  }
}

final_features_men <- consensus_men
cat(sprintf("Final alpine features for men: %s\n", paste(final_features_men, collapse = ", ")))
```

**Purpose**: Integrates results from multiple feature selection methods to create robust, consensus-based feature sets for alpine skiing prediction.

**Consensus Strategy**:
- **Multi-Method Integration**: Combines LASSO, Boruta, and exhaustive search results
- **Robust Selection**: Prioritizes features selected by 2+ methods for reliability
- **Fallback Mechanisms**: Uses union of methods or correlation-based selection when consensus fails
- **Method Transparency**: Reports which methods selected each consensus feature
- **Quality Assurance**: Ensures at least some features selected for model building

#### 6. Cross-Gender Feature Selection Replication
The same comprehensive feature selection process is applied to women's alpine data:

```r
cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION FOR LADIES ===\n")

# Repeat the same process for ladies with alpine-specific adaptations
# 1. CORRELATION ANALYSIS
# 2. LASSO REGULARIZATION  
# 3. BORUTA FEATURE SELECTION
# 4. EXHAUSTIVE SEARCH
# 5. CONSENSUS FEATURE SELECTION
```

**Purpose**: Ensures consistent and thorough feature selection across both men's and women's alpine skiing datasets.

**Cross-Gender Consistency**:
- **Parallel Processing**: Applies identical methodology to both datasets
- **Gender-Specific Optimization**: Allows for different optimal feature sets between men's and women's alpine skiing
- **Comparative Analysis**: Enables comparison of feature importance patterns across genders
- **Independent Validation**: Validates feature selection robustness across different athlete populations

#### 7. Feature Selection Results Storage and Summary
```r
cat("\n=== ALPINE FEATURE SELECTION SUMMARY ===\n")
cat(sprintf("Men's final alpine features (%d): %s\n", length(final_features_men), paste(final_features_men, collapse = ", ")))
cat(sprintf("Ladies final alpine features (%d): %s\n", length(final_features_ladies), paste(final_features_ladies, collapse = ", ")))

# Store feature selection results for later use
feature_selection_results_men <- list(
  lasso = lasso_selected_men,
  boruta = boruta_selected_men,
  exhaustive = leaps_selected_men,
  final = final_features_men
)

feature_selection_results_ladies <- list(
  lasso = lasso_selected_ladies,
  boruta = boruta_selected_ladies,
  exhaustive = leaps_selected_ladies,
  final = final_features_ladies
)

cat("\n=== COMPREHENSIVE ALPINE FEATURE SELECTION COMPLETE ===\n")
```

**Purpose**: Summarizes feature selection results and stores detailed outcomes for subsequent modeling and analysis.

**Results Documentation**:
- **Final Feature Sets**: Reports consensus features for both men's and women's alpine skiing
- **Method-Specific Results**: Preserves individual method results for analysis and debugging
- **Structured Storage**: Organizes results in lists for programmatic access in downstream modeling
- **Comprehensive Summary**: Provides clear overview of feature selection outcomes

### Alpine Feature Selection Design Considerations

#### Multi-Discipline Feature Space
Alpine skiing's unique feature requirements:
- **Discipline-Specific ELOs**: Individual ratings for Downhill, Super G, Giant Slalom, Slalom, Combined
- **Aggregate Category Features**: Technical vs Speed discipline groupings
- **Performance History**: Previous season success metrics and trend indicators
- **Demographic Factors**: Age and experience considerations

#### Method Complementarity
The multi-method approach leverages different selection strengths:
- **LASSO**: Linear relationship optimization with automatic feature selection
- **Boruta**: All-relevant features with statistical rigor and interaction capture
- **Exhaustive Search**: Optimal subset identification for linear prediction
- **Consensus Integration**: Robust feature sets through method agreement

#### Alpine-Specific Adaptations
- **Season-Aware Training**: Uses 2016-2025 timeframe for modern alpine competitive dynamics
- **Discipline Balance**: Ensures representation across alpine's diverse competitive structure
- **Performance Standardization**: Works with percentage of maximum points for cross-season comparability
- **Gender-Specific Optimization**: Allows for different optimal features between men's and women's alpine skiing

### Error Handling and Quality Assurance
- **Input Validation**: Comprehensive checks for data availability and quality
- **Method-Specific Validation**: Individual error handling for each selection method
- **Consensus Robustness**: Multiple fallback strategies when consensus fails
- **Cross-Dataset Consistency**: Parallel processing ensures consistent methodology
- **Results Documentation**: Detailed tracking of selection outcomes and method performance

This alpine feature selection section creates optimized, statistically validated feature sets that capture the most predictive aspects of alpine skiing performance while maintaining robustness across different modeling approaches and athlete populations.

## Section: {r gam-model} - Alpine GAM Model Building & Prediction

### Purpose
This section builds Generalized Additive Models (GAM) for alpine skiing season prediction using consensus-selected features, validates model performance, and generates 2026 season predictions with comprehensive error handling and diagnostic evaluation.

### Implementation Details

#### 1. GAM Model Construction and Input Validation
```r
cat("=== GAM MODEL BUILDING & VALIDATION ===\n")

# Build GAM models using consensus-selected features with comprehensive validation
cat("\n--- GAM Model Construction ---\n")

# Validate inputs for GAM model building
if (!exists("final_features_men") || !exists("final_features_ladies")) {
  stop("Final features not defined - ensure feature selection completed successfully")
}

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure data preparation completed successfully")
}

cat(sprintf("Input validation: Men %d features, Ladies %d features\n", 
            length(final_features_men), length(final_features_ladies)))

cat(sprintf("Training data: Men %d rows, Ladies %d rows\n", 
            nrow(train_men), nrow(train_ladies)))
```

**Purpose**: Establishes comprehensive validation framework for GAM model construction using alpine-specific consensus features.

**Input Validation Features**:
- **Feature Availability Check**: Ensures consensus feature selection completed successfully
- **Training Data Validation**: Confirms processed training data is available for modeling
- **Data Size Reporting**: Reports feature counts and training dataset sizes for both genders
- **Dependency Verification**: Validates that prerequisite processing steps completed successfully

#### 2. Men's GAM Model Construction with Robust Error Handling
```r
# Build GAM formula for Men using validated features
cat("\n--- Men's GAM Model ---\n")
men_gam_model <- NULL
tryCatch({
  if(length(final_features_men) > 0) {
    # Validate features exist in training data
    missing_features_men <- setdiff(final_features_men, names(train_men))
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's training data:", paste(missing_features_men, collapse = ", "), "\n")
      final_features_men <- intersect(final_features_men, names(train_men))
    }
    
    if (length(final_features_men) > 0) {
      smooth_terms_men <- paste("s(", final_features_men, ")", collapse = " + ")
      gam_formula_men <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_men))
      cat("Men's GAM Formula (Validated Features):\n")
      print(gam_formula_men)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_men) * min_obs_per_feature
      if (nrow(train_men) < required_obs) {
        warning(sprintf("Limited observations for men's GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_men), length(final_features_men), required_obs))
      }
      
      # Build GAM with error handling
      men_gam_model <- gam(gam_formula_men, data = train_men)
      cat(sprintf("✓ Men's GAM model built successfully with %d features\n", length(final_features_men)))
    }
  }
}, error = function(e) {
  cat("Error building men's GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_men <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_men))
  if (length(core_features_men) >= 2) {
    fallback_formula_men <- paste("Pct_of_Max_Points ~", paste("s(", core_features_men, ")", collapse = " + "))
    men_gam_model <- gam(as.formula(fallback_formula_men), data = train_men)
    final_features_men <- core_features_men
    cat("✓ Men's GAM fallback model built with core features\n")
  } else {
    stop("Cannot build men's GAM model - insufficient core features available")
  }
})
```

**Purpose**: Constructs robust GAM models for men's alpine skiing with comprehensive error handling and fallback strategies.

**GAM Construction Features**:
- **Feature Validation**: Confirms selected features exist in training data before model building
- **Formula Generation**: Creates GAM formula with smooth terms for non-linear relationships
- **Data Sufficiency Check**: Validates adequate observations per feature (10:1 ratio recommended)
- **Smooth Term Integration**: Uses `s()` notation for capturing non-linear alpine performance relationships
- **Robust Error Handling**: Implements fallback to core alpine features when consensus features fail

**Fallback Strategy**:
- **Core Features**: Falls back to proven alpine predictors (Prev_Pct_of_Max_Points, Prev_Pelo, Prev_Tech, Prev_Speed)
- **Minimum Requirements**: Requires at least 2 core features for fallback model
- **Graceful Degradation**: Ensures model building succeeds even with limited feature availability

#### 3. Ladies GAM Model Construction with Parallel Processing
```r
# Build GAM formula for Ladies using validated features
cat("\n--- Ladies GAM Model ---\n")
ladies_gam_model <- NULL
tryCatch({
  if(length(final_features_ladies) > 0) {
    # Validate features exist in training data
    missing_features_ladies <- setdiff(final_features_ladies, names(train_ladies))
    if (length(missing_features_ladies) > 0) {
      cat("Warning: Missing features in ladies training data:", paste(missing_features_ladies, collapse = ", "), "\n")
      final_features_ladies <- intersect(final_features_ladies, names(train_ladies))
    }
    
    if (length(final_features_ladies) > 0) {
      smooth_terms_ladies <- paste("s(", final_features_ladies, ")", collapse = " + ")
      gam_formula_ladies <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_ladies))
      cat("Ladies GAM Formula (Validated Features):\n")
      print(gam_formula_ladies)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_ladies) * min_obs_per_feature
      if (nrow(train_ladies) < required_obs) {
        warning(sprintf("Limited observations for ladies GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_ladies), length(final_features_ladies), required_obs))
      }
      
      # Build GAM with error handling
      ladies_gam_model <- gam(gam_formula_ladies, data = train_ladies)
      cat(sprintf("✓ Ladies GAM model built successfully with %d features\n", length(final_features_ladies)))
    }
  }
}, error = function(e) {
  cat("Error building ladies GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_ladies <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Pelo", "Prev_Tech", "Prev_Speed"), names(train_ladies))
  if (length(core_features_ladies) >= 2) {
    fallback_formula_ladies <- paste("Pct_of_Max_Points ~", paste("s(", core_features_ladies, ")", collapse = " + "))
    ladies_gam_model <- gam(as.formula(fallback_formula_ladies), data = train_ladies)
    final_features_ladies <- core_features_ladies
    cat("✓ Ladies GAM fallback model built with core features\n")
  } else {
    stop("Cannot build ladies GAM model - insufficient core features available")
  }
})
```

**Purpose**: Constructs women's alpine GAM models using identical methodology to ensure cross-gender consistency and robustness.

**Parallel Processing Benefits**:
- **Consistent Methodology**: Uses same validation and construction process as men's models
- **Gender-Specific Optimization**: Allows for different optimal features between men's and women's alpine skiing
- **Independent Validation**: Validates model construction robustness across different athlete populations
- **Comparative Analysis**: Enables comparison of model performance patterns across genders

#### 4. Comprehensive GAM Model Performance Evaluation
```r
# Model performance evaluation with validation
cat("\n=== GAM MODEL PERFORMANCE EVALUATION ===\n")

# Men's GAM Model Performance
cat("--- Men's GAM Model Performance ---\n")
tryCatch({
  men_summary <- summary(men_gam_model)
  
  # Validate summary components exist
  if (is.null(men_summary$dev.expl)) {
    warning("Men's GAM deviance explained not available")
    men_dev_expl <- NA
  } else {
    men_dev_expl <- men_summary$dev.expl * 100
  }
  
  if (is.null(men_summary$r.sq)) {
    warning("Men's GAM R-squared not available")
    men_r_sq <- NA
  } else {
    men_r_sq <- men_summary$r.sq
  }
  
  if (is.null(men_gam_model$gcv.ubre)) {
    warning("Men's GAM GCV score not available")
    men_gcv <- NA
  } else {
    men_gcv <- men_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", men_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", men_r_sq))
  cat(sprintf("GCV Score: %.4f\n", men_gcv))
  
  # Validate model performance
  if (!is.na(men_dev_expl) && men_dev_expl < 10) {
    warning("Men's GAM has very low deviance explained (<10%)")
  }
  if (!is.na(men_r_sq) && men_r_sq < 0.1) {
    warning("Men's GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(men_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(men_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating men's GAM performance:", e$message, "\n")
})
```

**Purpose**: Provides comprehensive evaluation of GAM model performance using multiple alpine-specific metrics.

**Performance Metrics**:
- **Deviance Explained**: Measures how much variance the model explains in alpine performance data
- **Adjusted R-squared**: Accounts for model complexity in goodness-of-fit assessment
- **GCV Score**: Generalized Cross-Validation score for model selection and validation
- **Effective Degrees of Freedom**: Measures model complexity for alpine feature relationships

**Quality Validation**:
- **Performance Thresholds**: Warns if deviance explained <10% or R-squared <0.1
- **Component Validation**: Ensures all performance metrics are available and valid
- **Model Complexity Assessment**: Reports observations and effective degrees of freedom

#### 5. Feature Importance Analysis Through Effective Degrees of Freedom
```r
# Feature importance from GAM (edf values) with validation
cat("\n--- Feature Importance Analysis ---\n")

# Men's Feature Importance
cat("Men's GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(men_summary$s.table) && nrow(men_summary$s.table) > 0) {
    men_edf <- men_summary$s.table[,"edf"]
    names(men_edf) <- rownames(men_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(men_edf))) {
      warning("Some men's GAM EDF values are NA")
      men_edf <- men_edf[!is.na(men_edf)]
    }
    
    if (length(men_edf) > 0) {
      edf_sorted <- sort(men_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features (high EDF suggests non-linear relationship)
      high_edf_features <- names(men_edf[men_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for men's model\n")
    }
  } else {
    cat("No smooth terms in men's GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing men's feature importance:", e$message, "\n")
})
```

**Purpose**: Analyzes feature importance in alpine GAM models using Effective Degrees of Freedom to understand non-linear relationships.

**EDF Analysis Features**:
- **Non-linearity Detection**: High EDF values (>3) indicate strong non-linear relationships in alpine performance
- **Feature Ranking**: Sorts features by complexity to identify most important alpine predictors
- **Complexity Assessment**: EDF ≈1 suggests linear relationship, higher values indicate more complex curves
- **Alpine-Specific Interpretation**: Helps understand which alpine disciplines show non-linear performance patterns

#### 6. Comprehensive GAM Model Diagnostics
```r
# Model diagnostics with validation
cat("\n=== GAM MODEL DIAGNOSTICS ===\n")

# Men's GAM Model Diagnostics
cat("--- Men's GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_men <- gam.check(men_gam_model, sub.caption = "Men's GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_men)) {
    # Check for model convergence issues
    if ("converged" %in% names(men_gam_model) && !men_gam_model$converged) {
      warning("Men's GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(men_summary)) {
      basis_dims <- men_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Men's GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Men's GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating men's GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})
```

**Purpose**: Generates comprehensive diagnostic plots and validates GAM model assumptions for alpine skiing data.

**Diagnostic Features**:
- **Residual Analysis**: QQ plots and residual vs fitted plots for assumption validation
- **Convergence Validation**: Checks if GAM optimization converged properly for alpine data
- **Basis Dimension Assessment**: Validates smooth function basis dimensions are adequate
- **Visual Diagnostics**: Four-panel diagnostic plots for comprehensive model validation

#### 7. 2026 Season Prediction Framework
```r
# Predict for 2026 season using 2025 ELO values with comprehensive validation
cat("\n=== 2026 SEASON PREDICTIONS ===\n")

# Validate prediction data availability
cat("--- Prediction Data Preparation ---\n")

# Check for 2025 ELO data (end-of-season values)
men_2025 <- M_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

ladies_2025 <- L_elo %>% 
  filter(Season == 2025) %>%
  group_by(Skier) %>%
  slice_tail(n = 1) %>%  # Get most recent record per skier (end-of-2025)
  ungroup()

# Rename columns to match GAM model expectations (Prev_* format)
cat("Renaming 2025 features to Prev_* format for GAM predictions...\n")
```

**Purpose**: Establishes comprehensive framework for generating 2026 alpine skiing season predictions using trained GAM models.

**Prediction Data Preparation**:
- **End-of-Season ELO**: Uses most recent 2025 ELO ratings as predictors for 2026 performance
- **Feature Alignment**: Renames 2025 ELO columns to match GAM model expected format (Prev_*)
- **Data Validation**: Ensures prediction data availability and quality before GAM prediction
- **Temporal Consistency**: Maintains proper time ordering for prediction validity

#### 8. Data Preprocessing for 2026 Predictions
```r
if (nrow(men_2025) > 0) {
  # First, remove existing Prev_* columns (which contain 2024 data)
  prev_cols_to_remove <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
                          "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")
  existing_prev_cols <- intersect(prev_cols_to_remove, names(men_2025))
  if (length(existing_prev_cols) > 0) {
    cat("Removing existing Prev_* columns (2024 data):", paste(existing_prev_cols, collapse = ", "), "\n")
    men_2025 <- men_2025 %>% dplyr::select(-all_of(existing_prev_cols))
  }
  
  # Then rename current 2025 columns to Prev_* format
  men_2025 <- men_2025 %>%
    rename(
      Prev_Pelo = Pelo,
      Prev_Downhill = Downhill_Pelo,
      Prev_Super_G = `Super G_Pelo`,
      Prev_Giant_Slalom = `Giant Slalom_Pelo`,
      Prev_Slalom = Slalom_Pelo,
      Prev_Combined = Combined_Pelo,
      Prev_Tech = Tech_Pelo,
      Prev_Speed = Speed_Pelo,
      Prev_Pct_of_Max_Points = Pct_of_Max_Points
    )
}

# Apply quartile replacement to handle missing values in 2025 data
cat("Applying quartile replacement for missing values in 2025 prediction data...\n")

if (nrow(men_2025) > 0) {
  men_2025 <- men_2025 %>%
    group_by(Season) %>%
    mutate(
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Downhill = replace_na_with_quartile(Prev_Downhill),
      Prev_Super_G = replace_na_with_quartile(Prev_Super_G),
      Prev_Giant_Slalom = replace_na_with_quartile(Prev_Giant_Slalom),
      Prev_Slalom = replace_na_with_quartile(Prev_Slalom),
      Prev_Combined = replace_na_with_quartile(Prev_Combined),
      Prev_Tech = replace_na_with_quartile(Prev_Tech),
      Prev_Speed = replace_na_with_quartile(Prev_Speed),
      Prev_Pct_of_Max_Points = replace_na_with_quartile(Prev_Pct_of_Max_Points)
    ) %>%
    ungroup()
}
```

**Purpose**: Implements robust data preprocessing for 2026 predictions with comprehensive missing value handling.

**Preprocessing Steps**:
- **Legacy Data Removal**: Removes outdated Prev_* columns containing 2024 data
- **Feature Renaming**: Converts 2025 ELO ratings to Prev_* format for GAM model compatibility
- **Missing Value Imputation**: Applies conservative quartile-based imputation for missing alpine ELO values
- **Discipline-Specific Treatment**: Handles missing values for each alpine discipline independently

#### 9. GAM-Based 2026 Prediction Generation
```r
# Men's 2026 Predictions
cat("\n--- Men's 2026 Predictions ---\n")
men_pred_data <- NULL
if(nrow(men_2025) > 0) {
  tryCatch({
    # Validate features are available in 2025 data
    available_features_men <- intersect(final_features_men, names(men_2025))
    missing_features_men <- setdiff(final_features_men, names(men_2025))
    
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's 2025 data for prediction:", paste(missing_features_men, collapse = ", "), "\n")
    }
    
    if (length(available_features_men) > 0) {
      # Debug: Show exact GAM model input for Marcel Hirscher
      if ("Marcel Hirscher" %in% men_2025$Skier) {
        hirscher_idx <- which(men_2025$Skier == "Marcel Hirscher")
        cat("\n=== DEBUG: Marcel Hirscher GAM Model Input ===\n")
        cat("Selected features for GAM:", paste(final_features_men, collapse = ", "), "\n")
        hirscher_model_data <- men_2025[hirscher_idx, c("Skier", final_features_men), drop = FALSE]
        print(hirscher_model_data)
      }
      
      # Use only available features for prediction
      pred_2026_men <- predict(men_gam_model, newdata = men_2025, se.fit = TRUE)
      
      # Validate predictions
      if (any(!is.finite(pred_2026_men$fit))) {
        warning("Some men's 2026 predictions are non-finite")
        pred_2026_men$fit[!is.finite(pred_2026_men$fit)] <- NA
      }
      
      men_pred_data <- men_2025 %>%
        mutate(
          Predicted_Pct_2026 = pred_2026_men$fit,
          Prediction_SE = pred_2026_men$se.fit,
          Lower_CI = Predicted_Pct_2026 - 1.96 * Prediction_SE,
          Upper_CI = Predicted_Pct_2026 + 1.96 * Prediction_SE
        ) %>%
        filter(!is.na(Predicted_Pct_2026)) %>%
        arrange(desc(Predicted_Pct_2026))
      
      cat(sprintf("✓ Men's 2026 predictions generated for %d athletes\n", nrow(men_pred_data)))
      cat(sprintf("Top predicted: %s (%.2f%% of max points)\n", 
                  men_pred_data$Skier[1], men_pred_data$Predicted_Pct_2026[1] * 100))
    }
  }, error = function(e) {
    cat("Error generating men's 2026 predictions:", e$message, "\n")
  })
}
```

**Purpose**: Generates 2026 season predictions with confidence intervals and comprehensive validation.

**Prediction Features**:
- **Feature Validation**: Ensures required features are available in 2025 prediction data
- **Debug Output**: Provides detailed model input for star athletes (Marcel Hirscher, Lara Colturi)
- **Uncertainty Quantification**: Generates standard errors and 95% confidence intervals
- **Prediction Validation**: Checks for non-finite predictions and handles gracefully
- **Results Ranking**: Sorts predictions by expected performance for easy interpretation

### Alpine GAM-Specific Design Considerations

#### Non-Linear Relationship Modeling
GAM models excel at capturing alpine skiing's complex performance patterns:
- **Smooth Functions**: Use spline smoothing to model non-linear relationships between ELO ratings and performance
- **Discipline Interactions**: Capture complex relationships between different alpine disciplines
- **Performance Curves**: Model diminishing returns and threshold effects in alpine performance
- **Age Effects**: Capture non-linear age-performance relationships in alpine skiing

#### Alpine-Specific Model Validation
- **EDF Interpretation**: High EDF values indicate complex non-linear relationships specific to alpine disciplines
- **Convergence Monitoring**: Ensures GAM optimization converges properly for alpine data patterns
- **Basis Dimension Validation**: Confirms adequate flexibility for modeling alpine performance curves
- **Cross-Gender Consistency**: Validates model construction robustness across different athlete populations

#### Prediction Robustness
- **Feature Alignment**: Ensures 2025 ELO data properly formatted for GAM prediction
- **Missing Value Handling**: Conservative quartile-based imputation maintains prediction reliability
- **Uncertainty Quantification**: Confidence intervals provide prediction reliability assessment
- **Star Athlete Debugging**: Detailed output for high-profile athletes ensures prediction transparency

### Error Handling and Quality Assurance
- **Comprehensive Input Validation**: Validates all prerequisites before GAM construction
- **Robust Fallback Strategies**: Core feature fallbacks ensure model building succeeds
- **Performance Monitoring**: Multiple metrics assess model quality and reliability
- **Prediction Validation**: Extensive checks ensure prediction quality and interpretability
- **Diagnostic Integration**: Built-in diagnostic plots validate model assumptions

This alpine GAM modeling section creates sophisticated, non-linear prediction models that capture the complex relationships inherent in alpine skiing performance while maintaining robustness and providing comprehensive uncertainty quantification for 2026 season predictions.

## Section: {r odds-setup} - Alpine Odds Framework & Categorical Outcome Preparation

### Purpose
This section establishes the comprehensive framework for odds calculation in alpine skiing by creating categorical performance outcomes, validating ranking systems, and preparing prediction data for statistical odds modeling across multiple performance thresholds.

### Implementation Details

#### 1. Training Data Validation for Odds Calculation
```r
cat("=== ODDS SETUP & VALIDATION ===\n")

# Validate training data availability for odds calculations
cat("\n--- Training Data Validation for Odds ---\n")

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure previous sections completed successfully")
}

if (nrow(train_men) == 0) {
  stop("Men's training data is empty")
}
if (nrow(train_ladies) == 0) {
  stop("Ladies training data is empty") 
}

cat(sprintf("Training data for odds: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Validate required columns exist
required_odds_cols <- c("Pct_of_Max_Points", "Season")
missing_men_cols <- setdiff(required_odds_cols, names(train_men))
missing_ladies_cols <- setdiff(required_odds_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop(sprintf("Men's training data missing required columns for odds: %s", paste(missing_men_cols, collapse = ", ")))
}
if (length(missing_ladies_cols) > 0) {
  stop(sprintf("Ladies training data missing required columns for odds: %s", paste(missing_ladies_cols, collapse = ", ")))
}
```

**Purpose**: Validates comprehensive training data availability and quality for alpine skiing odds calculation framework.

**Data Validation Features**:
- **Training Data Existence**: Confirms processed training data is available from previous sections
- **Empty Dataset Protection**: Prevents odds calculation with insufficient data
- **Required Column Validation**: Ensures essential variables (Pct_of_Max_Points, Season) are present
- **Cross-Gender Validation**: Validates data availability for both men's and women's alpine skiing

**Quality Assurance**:
- **Data Size Reporting**: Reports training dataset sizes for transparency
- **Dependency Verification**: Ensures prerequisite processing steps completed successfully
- **Error Prevention**: Stops processing if critical data components are missing

#### 2. Season-Based Ranking System Implementation
```r
# Add Place column based on rankings within each season with validation
cat("\n--- Season Ranking Calculation ---\n")

tryCatch({
  df_place <- train_men %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
  
  cat(sprintf("✓ Men's place rankings calculated: %d rows\n", nrow(df_place)))
}, error = function(e) {
  stop("Failed to calculate men's place rankings: ", e$message)
})

tryCatch({
  df_place_ladies <- train_ladies %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
    
  cat(sprintf("✓ Ladies place rankings calculated: %d rows\n", nrow(df_place_ladies)))
}, error = function(e) {
  stop("Failed to calculate ladies place rankings: ", e$message)
})

# Validate Place column creation
place_na_men <- sum(is.na(df_place$Place))
place_na_ladies <- sum(is.na(df_place_ladies$Place))

if (place_na_men > 0) {
  warning(sprintf("Men's Place column has %d NA values", place_na_men))
}
if (place_na_ladies > 0) {
  warning(sprintf("Ladies Place column has %d NA values", place_na_ladies))
}

# Validate ranking ranges
men_place_range <- range(df_place$Place, na.rm = TRUE)
ladies_place_range <- range(df_place_ladies$Place, na.rm = TRUE)

cat(sprintf("Men's Place range: %d - %d\n", men_place_range[1], men_place_range[2]))
cat(sprintf("Ladies Place range: %d - %d\n", ladies_place_range[1], ladies_place_range[2]))
```

**Purpose**: Implements robust season-based ranking system that creates competitive context for alpine skiing odds calculation.

**Ranking System Features**:
- **Season-Based Rankings**: Rankings calculated within each season to account for competitive context
- **Performance-Based Ordering**: Uses negative Pct_of_Max_Points for descending order (best performers ranked 1st)
- **Tie Handling**: Uses "min" method for consistent tie-breaking in alpine performance rankings
- **Cross-Gender Processing**: Applies identical ranking methodology to both men's and women's data

**Validation Framework**:
- **Missing Value Detection**: Identifies and reports any NA values in ranking calculations
- **Range Validation**: Confirms ranking ranges are logical (starting from 1)
- **Error Handling**: Robust error handling ensures ranking calculation succeeds or fails gracefully

#### 3. Comprehensive Season Ranking Validation
```r
# Debug and validate season rankings
cat("\n--- Season Ranking Validation ---\n")

# Check ladies data distribution
cat("Ladies Pct_of_Max_Points distribution:\n")
ladies_pct_summary <- summary(train_ladies$Pct_of_Max_Points)
print(ladies_pct_summary)

# Validate no negative or extreme values
if (any(train_ladies$Pct_of_Max_Points < 0, na.rm = TRUE)) {
  warning("Ladies data contains negative Pct_of_Max_Points values")
}
if (any(train_ladies$Pct_of_Max_Points > 2, na.rm = TRUE)) {
  warning("Ladies data contains very high Pct_of_Max_Points values (>200%)")
}

cat("Ladies Place distribution:\n")
ladies_place_table <- table(df_place_ladies$Place)
print(head(ladies_place_table, 10))

cat("Ladies seasons distribution:\n")
ladies_season_table <- table(df_place_ladies$Season)
print(ladies_season_table)

# Check for balanced season representation
if (any(ladies_season_table < 5)) {
  seasons_low_n <- names(ladies_season_table[ladies_season_table < 5])
  warning(sprintf("Ladies seasons with <5 observations: %s", paste(seasons_low_n, collapse = ", ")))
}

# Sample rankings validation
cat("Sample ladies season rankings (first 15):\n")
sample_rankings <- df_place_ladies %>% 
  arrange(Season, Place) %>% 
  dplyr::select(Season, Skier, Pct_of_Max_Points, Place) %>%
  head(15)
print(sample_rankings)
```

**Purpose**: Provides comprehensive validation of alpine skiing ranking system quality and distribution characteristics.

**Validation Components**:
- **Performance Distribution Analysis**: Examines Pct_of_Max_Points distribution for data quality
- **Extreme Value Detection**: Identifies negative or unrealistically high performance values
- **Ranking Distribution**: Analyzes place distribution to understand competitive structure
- **Season Balance Assessment**: Ensures adequate representation across all alpine skiing seasons
- **Sample Validation**: Provides concrete examples of ranking calculation results

**Quality Checks**:
- **Data Range Validation**: Confirms performance percentages are within expected bounds (0-200%)
- **Season Representation**: Warns about seasons with insufficient data (<5 observations)
- **Ranking Logic Verification**: Shows sample rankings to validate correct ordering

#### 4. Categorical Outcome Framework Creation
```r
# Create categorical outcomes for different cutoffs with validation
cat("\n--- Categorical Outcome Creation ---\n")

tryCatch({
  df_place <- df_place %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Men's categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create men's categorical outcomes: ", e$message)
})

tryCatch({
  df_place_ladies <- df_place_ladies %>%
    mutate(
      Win = factor(ifelse(Place <= 1, 1, 0)),
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Ladies categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create ladies categorical outcomes: ", e$message)
})
```

**Purpose**: Creates comprehensive categorical outcome framework for alpine skiing odds calculation across multiple performance thresholds.

**Categorical Outcome Structure**:
- **Win**: Season victory (Place <= 1) - captures championship-level performance
- **TopThree**: Podium finish (Place <= 3) - represents elite consistency in alpine skiing
- **Top5**: Elite performance (Place <= 5) - broader elite tier for alpine competitive analysis
- **Top10**: Strong performance (Place <= 10) - competitive alpine skiing threshold
- **Top30**: Points-scoring finish (Place <= 30) - alpine World Cup points eligibility

**Alpine-Specific Considerations**:
- **Championship Focus**: Win category captures seasonal dominance in alpine skiing
- **Podium Emphasis**: TopThree aligns with alpine skiing's podium ceremony tradition
- **Points Threshold**: Top30 corresponds to alpine World Cup points system (top 30 score points)
- **Factor Encoding**: Binary factors (0/1) enable logistic regression modeling for odds calculation

#### 5. Comprehensive Categorical Outcome Validation
```r
# Validate categorical outcome creation
cat("\n--- Categorical Outcome Validation ---\n")

# Check TopThree creation for ladies
cat("Ladies Place vs TopThree validation:\n")
topthree_crosstab <- table(df_place_ladies$Place, df_place_ladies$TopThree, useNA = "always")
print(topthree_crosstab[1:min(10, nrow(topthree_crosstab)), ])

# Validate factor levels
expected_levels <- c("0", "1")
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")

for (target in targets) {
  men_levels <- levels(df_place[[target]])
  ladies_levels <- levels(df_place_ladies[[target]])
  
  if (!all(expected_levels %in% men_levels)) {
    warning(sprintf("Men's %s missing expected levels: %s", target, paste(setdiff(expected_levels, men_levels), collapse = ", ")))
  }
  if (!all(expected_levels %in% ladies_levels)) {
    warning(sprintf("Ladies %s missing expected levels: %s", target, paste(setdiff(expected_levels, ladies_levels), collapse = ", ")))
  }
  
  # Check for class imbalance
  men_table <- table(df_place[[target]])
  ladies_table <- table(df_place_ladies[[target]])
  
  men_minority_pct <- min(men_table) / sum(men_table) * 100
  ladies_minority_pct <- min(ladies_table) / sum(ladies_table) * 100
  
  cat(sprintf("%s class balance: Men %.1f%% minority, Ladies %.1f%% minority\n", 
              target, men_minority_pct, ladies_minority_pct))
  
  if (men_minority_pct < 5) {
    warning(sprintf("Men's %s has severe class imbalance (<5%% minority class)", target))
  }
  if (ladies_minority_pct < 5) {
    warning(sprintf("Ladies %s has severe class imbalance (<5%% minority class)", target))
  }
}

# Sample TopThree values
cat("First 20 ladies Place and TopThree values:\n")
sample_topthree <- df_place_ladies %>% 
  dplyr::select(Skier, Season, Place, TopThree) %>% 
  head(20)
print(sample_topthree)
```

**Purpose**: Provides comprehensive validation of categorical outcome creation and identifies potential modeling challenges.

**Validation Framework**:
- **Cross-Tabulation Analysis**: Validates that categorical outcomes align correctly with place rankings
- **Factor Level Verification**: Ensures all categorical outcomes have expected binary levels (0, 1)
- **Class Balance Assessment**: Identifies class imbalance that could affect odds modeling quality
- **Sample Verification**: Provides concrete examples to validate categorical outcome logic

**Class Imbalance Monitoring**:
- **Severe Imbalance Detection**: Warns when minority class <5% (could cause modeling issues)
- **Cross-Gender Comparison**: Compares class balance between men's and women's alpine skiing
- **Performance Threshold Analysis**: Shows how class balance varies across different performance thresholds

#### 6. Prediction Data Preparation for Odds Calculation
```r
# Prepare 2025 prediction data with validation
cat("\n--- 2025 Prediction Data Preparation ---\n")

# Validate prediction data exists
if (!exists("men_pred_data") || is.null(men_pred_data)) {
  warning("Men's 2026 prediction data not available from previous section")
  men_pred_data <- data.frame()
}
if (!exists("ladies_pred_data") || is.null(ladies_pred_data)) {
  warning("Ladies 2026 prediction data not available from previous section") 
  ladies_pred_data <- data.frame()
}

# Men's prediction data preparation
pred_data_men <- NULL
if (nrow(men_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (alpine-specific)
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Downhill_Pelo", "Super G_Pelo", 
                           "Giant Slalom_Pelo", "Slalom_Pelo", "Combined_Pelo", 
                           "Tech_Pelo", "Speed_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(men_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(men_pred_data))
    
    cat(sprintf("Men's prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing men's prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_men <- men_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (alpine-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Downhill" = "Downhill_Pelo", 
                     "Prev_Super_G" = "Super G_Pelo", "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
                     "Prev_Slalom" = "Slalom_Pelo", "Prev_Combined" = "Combined_Pelo", 
                     "Prev_Tech" = "Tech_Pelo", "Prev_Speed" = "Speed_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "Nation")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_men)) {
          names(pred_data_men)[names(pred_data_men) == rename_map[old_name]] <- old_name
        }
      }
      
      # Handle column names with spaces by converting to underscores
      if ("Super G_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Super G_Pelo"] <- "Prev_Super_G"
      }
      if ("Giant Slalom_Pelo" %in% names(pred_data_men)) {
        names(pred_data_men)[names(pred_data_men) == "Giant Slalom_Pelo"] <- "Prev_Giant_Slalom"
      }
      
      cat(sprintf("✓ Men's prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_men), ncol(pred_data_men)))
    } else {
      warning("Insufficient columns for men's prediction data preparation")
      pred_data_men <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing men's prediction data:", e$message, "\n")
    pred_data_men <- data.frame()
  })
} else {
  cat("No men's prediction data available\n")
  pred_data_men <- data.frame()
}
```

**Purpose**: Prepares 2026 prediction data for odds calculation by aligning feature names and validating data availability.

**Prediction Data Processing**:
- **Alpine-Specific Column Mapping**: Handles all alpine disciplines (Downhill, Super G, Giant Slalom, Slalom, Combined)
- **Feature Name Alignment**: Converts prediction data column names to match training data format
- **Space Handling**: Properly manages alpine discipline names containing spaces
- **Minimum Data Requirements**: Ensures at least 4 columns available for meaningful odds calculation

**Data Validation**:
- **Column Availability Assessment**: Reports available vs missing prediction columns
- **Graceful Degradation**: Continues processing with available columns when some are missing
- **Error Handling**: Robust error handling ensures prediction data preparation succeeds or fails gracefully

### Alpine Odds-Specific Design Considerations

#### Performance Threshold Framework
Alpine skiing odds framework uses sport-specific performance thresholds:
- **Championship Level**: Win category captures seasonal overall victory
- **Elite Consistency**: TopThree represents podium-level alpine performance
- **Competitive Tiers**: Top5, Top10, Top30 provide graduated performance levels
- **Points System Alignment**: Top30 threshold aligns with alpine World Cup points eligibility

#### Season-Based Ranking Context
Ranking system accounts for alpine skiing's competitive structure:
- **Seasonal Context**: Rankings calculated within seasons to account for varying competitive fields
- **Performance Standardization**: Uses percentage of maximum points for cross-season comparability
- **Tie-Breaking Consistency**: Standardized tie-breaking ensures reproducible rankings

#### Alpine-Specific Data Requirements
Odds framework handles alpine skiing's multi-discipline structure:
- **Discipline Coverage**: Accommodates all five alpine disciplines plus aggregate categories
- **ELO Integration**: Incorporates discipline-specific and overall ELO ratings
- **Feature Flexibility**: Handles missing disciplines gracefully while maintaining prediction capability

### Error Handling and Quality Assurance
- **Comprehensive Data Validation**: Validates training and prediction data availability and quality
- **Ranking System Verification**: Extensive validation of season-based ranking calculations
- **Categorical Outcome Validation**: Cross-tabulation and factor level verification
- **Class Balance Monitoring**: Identifies potential modeling challenges from class imbalance
- **Prediction Data Alignment**: Ensures feature name consistency between training and prediction data

This alpine odds setup section establishes a robust framework for odds calculation that respects alpine skiing's competitive structure while providing comprehensive validation and error handling to ensure reliable odds modeling across multiple performance thresholds.
## Section: {r non-ml-feat} - Alpine Feature Selection for Odds Models

### Purpose
This section performs exhaustive feature selection specifically for alpine skiing odds models, identifying optimal feature combinations for predicting categorical outcomes (Win, TopThree, Top5, Top10, Top30) using non-machine learning statistical approaches.

### Alpine Feature Selection Framework

#### 1. Library Loading and Data Validation
```r
# Load required libraries with validation
cat("\n--- Library Loading ---\n")
tryCatch({
  library(leaps)
  cat("✓ leaps library loaded\n")
}, error = function(e) {
  stop("Failed to load leaps library: ", e$message)
})

tryCatch({
  library(caret)
  cat("✓ caret library loaded\n")
}, error = function(e) {
  stop("Failed to load caret library: ", e$message)
})
```
**Purpose**: Loads essential libraries for statistical feature selection. The `leaps` package provides exhaustive subset selection while `caret` offers model validation tools. Error handling ensures dependencies are available before proceeding.

#### 2. Training Data Availability Validation
```r
# Validate input data availability
if (\!exists("df_place") || \!exists("df_place_ladies")) {
  stop("Training data with places not available - ensure odds-setup section completed successfully")
}

if (nrow(df_place) == 0) {
  stop("Men's training data with places is empty")
}
if (nrow(df_place_ladies) == 0) {
  stop("Ladies training data with places is empty")
}

cat(sprintf("Training data with outcomes: Men %d rows, Ladies %d rows\n", nrow(df_place), nrow(df_place_ladies)))
```
**Purpose**: Ensures that the categorical outcome data created in the `odds-setup` section is available and non-empty. This data contains the binary target variables (Win, TopThree, etc.) needed for logistic regression modeling.

#### 3. Alpine Feature Definition and Validation
```r
# Define and validate features for alpine odds models
features <- c("Prev_Pelo", "Prev_Downhill", "Prev_Super_G", "Prev_Giant_Slalom", 
              "Prev_Slalom", "Prev_Combined", "Prev_Tech", "Prev_Speed", "Prev_Pct_of_Max_Points")

# Check feature availability in training data
men_available_features <- intersect(features, names(df_place))
ladies_available_features <- intersect(features, names(df_place_ladies))

cat(sprintf("Men's available alpine features: %d/%d\n", length(men_available_features), length(features)))
cat(sprintf("Ladies available alpine features: %d/%d\n", length(ladies_available_features), length(features)))
```
**Purpose**: Defines the comprehensive set of alpine skiing predictor variables and validates their availability in the training datasets. These features include:
- **Prev_Pelo**: Overall ELO rating from previous season
- **Discipline-specific ratings**: Downhill, Super G, Giant Slalom, Slalom, Combined
- **Category ratings**: Technical (Tech) and Speed discipline groupings
- **Performance metric**: Percentage of maximum points achieved

#### 4. Statistical Model Evaluation Function
```r
# Function to evaluate binary logistic model with validation
evaluate_glm <- function(feature_set, data, target, gender_label = "Unknown") {
  tryCatch({
    # Validate inputs and check feature existence
    if (length(feature_set) == 0) return(Inf)
    
    missing_features <- setdiff(feature_set, names(data))
    if (length(missing_features) > 0) return(Inf)
    
    # Check target variable quality
    if (\!target %in% names(data)) return(Inf)
    
    target_table <- table(data[[target]])
    if (length(target_table) < 2 || any(target_table < 5)) {
      return(Inf)  # Skip if insufficient observations per class
    }
    
    # Build and evaluate logistic regression model
    formula_str <- as.formula(paste(target, "~", paste(feature_set, collapse = " + ")))
    model <- glm(formula_str, family = binomial, data = data)
    
    # Validate model convergence
    if (\!model$converged) return(Inf)
    
    aic_value <- AIC(model)
    if (\!is.finite(aic_value)) return(Inf)
    
    return(aic_value)
  }, error = function(e) {
    return(Inf)
  })
}
```
**Purpose**: Creates a robust evaluation function for binary logistic regression models. Key validation steps include:
- **Feature Availability**: Ensures all features exist in the dataset
- **Target Quality**: Validates binary outcomes have sufficient observations in both classes (minimum 5 per class)
- **Model Convergence**: Checks that logistic regression converged successfully
- **AIC Calculation**: Returns Akaike Information Criterion for model comparison

#### 5. Exhaustive Feature Search Implementation
```r
# Exhaustive feature search function with validation
exhaustive_feature_search <- function(target, data_df, gender_label, available_features) {
  cat(sprintf("Searching %s alpine features for %s...\n", gender_label, target))
  
  best_aic <- Inf
  best_features <- NULL
  total_combinations <- 0
  successful_models <- 0
  
  # Search through feature combinations (2-5 features)
  max_features <- min(5, length(available_features))
  
  for(i in 2:max_features) {
    if (i > length(available_features)) break
    
    combinations <- combn(available_features, i, simplify = FALSE)
    total_combinations <- total_combinations + length(combinations)
    
    for(feature_set in combinations) {
      aic <- evaluate_glm(feature_set, data_df, target, gender_label)
      if(is.finite(aic)) {
        successful_models <- successful_models + 1
        if(aic < best_aic) {
          best_aic <- aic
          best_features <- feature_set
        }
      }
    }
  }
  
  cat(sprintf("  Tested %d combinations, %d successful models\n", total_combinations, successful_models))
  return(list(features = best_features, aic = best_aic))
}
```
**Purpose**: Implements comprehensive exhaustive search across alpine feature combinations. The algorithm:
- **Tests feature combinations** from 2 to 5 features (balancing complexity vs. overfitting)
- **Evaluates all possible combinations** using combinatorial approach
- **Tracks success rates** to identify data quality issues
- **Selects optimal features** based on lowest AIC (best balance of fit and complexity)

#### 6. Target Variable Distribution Analysis
```r
# Debug and validate data structure
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")
for (target in targets) {
  if (target %in% names(df_place)) {
    men_table <- table(df_place[[target]])
    cat(sprintf("Men's %s distribution: %s\n", target, paste(names(men_table), men_table, sep="=", collapse=", ")))
  }
  
  if (target %in% names(df_place_ladies)) {
    ladies_table <- table(df_place_ladies[[target]])
    cat(sprintf("Ladies %s distribution: %s\n", target, paste(names(ladies_table), ladies_table, sep="=", collapse=", ")))
  }
}
```
**Purpose**: Analyzes the distribution of binary outcome variables to ensure sufficient data for modeling. This helps identify:
- **Class imbalance issues**: Whether there are enough positive cases for each outcome
- **Data availability**: Which targets have sufficient observations for reliable modeling
- **Alpine-specific patterns**: How success rates differ between disciplines and genders

#### 7. Comprehensive Feature Search Execution
```r
# Perform exhaustive feature search with validation
cat("\n=== EXHAUSTIVE ALPINE FEATURE SEARCH ===\n")

# Initialize result storage
best_features_odds_men <- list()
best_features_odds_ladies <- list()

# Men's alpine feature search
for(target in targets) {
  if (target %in% names(df_place)) {
    result <- exhaustive_feature_search(target, df_place, "Men's", features_men)
    best_features_odds_men[[target]] <- result
  }
}

# Ladies alpine feature search  
for(target in targets) {
  if (target %in% names(df_place_ladies)) {
    result <- exhaustive_feature_search(target, df_place_ladies, "Ladies", features_ladies)
    best_features_odds_ladies[[target]] <- result
  }
}
```
**Purpose**: Executes the comprehensive feature selection process for all alpine outcome categories and both genders. This creates optimized feature sets for:
- **Win probability models**: Predicting race victories
- **Podium models**: TopThree finish probabilities  
- **Points-scoring models**: Top5, Top10, Top30 finish probabilities
- **Gender-specific optimization**: Separate feature selection for men's and ladies competitions

### Alpine-Specific Considerations

**Multi-Discipline Structure**: Alpine skiing's diverse disciplines (speed vs. technical) require discipline-specific ELO ratings alongside overall ratings for optimal prediction accuracy.

**Categorical Outcomes**: Unlike continuous GAM models, this section focuses on binary classification for practical betting/prediction applications.

**Feature Complexity Management**: Limits feature combinations to 2-5 features to prevent overfitting while maintaining model interpretability.

**Statistical Validation**: Emphasis on AIC-based model selection rather than pure accuracy to balance model fit with generalizability.

### Error Handling and Quality Assurance

The section implements comprehensive error handling including:
- **Library dependency validation** before feature selection begins
- **Training data existence checks** to ensure prerequisite sections completed
- **Model convergence validation** for all logistic regression attempts
- **Minimum observation requirements** to prevent unreliable models from insufficient data
- **Feature availability verification** to handle missing or corrupted predictor variables

This robust approach ensures that only statistically sound feature combinations are selected for the subsequent odds calculation models.
EOF < /dev/null

## Section: {r statistical-odds} - Statistical Odds Model Training and Prediction

### Purpose
This section trains logistic regression models using the optimized features from exhaustive feature selection, generates predictions for 2026 alpine skiers, and converts probabilities into betting odds with comprehensive normalization and validation.

### Statistical Odds Framework

#### 1. Feature Set Validation and Extraction
```r
cat("=== STATISTICAL ODDS VALIDATION ===\n")

# Input validation for feature sets
if (\!exists("best_features_odds_men") || \!is.list(best_features_odds_men)) {
  stop("best_features_odds_men object not found or invalid")
}
if (\!exists("best_features_odds_ladies") || \!is.list(best_features_odds_ladies)) {
  stop("best_features_odds_ladies object not found or invalid")
}

# Required outcome categories
required_outcomes <- c("Win", "TopThree", "Top5", "Top10", "Top30")
missing_men <- setdiff(required_outcomes, names(best_features_odds_men))
missing_ladies <- setdiff(required_outcomes, names(best_features_odds_ladies))

if (length(missing_men) > 0) {
  stop("Missing outcome categories in men's features: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing outcome categories in ladies features: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required outcome categories present\n")
```
**Purpose**: Validates that feature selection completed successfully and all required outcome categories have optimal feature sets. Ensures data pipeline integrity before model training begins.

#### 2. Optimal Feature Extraction for Men's Models
```r
tryCatch({
  # Use best features from exhaustive search for men
  win_features_men <- best_features_odds_men[["Win"]]$features
  topthree_features_men <- best_features_odds_men[["TopThree"]]$features
  top5_features_men <- best_features_odds_men[["Top5"]]$features
  top10_features_men <- best_features_odds_men[["Top10"]]$features
  top30_features_men <- best_features_odds_men[["Top30"]]$features
  
  # Validate men's features
  if (length(win_features_men) == 0) stop("No features found for men's Win")
  if (length(topthree_features_men) == 0) stop("No features found for men's TopThree")
  if (length(top5_features_men) == 0) stop("No features found for men's Top5")
  if (length(top10_features_men) == 0) stop("No features found for men's Top10")
  if (length(top30_features_men) == 0) stop("No features found for men's Top30")
  
  cat("Men's feature counts - Win:", length(win_features_men), 
      "Top3:", length(topthree_features_men),
      "Top5:", length(top5_features_men), 
      "Top10:", length(top10_features_men), 
      "Top30:", length(top30_features_men), "\n")
      
}, error = function(e) {
  stop("Error extracting men's features: ", e$message)
})
```
**Purpose**: Extracts the optimal feature combinations identified by exhaustive search for each outcome category. Validates that feature selection succeeded for all targets before proceeding to model training.

#### 3. Formula Creation and Validation
```r
# Create formulas with validation
cat("\n--- Formula Creation ---\n")
tryCatch({
  # Create formulas for men's models
  win_formula_men <- as.formula(paste("Win ~", paste(win_features_men, collapse = " + ")))
  topthree_formula_men <- as.formula(paste("TopThree ~", paste(topthree_features_men, collapse = " + ")))
  top5_formula_men <- as.formula(paste("Top5 ~", paste(top5_features_men, collapse = " + ")))
  top10_formula_men <- as.formula(paste("Top10 ~", paste(top10_features_men, collapse = " + ")))
  top30_formula_men <- as.formula(paste("Top30 ~", paste(top30_features_men, collapse = " + ")))
  
  # Validate formula creation
  if (\!inherits(win_formula_men, "formula")) stop("Failed to create Win formula for men")
  if (\!inherits(topthree_formula_men, "formula")) stop("Failed to create TopThree formula for men")
  if (\!inherits(top5_formula_men, "formula")) stop("Failed to create Top5 formula for men")
  if (\!inherits(top10_formula_men, "formula")) stop("Failed to create Top10 formula for men")
  if (\!inherits(top30_formula_men, "formula")) stop("Failed to create Top30 formula for men")
  
  cat("✓ Men's formulas created successfully\n")
  
}, error = function(e) {
  stop("Error creating men's formulas: ", e$message)
})
```
**Purpose**: Constructs R formula objects for logistic regression models using the optimized feature sets. Validates formula creation to ensure proper model specification.

#### 4. Training Data Quality Assessment
```r
# Validate data availability for modeling
if (\!exists("df_place") || \!is.data.frame(df_place)) {
  stop("df_place dataset not found or invalid")
}
if (nrow(df_place) == 0) {
  stop("df_place dataset is empty")
}

# Validate target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place[[target]], useNA = "always")
  cat("Target", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for target ", target, " - model may be unstable")
  }
}
```
**Purpose**: Assesses training data quality and class distributions before model fitting. Identifies potential modeling challenges such as class imbalance that could affect model reliability.

#### 5. Logistic Regression Model Training
```r
# Fit models with optimal feature sets and validation
cat("\n--- Model Training ---\n")
tryCatch({
  win_model <- glm(win_formula, family = binomial, data = df_place)
  
  # Validate model convergence
  if (\!win_model$converged) {
    warning("Win model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(win_model)))) {
    warning("Win model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Win model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Win model: ", e$message)
})
```
**Purpose**: Trains binary logistic regression models for each outcome category using optimal feature sets. Includes comprehensive validation for model convergence and coefficient estimation issues.

#### 6. Model Diagnostics and Quality Assessment
```r
# Model diagnostics
cat("\n--- Model Diagnostics ---\n")
models <- list(
  Win = win_model,
  TopThree = topthree_model,
  Top5 = top5_model,
  Top10 = top10_model,
  Top30 = top30_model
)

for (model_name in names(models)) {
  model <- models[[model_name]]
  cat(sprintf("\n%s Model Summary:\n", model_name))
  
  # AIC
  cat(sprintf("  AIC: %.2f\n", AIC(model)))
  
  # Deviance
  cat(sprintf("  Residual Deviance: %.2f\n", deviance(model)))
  
  # Pseudo R-squared (McFadden)
  null_deviance <- model$null.deviance
  residual_deviance <- model$deviance
  pseudo_r2 <- 1 - (residual_deviance / null_deviance)
  cat(sprintf("  Pseudo R²: %.3f\n", pseudo_r2))
  
  # Check for perfect separation issues
  fitted_probs <- fitted(model)
  if (any(fitted_probs == 0) || any(fitted_probs == 1)) {
    warning(sprintf("%s model may have perfect separation issues", model_name))
  }
}
```
**Purpose**: Provides comprehensive model diagnostics including AIC, deviance, pseudo R-squared, and perfect separation detection. Essential for assessing model quality and identifying potential issues.

#### 7. 2026 Prediction Generation
```r
# ========== 2026 PREDICTIONS ==========
cat("\n=== GENERATING 2026 ALPINE PREDICTIONS ===\n")

# Validate prediction dataset
if (\!exists("pred_data") || \!is.data.frame(pred_data)) {
  stop("pred_data dataset not found or invalid")
}
if (nrow(pred_data) == 0) {
  stop("pred_data dataset is empty")
}

# Generate predictions with comprehensive validation
tryCatch({
  win_probs <- predict(win_model, pred_data, type = "response")
  
  # Validate Win predictions
  if (any(is.na(win_probs))) {
    warning("NA predictions detected for Win - ", sum(is.na(win_probs)), " out of ", length(win_probs))
  }
  if (any(win_probs < 0  < /dev/null |  win_probs > 1, na.rm = TRUE)) {
    warning("Invalid probability values for Win (outside 0-1 range)")
  }
  
  cat("✓ Win predictions generated - Range: [", round(min(win_probs, na.rm = TRUE), 4), ", ", 
      round(max(win_probs, na.rm = TRUE), 4), "]\n")
      
}, error = function(e) {
  stop("Error generating Win predictions: ", e$message)
})
```
**Purpose**: Generates probability predictions for 2026 alpine skiers using trained models. Includes comprehensive validation for prediction quality and range validation.

#### 8. Probability Normalization Framework
```r
# Function for simple proportional scaling to cap maximum probability
simple_scale <- function(probs, max_prob = 0.95) {
  # Handle edge cases
  if (length(probs) == 0) return(probs)
  if (all(is.na(probs))) return(probs)
  
  max_current <- max(probs, na.rm = TRUE)
  if (max_current <= max_prob) return(probs)
  
  # Scale all probabilities proportionally so max becomes max_prob
  scaling_factor <- max_prob / max_current
  return(probs * scaling_factor)
}

# Function for proportional scaling with simple maximum compression
proportional_scale <- function(probs, target_sum, max_prob = 0.95) {
  # Handle edge cases
  if (length(probs) == 0) return(probs)
  if (sum(probs, na.rm = TRUE) == 0) return(probs)
  
  # First apply proportional scaling to achieve target sum
  scaled_probs <- (probs / sum(probs, na.rm = TRUE)) * target_sum
  
  # Then apply simple scaling to cap maximum at max_prob
  final_probs <- simple_scale(scaled_probs, max_prob)
  
  return(final_probs)
}

# Normalize probabilities with proportional scaling and simple maximum compression
# Win probabilities should sum to 100% (1.0), max individual 95%
win_probs_normalized <- proportional_scale(win_probs, 1.0, 0.95)

# Top3 probabilities should sum to 300% (3.0), max individual 95%
top3_probs_normalized <- proportional_scale(top3_probs, 3.0, 0.95)

# Top5 probabilities should sum to 500% (5.0), max individual 95%  
top5_probs_normalized <- proportional_scale(top5_probs, 5.0, 0.95)

# Top10 probabilities should sum to 1000% (10.0), max individual 95%
top10_probs_normalized <- proportional_scale(top10_probs, 10.0, 0.95)

# Top30 probabilities should sum to 3000% (30.0), max individual 95%
top30_probs_normalized <- proportional_scale(top30_probs, 30.0, 0.95)
```
**Purpose**: Implements sophisticated probability normalization that ensures:
- **Realistic probability bounds**: Maximum individual probability capped at 95%
- **Market consistency**: Total probabilities sum to theoretically correct values
- **Proportional scaling**: Maintains relative probability relationships
- **Edge case handling**: Robust handling of empty or invalid probability sets

#### 9. Odds Calculation and Formatting
```r
# Calculate decimal and American odds with validation
results <- results %>%
  mutate(
    Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
    Win_American_Odds = ifelse(Win_Prob >= 0.5,
                              -Win_Prob/(1-Win_Prob) * 100,
                              (1-Win_Prob)/Win_Prob * 100),
    Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
    Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                               -Top3_Prob/(1-Top3_Prob) * 100,
                               (1-Top3_Prob)/Top3_Prob * 100)
  ) %>%
  # Format probabilities and odds with validation
  mutate(
    Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
    Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
    
    # Round decimal odds with Inf handling
    Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                             ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
    
    # Format American odds with validation
    Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                              ifelse(Win_American_Odds > 0, 
                                    sprintf("+%.0f", round(Win_American_Odds, 0)),
                                    sprintf("%.0f", round(Win_American_Odds, 0))))
  )
```
**Purpose**: Converts normalized probabilities into standard betting odds formats:
- **Decimal odds**: European format (1/probability)
- **American odds**: US format (positive/negative based on probability threshold)
- **Robust formatting**: Handles infinite values and maintains consistent presentation
- **Percentage display**: User-friendly probability presentation

### Alpine-Specific Statistical Considerations

#### Multi-Outcome Probability Framework
Alpine skiing odds framework handles multiple performance thresholds simultaneously:
- **Win**: Season championship (100% total probability)
- **TopThree**: Podium consistency (300% total probability)
- **Top5/Top10/Top30**: Progressive performance tiers (500%/1000%/3000% total probability)

#### Normalization Strategy
The normalization approach balances statistical accuracy with betting market requirements:
- **Proportional scaling**: Maintains relative skill differences between athletes
- **Market viability**: Ensures probabilities sum to expected theoretical values
- **Risk management**: Caps maximum individual probability to prevent extreme outliers

#### Model Validation Integration
Statistical odds section includes comprehensive model validation:
- **Convergence monitoring**: Ensures reliable model parameter estimation
- **Coefficient validation**: Detects multicollinearity and estimation issues
- **Prediction range checking**: Validates probability bounds and distributions
- **Quality metrics**: Provides AIC, deviance, and pseudo R-squared for model assessment

### Error Handling and Quality Assurance

The section implements extensive error handling including:
- **Feature set validation** before model training
- **Formula construction verification** with type checking
- **Model convergence monitoring** for all logistic regression models
- **Prediction validation** including range and missing value checks
- **Normalization robustness** with edge case handling for empty or invalid probability sets
- **Odds calculation safety** with infinite value handling and formatting validation

This comprehensive approach ensures that alpine skiing odds are statistically sound, market-ready, and properly validated throughout the entire prediction pipeline.

## Section: {r ladies-odds} - Ladies Alpine Odds Generation

### Purpose
This section generates comprehensive odds for ladies alpine skiing using gender-specific models and features, following the same statistical framework as men's odds but with ladies-specific feature optimization and model training.

### Ladies Alpine Odds Framework

#### 1. Ladies Formula Validation and Prerequisites
```r
cat("=== LADIES ODDS VALIDATION ===\n")

# Validate ladies-specific formulas exist
if (\!exists("win_formula_ladies") || \!inherits(win_formula_ladies, "formula")) {
  stop("win_formula_ladies not found or invalid")
}
if (\!exists("topthree_formula_ladies") || \!inherits(topthree_formula_ladies, "formula")) {
  stop("topthree_formula_ladies not found or invalid")
}
if (\!exists("top5_formula_ladies") || \!inherits(top5_formula_ladies, "formula")) {
  stop("top5_formula_ladies not found or invalid")
}
if (\!exists("top10_formula_ladies") || \!inherits(top10_formula_ladies, "formula")) {
  stop("top10_formula_ladies not found or invalid")
}
if (\!exists("top30_formula_ladies") || \!inherits(top30_formula_ladies, "formula")) {
  stop("top30_formula_ladies not found or invalid")
}
cat("✓ All ladies formulas validated\n")
```
**Purpose**: Validates that ladies-specific logistic regression formulas were created successfully from the exhaustive feature selection process. These formulas use optimal feature combinations specifically identified for ladies alpine competition patterns.

#### 2. Ladies Training Data Quality Assessment
```r
# Validate ladies training data
cat("\n--- Ladies Model Training Data Validation ---\n")
if (\!exists("df_place_ladies") || \!is.data.frame(df_place_ladies)) {
  stop("df_place_ladies dataset not found or invalid")
}
if (nrow(df_place_ladies) == 0) {
  stop("df_place_ladies dataset is empty")
}

# Validate ladies target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place_ladies[[target]], useNA = "always")
  cat("Ladies", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for ladies ", target, " - model may be unstable")
  }
}

cat("Ladies training data:", nrow(df_place_ladies), "observations\n")
```
**Purpose**: Assesses ladies-specific training data quality and target variable distributions. Identifies potential modeling challenges such as class imbalance that could affect ladies model reliability. Important for detecting gender-specific patterns in alpine skiing performance.

#### 3. Ladies Model Training with Gender-Specific Features
```r
# Fit ladies models with validation
cat("\n--- Ladies Model Training ---\n")
tryCatch({
  win_model_ladies <- glm(win_formula_ladies, family = binomial, data = df_place_ladies)
  
  # Validate model convergence
  if (\!win_model_ladies$converged) {
    warning("Ladies Win model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(win_model_ladies)))) {
    warning("Ladies Win model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Ladies Win model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Win model: ", e$message)
})
```
**Purpose**: Trains ladies-specific logistic regression models using optimal feature sets identified through exhaustive search. Each model uses features specifically optimized for ladies alpine competition, potentially differing from men's models due to gender-specific performance patterns.

#### 4. Ladies Prediction Data Validation
```r
# Validate ladies prediction data
cat("\n--- Ladies Prediction Data Validation ---\n")
if (\!exists("pred_data_ladies") || \!is.data.frame(pred_data_ladies)) {
  stop("pred_data_ladies dataset not found or invalid")
}
if (nrow(pred_data_ladies) == 0) {
  stop("pred_data_ladies dataset is empty")
}

# Check for required features in ladies prediction data
all_required_features <- unique(c(topthree_features_ladies, top5_features_ladies, top10_features_ladies, top30_features_ladies))
missing_pred_features <- setdiff(all_required_features, names(pred_data_ladies))
if (length(missing_pred_features) > 0) {
  warning("Missing features in ladies prediction data: ", paste(missing_pred_features, collapse = ", "))
}

cat("Ladies prediction dataset has", nrow(pred_data_ladies), "observations and", ncol(pred_data_ladies), "variables\n")
```
**Purpose**: Validates that ladies prediction data contains all features required by the optimized models. Ensures data quality and completeness for reliable 2026 ladies alpine predictions.

#### 5. Ladies 2026 Probability Predictions
```r
# Get predicted probabilities for ladies with validation
cat("\n--- Ladies Model Predictions ---\n")
tryCatch({
  win_probs_ladies <- predict(win_model_ladies, pred_data_ladies, type = "response")
  
  # Validate predictions
  if (any(is.na(win_probs_ladies))) {
    warning("NA predictions detected for ladies Win - ", sum(is.na(win_probs_ladies)), " out of ", length(win_probs_ladies))
  }
  if (any(win_probs_ladies < 0  < /dev/null |  win_probs_ladies > 1, na.rm = TRUE)) {
    warning("Invalid probability values for ladies Win (outside 0-1 range)")
  }
  
  cat("✓ Ladies Win predictions generated - Range: [", round(min(win_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(win_probs_ladies, na.rm = TRUE), 4), "]\n")
      
}, error = function(e) {
  stop("Error generating ladies Win predictions: ", e$message)
})
```
**Purpose**: Generates 2026 probability predictions for all ladies alpine skiers using trained gender-specific models. Includes comprehensive validation for prediction quality, range checking, and missing value detection.

#### 6. Ladies Probability Normalization
```r
# ========== NORMALIZATION FOR LADIES ODDS ==========
cat("\n--- Normalizing Ladies Probabilities ---\n")

# Use the same proportional scaling function as men's odds
# (Function already defined above in men's section)

# Normalize ladies probabilities with proportional scaling and simple maximum compression
# Win probabilities should sum to 100% (1.0), max individual 95%
win_probs_normalized_ladies <- proportional_scale(win_probs_ladies, 1.0, 0.95)

# Top3 probabilities should sum to 300% (3.0), max individual 95%
top3_probs_normalized_ladies <- proportional_scale(top3_probs_ladies, 3.0, 0.95)

# Top5 probabilities should sum to 500% (5.0), max individual 95%
top5_probs_normalized_ladies <- proportional_scale(top5_probs_ladies, 5.0, 0.95)

# Top10 probabilities should sum to 1000% (10.0), max individual 95%
top10_probs_normalized_ladies <- proportional_scale(top10_probs_ladies, 10.0, 0.95)

# Top30 probabilities should sum to 3000% (30.0), max individual 95%
top30_probs_normalized_ladies <- proportional_scale(top30_probs_ladies, 30.0, 0.95)

cat("Ladies Normalization applied:\n")
cat("Win probs sum:", round(sum(win_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 1.0)\n")
cat("Top3 probs sum:", round(sum(top3_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 3.0)\n")
cat("Top5 probs sum:", round(sum(top5_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 5.0)\n")
cat("Top10 probs sum:", round(sum(top10_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 10.0)\n")
cat("Top30 probs sum:", round(sum(top30_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 30.0)\n")
```
**Purpose**: Applies the same sophisticated normalization framework used for men's odds to ladies predictions. Ensures:
- **Market consistency**: Total probabilities sum to theoretically correct values
- **Risk management**: Maximum individual probability capped at 95%
- **Proportional scaling**: Maintains relative skill differences between ladies athletes
- **Gender-specific calibration**: Accounts for potential differences in competitive depth between men's and ladies fields

#### 7. Ladies Results DataFrame Creation
```r
# Create ladies results dataframe with validation
tryCatch({
  # Create ladies results dataframe with all probabilities (USING NORMALIZED VALUES)
  results_ladies <- data.frame(
    Skier = pred_data_ladies$Skier,
    Nation = pred_data_ladies$Nation,
    Top3_Prob = top3_probs_normalized_ladies,    # Normalized Top3 probability
    Win_Prob = win_probs_normalized_ladies,      # Normalized win probability
    Second_Prob = second_probs_normalized_ladies, # Normalized second probability
    Third_Prob = third_probs_normalized_ladies,  # Normalized third probability
    Top5_Prob = top5_probs_normalized_ladies,    # Normalized Top5 probability
    Top10_Prob = top10_probs_normalized_ladies,  # Normalized Top10 probability
    Top30_Prob = top30_probs_normalized_ladies,  # Normalized Top30 probability
    Outside_Prob = 1 - (top30_probs_normalized_ladies / 30.0)  # Adjusted for normalization
  )
  
  # Validate ladies results dataframe
  if (nrow(results_ladies) == 0) stop("Ladies results dataframe is empty")
  if (any(is.na(results_ladies$Skier))) warning("Missing skier names in ladies results")
  
  # Check probability consistency for ladies
  invalid_prob_consistency <- sum(results_ladies$Top3_Prob > results_ladies$Top5_Prob | 
                                  results_ladies$Top5_Prob > results_ladies$Top10_Prob | 
                                  results_ladies$Top10_Prob > results_ladies$Top30_Prob, na.rm = TRUE)
  
  if (invalid_prob_consistency > 0) {
    warning("Probability inconsistency detected in ", invalid_prob_consistency, " ladies cases (P(smaller) > P(larger))")
  }
  
  cat("✓ Ladies results dataframe created with", nrow(results_ladies), "skiers\n")
  
}, error = function(e) {
  stop("Error creating ladies results dataframe: ", e$message)
})
```
**Purpose**: Creates comprehensive ladies results dataframe with all normalized probabilities and validates logical consistency. Ensures probability relationships make sense (e.g., TopThree probability ≤ Top5 probability) for ladies-specific predictions.

#### 8. Ladies Odds Calculation and Formatting
```r
# Calculate ladies decimal and American odds with validation
tryCatch({
  results_ladies <- results_ladies %>%
    mutate(
      Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
      Win_American_Odds = ifelse(Win_Prob >= 0.5,
                                -Win_Prob/(1-Win_Prob) * 100,
                                (1-Win_Prob)/Win_Prob * 100),
      Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
      Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                                 -Top3_Prob/(1-Top3_Prob) * 100,
                                 (1-Top3_Prob)/Top3_Prob * 100)
    ) %>%
    # Format ladies probabilities and odds with validation
    mutate(
      Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
      Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
      
      # Round ladies decimal odds with Inf handling
      Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                               ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
      
      # Format ladies American odds with validation
      Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                                ifelse(Win_American_Odds > 0, 
                                      sprintf("+%.0f", round(Win_American_Odds, 0)),
                                      sprintf("%.0f", round(Win_American_Odds, 0))))
    )
  
  cat("✓ Ladies odds calculation and formatting completed\n")
  
}, error = function(e) {
  stop("Error calculating ladies odds: ", e$message)
})
```
**Purpose**: Converts ladies normalized probabilities into standard betting odds formats with the same robust formatting applied to men's odds. Handles infinite values and maintains consistent presentation for ladies alpine predictions.

#### 9. Ladies Results Summary and Output
```r
cat("\n--- Ladies Final Results Summary ---\n")
cat("Total ladies with odds:", nrow(results_ladies), "\n")
cat("Ladies with valid Win probabilities:", sum(results_ladies$Win_Prob \!= "N/A"), "\n")
cat("Highest ladies win probability:", max(numeric_win_probs_ladies, na.rm = TRUE), "%\n")

print("=== 2026 LADIES ALPINE SEASON ODDS ===")
print("Top 10 Ladies Season Winner Odds:")
print(results_ladies %>% 
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      head(10))

print("Top 10 Ladies Podium Finish Odds:")
print(results_ladies %>% 
      arrange(desc(as.numeric(sub("%", "", Top3_Prob)))) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      head(10))
```
**Purpose**: Provides comprehensive summary of ladies alpine odds generation results and displays top performers across different outcome categories. Essential for verifying ladies-specific model performance and identifying key contenders.

#### 10. Ladies Excel Export with Gender-Specific Formatting
```r
# Export Ladies Odds to Excel
cat("\n=== EXPORTING LADIES ALPINE ODDS TO EXCEL ===\n")
tryCatch({
  if (\!is.null(results_ladies) && nrow(results_ladies) > 0) {
    # Prepare data with numeric probabilities for proper sorting
    ladies_odds_export <- results_ladies %>%
      mutate(
        # Convert probability percentages to numeric for proper handling
        Win_Prob_Numeric = as.numeric(gsub("%", "", Win_Prob)),
        Top3_Prob_Numeric = as.numeric(gsub("%", "", Top3_Prob)),
        Top10_Prob_Numeric = as.numeric(gsub("%", "", Top10_Prob)),
        Top30_Prob_Numeric = as.numeric(gsub("%", "", Top30_Prob))
      ) %>%
      arrange(desc(Win_Prob_Numeric))
    
    # Create separate Excel files for each outcome type
    # Ladies Win odds file
    win_data <- ladies_odds_export %>%
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(
        "Win Prob" = Win_Prob,
        "Win Decimal Odds" = Win_Decimal_Odds,
        "Win American Odds" = Win_American_Odds
      )
    
    win_wb <- createWorkbook()
    addWorksheet(win_wb, "Ladies Alpine Win Odds 2026")
    writeData(win_wb, "Ladies Alpine Win Odds 2026", win_data, startRow = 1, startCol = 1)
    addStyle(win_wb, "Ladies Alpine Win Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(win_data))
    setColWidths(win_wb, "Ladies Alpine Win Odds 2026", cols = 1:ncol(win_data), widths = "auto")
    saveWorkbook(win_wb, "excel365/Ladies_Win_Odds_2026.xlsx", overwrite = TRUE)
    
    cat("✓ Ladies alpine odds Excel files saved:\n")
    cat("  - excel365/Ladies_Win_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top3_Odds_2026.xlsx\n") 
    cat("  - excel365/Ladies_Top10_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top30_Odds_2026.xlsx\n")
    
  } else {
    cat("No ladies alpine odds data available for export\n")
  }
  
}, error = function(e) {
  cat("Error exporting ladies alpine odds to Excel:", e$message, "\n")
})
```
**Purpose**: Exports ladies alpine odds to separate Excel files with professional formatting. Creates gender-specific output files for easy comparison with men's odds and streamlined analysis of ladies competition predictions.

### Gender-Specific Alpine Considerations

#### Feature Optimization Differences
Ladies alpine models may use different optimal feature combinations than men's models due to:
- **Competitive depth variations**: Differences in field size and skill distribution
- **Discipline emphasis patterns**: Potential gender-specific strengths in technical vs. speed disciplines  
- **Performance trajectory differences**: Age-related performance patterns that may vary by gender

#### Model Validation Approach
Ladies models receive the same rigorous validation as men's models:
- **Convergence monitoring**: Ensures reliable parameter estimation for ladies-specific patterns
- **Class balance assessment**: Identifies potential issues with limited ladies competition data
- **Prediction range validation**: Validates probability bounds for ladies alpine predictions

#### Normalization Consistency
Ladies probabilities use identical normalization framework to men's odds ensuring:
- **Cross-gender comparability**: Consistent probability interpretation across genders
- **Market integration**: Ladies odds can be combined with men's odds for mixed betting markets
- **Risk management consistency**: Same maximum probability caps prevent extreme outliers

### Error Handling and Quality Assurance

The ladies odds section implements comprehensive error handling including:
- **Gender-specific formula validation** ensuring ladies models exist and are properly specified
- **Ladies training data validation** with class distribution assessment
- **Model convergence monitoring** for all ladies logistic regression models  
- **Prediction quality validation** including range and missing value checks
- **Results consistency verification** ensuring logical probability relationships
- **Export validation** with robust Excel file creation and error handling

This comprehensive approach ensures that ladies alpine skiing odds are statistically sound, properly normalized, and maintain the same quality standards as men's odds while accounting for gender-specific competitive patterns.

## Section: {r breakout-identifier} - Alpine Breakthrough Analysis

### Purpose
This section identifies historical breakthrough performers in alpine skiing and analyzes the patterns that characterize skiers who achieve significant performance improvements, establishing a foundation for predicting future breakthrough candidates.

### Alpine Breakthrough Analysis Framework

#### 1. Training Data Validation and Prerequisites
```r
cat("=== BREAKTHROUGH ANALYSIS VALIDATION ===\n")

# Validate training data availability
if (\!exists("train_men") || \!is.data.frame(train_men)) {
  stop("train_men dataset not found or invalid")
}
if (\!exists("train_ladies") || \!is.data.frame(train_ladies)) {
  stop("train_ladies dataset not found or invalid")
}

if (nrow(train_men) == 0) stop("train_men dataset is empty")
if (nrow(train_ladies) == 0) stop("train_ladies dataset is empty")

cat("Training data validated - Men:", nrow(train_men), "observations, Ladies:", nrow(train_ladies), "observations\n")
```
**Purpose**: Validates that comprehensive training datasets are available for breakthrough analysis. These datasets contain historical performance data necessary for identifying breakthrough patterns in alpine skiing.

#### 2. Required Column Validation for Breakthrough Analysis
```r
# Validate required columns for breakthrough analysis
required_breakthrough_cols <- c("Skier", "Nation", "Season", "Pct_of_Max_Points", "Age")
missing_men_cols <- setdiff(required_breakthrough_cols, names(train_men))
missing_ladies_cols <- setdiff(required_breakthrough_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop("Missing required columns in train_men: ", paste(missing_men_cols, collapse = ", "))
}
if (length(missing_ladies_cols) > 0) {
  stop("Missing required columns in train_ladies: ", paste(missing_ladies_cols, collapse = ", "))
}
cat("✓ All required columns present in both datasets\n")
```
**Purpose**: Ensures all essential columns are available for breakthrough analysis:
- **Skier**: Athlete identification for tracking individual performance trajectories
- **Nation**: Country representation for potential geographic/development pattern analysis
- **Season**: Temporal context for breakthrough timing analysis
- **Pct_of_Max_Points**: Key performance metric for defining breakthrough thresholds
- **Age**: Critical factor for understanding breakthrough timing in athlete development

#### 3. Performance Data Quality Assessment
```r
# Validate Pct_of_Max_Points data quality
cat("\n--- Data Quality Validation ---\n")

# Men's data validation
men_invalid_pct <- sum(is.na(train_men$Pct_of_Max_Points)  < /dev/null |  
                      train_men$Pct_of_Max_Points < 0 | 
                      train_men$Pct_of_Max_Points > 1 | 
                      \!is.finite(train_men$Pct_of_Max_Points))

ladies_invalid_pct <- sum(is.na(train_ladies$Pct_of_Max_Points) | 
                         train_ladies$Pct_of_Max_Points < 0 | 
                         train_ladies$Pct_of_Max_Points > 1 | 
                         \!is.finite(train_ladies$Pct_of_Max_Points))

cat("Men's invalid Pct_of_Max_Points values:", men_invalid_pct, "\n")
cat("Ladies invalid Pct_of_Max_Points values:", ladies_invalid_pct, "\n")

if (men_invalid_pct > nrow(train_men) * 0.1) {
  warning("More than 10% of men's Pct_of_Max_Points values are invalid")
}
if (ladies_invalid_pct > nrow(train_ladies) * 0.1) {
  warning("More than 10% of ladies Pct_of_Max_Points values are invalid")
}
```
**Purpose**: Validates the quality of the key performance metric used for breakthrough identification. The `Pct_of_Max_Points` should be bounded between 0 and 1, representing the percentage of maximum possible alpine World Cup points achieved in a season.

#### 4. Historical Top Performers Identification
```r
# Identify historical top performers with validation
cat("\n--- Historical Top Performers Analysis ---\n")

tryCatch({
  top_performers_men <- train_men %>%
    filter(\!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.2,
           \!is.na(Skier),
           \!is.na(Season),
           \!is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_men) == 0) {
    warning("No men's breakthrough performers found with >20% points")
  } else {
    cat("✓ Men's breakthrough performers identified:", nrow(top_performers_men), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying men's top performers: ", e$message)
})
```
**Purpose**: Identifies historical breakthrough performers using a 20% threshold of maximum alpine points. This threshold represents significant alpine performance that indicates genuine breakthrough rather than minor improvements. The analysis:
- **Filters for substantial performance**: 20% of max points represents meaningful alpine World Cup success
- **Removes incomplete data**: Ensures all essential fields are available for analysis
- **Creates baseline for comparison**: Establishes what constitutes breakthrough performance in alpine skiing

#### 5. Breakthrough Performance Summary and Analysis
```r
# Summary statistics with validation
tryCatch({
  unique_men_breakthroughs <- length(unique(top_performers_men$Skier))
  unique_ladies_breakthroughs <- length(unique(top_performers_ladies$Skier))
  
  cat("✓ Analysis completed successfully\n")
  cat("Men's breakthrough entries:", nrow(top_performers_men), "\n")
  cat("Ladies breakthrough entries:", nrow(top_performers_ladies), "\n")
  
  print("=== MEN'S HISTORICAL BREAKTHROUGH PERFORMERS (>20% of max points) ===")
  print(paste("Unique men's breakthrough skiers:", unique_men_breakthroughs))
  
  if (nrow(top_performers_men) > 0) {
    print("Recent men's breakthrough examples:")
    recent_men <- top_performers_men %>%
      arrange(desc(Season), desc(Pct_of_Max_Points))
    print(recent_men)
    
    # Age distribution analysis
    if (\!all(is.na(top_performers_men$Age))) {
      cat("Men's breakthrough age range:", 
          round(min(top_performers_men$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_men$Age, na.rm = TRUE), 1), "\n")
      cat("Men's mean breakthrough age:", 
          round(mean(top_performers_men$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No men's breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in men's breakthrough summary: ", e$message)
})
```
**Purpose**: Provides comprehensive summary of historical breakthrough performances including:
- **Unique athlete count**: Number of different skiers achieving breakthrough performance
- **Recent examples**: Most recent breakthrough cases for pattern analysis
- **Age distribution analysis**: Understanding the typical age range for alpine breakthrough
- **Performance levels**: Distribution of breakthrough achievement levels

### Alpine-Specific Breakthrough Considerations

#### Performance Threshold Framework
Alpine skiing breakthrough analysis uses sport-specific thresholds:
- **Primary threshold (20%)**: Represents significant World Cup success and points-scoring consistency
- **Secondary threshold (10%)**: Fallback for analysis when breakthrough cases are limited
- **Age-inclusive approach**: No upper age limits as alpine skiing allows for later-career breakthroughs

#### Multi-Discipline Impact
Alpine skiing's diverse disciplines mean breakthrough can occur through:
- **Technical discipline focus**: Excellence in Slalom and Giant Slalom
- **Speed discipline success**: Breakthrough in Downhill and Super G events
- **Combined approach**: Balanced performance across all alpine disciplines
- **Seasonal consistency**: Regular points-scoring across the alpine calendar

#### Development Pattern Recognition
Breakthrough analysis in alpine skiing considers:
- **National development systems**: Different countries have varying alpine development approaches
- **Equipment and technique evolution**: Technological changes can enable breakthrough performance
- **Competition depth changes**: Evolving competitive landscape affects breakthrough difficulty
- **Career trajectory diversity**: Alpine careers can have multiple breakthrough phases

### Data Quality and Validation

The breakthrough identification process includes comprehensive validation:
- **Performance metric bounds checking**: Ensures Pct_of_Max_Points values are realistic
- **Completeness requirements**: All essential fields must be present for inclusion
- **Temporal consistency**: Season and age data must be logical and consistent
- **Missing data tolerance**: Handles cases where some data points may be unavailable
- **Threshold adaptation**: Adjusts breakthrough criteria based on data availability

### Statistical Robustness

The analysis implements robust statistical practices:
- **Error handling**: Comprehensive error catching for data quality issues
- **Warning systems**: Alerts for potential data quality problems
- **Validation checkpoints**: Multiple verification steps throughout the analysis
- **Graceful degradation**: Continues analysis even when some components fail
- **Result validation**: Ensures breakthrough identification produces meaningful results

This alpine breakthrough identification section establishes the foundation for understanding what constitutes significant performance improvement in alpine skiing and provides the historical context necessary for predicting future breakthrough candidates.

## Section: {r feat-select-break} - Alpine Breakthrough Feature Selection

### Purpose
This section implements comprehensive feature selection for alpine breakthrough prediction using machine learning techniques to identify the most predictive variables for determining which skiers are likely to achieve breakthrough performance (>20% of maximum alpine points).

### Alpine Breakthrough Feature Selection Framework

#### 1. Required Libraries and Dependencies
```r
# Load required libraries for breakthrough analysis
tryCatch({
  library(caret)
  library(ranger)
  library(pROC)
  cat("✓ Required libraries loaded successfully\n")
}, error = function(e) {
  stop("Error loading required libraries: ", e$message)
})
```
**Purpose**: Loads essential machine learning libraries for breakthrough analysis:
- **caret**: Comprehensive framework for model training and validation
- **ranger**: High-performance Random Forest implementation
- **pROC**: ROC curve analysis for model evaluation

#### 2. Enhanced Breakthrough Predictor Evaluation Function
```r
# Enhanced function to evaluate predictor importance for breakthrough prediction
evaluate_breakthrough_predictors <- function(df, predictors) {
  cat("\n--- Breakthrough Predictor Evaluation ---\n")
  
  # Input validation
  if (\!is.data.frame(df)) stop("Input df is not a data frame")
  if (nrow(df) == 0) stop("Input dataframe is empty")
  if (is.null(predictors) || length(predictors) == 0) stop("No predictors provided")
  
  # Validate predictors exist in dataframe
  missing_predictors <- setdiff(predictors, names(df))
  if (length(missing_predictors) > 0) {
    warning("Missing predictors: ", paste(missing_predictors, collapse = ", "))
    predictors <- intersect(predictors, names(df))
  }
  
  if (length(predictors) == 0) stop("No valid predictors remain after filtering")
  cat("Using", length(predictors), "predictors for breakthrough analysis\n")
```
**Purpose**: Creates a comprehensive function for evaluating which features best predict alpine breakthrough performance. Includes robust input validation to ensure data quality and predictor availability.

#### 3. Adaptive Breakthrough Definition and Data Preparation
```r
# Prepare data with validation and adaptive age filtering
tryCatch({
  # First, try broader age range to get sufficient breakthrough cases
  initial_data <- df %>%
    mutate(
      # Define breakthrough as achieving >20% in this season
      Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.2),
      Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                               labels = c("No", "Yes")),
      Age = as.numeric(Age)
    ) %>%
    filter(\!is.na(Will_Breakthrough),
           \!is.na(Pct_of_Max_Points),
           \!is.na(Age)) %>%
    dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
    na.omit()
  
  # Check breakthrough distribution across age ranges
  breakthrough_by_age <- initial_data %>%
    filter(Will_Breakthrough == "Yes") %>%
    summarise(
      n_breakthroughs = n(),
      min_age = min(Age, na.rm = TRUE),
      max_age = max(Age, na.rm = TRUE),
      mean_age = mean(Age, na.rm = TRUE)
    )
  
  cat("Initial breakthrough cases found:", breakthrough_by_age$n_breakthroughs, "\n")
  if (breakthrough_by_age$n_breakthroughs > 0) {
    cat("Breakthrough age range:", round(breakthrough_by_age$min_age, 1), "-", round(breakthrough_by_age$max_age, 1), "\n")
  }
  
  # If still too few cases, try lower breakthrough threshold
  if (breakthrough_by_age$n_breakthroughs < 5) {
    cat("Very few breakthrough cases at 20% threshold, trying 10% threshold\n")
    initial_data <- df %>%
      mutate(
        # Lower threshold for breakthrough (10%)
        Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.1),
        Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                 labels = c("No", "Yes")),
        Age = as.numeric(Age)
      ) %>%
      filter(\!is.na(Will_Breakthrough),
             \!is.na(Pct_of_Max_Points),
             \!is.na(Age)) %>%
      dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
      na.omit()
  }
```
**Purpose**: Implements adaptive breakthrough definition with intelligent threshold adjustment:
- **Primary threshold (20%)**: Represents significant alpine breakthrough performance
- **Fallback threshold (10%)**: Used when insufficient cases exist at higher threshold
- **Age-inclusive approach**: Uses all ages for alpine breakthrough model training
- **Data quality filtering**: Removes incomplete cases for reliable model training

#### 4. Class Distribution Analysis and Validation
```r
# Validate class distribution
breakthrough_dist <- table(model_data$Will_Breakthrough, useNA = "always")
print("Breakthrough distribution:")
print(breakthrough_dist)

# Check for class imbalance with adaptive thresholds
min_class_size <- min(breakthrough_dist[breakthrough_dist > 0])  # Exclude NA count
breakthrough_count <- breakthrough_dist[["Yes"]]
no_breakthrough_count <- breakthrough_dist[["No"]]

cat("Breakthrough cases (Yes):", breakthrough_count, "\n")
cat("Non-breakthrough cases (No):", no_breakthrough_count, "\n")

# Adaptive validation based on data availability
if (min_class_size < 2) {
  stop("Insufficient data for model training - need at least 2 cases per class")
} else if (min_class_size < 5) {
  warning("Very few cases in minority class (", min_class_size, ") - model may be unstable")
} else if (breakthrough_count < 10) {
  warning("Few breakthrough cases (", breakthrough_count, ") - consider this when interpreting results")
}

# Calculate class imbalance ratio
imbalance_ratio <- max(breakthrough_count, no_breakthrough_count) / min(breakthrough_count, no_breakthrough_count)
if (imbalance_ratio > 20) {
  warning("Severe class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
} else if (imbalance_ratio > 10) {
  warning("Moderate class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
}
```
**Purpose**: Analyzes class distribution and identifies potential modeling challenges:
- **Minimum case requirements**: Ensures sufficient data for reliable model training
- **Class imbalance detection**: Identifies when breakthrough cases are very rare
- **Model stability assessment**: Warns when limited data may affect model reliability
- **Adaptive validation**: Adjusts validation criteria based on data availability

#### 5. Cross-Validation Setup with Adaptive Parameters
```r
# Cross-validation setup with adaptive parameters
tryCatch({
  # Adaptive CV parameters based on data size
  if (nrow(model_data) < 50) {
    cv_method <- "LOOCV"  # Leave-one-out for very small datasets
    cv_number <- NULL
  } else if (nrow(model_data) < 200) {
    cv_method <- "cv"
    cv_number <- 5  # 5-fold for small datasets
  } else {
    cv_method <- "cv"
    cv_number <- 10  # 10-fold for larger datasets
  }
  
  if (cv_method == "LOOCV") {
    ctrl <- trainControl(method = "LOOCV", classProbs = TRUE, summaryFunction = twoClassSummary)
    cat("Using Leave-One-Out Cross-Validation\n")
  } else {
    ctrl <- trainControl(method = cv_method, number = cv_number, classProbs = TRUE, summaryFunction = twoClassSummary)
    cat("Using", cv_number, "-fold Cross-Validation\n")
  }
  
}, error = function(e) {
  stop("Error setting up cross-validation: ", e$message)
})
```
**Purpose**: Implements adaptive cross-validation strategy based on dataset size:
- **Leave-One-Out CV**: For very small datasets (<50 observations)
- **5-fold CV**: For small datasets (50-200 observations)
- **10-fold CV**: For larger datasets (>200 observations)
- **ROC optimization**: Uses ROC as the optimization metric for breakthrough prediction

#### 6. Logistic Regression Model Training
```r
# Train logistic model with validation
tryCatch({
  breakthrough_formula <- as.formula(paste("Will_Breakthrough ~", paste(predictors, collapse = " + ")))
  cat("Training logistic regression model with", length(predictors), "predictors\n")
  
  logistic_model <- train(
    breakthrough_formula,
    data = model_data,
    method = "glm",
    family = "binomial",
    trControl = ctrl,
    metric = "ROC"
  )
  
  cat("✓ Logistic regression model trained\n")
  
  # Extract coefficient importance
  logistic_coefs <- summary(logistic_model$finalModel)$coefficients
  logistic_importance <- abs(logistic_coefs[-1, "Estimate"])  # Exclude intercept
  names(logistic_importance) <- rownames(logistic_coefs)[-1]
  
}, error = function(e) {
  stop("Error training logistic regression: ", e$message)
})
```
**Purpose**: Trains logistic regression model for breakthrough prediction:
- **Binary classification**: Predicts breakthrough vs. non-breakthrough outcomes
- **Coefficient importance**: Uses absolute coefficient values to rank feature importance
- **Cross-validation**: Uses established CV framework for robust evaluation
- **Error handling**: Robust error catching for model training issues

#### 7. Random Forest Model Training with Importance
```r
# Train Random Forest with validation
tryCatch({
  cat("Training Random Forest model for variable importance\n")
  
  rf_model <- train(
    breakthrough_formula,
    data = model_data,
    method = "ranger",
    trControl = ctrl,
    importance = 'impurity',
    metric = "ROC"
  )
  
  cat("✓ Random Forest model trained\n")
  
  # Extract variable importance
  rf_importance <- rf_model$finalModel$variable.importance
  
}, error = function(e) {
  warning("Error training Random Forest - using logistic regression only: ", e$message)
  rf_model <- NULL
  rf_importance <- NULL
})
```
**Purpose**: Trains Random Forest model to complement logistic regression:
- **Ensemble approach**: Captures non-linear relationships and interactions
- **Variable importance**: Uses impurity-based importance measures
- **Robust fallback**: Continues analysis even if Random Forest fails
- **Complementary insights**: Provides different perspective on feature importance

#### 8. Combined Importance Score Calculation
```r
# Combine and rank importance scores with validation
tryCatch({
  if (\!is.null(rf_importance)) {
    # Normalize importance scores to 0-1 scale
    logistic_norm <- (logistic_importance - min(logistic_importance)) / 
                    (max(logistic_importance) - min(logistic_importance))
    rf_norm <- (rf_importance - min(rf_importance)) / 
               (max(rf_importance) - min(rf_importance))
    
    # Combine scores (equal weighting)
    common_vars <- intersect(names(logistic_norm), names(rf_norm))
    combined_importance <- (logistic_norm[common_vars] + rf_norm[common_vars]) / 2
    
    # Create comprehensive importance dataframe
    importance_df <- data.frame(
      Variable = common_vars,
      Logistic_Importance = logistic_norm[common_vars],
      RF_Importance = rf_norm[common_vars],
      Combined_Importance = combined_importance,
      stringsAsFactors = FALSE
    ) %>%
      arrange(desc(Combined_Importance))
    
    cat("✓ Combined importance scores calculated\n")
    
  } else {
    # Use only logistic regression importance
    importance_df <- data.frame(
      Variable = names(logistic_importance),
      Logistic_Importance = logistic_importance,
      RF_Importance = NA,
      Combined_Importance = logistic_importance,
      stringsAsFactors = FALSE
    ) %>%
      arrange(desc(Combined_Importance))
    
    cat("✓ Logistic-only importance scores calculated\n")
  }
  
}, error = function(e) {
  stop("Error calculating variable importance: ", e$message)
})
```
**Purpose**: Creates comprehensive feature importance rankings:
- **Normalization**: Scales different importance metrics to comparable ranges
- **Equal weighting**: Combines logistic and Random Forest importance equally
- **Fallback strategy**: Uses single-method importance when one model fails
- **Ranked output**: Provides ordered list of most important breakthrough predictors

#### 9. Model Performance Comparison and Validation
```r
# Model performance comparison with validation
tryCatch({
  models_list <- list(Logistic = logistic_model)
  if (\!is.null(rf_model)) {
    models_list$RandomForest <- rf_model
  }
  
  model_comparison <- resamples(models_list)
  performance_summary <- summary(model_comparison)
  
  cat("✓ Model performance comparison completed\n")
  
}, error = function(e) {
  warning("Error in model comparison: ", e$message)
  model_comparison <- NULL
  performance_summary <- NULL
})
```
**Purpose**: Compares model performance across different algorithms:
- **Cross-validation metrics**: Uses CV results for fair comparison
- **Multiple algorithms**: Compares logistic regression and Random Forest when available
- **Performance summary**: Provides comprehensive evaluation metrics
- **Robust evaluation**: Handles cases where only one model is available

#### 10. Top Predictor Selection and Reduced Model Training
```r
# Select top predictors with validation
tryCatch({
  # Select top predictors (up to 5, or fewer if not enough predictors)
  n_top <- min(5, nrow(importance_df))
  top_predictors <- importance_df$Variable[1:n_top]
  
  cat("✓ Top", n_top, "predictors selected\n")
  
  # Train reduced model with only top predictors
  if (n_top >= 2) {  # Need at least 2 predictors for meaningful model
    reduced_formula <- as.formula(paste("Will_Breakthrough ~", paste(top_predictors, collapse = " + ")))
    
    reduced_model <- train(
      reduced_formula,
      data = model_data,
      method = "glm",
      family = "binomial",
      trControl = ctrl,
      metric = "ROC"
    )
    
    cat("✓ Reduced model with top predictors trained\n")
  } else {
    warning("Too few predictors for reduced model")
    reduced_model <- logistic_model
  }
  
}, error = function(e) {
  warning("Error creating reduced model: ", e$message)
  top_predictors <- predictors[1:min(3, length(predictors))]  # Fallback
  reduced_model <- logistic_model
})
```
**Purpose**: Creates optimized model using only the most important features:
- **Feature reduction**: Selects top 5 predictors to prevent overfitting
- **Minimum requirements**: Ensures at least 2 predictors for meaningful modeling
- **Comparative analysis**: Allows comparison between full and reduced models
- **Robust fallback**: Provides alternative when optimal selection fails

### Alpine-Specific Feature Selection Considerations

#### Multi-Discipline Feature Integration
Alpine breakthrough prediction considers features across all disciplines:
- **Overall ratings**: General alpine performance indicators
- **Technical discipline focus**: Slalom and Giant Slalom specific ratings
- **Speed discipline emphasis**: Downhill and Super G performance metrics
- **Combined performance**: Integrated multi-discipline capabilities
- **Age factor**: Critical for understanding alpine breakthrough timing

#### Breakthrough Threshold Adaptation
Alpine feature selection uses adaptive thresholds:
- **Primary (20%)**: Significant World Cup points achievement
- **Secondary (10%)**: Lower threshold when data is limited
- **Career-based assessment**: Considers entire career trajectory rather than single season
- **Competition depth awareness**: Accounts for varying competitive levels

#### Model Ensemble Strategy
The analysis employs multiple algorithms for robust feature selection:
- **Logistic regression**: Linear relationships and statistical significance
- **Random Forest**: Non-linear patterns and feature interactions
- **Combined scoring**: Leverages strengths of both approaches
- **Cross-validation**: Ensures reliable performance estimation

### Quality Assurance and Validation

The feature selection process includes comprehensive validation:
- **Data quality checks**: Validates predictor availability and completeness
- **Class distribution analysis**: Identifies and handles class imbalance issues
- **Adaptive validation**: Adjusts criteria based on data availability
- **Model stability assessment**: Warns about potential reliability issues
- **Performance monitoring**: Tracks model quality throughout the process
- **Error resilience**: Continues analysis even when components fail

This alpine breakthrough feature selection section provides a robust framework for identifying the most predictive variables for breakthrough performance while handling the challenges of limited breakthrough cases and ensuring statistical reliability.
EOF < /dev/null

## Section: {r big-break} - Alpine 2026 Breakthrough Predictions

### Purpose
This section generates comprehensive predictions for 2026 alpine breakthrough candidates using trained machine learning models, identifying skiers who have never achieved 20% of maximum alpine points but show potential for breakthrough performance in the upcoming season.

### Alpine 2026 Breakthrough Prediction Framework

#### 1. Enhanced Breakthrough Prediction Function
```r
# Enhanced function to predict 2026 breakthrough candidates
predict_2026_breakthroughs <- function(current_data, breakthrough_model, top_predictors) {
  cat("\n--- 2026 Breakthrough Prediction Function ---\n")
  
  # Input validation
  if (\!is.data.frame(current_data)) stop("current_data is not a data frame")
  if (nrow(current_data) == 0) stop("current_data is empty")
  if (is.null(breakthrough_model)) stop("breakthrough_model is NULL")
  if (is.null(top_predictors) || length(top_predictors) == 0) stop("No top_predictors provided")
  
  cat("Input validation passed\n")
  cat("Using", length(top_predictors), "top predictors for breakthrough prediction\n")
```
**Purpose**: Creates a comprehensive function for generating 2026 breakthrough predictions with robust input validation. Ensures all required components are available before proceeding with predictions.

#### 2. Predictor Mapping and Data Preparation
```r
# Define mapping from prev variables to current Elo variables with validation
predictor_mapping <- c(
  "Prev_Pelo" = "Pelo",
  "Prev_Downhill" = "Downhill_Pelo", 
  "Prev_Super_G" = "Super G_Pelo",
  "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
  "Prev_Slalom" = "Slalom_Pelo",
  "Prev_Combined" = "Combined_Pelo",
  "Prev_Tech" = "Tech_Pelo",
  "Prev_Speed" = "Speed_Pelo",
  "Age" = "Age"
)

# Validate required columns exist in current_data
required_cols <- c("Skier", "Nation", "Season", "Age", "Pct_of_Max_Points")
missing_cols <- setdiff(required_cols, names(current_data))
if (length(missing_cols) > 0) {
  stop("Missing required columns in current_data: ", paste(missing_cols, collapse = ", "))
}
```
**Purpose**: Establishes mapping between training data features (Prev_*) and current prediction data features, ensuring compatibility between model expectations and available data for 2026 predictions.

#### 3. Career History Analysis and Candidate Identification
```r
# Career history analysis with validation
cat("\n--- Career History Analysis ---\n")

# Get 2025 data for potential breakthrough candidates
tryCatch({
  # Focus on 2025 season as the most recent complete season
  season_2025_data <- current_data %>%
    filter(Season == 2025) %>%
    group_by(Skier) %>%
    arrange(desc(Season)) %>%
    slice(1) %>%  # Take most recent entry for each skier in 2025
    ungroup()
  
  if (nrow(season_2025_data) == 0) {
    stop("No 2025 season data found")
  }
  
  cat("✓ 2025 season data identified:", nrow(season_2025_data), "skiers\n")
  
}, error = function(e) {
  stop("Error accessing 2025 season data: ", e$message)
})
```
**Purpose**: Identifies potential breakthrough candidates by focusing on 2025 season performance as the baseline for 2026 predictions. Uses most recent complete season data for accurate candidate assessment.

#### 4. Breakthrough Candidate Filtering with Career Analysis
```r
# Identify breakthrough candidates with validation
tryCatch({
  # Define breakthrough candidates: those who haven't yet achieved 20% in their CAREER
  # First, calculate career maximum performance for each skier across ALL seasons
  career_max_performance <- current_data %>%
    filter(\!is.na(Pct_of_Max_Points)) %>%
    group_by(Skier) %>%
    summarise(
      Career_Max_Pct = max(Pct_of_Max_Points, na.rm = TRUE),
      .groups = 'drop'
    )
  
  # Then get the most recent season data and filter based on career maximum
  current_candidates <- season_2025_data %>%
    filter(
      \!is.na(Age),
      \!is.na(Pct_of_Max_Points),
      Pct_of_Max_Points > 0.01   # Must have some competitive results in recent season
    ) %>%
    group_by(Skier) %>%
    arrange(desc(Season)) %>%
    slice(1) %>%  # Take most recent season for each skier (should be 2025)
    ungroup() %>%
    # Join with career maximum performance
    left_join(career_max_performance, by = "Skier") %>%
    # Filter out those who have EVER achieved 20% or more in their career
    filter(
      \!is.na(Career_Max_Pct),
      Career_Max_Pct < 0.2  # Haven't achieved 20% breakthrough in their ENTIRE CAREER
    )
```
**Purpose**: Implements sophisticated candidate filtering that examines entire career trajectories rather than single seasons:
- **Career-based assessment**: Excludes skiers who have already achieved breakthrough at any point
- **Recent activity requirement**: Ensures candidates have meaningful 2025 performance
- **Comprehensive evaluation**: Uses all available historical data for accurate filtering

#### 5. Data Quality Assessment and Candidate Validation
```r
# Check for data quality issues in candidates
na_age_count <- sum(is.na(current_candidates$Age))
na_pct_count <- sum(is.na(current_candidates$Pct_of_Max_Points))

if (na_age_count > 0) {
  warning("Found ", na_age_count, " candidates with missing age data")
}
if (na_pct_count > 0) {
  warning("Found ", na_pct_count, " candidates with missing performance data")
}

cat("✓ Breakthrough candidates identified:", nrow(current_candidates), "\n")
```
**Purpose**: Validates data quality for identified breakthrough candidates and provides transparency about any data limitations that might affect prediction reliability.

#### 6. Top Candidates Analysis and Age Distribution
```r
# Top candidates analysis with validation
tryCatch({
  print("Top 2025 performers among breakthrough candidates:")
  top_candidates <- current_candidates %>% 
    filter(\!is.na(Pct_of_Max_Points)) %>%
    dplyr::select(Skier, Nation, Age, Pct_of_Max_Points) %>% 
    arrange(desc(Pct_of_Max_Points)) %>% 
    head(15)
  
  if (nrow(top_candidates) > 0) {
    print(top_candidates)
    cat("✓ Top candidates validated\n")
  } else {
    warning("No valid top candidates found")
  }
  
}, error = function(e) {
  warning("Error analyzing top candidates: ", e$message)
})

# Age distribution analysis with validation
tryCatch({
  age_summary <- current_candidates %>%
    filter(\!is.na(Age)) %>%
    summarise(
      min_age = min(Age),
      max_age = max(Age),
      mean_age = round(mean(Age), 1),
      median_age = median(Age),
      n_under_25 = sum(Age <= 25)
    )
  
  print("Breakthrough candidates age distribution:")
  print(age_summary)
  
  cat("Candidates under 25:", age_summary$n_under_25, "out of", nrow(current_candidates), "\n")
  
}, error = function(e) {
  warning("Error analyzing age distribution: ", e$message)
})
```
**Purpose**: Provides comprehensive analysis of breakthrough candidate pool including performance levels and age demographics, helping understand the characteristics of potential breakthrough athletes.

#### 7. Prediction Data Preparation and Feature Mapping
```r
# Prepare prediction data with validation
tryCatch({
  cat("\n--- Prediction Data Preparation ---\n")
  
  # Create prediction dataset by mapping current Elo variables to previous variables
  prediction_data <- current_candidates
  
  # Map current variables to "previous" variables for model prediction
  for (prev_var in names(predictor_mapping)) {
    current_var <- predictor_mapping[[prev_var]]
    
    if (current_var %in% names(prediction_data)) {
      prediction_data[[prev_var]] <- prediction_data[[current_var]]
    } else {
      warning("Current variable ", current_var, " not found in data")
      prediction_data[[prev_var]] <- NA
    }
  }
  
  # Validate prediction data quality
  prediction_cols_available <- intersect(top_predictors, names(prediction_data))
  missing_pred_cols <- setdiff(top_predictors, names(prediction_data))
  
  if (length(missing_pred_cols) > 0) {
    warning("Missing prediction columns: ", paste(missing_pred_cols, collapse = ", "))
  }
  
  cat("Available prediction columns:", length(prediction_cols_available), "out of", length(top_predictors), "\n")
  
}, error = function(e) {
  stop("Error preparing prediction data: ", e$message)
})
```
**Purpose**: Transforms current alpine performance data into the format expected by breakthrough prediction models, handling feature name mapping and validating data availability for reliable predictions.

#### 8. Breakthrough Probability Generation
```r
# Generate breakthrough predictions with validation
tryCatch({
  cat("\n--- Generating Breakthrough Predictions ---\n")
  
  # Validate predictors are available for model
  missing_predictors <- setdiff(top_predictors, names(prediction_data))
  if (length(missing_predictors) > 0) {
    warning("Missing predictors for model prediction: ", paste(missing_predictors, collapse = ", "))
  }
  
  # Make breakthrough predictions
  breakthrough_probs <- predict(breakthrough_model,
                               newdata = prediction_data,
                               type = "prob")
  
  # Validate prediction results
  if (is.null(breakthrough_probs)) {
    stop("Model prediction returned NULL")
  }
  if (nrow(breakthrough_probs) \!= nrow(prediction_data)) {
    stop("Prediction result row count mismatch")
  }
  if (\!"Yes" %in% names(breakthrough_probs)) {
    stop("Missing 'Yes' probability column in predictions")
  }
  if (any(is.na(breakthrough_probs$Yes))) {
    warning("NA values detected in breakthrough probabilities")
  }
  
  cat("✓ Breakthrough predictions generated for", nrow(breakthrough_probs), "candidates\n")
  
}, error = function(e) {
  stop("Error generating breakthrough predictions: ", e$message)
})
```
**Purpose**: Generates actual breakthrough probability predictions using trained models with comprehensive validation to ensure prediction quality and reliability.

#### 9. Prediction Analysis and Distribution Assessment
```r
# Prediction analysis with validation
tryCatch({
  yes_probs <- breakthrough_probs[,"Yes"]
  
  # Validate probability values
  if (any(is.na(yes_probs))) {
    warning("Found NA values in breakthrough probabilities")
  }
  
  if (any(yes_probs < 0  < /dev/null |  yes_probs > 1, na.rm = TRUE)) {
    warning("Found invalid probability values (outside 0-1 range)")
  }
  
  print("Distribution of breakthrough probabilities:")
  print(summary(yes_probs))
  
  max_prob <- max(yes_probs, na.rm = TRUE)
  high_prob_count <- sum(yes_probs > 0.1, na.rm = TRUE)
  medium_prob_count <- sum(yes_probs > 0.05, na.rm = TRUE)
  
  cat("Highest breakthrough probability:", round(max_prob * 100, 1), "%\n")
  cat("Candidates with >10% breakthrough probability:", high_prob_count, "\n")
  cat("Candidates with >5% breakthrough probability:", medium_prob_count, "\n")
  
}, error = function(e) {
  warning("Error analyzing predictions: ", e$message)
})
```
**Purpose**: Analyzes the distribution and quality of breakthrough predictions, providing insights into prediction confidence and identifying candidates with meaningful breakthrough potential.

#### 10. Results DataFrame Creation with Likelihood Categories
```r
# Create results dataframe with validation
tryCatch({
  cat("\n--- Creating Results DataFrame ---\n")
  
  # Ensure we have required predictors for output
  available_predictors <- intersect(top_predictors, names(prediction_data))
  
  results <- prediction_data %>%
    dplyr::select(Skier, Nation, Age, all_of(available_predictors), Pct_of_Max_Points) %>%
    mutate(
      Breakthrough_Prob = breakthrough_probs[,"Yes"],
      Points_To_Threshold = pmax(0, 0.2 - Pct_of_Max_Points, na.rm = TRUE),
      Likelihood = case_when(
        is.na(Breakthrough_Prob) ~ "Unknown",
        Breakthrough_Prob >= 0.6 ~ "Very High",
        Breakthrough_Prob >= 0.4 ~ "High", 
        Breakthrough_Prob >= 0.2 ~ "Moderate",
        Breakthrough_Prob >= 0.1 ~ "Low",
        TRUE ~ "Very Low"
      )
    ) %>%
    arrange(desc(Breakthrough_Prob))
  
  # Create age-filtered subset for young prospects
  under25_results <- results %>%
    filter(Age <= 25) %>%
    arrange(desc(Breakthrough_Prob))
  
  cat("✓ Results created with", nrow(results), "total candidates\n")
  cat("Young prospects (≤25):", nrow(under25_results), "candidates\n")
  
}, error = function(e) {
  stop("Error creating results: ", e$message)
})
```
**Purpose**: Creates comprehensive results dataframe with categorical likelihood assessments and identifies young prospects with special breakthrough potential for focused analysis.

#### 11. Model Execution for Men's and Ladies Predictions
```r
# Execute breakthrough predictions with validation
cat("\n--- 2026 Breakthrough Prediction Execution ---\n")

# Make 2026 breakthrough predictions for men
tryCatch({
  cat("Generating men's breakthrough predictions\n")
  
  # Validate inputs
  if (is.null(breakthrough_analysis_men$reduced_model)) {
    stop("Men's breakthrough model is NULL")
  }
  if (is.null(breakthrough_analysis_men$top_predictors) || length(breakthrough_analysis_men$top_predictors) == 0) {
    stop("Men's top predictors are NULL or empty")
  }
  
  breakthrough_predictions_men <- predict_2026_breakthroughs(
    train_men,  # Use full training data to check career history
    breakthrough_analysis_men$reduced_model,
    breakthrough_analysis_men$top_predictors
  )
  
  cat("✓ Men's breakthrough predictions completed\n")
  
}, error = function(e) {
  stop("Error generating men's breakthrough predictions: ", e$message)
})
```
**Purpose**: Executes the breakthrough prediction process for both men's and ladies alpine skiing with comprehensive validation and error handling.

#### 12. Historical Breakthrough Model Validation
```r
# Create comparative analysis with historical breakthroughs
cat("\n=== HISTORICAL BREAKTHROUGH COMPARISON ===\n")

# Function to apply breakthrough model to historical data
predict_historical_breakthrough <- function(historical_data, breakthrough_model, top_predictors) {
  
  # Define mapping from prev variables to current Elo variables
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Downhill" = "Downhill_Pelo",
    "Prev_Super_G" = "Super G_Pelo", 
    "Prev_Giant_Slalom" = "Giant Slalom_Pelo",
    "Prev_Slalom" = "Slalom_Pelo",
    "Prev_Combined" = "Combined_Pelo",
    "Prev_Tech" = "Tech_Pelo",
    "Prev_Speed" = "Speed_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points"
  )
  
  # Create prediction dataset by mapping current values to prev_ names
  prediction_data <- historical_data
  
  for(prev_var in names(predictor_mapping)) {
    if(prev_var %in% top_predictors) {
      current_var <- predictor_mapping[prev_var]
      if(current_var %in% names(historical_data)) {
        prediction_data[[prev_var]] <- prediction_data[[current_var]]
      }
    }
  }
  
  # Handle missing values with median imputation
  for(pred in top_predictors) {
    if(pred %in% names(prediction_data)) {
      na_count <- sum(is.na(prediction_data[[pred]]))
      if(na_count > 0) {
        pred_median <- median(prediction_data[[pred]], na.rm = TRUE)
        if(is.na(pred_median)) {
          pred_median <- 0
        }
        prediction_data[[pred]] <- ifelse(is.na(prediction_data[[pred]]),
                                        pred_median,
                                        prediction_data[[pred]])
      }
    }
  }
  
  # Make predictions
  tryCatch({
    breakthrough_probs <- predict(breakthrough_model,
                                 newdata = prediction_data,
                                 type = "prob")
    return(breakthrough_probs[,"Yes"])
  }, error = function(e) {
    warning("Error predicting historical breakthroughs: ", e$message)
    return(rep(0.5, nrow(prediction_data)))  # Default to 50% if prediction fails
  })
}
```
**Purpose**: Validates breakthrough prediction models by testing them against historical breakthrough cases, providing confidence assessment for 2026 predictions through backtesting on known outcomes.

### Alpine-Specific Breakthrough Prediction Considerations

#### Career-Based Assessment Framework
Alpine breakthrough prediction uses comprehensive career analysis:
- **Full career evaluation**: Examines entire competitive history rather than single seasons
- **20% threshold consistency**: Maintains consistent definition of breakthrough across analysis
- **Recent activity requirements**: Ensures candidates have meaningful current competitive engagement
- **Multi-season trajectory consideration**: Accounts for alpine skiing's varying performance patterns

#### Age and Development Patterns
Alpine breakthrough analysis considers age-specific factors:
- **Young prospects focus**: Special attention to skiers ≤25 years old
- **No upper age limits**: Alpine skiing allows for breakthrough at various career stages
- **Development trajectory diversity**: Accommodates different paths to alpine success
- **Experience vs. potential balance**: Weighs both current performance and growth potential

#### Multi-Discipline Integration
Alpine breakthrough predictions incorporate discipline diversity:
- **Technical vs. Speed emphasis**: Considers different paths to breakthrough through discipline specialization
- **Overall rating importance**: Uses comprehensive alpine performance metrics
- **Discipline-specific features**: Incorporates individual discipline ELO ratings
- **Combined performance assessment**: Evaluates overall alpine versatility

#### Historical Validation Approach
The prediction system includes robust validation:
- **Backtesting against known outcomes**: Tests model performance on historical breakthrough cases
- **Predictor variable consistency**: Ensures fair comparison between historical and current predictions
- **Missing data handling**: Robust imputation strategies for incomplete historical data
- **Model confidence assessment**: Provides reliability indicators for predictions

### Quality Assurance and Validation

The breakthrough prediction process includes comprehensive validation:
- **Input data validation** ensuring all required components are available
- **Career history verification** confirming accurate breakthrough candidate identification
- **Prediction quality assessment** validating probability ranges and distributions
- **Results consistency checking** ensuring logical relationships in output
- **Historical model validation** through backtesting on known breakthrough cases
- **Error resilience** with graceful handling of missing data or model failures

This alpine breakthrough prediction section provides a sophisticated framework for identifying 2026 breakthrough candidates while maintaining statistical rigor and practical applicability for understanding future alpine skiing success patterns.
