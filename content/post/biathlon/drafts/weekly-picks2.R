# Biathlon Weekly Predictions: Methodology with Race Probabilities
library(dplyr)
library(tidyr)
library(openxlsx)
library(arrow)
library(mgcv)
library(leaps)
library(logger)
library(purrr)
library(lubridate) # For better date handling
library(slider)    # For sliding window operations

# Define points systems
regular_points <- c(90,75,65,55,50,45,41,37,34,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
mass_start_points <- c(90,75,65,55,50,45,41,37,34,31,30,29,28,27,26,25,24,23,22,21,20,18,16,14,12,10,8,6,4,2)

# Function to replace NAs with first quartile value
replace_na_with_quartile <- function(x) {
  if(all(is.na(x))) return(rep(0, length(x)))
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  ifelse(is.na(x), q1, x)
}

# Set up logging
log_dir <- "~/ski/elo/python/biathlon/polars/excel365/weekly-predictions"
if (!dir.exists(log_dir)) {
  dir.create(log_dir, recursive = TRUE)
}

log_threshold(DEBUG)
log_appender(appender_file(file.path(log_dir, "weekly_picks_processing.log")))
log_info("Starting biathlon weekly predictions process")

# Read in the race schedule from weekends.csv with proper date parsing
log_info("Reading weekends data")
weekends <- read.csv("~/ski/elo/python/biathlon/polars/excel365/weekends.csv", 
                     stringsAsFactors = FALSE) %>%
  mutate(Date = as.Date(Date, format="%m/%d/%Y")) # Parse date in month/day/year format with 4-digit year

# Find the next race weekend after today
current_date <- as.Date(format(Sys.time(), tz = "UTC"), "%Y-%m-%d")
log_info(paste("Current date:", current_date))

# dplyr::filter races for the current date and get the next date
next_races <- weekends %>%
  dplyr::filter(Date == current_date) %>%
  arrange(Date)

# Get the date of the next race weekend
next_weekend_date <- min(next_races$Date, na.rm = TRUE)
log_info(paste("Next weekend date:", next_weekend_date))

# dplyr::filter races for just the next weekend
next_weekend_races <- next_races %>%
  dplyr::filter(Date == next_weekend_date)

if (nrow(next_weekend_races) == 0) {
  log_info("No races found for the next weekend. Terminating program.")
  quit(save = "no", status = 0)  # Exit R without saving workspace
}

# Create race dataframes for men and ladies
men_races <- next_weekend_races %>%
  dplyr::filter(Sex == "M", 
                !RaceType %in% c("Relay", "Mixed Relay", "Single Mixed Relay")) %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

ladies_races <- next_weekend_races %>%
  dplyr::filter(Sex == "L", 
                !RaceType %in% c("Relay", "Mixed Relay", "Single Mixed Relay")) %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

mixed_races <- next_weekend_races %>%
  dplyr::filter(Sex == "Mixed") %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

# Create race dataframes for relays
# Create separate relays dataframes by gender
men_relays <- next_weekend_races %>%
  dplyr::filter(RaceType %in% c("Relay"), Sex == "M") %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

ladies_relays <- next_weekend_races %>%
  dplyr::filter(RaceType %in% c("Relay"), Sex == "L") %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

# Create a combined relays dataframe for backward compatibility
relays <- next_weekend_races %>%
  dplyr::filter(RaceType %in% c("Relay")) %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

log_info(paste("Found", nrow(men_relays), "men's relay races,", 
               nrow(ladies_relays), "ladies's relay races"))

mixed_relays <- next_weekend_races %>%
  dplyr::filter(RaceType %in% c("Mixed Relay")) %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

single_mixed_relays <- next_weekend_races %>%
  dplyr::filter(RaceType %in% c("Single Mixed Relay")) %>%
  dplyr::select(RaceType, Period, Elevation) %>%
  rename(racetype = RaceType, period = Period, elevation = Elevation)

log_info(paste("Found", nrow(men_races), "men's races,", nrow(ladies_races), "ladies's races, and", 
               nrow(relays) + nrow(mixed_relays) + nrow(single_mixed_relays), "relay races"))

# Calculate Race Probabilities
calculate_race_probabilities <- function() {
  log_info("Calculating race participation probabilities")
  
  # Initialize empty data frames
  men_startlist <- data.frame()
  ladies_startlist <- data.frame()
  
  men_chrono <- data.frame()
  ladies_chrono <- data.frame()
  
  # Only load data for race types that are happening this weekend
  if(nrow(men_races) > 0) {
    log_info("Reading men's chronological data and startlist")
    men_chrono <- read.csv("~/ski/elo/python/biathlon/polars/relay/excel365/men_chrono_elevation.csv", 
                           stringsAsFactors = FALSE) %>%
      mutate(Date = as.Date(Date))
    
    men_startlist <- read.csv("~/ski/elo/python/biathlon/polars/excel365/startlist_weekend_men.csv", 
                              stringsAsFactors = FALSE)

    men_startlist$Sex = "M"
  }
  
  if(nrow(ladies_races) > 0) {
    log_info("Reading ladies's chronological data and startlist")
    ladies_chrono <- read.csv("~/ski/elo/python/biathlon/polars/relay/excel365/ladies_chrono_elevation.csv", 
                              stringsAsFactors = FALSE) %>%
      mutate(Date = as.Date(Date))
    
    ladies_startlist <- read.csv("~/ski/elo/python/biathlon/polars/excel365/startlist_weekend_ladies.csv", 
                                 stringsAsFactors = FALSE)
    ladies_startlist$Sex = "L"
  }
  
  # Initialize relay variables
  men_relay_startlist <- data.frame()
  ladies_relay_startlist <- data.frame()
  mixed_relay_startlist <- data.frame()
  single_mixed_relay_startlist <- data.frame()
  
  # For relay events
  # Regular relays
  if(nrow(relays) > 0) {
    log_info("Reading relay chronological data and startlist")
    
    # Load men's relay startlist if it exists
    men_relay_file <- "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_relay_weekend_teams_men.csv"
    if(file.exists(men_relay_file)) {
      men_relay_startlist <- read.csv(men_relay_file, stringsAsFactors = FALSE)

      log_info(paste("Loaded men's relay startlist with", nrow(men_relay_startlist), "teams"))
    } else {
      log_warn("Men's relay startlist file not found")
    }
    
    # Load ladies' relay startlist if it exists
    ladies_relay_file <- "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_relay_weekend_teams_ladies.csv"
    if(file.exists(ladies_relay_file)) {
      ladies_relay_startlist <- read.csv(ladies_relay_file, stringsAsFactors = FALSE)
      log_info(paste("Loaded ladies' relay startlist with", nrow(ladies_relay_startlist), "teams"))
    } else {
      log_warn("Ladies' relay startlist file not found")
    }
  }
  
  # Mixed relay
  if(nrow(mixed_relays) > 0) {
    log_info("Reading mixed relay startlist")
    mixed_relay_file <- "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_mixed_relay_weekend_teams.csv"
    if(file.exists(mixed_relay_file)) {
      mixed_relay_startlist <- read.csv(mixed_relay_file, stringsAsFactors = FALSE)
      log_info(paste("Loaded mixed relay startlist with", nrow(mixed_relay_startlist), "teams"))
    } else {
      log_warn("Mixed relay startlist file not found")
    }
  }
  
  # Single mixed relay
  if(nrow(single_mixed_relays) > 0) {
    log_info("Reading single mixed relay startlist")
    single_mixed_relay_file <- "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_single_mixed_relay_weekend_teams.csv"
    if(file.exists(single_mixed_relay_file)) {
      single_mixed_relay_startlist <- read.csv(single_mixed_relay_file, stringsAsFactors = FALSE)
      log_info(paste("Loaded single mixed relay startlist with", nrow(single_mixed_relay_startlist), "teams"))
    } else {
      log_warn("Single mixed relay startlist file not found")
    }
  }
  
  # Function to get race probability for a skier/team
  get_race_probability <- function(chronos, participant, racetype, is_relay = FALSE) {
    log_debug(paste("Calculating probability for participant:", participant))
    
    # For relay, participant is a Nation
    id_col <- if(is_relay) "Nation" else "Skier"
    
    # Get participant's first ever race date
    participant_first_race <- chronos %>%
      dplyr::filter(get(id_col) == participant) %>%
      arrange(Date) %>%
      dplyr::slice(1) %>%
      pull(Date)
    
    # Calculate date from 5 years ago
    five_years_ago <- Sys.Date() - (5 * 365)
    
    # Use 5 years ago or participant's first race, whichever is later
    start_date <- if(length(participant_first_race) == 0) {
      five_years_ago
    } else {
      max(five_years_ago, as.Date(participant_first_race))
    }
    
    log_debug(paste("Using start date:", format(start_date, "%Y-%m-%d"), "for participant:", participant))
    
    # First get all matching races since start_date
    all_races <- chronos %>%
      dplyr::filter(
        Date >= start_date,
        RaceType == racetype
      ) %>%
      distinct(Date, City)
    
    # Then get this participant's participations
    participant_races <- chronos %>%
      dplyr::filter(
        Date >= start_date,
        get(id_col) == participant,
        RaceType == racetype
      ) %>%
      distinct(Date, City)
    
    total_races <- nrow(all_races)
    
    if(total_races == 0) {
      log_debug(paste("No races found for race type:", racetype))
      return(0)
    }
    
    races_participated <- nrow(participant_races)
    # Cap probability at 1
    prob <- min(1, races_participated / total_races)
    
    log_debug(paste("Probability for", participant, "since", start_date, ":", prob, 
                    "(", races_participated, "/", total_races, " races)"))
    
    return(prob)
  }
  
  # Process men's and ladies's race probabilities
  process_individual_probabilities <- function(startlist, chronos, races, gender) {
    # Check if we have FIS startlist (at least one skier has In_Startlist=True)
    has_fis_startlist <- FALSE
    if("In_Startlist" %in% names(startlist)) {
      has_fis_startlist <- any(startlist$In_Startlist, na.rm = TRUE)
    }
    
    # Handle Race1_Prob based on FIS startlist existence
    if(has_fis_startlist) {
      log_info("FIS startlist exists (at least one In_Startlist=True), keeping existing Race1_Prob values")
      # Keep existing Race1_Prob if it exists, otherwise set based on In_Startlist
      if(!"Race1_Prob" %in% names(startlist)) {
        startlist$Race1_Prob <- ifelse(startlist$In_Startlist, 1, 0)
      }
    } else {
      log_info("No FIS startlist (all In_Startlist=False), will calculate Race1_Prob")
      # Race1_Prob will be calculated like other races below
    }
    
    # Process each race
    for(i in 1:nrow(races)) {
      race_prob_col <- paste0("Race", i, "_Prob")
      
      # Skip Race1_Prob if we have a FIS startlist and it's already set
      if(race_prob_col == "Race1_Prob" && has_fis_startlist && race_prob_col %in% names(startlist)) {
        log_info("Using existing Race1_Prob from FIS startlist, skipping calculation")
        next
      }
      
      # Create the column if it doesn't exist
      if(!(race_prob_col %in% names(startlist))) {
        startlist[[race_prob_col]] <- NA_real_
      }
      
      # Process probabilities for each skier
      for(j in 1:nrow(startlist)) {
        skier <- startlist$Skier[j]
        startlist[j, race_prob_col] <- 
          get_race_probability(chronos, skier, races$racetype[i], is_relay = FALSE)
      }
    }
    
    return(startlist)
  }
  
  # Process relay race probabilities - set all to 1 for simplicity
  process_relay_probabilities <- function(startlist, races) {
    log_info("Processing relay race probabilities - setting all to 1")
    log_info(paste("Input races dataframe has", nrow(races), "rows"))
    
    # We should treat this as a single race type regardless of how many rows are in races
    # So we'll just set Race1_Prob for all teams
    race_prob_col <- "Race1_Prob"
    
    # Create the column if it doesn't exist
    if(!(race_prob_col %in% names(startlist))) {
      startlist[[race_prob_col]] <- 1  # Set probability to 1 for all teams
      log_info(paste("Set", race_prob_col, "to 1 for all", nrow(startlist), "teams"))
    } else {
      log_info(paste(race_prob_col, "already exists in startlist"))
    }

    return(startlist)
  }
  
  # Process each gender and relay
  if(nrow(men_races) > 0 && nrow(men_startlist) > 0) {
    log_info("Processing men's race probabilities")
    men_startlist_with_probs <- process_individual_probabilities(men_startlist, men_chrono, men_races, "M")
  } else {
    men_startlist_with_probs <- men_startlist
  }
  
  if(nrow(ladies_races) > 0 && nrow(ladies_startlist) > 0) {
    log_info("Processing ladies' race probabilities")
    ladies_startlist_with_probs <- process_individual_probabilities(ladies_startlist, ladies_chrono, ladies_races, "L")
  } else {
    ladies_startlist_with_probs <- ladies_startlist
  }
  
  # Process regular relays if we have any
  if(nrow(relays) > 0) {
    if(nrow(men_relay_startlist) > 0) {
      log_info("Processing men's relay race probabilities")

      men_relay_startlist_with_probs <- process_relay_probabilities(men_relay_startlist, relays)
    } else {
      men_relay_startlist_with_probs <- men_relay_startlist
    }
    
    if(nrow(ladies_relay_startlist) > 0) {
      log_info("Processing ladies' relay race probabilities")
      ladies_relay_startlist_with_probs <- process_relay_probabilities(ladies_relay_startlist, relays)
    } else {
      ladies_relay_startlist_with_probs <- ladies_relay_startlist
    }
  } else {
    men_relay_startlist_with_probs <- men_relay_startlist
    ladies_relay_startlist_with_probs <- ladies_relay_startlist
  }
  
  # Process mixed relays if we have any
  if(nrow(mixed_relays) > 0 && nrow(mixed_relay_startlist) > 0) {
    log_info("Processing mixed relay race probabilities")
    mixed_relay_startlist_with_probs <- process_relay_probabilities(mixed_relay_startlist, mixed_relays)
  } else {
    mixed_relay_startlist_with_probs <- mixed_relay_startlist
  }
  
  # Process single mixed relays if we have any
  if(nrow(single_mixed_relays) > 0 && nrow(single_mixed_relay_startlist) > 0) {
    log_info("Processing single mixed relay race probabilities")
    single_mixed_relay_startlist_with_probs <- process_relay_probabilities(single_mixed_relay_startlist, single_mixed_relays)
  } else {
    single_mixed_relay_startlist_with_probs <- single_mixed_relay_startlist
  }
  
  # Save results
  log_info("Saving race probability results")
  
  if(nrow(men_races) > 0 && nrow(men_startlist_with_probs) > 0) {
    write.csv(men_startlist_with_probs, 
              "~/ski/elo/python/biathlon/polars/excel365/startlist_weekend_men.csv", 
              row.names = FALSE)
  }
  
  if(nrow(ladies_races) > 0 && nrow(ladies_startlist_with_probs) > 0) {
    write.csv(ladies_startlist_with_probs, 
              "~/ski/elo/python/biathlon/polars/excel365/startlist_weekend_ladies.csv", 
              row.names = FALSE)
  }
  
  if(nrow(relays) > 0) {
    if(nrow(men_relay_startlist_with_probs) > 0) {
      write.csv(men_relay_startlist_with_probs,
                "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_relay_weekend_teams_men.csv",
                row.names = FALSE)
    }
    
    if(nrow(ladies_relay_startlist_with_probs) > 0) {
      write.csv(ladies_relay_startlist_with_probs,
                "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_relay_weekend_teams_ladies.csv",
                row.names = FALSE)
    }
  }
  
  if(nrow(mixed_relays) > 0 && nrow(mixed_relay_startlist_with_probs) > 0) {
    write.csv(mixed_relay_startlist_with_probs,
              "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_mixed_relay_weekend_teams.csv",
              row.names = FALSE)
  }
  
  if(nrow(single_mixed_relays) > 0 && nrow(single_mixed_relay_startlist_with_probs) > 0) {
    write.csv(single_mixed_relay_startlist_with_probs,
              "~/ski/elo/python/biathlon/polars/relay/excel365/startlist_single_mixed_relay_weekend_teams.csv",
              row.names = FALSE)
  }
  
  log_info("Race probability calculation complete")
  # Return all processed startlists
  return(list(
    men = men_startlist_with_probs,
    ladies = ladies_startlist_with_probs,
    men_relay = men_relay_startlist_with_probs,
    ladies_relay = ladies_relay_startlist_with_probs,
    mixed_relay = mixed_relay_startlist_with_probs,
    single_mixed_relay = single_mixed_relay_startlist_with_probs
  ))
}

# Create processed relay chrono files
# Function to create relay chronos with error handling for missing Points column
create_relay_chronos <- function() {
  log_info("Creating team-based relay chronological files")
  
  # Only process if we have relay races
  if(nrow(relays) + nrow(mixed_relays) + nrow(single_mixed_relays) == 0) {
    log_info("No relay races scheduled - skipping relay chrono creation")
    return(FALSE)
  }
  
  # Load men's and ladies's chronological data
  men_chrono <- read.csv("~/ski/elo/python/biathlon/polars/relay/excel365/men_chrono_elevation.csv", 
                         stringsAsFactors = FALSE) %>%
    mutate(Date = as.Date(Date))
  
  ladies_chrono <- read.csv("~/ski/elo/python/biathlon/polars/relay/excel365/ladies_chrono_elevation.csv", 
                            stringsAsFactors = FALSE) %>%
    mutate(Date = as.Date(Date))
  
  # Check if Points column exists, if not create it
  if(!"Points" %in% names(men_chrono)) {
    log_info("Creating Points column in men's chrono based on Place")
    men_chrono$Points <- mapply(function(place, RaceType) {
      get_points(place, RaceType)
    }, men_chrono$Place, men_chrono$RaceType)
  }
  
  if(!"Points" %in% names(ladies_chrono)) {
    log_info("Creating Points column in ladies' chrono based on Place")
    ladies_chrono$Points <- mapply(function(place, RaceType) {
      get_points(place, RaceType)
    }, ladies_chrono$Place, ladies_chrono$RaceType)
  }
  
  # Process men's relay chrono
  if(nrow(relays) > 0) {
    log_info("Creating men's relay chrono")
    men_relay_chrono <- men_chrono %>%
      dplyr::filter(RaceType == "Relay") %>%
      # Group by race to get team results
      group_by(Date, City, Country, Nation, RaceType, Season, Race, Event, Elevation) %>%
      summarize(
        # Team rank is the first Place value within each group
        Place = first(Place),
        Points = first(Points),
        # Calculate average Elo/Pelo values for the team
        Avg_Elo = mean(Elo, na.rm = TRUE),
        Avg_Individual_Elo = mean(Individual_Elo, na.rm = TRUE),
        Avg_Sprint_Elo = mean(Sprint_Elo, na.rm = TRUE),
        Avg_Pursuit_Elo = mean(Pursuit_Elo, na.rm = TRUE),
        Avg_MassStart_Elo = mean(MassStart_Elo, na.rm = TRUE),
        Avg_Pelo = mean(Pelo, na.rm = TRUE),
        Avg_Individual_Pelo = mean(Individual_Pelo, na.rm = TRUE),
        Avg_Sprint_Pelo = mean(Sprint_Pelo, na.rm = TRUE),
        Avg_Pursuit_Pelo = mean(Pursuit_Pelo, na.rm = TRUE),
        Avg_MassStart_Pelo = mean(MassStart_Pelo, na.rm = TRUE),
        #Avg_Relay_Pelo = mean(Pelo, na.rm = TRUE),  # Using general Pelo as Relay Pelo
        # Additional metadata
        MassStart = first(MassStart),
        Sex = "M",
        .groups = "drop"
      )
    
    # Save men's relay chrono
    write.csv(men_relay_chrono,
              "~/ski/elo/python/biathlon/polars/relay/excel365/men_relay_chrono.csv",
              row.names = FALSE)
    log_info(paste("Created men's relay chrono with", nrow(men_relay_chrono), "team entries"))
  }
  
  # Process ladies' relay chrono
  if(nrow(relays) > 0) {
    log_info("Creating ladies' relay chrono")
    ladies_relay_chrono <- ladies_chrono %>%
      dplyr::filter(RaceType == "Relay") %>%
      # Group by race to get team results
      group_by(Date, City, Country, Nation, RaceType, Season, Race, Event, Elevation) %>%
      summarize(
        # Team rank is the first Place value within each group
        Place = first(Place),
        Points = first(Points),
        # Calculate average Elo/Pelo values for the team
        Avg_Elo = mean(Elo, na.rm = TRUE),
        Avg_Individual_Elo = mean(Individual_Elo, na.rm = TRUE),
        Avg_Sprint_Elo = mean(Sprint_Elo, na.rm = TRUE),
        Avg_Pursuit_Elo = mean(Pursuit_Elo, na.rm = TRUE),
        Avg_MassStart_Elo = mean(MassStart_Elo, na.rm = TRUE),
        
        Avg_Pelo = mean(Pelo, na.rm = TRUE),
        Avg_Individual_Pelo = mean(Individual_Pelo, na.rm = TRUE),
        Avg_Sprint_Pelo = mean(Sprint_Pelo, na.rm = TRUE),
        Avg_Pursuit_Pelo = mean(Pursuit_Pelo, na.rm = TRUE),
        Avg_MassStart_Pelo = mean(MassStart_Pelo, na.rm = TRUE),
        #Avg_Relay_Pelo = mean(Pelo, na.rm = TRUE),  # Using general Pelo as Relay Pelo
        # Additional metadata
        MassStart = first(MassStart),
        Sex = "L",
        .groups = "drop"
      )
    
    # Save ladies' relay chrono
    write.csv(ladies_relay_chrono,
              "~/ski/elo/python/biathlon/polars/relay/excel365/ladies_relay_chrono.csv",
              row.names = FALSE)
    log_info(paste("Created ladies' relay chrono with", nrow(ladies_relay_chrono), "team entries"))
  }
  
  # Process mixed relay chrono
  if(nrow(mixed_relays) > 0) {
    log_info("Creating mixed relay chrono")
    
    # Combine men's and ladies's chronos for mixed events
    combined_chrono <- bind_rows(men_chrono, ladies_chrono)
    
    # Check if there are any Mixed Relay records
    mixed_relay_records <- combined_chrono %>% dplyr::filter(RaceType == "Mixed Relay")
    
    if(nrow(mixed_relay_records) > 0) {
      mixed_relay_chrono <- mixed_relay_records %>%
        # Group by race to get team results
        group_by(Date, City, Country, Nation, RaceType, Season, Race, Event, Elevation) %>%
        summarize(
          # Team rank is the first Place value within each group
          Place = first(Place),
          Points = first(Points),
          # Calculate average Elo/Pelo values for the team
          Avg_Elo = mean(Elo, na.rm = TRUE),
          Avg_Individual_Elo = mean(Individual_Elo, na.rm = TRUE),
          Avg_Sprint_Elo = mean(Sprint_Elo, na.rm = TRUE),
          Avg_Pursuit_Elo = mean(Pursuit_Elo, na.rm = TRUE),
          Avg_MassStart_Elo = mean(MassStart_Elo, na.rm = TRUE),
          #Avg_Mixed_Relay_Elo = mean(Elo, na.rm = TRUE),  # Using general Elo as Mixed Relay Elo
          Avg_Pelo = mean(Pelo, na.rm = TRUE),
          Avg_Individual_Pelo = mean(Individual_Pelo, na.rm = TRUE),
          Avg_Sprint_Pelo = mean(Sprint_Pelo, na.rm = TRUE),
          Avg_Pursuit_Pelo = mean(Pursuit_Pelo, na.rm = TRUE),
          Avg_MassStart_Pelo = mean(MassStart_Pelo, na.rm = TRUE),
          #Avg_Mixed_Relay_Pelo = mean(Pelo, na.rm = TRUE),  # Using general Pelo as Mixed Relay Pelo
          # Additional metadata
          MassStart = first(MassStart),
          Sex = "Mixed",
          .groups = "drop"
        )
      
      # Save mixed relay chrono
      write.csv(mixed_relay_chrono,
                "~/ski/elo/python/biathlon/polars/relay/excel365/mixed_relay_chrono.csv",
                row.names = FALSE)
      log_info(paste("Created mixed relay chrono with", nrow(mixed_relay_chrono), "team entries"))
    } else {
      log_warn("No Mixed Relay records found in chronological data")
      
      # Create an empty chrono file with the correct structure
      mixed_relay_chrono <- data.frame(
        Date = as.Date(character()),
        City = character(),
        Country = character(),
        Nation = character(),
        RaceType = character(),
        Season = integer(),
        Race = integer(),
        Event = character(),
        Elevation = integer(),
        Place = integer(),
        Points = numeric(),
        Avg_Elo = numeric(),
        Avg_Individual_Elo = numeric(),
        Avg_Sprint_Elo = numeric(),
        Avg_Pursuit_Elo = numeric(),
        Avg_MassStart_Elo = numeric(),
        #Avg_Mixed_Relay_Elo = numeric(),
        Avg_Pelo = numeric(),
        Avg_Individual_Pelo = numeric(),
        Avg_Sprint_Pelo = numeric(),
        Avg_Pursuit_Pelo = numeric(),
        Avg_MassStart_Pelo = numeric(),
        #Avg_Mixed_Relay_Pelo = numeric(),
        MassStart = integer(),
        Sex = character(),
        stringsAsFactors = FALSE
      )
      
      write.csv(mixed_relay_chrono,
                "~/ski/elo/python/biathlon/polars/relay/excel365/mixed_relay_chrono.csv",
                row.names = FALSE)
      log_info("Created empty mixed relay chrono file with correct structure")
    }
  }
  
  # Process single mixed relay chrono
  if(nrow(single_mixed_relays) > 0) {
    log_info("Creating single mixed relay chrono")
    
    # Ensure we have combined chronos
    if(!exists("combined_chrono")) {
      combined_chrono <- bind_rows(men_chrono, ladies_chrono)
    }
    
    # Check if there are any Single Mixed Relay records
    single_mixed_relay_records <- combined_chrono %>% dplyr::filter(RaceType == "Single Mixed Relay")
    
    if(nrow(single_mixed_relay_records) > 0) {
      single_mixed_relay_chrono <- single_mixed_relay_records %>%
        # Group by race to get team results
        group_by(Date, City, Country, Nation, RaceType, Season, Race, Event, Elevation) %>%
        summarize(
          # Team rank is the first Place value within each group
          Place = first(Place),
          Points = first(Points),
          # Calculate average Elo/Pelo values for the team
          Avg_Elo = mean(Elo, na.rm = TRUE),
          Avg_Individual_Elo = mean(Individual_Elo, na.rm = TRUE),
          Avg_Sprint_Elo = mean(Sprint_Elo, na.rm = TRUE),
          Avg_Pursuit_Elo = mean(Pursuit_Elo, na.rm = TRUE),
          Avg_MassStart_Elo = mean(MassStart_Elo, na.rm = TRUE),
          #Avg_Single_Mixed_Relay_Elo = mean(Elo, na.rm = TRUE),  # Using general Elo as Single Mixed Relay Elo
          Avg_Pelo = mean(Pelo, na.rm = TRUE),
          Avg_Individual_Pelo = mean(Individual_Pelo, na.rm = TRUE),
          Avg_Sprint_Pelo = mean(Sprint_Pelo, na.rm = TRUE),
          Avg_Pursuit_Pelo = mean(Pursuit_Pelo, na.rm = TRUE),
          Avg_MassStart_Pelo = mean(MassStart_Pelo, na.rm = TRUE),
          #Avg_Single_Mixed_Relay_Pelo = mean(Pelo, na.rm = TRUE),  # Using general Pelo as Single Mixed Relay Pelo
          # Additional metadata
          MassStart = first(MassStart),
          Sex = "Mixed",
          .groups = "drop"
        )
      
      # Save single mixed relay chrono
      write.csv(single_mixed_relay_chrono,
                "~/ski/elo/python/biathlon/polars/relay/excel365/single_mixed_relay_chrono.csv",
                row.names = FALSE)
      log_info(paste("Created single mixed relay chrono with", nrow(single_mixed_relay_chrono), "team entries"))
    } else {
      log_warn("No Single Mixed Relay records found in chronological data")
      
      # Create an empty chrono file with the correct structure
      single_mixed_relay_chrono <- data.frame(
        Date = as.Date(character()),
        City = character(),
        Country = character(),
        Nation = character(),
        RaceType = character(),
        Season = integer(),
        Race = integer(),
        Event = character(),
        Elevation = integer(),
        Place = integer(),
        Points = numeric(),
        Avg_Elo = numeric(),
        Avg_Individual_Elo = numeric(),
        Avg_Sprint_Elo = numeric(),
        Avg_Pursuit_Elo = numeric(),
        Avg_MassStart_Elo = numeric(),
        #Avg_Single_Mixed_Relay_Elo = numeric(),
        Avg_Pelo = numeric(),
        Avg_Individual_Pelo = numeric(),
        Avg_Sprint_Pelo = numeric(),
        Avg_Pursuit_Pelo = numeric(),
        Avg_MassStart_Pelo = numeric(),
        #Avg_Single_Mixed_Relay_Pelo = numeric(),
        MassStart = integer(),
        Sex = character(),
        stringsAsFactors = FALSE
      )
      
      write.csv(single_mixed_relay_chrono,
                "~/ski/elo/python/biathlon/polars/relay/excel365/single_mixed_relay_chrono.csv",
                row.names = FALSE)
      log_info("Created empty single mixed relay chrono file with correct structure")
    }
  }
  
  return(TRUE)
}

# Combine predictions from multiple races
combine_predictions <- function(race_dfs, startlist, is_relay = FALSE) {
  log_info("Combining race predictions")
  
  # Different ID column based on type
  id_col <- if(is_relay) "Nation" else "ID"
  participant_col <- if(is_relay) "Nation" else "Skier"
  
  # Start with first race
  log_info("Starting with first race data")
  final_predictions <- race_dfs[[1]] %>%
    rename(
      Race1_Base = Base_Prediction,
      Race1_Period = period_adjustment,
      Race1_Elevation = elevation_adjustment,
      Race1_Points = Final_Prediction,
      Race1_Safe = Safe_Prediction,
      Race1_Upside = Upside_Prediction,
      Race1_Volatility = prediction_volatility,
      Race1_Ratio = volatility_ratio,
      Race1_Confidence = confidence_factor,
      Race1_Probability = Race1_Prob
    )
  
  # Add Sex column if needed
  if(!is_relay) {
    final_predictions <- final_predictions %>%
      left_join(
        startlist %>% dplyr::select(Skier, ID, Sex),
        by = "Skier"
      )
  }
  
  # Add remaining races dynamically
  if(length(race_dfs) > 1) {
    for(i in 2:length(race_dfs)) {
      log_info(paste("Adding race", i, "to combined predictions"))
      
      # Get probability column name
      race_prob_col <- paste0("Race", i, "_Prob")
      
      # Check if Race{i}_Prob exists in this race_df
      if(!race_prob_col %in% names(race_dfs[[i]])) {
        log_warn(paste("Race probability column", race_prob_col, "not found in race_dfs[[", i, "]]"))
        
        # Try to fix by getting from startlist
        if(race_prob_col %in% names(startlist)) {
          log_info("Copying probability from original startlist")
          race_dfs[[i]][[race_prob_col]] <- startlist[match(race_dfs[[i]][[participant_col]], startlist[[participant_col]]), race_prob_col]
        } else {
          log_warn("Cannot find probability in startlist either, using default value")
          race_dfs[[i]][[race_prob_col]] <- 0
        }
      }
      
      # Handle Race{i}_Probability column properly
      final_predictions <- final_predictions %>%
        left_join(
          race_dfs[[i]] %>%
            rename(
              !!paste0("Race", i, "_Base") := Base_Prediction,
              !!paste0("Race", i, "_Period") := period_adjustment,
              !!paste0("Race", i, "_Elevation") := elevation_adjustment,
              !!paste0("Race", i, "_Points") := Final_Prediction,
              !!paste0("Race", i, "_Safe") := Safe_Prediction,
              !!paste0("Race", i, "_Upside") := Upside_Prediction,
              !!paste0("Race", i, "_Volatility") := prediction_volatility,
              !!paste0("Race", i, "_Ratio") := volatility_ratio,
              !!paste0("Race", i, "_Confidence") := confidence_factor,
              !!paste0("Race", i, "_Probability") := !!sym(paste0("Race", i, "_Prob"))
            ) %>%
            dplyr::select(!!participant_col, 
                          !!paste0("Race", i, "_Base"),
                          !!paste0("Race", i, "_Period"),
                          !!paste0("Race", i, "_Elevation"),
                          !!paste0("Race", i, "_Points"),
                          !!paste0("Race", i, "_Safe"),
                          !!paste0("Race", i, "_Upside"),
                          !!paste0("Race", i, "_Volatility"),
                          !!paste0("Race", i, "_Ratio"),
                          !!paste0("Race", i, "_Confidence"),
                          !!paste0("Race", i, "_Probability")),
          by = participant_col
        )
    }
  }
  
  # Check if probability columns exist in final predictions
  prob_cols <- paste0("Race", 1:length(race_dfs), "_Probability")
  for(col in prob_cols) {
    if(!col %in% names(final_predictions)) {
      log_warn(paste("Probability column", col, "missing from final predictions!"))
    } else {
      log_info(paste("Probability column", col, "exists in final predictions"))
      log_info(paste("  Mean:", mean(final_predictions[[col]], na.rm = TRUE)))
      log_info(paste("  Sum:", sum(final_predictions[[col]], na.rm = TRUE)))
    }
  }
  
  # Weighted sum expression that accounts for Race{i}_Probability
  weighted_sum_expr <- function(prefix, n_races) {
    terms <- sapply(1:n_races, function(i) {
      paste0("Race", i, "_", prefix, " * Race", i, "_Probability")
    })
    parse(text = paste(terms, collapse = " + "))
  }
  
  avg_expr <- function(prefix, n_races) {
    syms <- paste0("Race", 1:n_races, "_", prefix)
    parse(text = paste0("(", paste(syms, collapse = " + "), ")/", n_races))
  }
  
  # Calculate totals dynamically based on number of races, using probability-weighted sums
  log_info("Calculating totals with probability weighting")
  final_predictions <- final_predictions %>%
    mutate(
      # Use probability-weighted sums for point calculations
      Total_Points = eval(weighted_sum_expr("Points", length(race_dfs))),
      Total_Period = eval(weighted_sum_expr("Period", length(race_dfs))),
      Total_Elevation = eval(weighted_sum_expr("Elevation", length(race_dfs))),
      Total_Safe = eval(weighted_sum_expr("Safe", length(race_dfs))),
      Total_Upside = eval(weighted_sum_expr("Upside", length(race_dfs))),
      Avg_Volatility = eval(avg_expr("Volatility", length(race_dfs))),
      Avg_Confidence = eval(avg_expr("Confidence", length(race_dfs)))
    ) %>%
    arrange(desc(Total_Points))
  
  # Select columns dynamically based on number of races
  select_cols <- c(participant_col)
  
  # For individual races, include ID, Nation, Sex
  if(!is_relay) {
    select_cols <- c(select_cols, "ID", "Nation", "Sex")
  }
  
  for(i in 1:length(race_dfs)) {
    select_cols <- c(select_cols,
                     paste0("Race", i, "_Base"),
                     paste0("Race", i, "_Period"),
                     paste0("Race", i, "_Elevation"),
                     paste0("Race", i, "_Points"),
                     paste0("Race", i, "_Safe"),
                     paste0("Race", i, "_Upside"),
                     paste0("Race", i, "_Volatility"),
                     paste0("Race", i, "_Ratio"),
                     paste0("Race", i, "_Confidence"),
                     paste0("Race", i, "_Probability"))
  }
  select_cols <- c(select_cols,
                   "Total_Points", "Total_Safe", "Total_Upside",
                   "Total_Period", "Total_Elevation",
                   "Avg_Volatility", "Avg_Confidence")
  
  log_info("Returning final predictions")
  final_predictions %>%
    dplyr::select(all_of(select_cols))
}

# Function to prepare startlist data with ELO information
prepare_startlist_data <- function(startlist, race_df, pelo_col, is_relay = FALSE) {
  # Print some debug info

  log_info(paste("Preparing startlist data for", pelo_col))
  
  # Dynamically get race probability columns - important to preserve these!
  race_prob_cols <- grep("^Race\\d+_Prob$", names(startlist), value = TRUE)
  log_info(paste("Race probability columns found:", paste(race_prob_cols, collapse=", ")))
  
  # Different ID column based on type
  id_col <- if(is_relay) "Nation" else "ID"
  participant_col <- if(is_relay) "Nation" else "Skier"
  
  # For relays, handle differently since startlist already has team average Elos
  if(is_relay) {
    # Get all columns that might be needed for the model
    elo_cols <- c("Avg_Sprint_Elo", "Avg_Individual_Elo", "Avg_MassStart_Elo", "Avg_Pursuit_Elo", "Avg_Elo")
    pelo_cols <- c("Avg_Sprint_Pelo", "Avg_Individual_Pelo", "Avg_MassStart_Pelo", "Avg_Pursuit_Pelo", "Avg_Pelo")
    
    # Select needed columns from startlist
    result_cols <- c("Nation", elo_cols, race_prob_cols)
    result_df <- startlist %>%
      dplyr::select(any_of(result_cols))
    
    # Get recent points from historical data if available
    if("Points" %in% names(race_df)) {
      recent_points <- race_df %>%
        dplyr::filter(Nation %in% result_df$Nation) %>%
        group_by(Nation) %>%
        arrange(Season, Race) %>%
        slice_tail(n = 5) %>%
        summarise(
          Prev_Points_Weighted = if(n() > 0) 
            weighted.mean(Points, w = seq_len(n()), na.rm = TRUE) 
          else 0
        )
      
      # Add previous points if they exist
      if(nrow(recent_points) > 0) {
        result_df <- result_df %>%
          left_join(recent_points, by = "Nation") %>%
          mutate(Prev_Points_Weighted = replace_na(Prev_Points_Weighted, 0))
      } else {
        result_df$Prev_Points_Weighted <- 0
      }
    } else {
      # If no points in historical data
      result_df$Prev_Points_Weighted <- 0
    }
    
    # Set default values for missing Elo columns
    for(col in elo_cols) {
      if(!col %in% names(result_df)) {
        log_info(paste("Adding missing Elo column:", col))
        result_df[[col]] <- 0
      }
    }
  } else {
    # For individual races, use the original approach
    base_df <- startlist %>%
      dplyr::select(Skier, ID, Nation, Sex, all_of(race_prob_cols))
    
    # For individual races
    elo_cols <- c("Sprint_Elo", "Individual_Elo", "MassStart_Elo", "Pursuit_Elo", "Elo")
    pelo_cols <- c("Sprint_Pelo", "Individual_Pelo", "MassStart_Pelo", "Pursuit_Pelo", "Pelo")
    
    # Get most recent Elo values
    most_recent_elos <- race_df %>%
      dplyr::filter(Skier %in% base_df$Skier) %>%
      group_by(Skier) %>%
      arrange(Date, Season, Race) %>%
      slice_tail(n = 1) %>%
      ungroup() %>%
      dplyr::select(Skier, any_of(elo_cols))
    
    # Debug: Check elo columns
    log_info(paste("Available elo columns:", paste(names(most_recent_elos), collapse=", ")))
    
    # Get recent points for specific race type
    recent_points <- race_df %>%
      dplyr::filter(Skier %in% base_df$Skier) %>%
      group_by(Skier) %>%
      arrange(Season, Race) %>%
      slice_tail(n = 5) %>%
      summarise(
        Prev_Points_Weighted = if(n() > 0) 
          weighted.mean(Points, w = seq_len(n()), na.rm = TRUE) 
        else 0
      )
    
    # Combine all data
    result_df <- base_df %>%
      left_join(most_recent_elos, by = "Skier") %>%
      left_join(recent_points, by = "Skier")
  }
  
  # For both relay and individual: create Pelo percentage columns
  # Ensure we have all the required Pelo_Pct columns for model prediction
  for(i in seq_along(pelo_cols)) {
    pelo_pct_col <- paste0(pelo_cols[i], "_Pct")
    
    # First check if we have the corresponding Elo column to map from
    elo_col <- elo_cols[i]
    if(elo_col %in% names(result_df)) {
      # If we have race_df with this column, get max values for normalization
      if(elo_col %in% names(race_df)) {
        max_val <- max(race_df[[elo_col]], na.rm = TRUE)
        if(!is.na(max_val) && max_val > 0) {
          log_info(paste("Calculating", pelo_pct_col, "from", elo_col))
          result_df[[pelo_pct_col]] <- result_df[[elo_col]] / max_val
        } else {
          log_info(paste("Using default value for", pelo_pct_col, "(max value issue)"))
          result_df[[pelo_pct_col]] <- 0.5
        }
      } else {
        # If not available in race_df, normalize within the current dataset
        max_val <- max(result_df[[elo_col]], na.rm = TRUE)
        if(!is.na(max_val) && max_val > 0) {
          log_info(paste("Calculating", pelo_pct_col, "from", elo_col, "(internal max)"))
          result_df[[pelo_pct_col]] <- result_df[[elo_col]] / max_val
        } else {
          log_info(paste("Using default value for", pelo_pct_col, "(internal max issue)"))
          result_df[[pelo_pct_col]] <- 0.5
        }
      }
    } else if(!pelo_pct_col %in% names(result_df)) {
      # If we don't have the Elo column and the PCT doesn't exist yet
      log_info(paste("Creating missing Pelo Pct column:", pelo_pct_col))
      result_df[[pelo_pct_col]] <- 0.5  # Default to 0.5 (middle value)
    }
  }
  
  # Replace NAs with first quartile
  result_df <- result_df %>%
    mutate(
      across(
        ends_with("_Pct"),
        ~replace_na_with_quartile(.x)
      ),
      Prev_Points_Weighted = replace_na(Prev_Points_Weighted, 0)
    )
  
  # Check race probability columns in result
  for(col in race_prob_cols) {
    if(!is.null(result_df[[col]])) {
      log_info(paste("Race probability column", col, "summary:"))
      log_info(paste("  Mean:", mean(result_df[[col]], na.rm = TRUE)))
      log_info(paste("  Sum:", sum(result_df[[col]], na.rm = TRUE)))
      log_info(paste("  Max:", max(result_df[[col]], na.rm = TRUE)))
    } else {
      log_warn(paste("Race probability column", col, "is missing from result_df!"))
    }
  }
  
  # Ensure result_df has all the columns needed by the model
  log_info(paste("Final columns in result_df:", paste(names(result_df), collapse=", ")))
  
  return(result_df)
}

# Function to get points based on place
get_points <- function(place, RaceType) {
  points_list <- if(RaceType == "MassStart") mass_start_points else regular_points
  
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

# Normalization function for position probabilities
# Normalization function for position probabilities
normalize_position_probabilities <- function(predictions, race_prob_col, position_thresholds) {
  # Make a copy to avoid modifying the original data frame
  normalized <- predictions
  
  # Log initial sums before any modifications
  log_info("Position probability sums BEFORE normalization:")
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    if(prob_col %in% names(normalized)) {
      initial_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
      log_info(sprintf("  %s: %.2f%% (target: %d%%)", 
                       prob_col, initial_sum, 100 * threshold))
    }
  }
  
  # For each threshold, adjust and normalize probabilities
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    
    # First, adjust by race participation probability
    if(race_prob_col %in% names(normalized)) {
      # Log sum before race probability adjustment
      sum_before_race_adj <- sum(normalized[[prob_col]], na.rm = TRUE)
      
      # Apply race probability adjustment
      normalized[[prob_col]] <- normalized[[prob_col]] * normalized[[race_prob_col]]
      
      # Log sum after race probability adjustment
      sum_after_race_adj <- sum(normalized[[prob_col]], na.rm = TRUE)
      log_info(sprintf("  %s after race prob adjustment: %.2f%% (scaling by race participation)", 
                       prob_col, sum_after_race_adj))
    }
    
    # Calculate the current sum
    current_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
    
    # Target sum should be 100 * threshold (e.g., 100% for top 1, 300% for top 3)
    target_sum <- 100 * threshold
    
    # Normalize only if current sum is not zero to avoid division by zero
    if(current_sum > 0) {
      # Apply scaling factor to adjust the probabilities
      scaling_factor <- target_sum / current_sum
      normalized[[prob_col]] <- normalized[[prob_col]] * scaling_factor
      
      # Cap individual probabilities at 100%
      over_hundred <- which(normalized[[prob_col]] > 100)
      if(length(over_hundred) > 0) {
        log_info(sprintf("  Capping %d participants with >100%% probability for %s", 
                         length(over_hundred), prob_col))
        
        # Calculate excess probability that needs to be redistributed
        excess <- sum(normalized[[prob_col]][over_hundred] - 100)
        
        # Cap values at 100%
        normalized[[prob_col]][over_hundred] <- 100
        
        # Redistribute the excess to other participants proportionally
        under_hundred <- which(normalized[[prob_col]] < 100)
        if(length(under_hundred) > 0 && excess > 0) {
          # Get current sum of under-100 probabilities
          under_sum <- sum(normalized[[prob_col]][under_hundred])
          
          # Calculate scaling factor for redistribution
          if(under_sum > 0) {
            redistrib_factor <- (under_sum + excess) / under_sum
            normalized[[prob_col]][under_hundred] <- normalized[[prob_col]][under_hundred] * redistrib_factor
            
            # Recursively cap again if needed (unlikely but possible)
            if(any(normalized[[prob_col]][under_hundred] > 100)) {
              log_info("  Recursive capping needed after redistribution")
              # This is a simplification - in practice you might want a more robust approach
              normalized[[prob_col]][normalized[[prob_col]] > 100] <- 100
            }
          }
        }
      }
      
      log_info(sprintf("  %s normalization: applied scaling factor of %.4f", 
                       prob_col, scaling_factor))
    } else {
      # If sum is zero, distribute evenly among all participants
      # This is a fallback that should rarely be needed
      log_warn(paste("Zero sum for", prob_col, "- distributing evenly"))
      normalized[[prob_col]] <- target_sum / nrow(normalized)
    }
    
    # Final check to ensure we're close to the target sum
    final_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
    if(abs(final_sum - target_sum) > 1) {  # Allow for small rounding differences
      log_warn(sprintf("  %s sum after capping: %.2f%% (target: %.2f%%)", 
                       prob_col, final_sum, target_sum))
    }
  }
  
  # Log final sums after all adjustments
  log_info("Position probability sums AFTER normalization:")
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    if(prob_col %in% names(normalized)) {
      final_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
      log_info(sprintf("  %s: %.2f%% (target: %d%%)", 
                       prob_col, final_sum, 100 * threshold))
    }
  }
  
  # Return normalized probabilities
  return(normalized)
}

# Helper function to format position probability results - fixed version
format_position_results <- function(position_results, next_weekend_date, gender, is_relay = FALSE, relay_type = NULL) {
  # Create a more reader-friendly version
  participant_col <- if(is_relay) "Nation" else "Skier"
  
  # Use standard R operations for adding columns
  formatted_results <- position_results
  
  # Add participation and probability columns
  formatted_results$Participation <- NA_real_
  formatted_results$Win <- NA_real_
  formatted_results$Podium <- NA_real_
  formatted_results$Top5 <- NA_real_
  formatted_results$Top10 <- NA_real_
  formatted_results$Top30 <- NA_real_
  
  # Process row by row instead of using rowwise()
  for(i in 1:nrow(formatted_results)) {
    race_num <- formatted_results$Race[i]
    race_prob_col <- paste0("Race", race_num, "_Prob")
    
    if(race_prob_col %in% names(position_results)) {
      formatted_results$Participation[i] <- position_results[[race_prob_col]][i]
    }
    
    formatted_results$Win[i] <- position_results$prob_top1[i]
    formatted_results$Podium[i] <- position_results$prob_top3[i]
    formatted_results$Top5[i] <- position_results$prob_top5[i]
    formatted_results$Top10[i] <- position_results$prob_top10[i]
    formatted_results$Top30[i] <- position_results$prob_top30[i]
  }
  
  # Select columns without sym()
  select_cols <- c(participant_col)
  if(!is_relay) {
    select_cols <- c(select_cols, "ID", "Nation", "Sex")
  }
  select_cols <- c(select_cols, "Race", "Participation", "Win", "Podium", "Top5", "Top10", "Top30")
  
  formatted_results <- formatted_results[, select_cols]
  
  # Sort results by Race and Win
  formatted_results <- formatted_results[order(formatted_results$Race, -formatted_results$Win),]
  
  weekend_folder <- format(next_weekend_date, "%Y%m%d")
  dir_path <- paste0(
    "~/blog/daehl-e/content/post/biathlon/drafts/weekly-picks/", 
    weekend_folder
  )
  
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  # Split by race
  races <- unique(formatted_results$Race)
  race_dfs <- list()
  
  for(race_num in races) {
    race_df <- formatted_results[formatted_results$Race == race_num, ]
    race_df <- race_df[, colnames(race_df) != "Race"]  # Remove Race column
    
    if(is_relay) {
      # Relay sheet naming
      relay_prefix <- if(is.null(relay_type)) "Relay" else relay_type
      sheet_name <- paste0(relay_prefix, " Race ", race_num)
    } else {
      # Individual race sheet naming
      sheet_name <- paste0(
        ifelse(gender == "men", "Men", "Ladies"),
        " Race ", race_num
      )
    }
    
    race_dfs[[sheet_name]] <- race_df
  }
  
  # Save to Excel
  if(is_relay) {
    relay_type_short <- if(is.null(relay_type)) "relay" else gsub(" ", "_", tolower(relay_type))
    output_file <- file.path(
      dir_path,
      paste0(ifelse(is.null(gender), "", paste0(gender, "_")), 
             relay_type_short, "_position_probabilities.xlsx")
    )
  } else {
    output_file <- file.path(
      dir_path,
      paste0(ifelse(gender == "men", "men", "ladies"), "_position_probabilities.xlsx")
    )
  }
  
  write.xlsx(race_dfs, output_file)
  
  log_info(paste("Formatted position probabilities saved to", output_file))
  
  return(race_dfs)
}

# Function to create top contenders summary for biathlon - fixed version
create_top_contenders_summary <- function(results_list, next_weekend_date) {
  weekend_folder <- format(next_weekend_date, "%Y%m%d")
  dir_path <- paste0(
    "~/blog/daehl-e/content/post/biathlon/drafts/weekly-picks/", 
    weekend_folder
  )
  
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  top_contenders <- list()
  
  # Process each result set
  for(result_name in names(results_list)) {
    # Skip if this result doesn't have position predictions
    if(!("position_predictions" %in% names(results_list[[result_name]]))) {
      next
    }
    
    position_data <- results_list[[result_name]]$position_predictions
    
    # Determine if this is a relay result
    is_relay <- grepl("relay", result_name)
    participant_col <- if(is_relay) "Nation" else "Skier"
    
    # Get races
    races <- unique(position_data$Race)
    
    # Format the display name
    display_name <- result_name
    if(result_name == "men") display_name <- "Men"
    else if(result_name == "ladies") display_name <- "Ladies"
    else if(result_name == "men_relay") display_name <- "Men Relay"
    else if(result_name == "ladies_relay") display_name <- "Ladies Relay"
    else if(result_name == "mixed_relay") display_name <- "Mixed Relay"
    else if(result_name == "single_mixed_relay") display_name <- "Single Mixed Relay"
    
    for(race_num in races) {
      race_df <- position_data[position_data$Race == race_num, ]
      
      # Top 5 for win probability
      win_order <- order(-race_df$prob_top1)
      win_contenders <- race_df[win_order[1:min(5, length(win_order))], ]
      
      if(!is_relay) {
        win_contenders <- win_contenders[, c(participant_col, "Nation", "prob_top1")]
      } else {
        win_contenders <- win_contenders[, c(participant_col, "prob_top1")]
      }
      
      names(win_contenders)[names(win_contenders) == "prob_top1"] <- "Win%"
      
      sheet_name <- paste0(display_name, " Race ", race_num, " - Win")
      top_contenders[[sheet_name]] <- win_contenders
      
      # Top 5 for podium probability
      podium_order <- order(-race_df$prob_top3)
      podium_contenders <- race_df[podium_order[1:min(5, length(podium_order))], ]
      
      if(!is_relay) {
        podium_contenders <- podium_contenders[, c(participant_col, "Nation", "prob_top3")]
      } else {
        podium_contenders <- podium_contenders[, c(participant_col, "prob_top3")]
      }
      
      names(podium_contenders)[names(podium_contenders) == "prob_top3"] <- "Podium%"
      
      sheet_name <- paste0(display_name, " Race ", race_num, " - Podium")
      top_contenders[[sheet_name]] <- podium_contenders
      
      # Top 5 for Top-5 probability
      top5_order <- order(-race_df$prob_top5)
      top5_contenders <- race_df[top5_order[1:min(5, length(top5_order))], ]
      
      if(!is_relay) {
        top5_contenders <- top5_contenders[, c(participant_col, "Nation", "prob_top5")]
      } else {
        top5_contenders <- top5_contenders[, c(participant_col, "prob_top5")]
      }
      
      names(top5_contenders)[names(top5_contenders) == "prob_top5"] <- "Top5%"
      
      sheet_name <- paste0(display_name, " Race ", race_num, " - Top5")
      top_contenders[[sheet_name]] <- top5_contenders
    }
  }
  
  # Save to Excel
  output_file <- file.path(dir_path, "biathlon_top_contenders.xlsx")
  write.xlsx(top_contenders, output_file)
  
  log_info(paste("Biathlon top contenders summary saved to", output_file))
  
  return(top_contenders)
}
# Preprocessing function for historical race data
preprocess_data <- function(df, is_relay = FALSE) {
  # Load weekends data to determine points systems for historical races
  weekends_data <- read.csv("~/ski/elo/python/biathlon/polars/excel365/weekends.csv", 
                            stringsAsFactors = FALSE) %>%
    mutate(Date = as.Date(Date, format="%Y-%m-%d"))
  
  participant_col <- if(is_relay) "Nation" else "Skier"
  id_col <- if(is_relay) "Nation" else "ID"
  
  # For relay data, we want to keep the team structure
  if(is_relay) {
    log_info("Processing relay data - using team-based metrics")
    
    # Define the relay-specific columns we expect/need (without relay-specific PELOs)
    relay_cols <- c("Avg_Sprint_Elo", "Avg_Individual_Elo", "Avg_MassStart_Elo", "Avg_Pursuit_Elo", "Avg_Elo",
                    "Avg_Sprint_Pelo", "Avg_Individual_Pelo", "Avg_MassStart_Pelo", "Avg_Pursuit_Pelo", "Avg_Pelo")
    # Check which columns exist and create missing ones
    for(col in relay_cols) {
      if(!col %in% names(df)) {
        log_info(paste("Creating missing relay column:", col))
        # If we're missing a column but have the corresponding base column without Avg_
        base_col <- gsub("^Avg_", "", col)
        if(base_col %in% names(df)) {
          log_info(paste("Using base column", base_col, "to create", col))
          df[[col]] <- df[[base_col]]
        } else {
          df[[col]] <- 0
        }
      }
    }
  }
  
  # First calculate points using data with appropriate points system
  df_with_points <- df %>%
    # Add points based on the race type if they don't already exist
    mutate(
      Points = if("Points" %in% names(df)) {
        Points
      } else {
        mapply(function(place, RaceType) {
          get_points(place, RaceType)
        }, Place, RaceType)
      }
    ) %>%
    # Sort
    arrange(Season, Race, Place)

  # Calculate weighted previous points separately for each race type
  df_with_points <- df_with_points %>%
    # Group by ID and race type
    group_by(!!sym(id_col), RaceType) %>%
    arrange(Season, Race) %>%
    mutate(Prev_Points_Weighted = sapply(1:n(), function(j) {
      if (j == 1) return(0)
      start_index <- max(1, j - 5)
      num_races <- j - start_index
      weights <- seq(1, num_races)
      weighted.mean(Points[start_index:(j-1)], w = weights, na.rm = TRUE)
    })) %>%
    ungroup()
  
  # Check if Pelo columns exist, if not create them
  if(is_relay) {
    pelo_cols <- c("Avg_Sprint_Pelo", "Avg_Individual_Pelo", "Avg_MassStart_Pelo", "Avg_Pursuit_Pelo", "Avg_Pelo")
  } else {
    pelo_cols <- c("Sprint_Pelo", "Individual_Pelo", "MassStart_Pelo", "Pursuit_Pelo", "Pelo")
  }
  
  # Make sure these columns exist (create if missing)
  for (col in pelo_cols) {
    if (!col %in% names(df_with_points)) {
      log_info(paste("Creating missing column:", col))
      df_with_points[[col]] <- 0
    }
  }
  
  # Now apply other preprocessing steps and dplyr::filter for recent data
  processed_df <- df_with_points %>%
    # Add period (biathlon has 4 periods per season)
    group_by(Season) %>%
    mutate(
      Num_Races = max(Race),
      Period = case_when(
        Num_Races <= 5 ~ 1,
        Num_Races <= 10 ~ 2,
        Num_Races <= 15 ~ 3,
        TRUE ~ 4
      )
    ) %>%
    ungroup() %>%
    # Add elevation flag (0 if below 1300m, 1 if above)
    mutate(
      Elevation_Flag = ifelse(Elevation >= 1300, 1, 0)
    ) %>%
    # dplyr::filter relevant races and add cumulative points
    dplyr::filter(
      Season >= max(Season-10)
    ) %>%
    group_by(!!sym(id_col), Season) %>%
    mutate(Cumulative_Points = cumsum(Points)) %>%
    ungroup() %>%
    # Handle NAs and calculate percentages
    group_by(Season, Race) %>%
    mutate(
      across(
        all_of(pelo_cols),
        ~replace_na_with_quartile(.x)
      )
    ) %>%
    # Calculate percentages for each Pelo column
    mutate(
      across(
        all_of(pelo_cols),
        ~{
          max_val <- max(.x, na.rm = TRUE)
          if (max_val == 0) return(rep(0, length(.x)))
          .x / max_val
        },
        .names = "{.col}_Pct"
      )
    ) %>%
    ungroup()
  
  # Ensure all required Pelo_Pct columns exist
  pct_cols <- paste0(pelo_cols, "_Pct")
  for (col in pct_cols) {
    if (!col %in% names(processed_df)) {
      log_info(paste("Creating missing percentage column:", col))
      processed_df[[col]] <- 0
    }
  }
  
  log_info(paste("Preprocessing complete - final dimensions:", nrow(processed_df), "x", ncol(processed_df)))
  log_info(paste("Final columns:", paste(names(processed_df)[1:min(10, length(names(processed_df)))], collapse=", "), "..."))
  
  return(processed_df)
}

create_post_predictions <- function(final_predictions, n_races, gender=NULL, is_relay = FALSE) {
  # Select columns dynamically based on number of races
  participant_col <- if(is_relay) "Nation" else "Skier"
  
  select_cols <- c(participant_col)
  
  if(!is_relay) {
    select_cols <- c(select_cols, "ID", "Nation")
    if("Sex" %in% names(final_predictions)) {
      select_cols <- c(select_cols, "Sex")  # Include Sex if it exists
    }
  }
  
  for(i in 1:n_races) {
    select_cols <- c(select_cols,
                     paste0("Race", i, "_Points"),
                     paste0("Race", i, "_Probability"))
  }
  select_cols <- c(select_cols, "Total_Points")
  
  post_predictions <- final_predictions %>%
    dplyr::select(all_of(select_cols)) %>%
    # Add Sex if not present and not a relay
    mutate(
      Sex = if(!is_relay && "Sex" %in% names(.)) {
        Sex  # Use existing Sex column
      } else if(!is_relay) {
        ifelse(gender == "men", "M", "L")  # Fallback
      } else {
        NULL  # No Sex for relays
      }
    )
  
  # Make sure Sex is in the right position for individuals (after Nation)
  if(!is_relay) {
    post_predictions <- post_predictions %>%
      dplyr::select(Skier, ID, Nation, Sex, everything())
  }
  
  # Arrange by total points
  post_predictions <- post_predictions %>%
    arrange(desc(Total_Points))
  
  # Replace underscores with spaces in column names
  post_predictions <- post_predictions %>%
    rename_with(~ gsub("_", " ", .x), .cols = contains("_"))
  
  return(post_predictions)
}

# Predict races function with support for relay races
# Modified predict_races function with position probability
predict_races <- function(gender, is_relay = FALSE, relay_type = NULL, startlist_override = NULL) {
  # Add logging for the startlist_override
  if(!is.null(startlist_override)) {
    log_info(paste("Using provided startlist_override with", nrow(startlist_override), "entries"))
  }
  
  # Determine the race type and paths based on gender and is_relay
  if(is_relay) {
    participant_col <- "Nation"
    
    # Define races variable based on relay_type FIRST
    if(relay_type == "Relay") {
      if(gender == "men") {
        races <- men_relays
        log_info(paste("Using men's relay races:", nrow(races), "races found"))
      } else if(gender == "ladies") {
        races <- ladies_relays
        log_info(paste("Using ladies' relay races:", nrow(races), "races found"))
      } else {
        races <- relays
        log_info(paste("Using all relay races:", nrow(races), "races found"))
      }
      
      log_info(paste("Using relay races:", nrow(races), "races found"))
      
      # Set chrono_path based on gender, regardless of startlist override
      if(gender == "men") {
        chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/men_relay_chrono.csv"
        log_info("Using men's relay chronological data")
      } else {
        chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/ladies_relay_chrono.csv"
        log_info("Using ladies' relay chronological data")
      }
    } else if(relay_type == "Mixed Relay") {
      races <- mixed_relays
      chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/mixed_relay_chrono.csv"
      log_info(paste("Using mixed relay races:", nrow(races), "races found"))
    } else if(relay_type == "Single Mixed Relay") {
      races <- single_mixed_relays
      chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/single_mixed_relay_chrono.csv"
      log_info(paste("Using single mixed relay races:", nrow(races), "races found"))
    } else {
      races <- relays
      # Default chrono path
      if(gender == "men") {
        chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/men_relay_chrono.csv"
      } else {
        chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/ladies_relay_chrono.csv"
      }
      log_info(paste("Using default relay races:", nrow(races), "races found"))
    }
    
    # Now handle startlist selection - separate from chrono_path selection
    if(!is.null(startlist_override)) {
      startlist <- startlist_override
    } else if(relay_type == "Relay") {
      if(gender == "men") {
        startlist <- men_relay_startlist
        log_info("Processing men's relay data")
      } else {
        startlist <- ladies_relay_startlist
        log_info("Processing ladies' relay data")
      }
    } else if(relay_type == "Mixed Relay") {
      startlist <- mixed_relay_startlist
      log_info("Processing mixed relay data")
    } else if(relay_type == "Single Mixed Relay") {
      startlist <- single_mixed_relay_startlist
      log_info("Processing single mixed relay data")
    } else {
      # Default relay handling if relay_type not specified
      log_warn("No relay type specified, using default settings")
      if(gender == "men") {
        startlist <- men_relay_startlist
      } else {
        startlist <- ladies_relay_startlist
      }
    }
  } else {
    # Individual race handling
    # Set races variable first
    if(gender == "men") {
      races <- men_races
      chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/men_chrono_elevation.csv"
      log_info(paste("Using men's races:", nrow(races), "races found"))
    } else {
      races <- ladies_races
      chrono_path <- "~/ski/elo/python/biathlon/polars/relay/excel365/ladies_chrono_elevation.csv"
      log_info(paste("Using ladies' races:", nrow(races), "races found"))
    }
    
    # Then handle startlist - separate from chrono_path
    if(!is.null(startlist_override)) {
      startlist <- startlist_override
    } else if(gender == "men") {
      startlist <- men_startlist
    } else {
      startlist <- ladies_startlist
    }
    participant_col <- "Skier"
  }
  
  # Log the size of the startlist to track if it's being modified
  log_info(paste("Selected startlist has", nrow(startlist), "entries"))
  log_info(paste("Using chronological data from:", chrono_path))
  
  # Check if races variable is defined and non-empty
  if(!exists("races") || nrow(races) == 0) {
    log_error("No races found for this race type")
    return(NULL)
  }
  
  # Load chronological data
  log_info(paste("Loading chronological data from", chrono_path))
  
  # Handle the fact that some chrono files might not exist yet
  # Create a fallback mechanism for relay chronos
  if(is_relay) {
    tryCatch({
      # Try to read the specified chrono file
      df <- read.csv(chrono_path, stringsAsFactors = FALSE) %>%
        mutate(Date = as.Date(Date)) %>%
        preprocess_data(is_relay = TRUE)
      
      log_info(paste("Successfully read relay chrono data from", chrono_path, 
                     "with", nrow(df), "rows"))
    }, error = function(e) {
      log_warn(paste("Error reading relay chrono file:", e$message))
      log_info("Creating a synthetic relay chronology from the startlist")
      
      # If we can't read the chrono file, create a minimal chronology from the startlist
      # This allows the prediction code to run even if historical team data is missing
      
      # First check if we have a valid startlist
      if(is.null(startlist) || nrow(startlist) == 0) {
        log_error("No startlist available for creating synthetic relay chronology")
        stop("Cannot proceed without chronology or startlist data")
      }
      
      # Create a minimal chronology from the startlist - using <- not <<-
      df <- startlist %>%
        dplyr::select(Nation, 
                      # Include any average Elo columns that exist
                      matches("^Avg_.+_Elo$")) %>%
        # Add minimum required columns for the prediction pipeline
        mutate(
          Date = Sys.Date() - 30,  # Use a recent date
          Season = as.integer(format(Sys.Date(), "%Y")),  # Current year as integer
          Race = 1,
          Place = row_number(),  # Rank teams by their order in the startlist
          City = "Unknown",
          Country = "Unknown",  # Add Country column which is often needed
          Event = "World Cup",
          Elevation = 1000,  # Default value
          RaceType = relay_type,  # String value is fine here
          Points = 0,
          MassStart = 0,  # Add MassStart flag commonly needed
          Elevation_Flag = ifelse(Elevation >= 1300, 1, 0)  # Add Elevation_Flag
        ) %>%
        preprocess_data(is_relay = TRUE)
      
      log_info(paste("Created synthetic relay chronology with", nrow(df), "teams"))
      return(df)  # Return the created dataframe from the error handler
    })
  } else {
    # Standard individual race handling
    df <- read.csv(chrono_path, stringsAsFactors = FALSE) %>%
      mutate(Date = as.Date(Date)) %>%
      preprocess_data(is_relay = is_relay)
  }
  
  # For debugging
  log_info(paste("Chronological data dimensions:", nrow(df), "x", ncol(df)))
  log_info(paste("First few columns:", paste(names(df)[1:min(10, length(names(df)))], collapse=", ")))
  
  # Initialize results list
  race_predictions <- list()
  race_dfs <- list()
  
  # Initialize position predictions list
  position_predictions <- list()
  
  # Define position thresholds
  position_thresholds <- c(1, 3, 5, 10, 30)  # Win, Podium, Top 5, Top 10, Top 30
  
  # Debug: Show race probability columns in startlist
  race_prob_cols <- grep("^Race\\d+_Prob$", names(startlist), value = TRUE)
  log_info(paste("Race probability columns in startlist:", paste(race_prob_cols, collapse=", ")))
  
  # Process each race
  for(i in 1:nrow(races)) {
    log_info(sprintf("Processing %s race %d: %s", 
                     if(is_relay) "relay" else gender, 
                     i, races$racetype[i]))
    
    # Get race probability column name for this race
    race_prob_col <- paste0("Race", i, "_Prob")
    
    race_info <- next_weekend_races %>%
      dplyr::filter(if(is_relay) {
        RaceType %in% c("Relay", "Mixed Relay", "Single Mixed Relay")
      } else {
        Sex == ifelse(gender == "men", "M", "L")
      }) %>%
      dplyr::slice(i)
    
    # Use the appropriate points system
    points_system <- if(races$racetype[i] == "MassStart") mass_start_points else regular_points
    
    log_info(paste("Using World Cup points for this race"))
    
    # Debug: Check if this race probability column exists in startlist
    if(race_prob_col %in% names(startlist)) {
      log_info(paste("Race probability column", race_prob_col, "exists in startlist"))
      # Show some stats
      log_info(paste("  Mean:", mean(startlist[[race_prob_col]], na.rm = TRUE)))
      log_info(paste("  Sum:", sum(startlist[[race_prob_col]], na.rm = TRUE)))
    } else {
      log_warn(paste("Race probability column", race_prob_col, "NOT FOUND in startlist!"))
    }
    
    # Filter base dataset for race type
    race_df <- df %>%
      dplyr::filter(RaceType == races$racetype[i])
    
    # Get relevant Pelo column based on race type
    if(is_relay) {
      # For relay races, use general average PELO
      pelo_col <- "Avg_Pelo_Pct"
    } else {
      if(races$racetype[i] == "Sprint") {
        pelo_col <- "Sprint_Pelo_Pct"
      } else if(races$racetype[i] == "Individual") {
        pelo_col <- "Individual_Pelo_Pct"
      } else if(races$racetype[i] == "MassStart") {
        pelo_col <- "MassStart_Pelo_Pct"
      } else if(races$racetype[i] == "Pursuit") {
        pelo_col <- "Pursuit_Pelo_Pct"
      } else {
        pelo_col <- "Pelo_Pct"
      }
    }
    
    # Filter for top performers and add previous points
    race_df_75 <- race_df %>%
      dplyr::filter(get(pelo_col) > 0.75) %>%
      group_by(!!sym(participant_col)) %>%
      arrange(Season, Race) %>%
      ungroup()
    
    # Feature selection and model fitting for points prediction
    response_variable <- "Points"
    
    # Define explanatory variables based on race type
    if(is_relay) {
      explanatory_vars <- c("Avg_Sprint_Pelo_Pct", "Avg_Individual_Pelo_Pct", 
                            "Avg_MassStart_Pelo_Pct", "Avg_Pursuit_Pelo_Pct", 
                            "Avg_Pelo_Pct")
    } else {
      explanatory_vars <- c("Prev_Points_Weighted", 
                            "Sprint_Pelo_Pct", "Individual_Pelo_Pct", 
                            "MassStart_Pelo_Pct", "Pursuit_Pelo_Pct", 
                            "Pelo_Pct", "Period", "Elevation_Flag")
    }
    
    # Create and fit model for points
    formula <- as.formula(paste(response_variable, "~", paste(explanatory_vars, collapse = " + ")))
    tryCatch({
      exhaustive_selection <- regsubsets(formula, data = race_df_75, nbest = 1, method = "exhaustive")
      summary_exhaustive <- summary(exhaustive_selection)
      best_bic_vars <- names(coef(exhaustive_selection, which.min(summary_exhaustive$bic)))
      smooth_terms <- paste("s(", best_bic_vars[-1], ")", collapse=" + ")
      gam_formula <- as.formula(paste("Points ~", smooth_terms))
      
      model <- gam(gam_formula, data = race_df_75)
    }, error = function(e) {
      log_warn(paste("Error in model selection:", e$message))
      # Fallback to a simpler model
      fallback_formula <- as.formula(paste("Points ~ s(", pelo_col, ") + s(Period) + s(Elevation_Flag)"))
      model <<- gam(fallback_formula, data = race_df_75)
    })
    
    # Calculate adjustments for historical data step by step
    race_df_75 <- race_df_75 %>%
      arrange(Date) %>%
      group_by(!!sym(participant_col)) %>%
      mutate(
        row_id = row_number()
      ) %>%
      ungroup() %>%
      # Step 1: Initial predictions
      mutate(
        Initial_Prediction = predict(model, newdata = .)
      ) %>%
      group_by(!!sym(participant_col)) %>%
      mutate(
        Prediction_Diff = Points - Initial_Prediction
      ) %>%
      # Step 2: Calculate Period adjustments
      mutate(
        period_p = purrr::map_dbl(row_id, function(r) {
          if(r <= 1) return(1)
          prior_period_curr <- Prediction_Diff[Period == Period[r] & row_id < r]
          prior_period_other <- Prediction_Diff[Period != Period[r] & row_id < r]
          if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
          tryCatch({
            t.test(prior_period_curr, prior_period_other)$p.value
          }, error = function(e) 1)
        }),
        period_correction = ifelse(period_p < 0.05,
                                   mean(Prediction_Diff[Period == Period], na.rm = TRUE),
                                   0),
        
        # Step 3: Calculate Elevation adjustments
        elevation_p = purrr::map_dbl(row_id, function(r) {
          if(r <= 1) return(1)
          prior_elev_curr <- Prediction_Diff[Elevation_Flag == Elevation_Flag[r] & row_id < r]
          prior_elev_other <- Prediction_Diff[Elevation_Flag != Elevation_Flag[r] & row_id < r]
          if(length(prior_elev_curr) < 3 || length(prior_elev_other) < 3) return(1)
          tryCatch({
            t.test(prior_elev_curr, prior_elev_other)$p.value
          }, error = function(e) 1)
        }),
        elevation_correction = ifelse(elevation_p < 0.05,
                                      mean(Prediction_Diff[Elevation_Flag == Elevation_Flag], na.rm = TRUE),
                                      0),
        
        # Combine adjustments
        Adjusted_Prediction = Initial_Prediction + period_correction + elevation_correction
      ) %>%
      ungroup()
    
    # NEW CODE: Create position probability models using the same variables as points model
    position_models <- list()
    position_adjustments <- list()  # To store adjustments for each threshold
    
    # Feature selection - use the same explanatory variables as the points model
    position_feature_vars <- explanatory_vars
    
    # Create models for each position threshold
    for(threshold in position_thresholds) {
      log_info(paste("Creating model for top", threshold, "positions"))
      
      # Create binary outcome variable for position threshold
      race_df$position_achieved <- race_df$Place <= threshold
      
      # Create formula for regsubsets using the same explanatory variables as the points model
      pos_formula <- as.formula(paste("position_achieved ~", paste(position_feature_vars, collapse = " + ")))
      
      # Use regsubsets to select best features for this position threshold
      tryCatch({
        pos_selection <- regsubsets(pos_formula, data = race_df, nbest = 1, method = "exhaustive")
        pos_summary <- summary(pos_selection)
        pos_best_bic_vars <- names(coef(pos_selection, which.min(pos_summary$bic)))
        
        # Create smooth terms for GAM using best BIC variables (remove intercept)
        pos_smooth_terms <- paste("s(", pos_best_bic_vars[-1], ")", collapse=" + ")
        pos_gam_formula <- as.formula(paste("position_achieved ~", pos_smooth_terms))
        
        # Fit the position model with binomial family
        position_model <- gam(pos_gam_formula,
                              data = race_df,
                              family = binomial,
                              method = "REML")
        
        # Calculate Brier score for model evaluation
        predicted_probs <- predict(position_model, newdata = race_df, type = "response")
        brier_score <- mean((race_df$position_achieved - predicted_probs)^2, na.rm = TRUE)
        log_info(paste("Brier score for threshold", threshold, ":", round(brier_score, 4)))
        
        # Log selected variables
        log_info(paste("Variables selected for", threshold, "position model:", 
                       paste(pos_best_bic_vars[-1], collapse=", ")))
        
        # Store the model
        position_models[[paste0("threshold_", threshold)]] <- position_model
        
        # Calculate adjustments for period for this threshold
        position_df <- race_df %>%
          arrange(Date) %>%
          group_by(!!sym(participant_col)) %>%
          mutate(
            row_id = row_number()
          ) %>%
          ungroup()
        
        # Add predictions separately (outside of mutate)
        position_df$initial_prob <- predict(position_model, newdata = position_df, type = "response")
        
        # Continue with period adjustment calculations
        position_df <- position_df %>%
          group_by(!!sym(participant_col)) %>%
          mutate(
            prob_diff = as.numeric(position_achieved) - initial_prob,
            
            # Calculate period adjustments
            period_p = purrr::map_dbl(row_id, function(r) {
              if(r <= 1) return(1)
              prior_period_curr <- prob_diff[Period == Period[r] & row_id < r]
              prior_period_other <- prob_diff[Period != Period[r] & row_id < r]
              if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
              tryCatch({
                t.test(prior_period_curr, prior_period_other)$p.value
              }, error = function(e) 1)
            }),
            period_correction = ifelse(period_p < 0.05,
                                       mean(prob_diff[Period == Period], na.rm = TRUE),
                                       0),
            period_adjusted = pmin(pmax(initial_prob + period_correction, 0), 1)
          ) %>%
          ungroup()
        
        # Get final adjustments for each participant
        skier_pos_adjustments <- position_df %>%
          group_by(!!sym(participant_col)) %>%
          summarise(
            period_effect = last(period_correction)
          )
        
        # Store adjustments for this threshold
        position_adjustments[[paste0("threshold_", threshold)]] <- skier_pos_adjustments
        
      }, error = function(e) {
        log_warn(paste("Error in position model for threshold", threshold, ":", e$message))
        
        # Create a simpler fallback model with just the pelo column
        fallback_vars <- c("Prev_Points_Weighted", pelo_col)
        fallback_vars <- fallback_vars[fallback_vars %in% names(race_df)]
        
        if(length(fallback_vars) > 0) {
          fallback_terms <- paste("s(", fallback_vars, ")", collapse=" + ")
          fallback_formula <- as.formula(paste("position_achieved ~", fallback_terms))
          
          position_models[[paste0("threshold_", threshold)]] <- gam(
            fallback_formula,
            data = race_df,
            family = binomial,
            method = "REML"
          )
          
          # Create empty adjustments object since we can't calculate them for the fallback model
          empty_adjustments <- data.frame(x = unique(race_df[[participant_col]]))
          names(empty_adjustments)[1] <- participant_col
          empty_adjustments$period_effect <- 0
          position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
          
          log_info(paste("Created fallback model for threshold", threshold, 
                         "using variables:", paste(fallback_vars, collapse=", ")))
        } else {
          # Last resort fallback - just use the pelo column
          fallback_formula <- as.formula(paste("position_achieved ~ s(", pelo_col, ")"))
          position_models[[paste0("threshold_", threshold)]] <- gam(
            fallback_formula,
            data = race_df,
            family = binomial,
            method = "REML"
          )
          
          # Create empty adjustments object
          empty_adjustments <- data.frame(x = unique(race_df[[participant_col]]))
          names(empty_adjustments)[1] <- participant_col
          empty_adjustments$period_effect <- 0
          position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
          
          log_info(paste("Created last-resort fallback model for threshold", threshold, 
                         "using only", pelo_col))
        }
      })
    }
    
    # Calculate volatility metrics using recent races
    race_df_75 <- race_df_75 %>%
      group_by(!!sym(participant_col)) %>%
      arrange(Date) %>%  # Ensure chronological order
      mutate(
        # Create rolling window calculations for last 10 races
        recent_prediction_volatility = slider::slide_dbl(
          Points - Initial_Prediction,
          sd,
          .before = 9,  # Look at current race plus 9 previous
          .complete = FALSE  # Allow partial windows
        ),
        
        recent_consistency_score = slider::slide_dbl(
          abs(Points - Initial_Prediction),
          mean,
          .before = 9,
          .complete = FALSE
        ),
        
        recent_upside_potential = slider::slide_dbl(
          Points - Initial_Prediction,
          ~quantile(.x, 0.9, na.rm = TRUE),
          .before = 9,
          .complete = FALSE
        ),
        
        recent_downside_risk = slider::slide_dbl(
          Points - Initial_Prediction,
          ~quantile(.x, 0.1, na.rm = TRUE),
          .before = 9,
          .complete = FALSE
        )
      ) %>%
      mutate(
        recent_volatility_ratio = recent_upside_potential / abs(recent_downside_risk)
      ) %>%
      ungroup()
    
    # Get final adjustments for each participant
    skier_adjustments <- race_df_75 %>%
      group_by(!!sym(participant_col)) %>%
      summarise(
        period_effect = last(period_correction),
        elevation_effect = last(elevation_correction),
        
        # Recent volatility metrics
        prediction_volatility = last(recent_prediction_volatility),
        consistency_score = last(recent_consistency_score),
        upside_potential = last(recent_upside_potential),
        downside_risk = last(recent_downside_risk),
        volatility_ratio = last(recent_volatility_ratio),
        
        # Add number of recent races for confidence
        n_recent_races = sum(!is.na(tail(Points, 10)))
      )
    
    # Prepare startlist data
    startlist_prepared <- prepare_startlist_data(startlist, race_df, pelo_col, is_relay = is_relay)
    
    # Ensure race probability column exists
    if(!(race_prob_col %in% names(startlist_prepared))) {
      log_warn(paste("Race probability column missing:", race_prob_col))
      if(race_prob_col %in% names(startlist)) {
        # Copy from original startlist if available
        log_info("Copying from original startlist")
        startlist_prepared[[race_prob_col]] <- startlist[match(startlist_prepared[[participant_col]], startlist[[participant_col]]), race_prob_col]
      } else {
        # Default to 1 for first race, 0 for others if not available
        log_info("Setting default probabilities")
        startlist_prepared[[race_prob_col]] <- if(i == 1) 1 else 0
      }
    }
    
    # NEW CODE: Make position probability predictions with adjustments
    position_preds <- data.frame(startlist_prepared[[participant_col]])
    names(position_preds)[1] <- participant_col
    
    # Add ID, Nation, Sex for individual races
    if(!is_relay) {
      position_preds$ID <- startlist_prepared$ID
      position_preds$Nation <- startlist_prepared$Nation
      position_preds$Sex <- startlist_prepared$Sex
    }
    
    # Add race number
    position_preds$Race <- i
    
    # Add race probability column for later normalization
    if(race_prob_col %in% names(startlist_prepared)) {
      position_preds[[race_prob_col]] <- startlist_prepared[[race_prob_col]]
    }
    
    # Make predictions for each threshold
    for(threshold in position_thresholds) {
      model_name <- paste0("threshold_", threshold)
      adj_name <- paste0("threshold_", threshold)
      prob_col <- paste0("prob_top", threshold)
      
      if(model_name %in% names(position_models)) {
        tryCatch({
          # Get the model
          pos_model <- position_models[[model_name]]
          
          # Check what variables the model actually needs
          model_vars <- names(pos_model$var.summary)
          log_info(paste("Model for threshold", threshold, "requires variables:", paste(model_vars, collapse=", ")))
          
          # Create a clean subset of prediction data with only required variables
          prediction_subset <- startlist_prepared
          
          # Explicitly check for each variable
          for(var in model_vars) {
            if(!(var %in% names(prediction_subset))) {
              log_warn(paste("Missing required variable:", var, "- adding with default values"))
              # Add missing variable with appropriate default value
              prediction_subset[[var]] <- 0
            } else {
              # Ensure the variable has the right type
              model_var_type <- class(pos_model$var.summary[[var]])
              data_var_type <- class(prediction_subset[[var]])
              
              if(!identical(model_var_type, data_var_type)) {
                log_warn(paste("Variable type mismatch for", var, ":", 
                               "model expects", model_var_type, "but got", data_var_type))
                # Convert to correct type
                if(model_var_type == "numeric") {
                  prediction_subset[[var]] <- as.numeric(prediction_subset[[var]])
                } else if(model_var_type == "factor") {
                  prediction_subset[[var]] <- as.factor(prediction_subset[[var]])
                }
              }
              
              # Handle NAs
              if(any(is.na(prediction_subset[[var]]))) {
                log_info(paste("Replacing NAs in", var))
                if(is.numeric(prediction_subset[[var]])) {
                  prediction_subset[[var]] <- replace_na_with_quartile(prediction_subset[[var]])
                } else {
                  # For non-numeric, use most common value
                  most_common <- names(sort(table(prediction_subset[[var]], useNA = "no"), decreasing = TRUE))[1]
                  prediction_subset[[var]][is.na(prediction_subset[[var]])] <- most_common
                }
              }
            }
          }
          
          # Make predictions with explicit try-catch
          base_predictions <- tryCatch({
            # Debug output
            log_info(paste("Attempting prediction for threshold", threshold, "with", nrow(prediction_subset), "rows"))
            
            # Explicit call to mgcv::predict.gam to avoid method dispatch issues
            mgcv::predict.gam(pos_model, newdata = prediction_subset, type = "response")
          }, error = function(e) {
            log_warn(paste("Prediction call failed:", e$message))
            
            # Try alternative prediction approach with one row at a time
            log_info("Trying row-by-row prediction as fallback")
            result <- numeric(nrow(prediction_subset))
            
            for(j in 1:nrow(prediction_subset)) {
              single_row <- prediction_subset[j,, drop = FALSE]
              result[j] <- tryCatch({
                mgcv::predict.gam(pos_model, newdata = single_row, type = "response")
              }, error = function(e2) {
                log_warn(paste("Failed on row", j, ":", e2$message))
                threshold/100  # Default value based on threshold
              })
            }
            return(result)
          })
          
          # Store predictions
          position_preds[[paste0(prob_col, "_base")]] <- base_predictions
          
          # Apply adjustments if available
          if(adj_name %in% names(position_adjustments)) {
            # Get adjustments
            pos_adj <- position_adjustments[[adj_name]]
            
            # Join with predictions
            position_preds <- position_preds %>%
              left_join(pos_adj, by = participant_col) %>%
              mutate(
                # Replace NAs with zeros
                period_effect = replace_na(period_effect, 0),
                
                # Apply adjustments
                period_adjustment = period_effect,
                
                # Calculate adjusted probabilities
                adjusted_prob = get(paste0(prob_col, "_base")) + period_adjustment,
                
                # Ensure probabilities are between 0 and 1
                adjusted_prob = pmin(pmax(adjusted_prob, 0), 1)
              )
            
            # Use adjusted probability as final
            position_preds[[prob_col]] <- position_preds$adjusted_prob
            
            # Clean up temporary columns
            position_preds <- position_preds %>%
              dplyr::select(-period_effect, -period_adjustment, -adjusted_prob)
          } else {
            # Use base prediction if no adjustments
            position_preds[[prob_col]] <- position_preds[[paste0(prob_col, "_base")]]
          }
          
          # Clean up base prediction column
          position_preds <- position_preds %>%
            dplyr::select(-paste0(prob_col, "_base"))
          
          # Convert to percentage and round
          position_preds[[prob_col]] <- round(position_preds[[prob_col]] * 100, 1)
          
          log_info(paste("Made predictions with adjustments for position threshold", threshold))
          
        }, error = function(e) {
          log_warn(paste("Complete failure for threshold", threshold, ":", e$message))
          # Set a reasonable default based on threshold (1% for top1, 3% for top3, etc.)
          position_preds[[prob_col]] <- rep(threshold, nrow(position_preds))
        })
      } else {
        log_warn(paste("No model found for threshold", threshold))
        position_preds[[prob_col]] <- NA
      }
    }
    
    # Normalize position probabilities to ensure they sum to the correct totals
    position_preds <- normalize_position_probabilities(position_preds, race_prob_col, position_thresholds)
    
    # Add verification logging for each threshold
    log_info(sprintf("Race %d position probability sums after normalization:", i))
    for(threshold in position_thresholds) {
      prob_col <- paste0("prob_top", threshold)
      if(prob_col %in% names(position_preds)) {
        sum_val <- sum(position_preds[[prob_col]], na.rm = TRUE)
        log_info(sprintf("  %s: %.2f%% (should be %d%%)", 
                         prob_col, sum_val, 100 * threshold))
      }
    }
    
    # Store position predictions for this race
    position_predictions[[i]] <- position_preds
    
    # Check if probabilities are getting lost
    log_info(paste("Race", i, "probability check:"))
    prob_summary <- startlist_prepared %>%
      group_by(if(!is_relay) Nation else NULL) %>%
      summarise(
        mean_prob = mean(get(race_prob_col), na.rm = TRUE),
        sum_prob = sum(get(race_prob_col), na.rm = TRUE),
        n = n()
      ) %>%
      arrange(desc(sum_prob))
    
    # Prepare startlist points predictions (original functionality)
    race_dfs[[i]] <- startlist_prepared %>%
      mutate(
        Base_Prediction = predict(model, newdata = .),
      ) %>%
      left_join(skier_adjustments, by = participant_col) %>%
      mutate(
        # Regular adjustments
        period_effect = replace_na(period_effect, 0),
        elevation_effect = replace_na(elevation_effect, 0),
        
        # Volatility metrics
        prediction_volatility = replace_na(prediction_volatility, 0),
        consistency_score = replace_na(consistency_score, 0),
        upside_potential = replace_na(upside_potential, 0),
        downside_risk = replace_na(downside_risk, 0),
        volatility_ratio = replace_na(volatility_ratio, 1),
        n_recent_races = replace_na(n_recent_races, 0),
        
        # Using existing adjustment approach
        period_adjustment = period_effect,
        elevation_adjustment = elevation_effect,
        
        # Base prediction and adjustments
        Predicted_Points = Base_Prediction + period_adjustment + elevation_adjustment,
        Predicted_Points = pmax(pmin(Predicted_Points, 100), 0),
        
        # Apply race probability to predictions
        Race_Prob = get(race_prob_col),
        Final_Prediction = Predicted_Points * Race_Prob,
        
        # Different scoring scenarios - adjusted by race probability
        confidence_factor = pmin(n_recent_races / 10, 1),
        scaled_upside_potential = upside_potential * (Predicted_Points/100),
        scaled_downside_potential = downside_risk * (Predicted_Points/100),
        
        # Safe prediction (downside)
        Safe_Prediction = pmax(
          (Predicted_Points - (prediction_volatility * 1.5 * confidence_factor)) * Race_Prob, 
          0
        ),
        
        # Upside prediction
        Upside_Prediction = pmin(
          (Predicted_Points + (prediction_volatility * 1.5 * confidence_factor)) * Race_Prob, 
          100 * Race_Prob  # Cap at 100 * probability
        )
      ) %>%
      dplyr::select(all_of(participant_col), 
                    if(!is_relay) "Nation" else NULL,
                    Base_Prediction, period_adjustment, elevation_adjustment,
                    prediction_volatility, volatility_ratio, confidence_factor,
                    Final_Prediction, Safe_Prediction, Upside_Prediction,
                    race_prob_col)
    
    # Extra check to ensure race probability column exists and is properly named
    if(!race_prob_col %in% names(race_dfs[[i]])) {
      log_warn(paste("Race probability column", race_prob_col, "not in final race_dfs!"))
      # Try to fix
      if("Race_Prob" %in% names(race_dfs[[i]])) {
        log_info("Renaming Race_Prob column to correct race probability column name")
        race_dfs[[i]][[race_prob_col]] <- race_dfs[[i]][["Race_Prob"]]
      }
    }
  }
  
  # Get number of races from races dataframe
  n_races <- nrow(races)
  
  # Combine all race predictions (points)
  final_predictions <- combine_predictions(race_dfs, startlist, is_relay = is_relay)
  
  log_info(paste("Final predictions calculated for", if(is_relay) "relay" else gender))
  
  # Create post predictions for blog (points)
  post_predictions <- create_post_predictions(final_predictions, n_races, gender, is_relay = is_relay)
  
  # Combine all position predictions into one dataframe
  all_position_predictions <- bind_rows(position_predictions)
  
  # Format position results
  formatted_position_results <- format_position_results(all_position_predictions, next_weekend_date, gender, is_relay, relay_type)
  
  # Create folder path based on next race weekend date
  weekend_folder <- format(next_weekend_date, "%Y%m%d")
  dir_path <- paste0("~/blog/daehl-e/content/post/biathlon/drafts/weekly-picks/", weekend_folder)
  
  # Create directory if it doesn't exist
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  # Save points predictions to Excel
  if(is_relay) {
    relay_type_short <- gsub(" ", "_", tolower(relay_type))
    if(is.null(gender) || gender == "") {
      file_name <- paste0(relay_type_short, ".xlsx")
    } else {
      file_name <- paste0(gender, "_", relay_type_short, ".xlsx")
    }
  } else {
    file_name <- paste0(gender, ".xlsx")
  }
  
  file_path <- file.path(dir_path, file_name)
  write.xlsx(post_predictions, file = file_path)
  
  log_info(paste("Saved predictions to", file_path))
  
  return(list(
    full_predictions = final_predictions,
    post_predictions = post_predictions,
    position_predictions = all_position_predictions,
    formatted_position_results = formatted_position_results
  ))
}

# Main workflow function
run_integrated_predictions_workflow <- function() {
  log_info("Running integrated predictions workflow (points and position probabilities)")
  
  # First calculate race probabilities
  log_info("Calculating race probabilities")
  prob_results <- calculate_race_probabilities()
  
  log_info("Updating startlist variables with calculated probabilities")
  # Individual events startlists
  men_startlist <- prob_results$men
  ladies_startlist <- prob_results$ladies
  
  # Relay startlists
  men_relay_startlist <- prob_results$men_relay
  ladies_relay_startlist <- prob_results$ladies_relay
  mixed_relay_startlist <- prob_results$mixed_relay
  single_mixed_relay_startlist <- prob_results$single_mixed_relay
  
  # Log the sizes of the startlists
  log_info(paste("Men's startlist has", nrow(men_startlist), "entries"))
  log_info(paste("Ladies' startlist has", nrow(ladies_startlist), "entries"))
  log_info(paste("Men's relay startlist has", nrow(men_relay_startlist), "entries"))
  log_info(paste("Ladies' relay startlist has", nrow(ladies_relay_startlist), "entries"))
  log_info(paste("Mixed relay startlist has", nrow(mixed_relay_startlist), "entries"))
  log_info(paste("Single mixed relay startlist has", nrow(single_mixed_relay_startlist), "entries"))
  
  # Create relay chronos if we have relay races
  if(nrow(relays) + nrow(mixed_relays) + nrow(single_mixed_relays) > 0) {
    log_info("Creating relay chronos")
    create_relay_chronos()
  }
  
  # Results containers
  all_results <- list()
  
  men_races <- men_races %>%
    dplyr::filter(!racetype %in% c("Relay", "Mixed Relay", "Single Mixed Relay"))
  log_info(paste("After filtering out relays:", nrow(men_races), "men's individual races remain"))
  
  ladies_races <- ladies_races %>%
    dplyr::filter(!racetype %in% c("Relay", "Mixed Relay", "Single Mixed Relay"))
  log_info(paste("After filtering out relays:", nrow(ladies_races), "ladies' individual races remain"))
  
  # Run for men if races exist
  if(nrow(men_races) > 0 && nrow(men_startlist) > 0) {
    log_info("Processing men's predictions")
    # Make a copy of the startlist to avoid global state issues
    men_startlist_copy <- men_startlist
    all_results$men <- predict_races("men", is_relay = FALSE, startlist_override = men_startlist_copy)
  } else {
    log_info("No men's races scheduled or no startlist available")
  }
  
  # Run for ladies if races exist
  if(nrow(ladies_races) > 0 && nrow(ladies_startlist) > 0) {
    log_info("Processing ladies' predictions")
    # Make a copy of the startlist to avoid global state issues
    ladies_startlist_copy <- ladies_startlist
    all_results$ladies <- predict_races("ladies", is_relay = FALSE, startlist_override = ladies_startlist_copy)
  } else {
    log_info("No ladies' races scheduled or no startlist available")
  }
  
  # Run for relay events (with tracking to avoid duplicate processing)
  processed_relays <- list()
  
  # Men's relay
  if(nrow(relays) > 0 && nrow(men_relay_startlist) > 0 && !("men_relay" %in% names(processed_relays))) {
    log_info("Processing men's relay predictions")
    # Make a copy of the startlist to avoid global state issues
    men_relay_startlist_copy <- men_relay_startlist
    all_results$men_relay <- predict_races("men", is_relay = TRUE, relay_type = "Relay", 
                                           startlist_override = men_relay_startlist_copy)
    processed_relays$men_relay <- TRUE
  } else if(nrow(relays) > 0) {
    log_info("No men's relay startlist available or already processed")
  }
  
  # Ladies' relay
  if(nrow(relays) > 0 && nrow(ladies_relay_startlist) > 0 && !("ladies_relay" %in% names(processed_relays))) {
    log_info("Processing ladies' relay predictions")
    # Make a copy of the startlist to avoid global state issues
    ladies_relay_startlist_copy <- ladies_relay_startlist
    all_results$ladies_relay <- predict_races("ladies", is_relay = TRUE, relay_type = "Relay", 
                                              startlist_override = ladies_relay_startlist_copy)
    processed_relays$ladies_relay <- TRUE
  } else if(nrow(relays) > 0) {
    log_info("No ladies' relay startlist available or already processed")
  }
  
  # Mixed relay
  if(nrow(mixed_relays) > 0 && nrow(mixed_relay_startlist) > 0) {
    log_info("Processing mixed relay predictions")
    # Make a copy of the startlist to avoid global state issues
    mixed_relay_startlist_copy <- mixed_relay_startlist
    all_results$mixed_relay <- predict_races(NULL, is_relay = TRUE, relay_type = "Mixed Relay", 
                                             startlist_override = mixed_relay_startlist_copy)
  } else if(nrow(mixed_relays) > 0) {
    log_info("No mixed relay startlist available")
  }
  
  # Single mixed relay
  if(nrow(single_mixed_relays) > 0 && nrow(single_mixed_relay_startlist) > 0) {
    log_info("Processing single mixed relay predictions")
    # Make a copy of the startlist to avoid global state issues
    single_mixed_relay_startlist_copy <- single_mixed_relay_startlist
    all_results$single_mixed_relay <- predict_races(NULL, is_relay = TRUE, relay_type = "Single Mixed Relay", 
                                                    startlist_override = single_mixed_relay_startlist_copy)
  } else if(nrow(single_mixed_relays) > 0) {
    log_info("No single mixed relay startlist available")
  }
  
  # Create top contenders summary
  #top_contenders <- create_top_contenders_summary(all_results, next_weekend_date)
  #all_results$top_contenders <- top_contenders
  
  log_info("Prediction workflow with position probabilities complete")
  return(all_results)
}

# Run the integrated predictions workflow
run_integrated_predictions_workflow()