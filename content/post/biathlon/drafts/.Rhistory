# Calculate Brier score for model evaluation
predicted_probs <- predict(position_model, newdata = race_df, type = "response")
brier_score <- mean((race_df$position_achieved - predicted_probs)^2, na.rm = TRUE)
log_info(paste("Brier score for threshold", threshold, ":", round(brier_score, 4)))
# Log selected variables
log_info(paste("Variables selected for", threshold, "position model:",
paste(pos_best_bic_vars[-1], collapse=", ")))
# Store the model
position_models[[paste0("threshold_", threshold)]] <- position_model
# Calculate adjustments for period for this threshold
position_df <- race_df %>%
arrange(Date) %>%
group_by(!!sym(participant_col)) %>%
mutate(
row_id = row_number()
) %>%
ungroup()
# Add predictions separately (outside of mutate)
position_df$initial_prob <- predict(position_model, newdata = position_df, type = "response")
# Continue with period adjustment calculations
position_df <- position_df %>%
group_by(!!sym(participant_col)) %>%
mutate(
prob_diff = as.numeric(position_achieved) - initial_prob,
# Calculate period adjustments (disabled for relay teams since team compositions change)
period_p = if(is_relay) 1 else purrr::map_dbl(row_id, function(r) {
if(r <= 1) return(1)
prior_period_curr <- prob_diff[Period == Period[r] & row_id < r]
prior_period_other <- prob_diff[Period != Period[r] & row_id < r]
if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
tryCatch({
t.test(prior_period_curr, prior_period_other)$p.value
}, error = function(e) 1)
}),
period_correction = if(is_relay) 0 else ifelse(period_p < 0.05,
mean(prob_diff[Period == Period], na.rm = TRUE),
0),
period_adjusted = pmin(pmax(initial_prob + period_correction, 0), 1)
) %>%
ungroup()
# Get final adjustments for each participant
skier_pos_adjustments <- position_df %>%
group_by(!!sym(participant_col)) %>%
summarise(
period_effect = last(period_correction)
)
# Store adjustments for this threshold
position_adjustments[[paste0("threshold_", threshold)]] <- skier_pos_adjustments
}, error = function(e) {
log_warn(paste("Error in position model for threshold", threshold, ":", e$message))
# Create a simpler fallback model with just the pelo column
fallback_vars <- c("Prev_Points_Weighted", pelo_col)
fallback_vars <- fallback_vars[fallback_vars %in% names(race_df)]
if(length(fallback_vars) > 0) {
fallback_terms <- paste("s(", fallback_vars, ")", collapse=" + ")
fallback_formula <- as.formula(paste("position_achieved ~", fallback_terms))
position_models[[paste0("threshold_", threshold)]] <- gam(
fallback_formula,
data = race_df,
family = binomial,
method = "REML"
)
# Create empty adjustments object since we can't calculate them for the fallback model
empty_adjustments <- data.frame(x = unique(race_df[[participant_col]]))
names(empty_adjustments)[1] <- participant_col
empty_adjustments$period_effect <- 0
position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
log_info(paste("Created fallback model for threshold", threshold,
"using variables:", paste(fallback_vars, collapse=", ")))
} else {
# Last resort fallback - just use the pelo column
fallback_formula <- as.formula(paste("position_achieved ~ s(", pelo_col, ")"))
position_models[[paste0("threshold_", threshold)]] <- gam(
fallback_formula,
data = race_df,
family = binomial,
method = "REML"
)
# Create empty adjustments object
empty_adjustments <- data.frame(x = unique(race_df[[participant_col]]))
names(empty_adjustments)[1] <- participant_col
empty_adjustments$period_effect <- 0
position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
log_info(paste("Created last-resort fallback model for threshold", threshold,
"using only", pelo_col))
}
})
}
# Calculate volatility metrics using recent races
race_df_75 <- race_df_75 %>%
group_by(!!sym(participant_col)) %>%
arrange(Date) %>%  # Ensure chronological order
mutate(
# Create rolling window calculations for last 10 races
recent_prediction_volatility = slider::slide_dbl(
Points - Initial_Prediction,
sd,
.before = 9,  # Look at current race plus 9 previous
.complete = FALSE  # Allow partial windows
),
recent_consistency_score = slider::slide_dbl(
abs(Points - Initial_Prediction),
mean,
.before = 9,
.complete = FALSE
),
recent_upside_potential = slider::slide_dbl(
Points - Initial_Prediction,
~quantile(.x, 0.9, na.rm = TRUE),
.before = 9,
.complete = FALSE
),
recent_downside_risk = slider::slide_dbl(
Points - Initial_Prediction,
~quantile(.x, 0.1, na.rm = TRUE),
.before = 9,
.complete = FALSE
)
) %>%
mutate(
recent_volatility_ratio = recent_upside_potential / abs(recent_downside_risk)
) %>%
ungroup()
# Get final adjustments for each participant
skier_adjustments <- race_df_75 %>%
group_by(!!sym(participant_col)) %>%
summarise(
period_effect = last(period_correction),
elevation_effect = last(elevation_correction),
# Recent volatility metrics
prediction_volatility = last(recent_prediction_volatility),
consistency_score = last(recent_consistency_score),
upside_potential = last(recent_upside_potential),
downside_risk = last(recent_downside_risk),
volatility_ratio = last(recent_volatility_ratio),
# Add number of recent races for confidence
n_recent_races = sum(!is.na(tail(Points, 10)))
)
# Prepare startlist data
startlist_prepared <- prepare_startlist_data(startlist, race_df, pelo_col, is_relay = is_relay)
# Ensure race probability column exists
if(!(race_prob_col %in% names(startlist_prepared))) {
log_warn(paste("Race probability column missing:", race_prob_col))
if(race_prob_col %in% names(startlist)) {
# Copy from original startlist if available
log_info("Copying from original startlist")
startlist_prepared[[race_prob_col]] <- startlist[match(startlist_prepared[[participant_col]], startlist[[participant_col]]), race_prob_col]
} else {
# Default to 1 for first race, 0 for others if not available
log_info("Setting default probabilities")
startlist_prepared[[race_prob_col]] <- if(i == 1) 1 else 0
}
}
# NEW CODE: Make position probability predictions with adjustments
position_preds <- data.frame(startlist_prepared[[participant_col]])
names(position_preds)[1] <- participant_col
# Add ID, Nation, Sex for individual races
if(!is_relay) {
position_preds$ID <- startlist_prepared$ID
position_preds$Nation <- startlist_prepared$Nation
position_preds$Sex <- startlist_prepared$Sex
}
# Add race number
position_preds$Race <- i
# Add race probability column for later normalization
if(race_prob_col %in% names(startlist_prepared)) {
position_preds[[race_prob_col]] <- startlist_prepared[[race_prob_col]]
}
# Make predictions for each threshold
for(threshold in position_thresholds) {
model_name <- paste0("threshold_", threshold)
adj_name <- paste0("threshold_", threshold)
prob_col <- paste0("prob_top", threshold)
if(model_name %in% names(position_models)) {
tryCatch({
# Get the model
pos_model <- position_models[[model_name]]
# Check what variables the model actually needs
model_vars <- names(pos_model$var.summary)
log_info(paste("Model for threshold", threshold, "requires variables:", paste(model_vars, collapse=", ")))
# Create a clean subset of prediction data with only required variables
prediction_subset <- startlist_prepared
# Explicitly check for each variable
for(var in model_vars) {
if(!(var %in% names(prediction_subset))) {
log_warn(paste("Missing required variable:", var, "- adding with default values"))
# Add missing variable with appropriate default value
prediction_subset[[var]] <- 0
} else {
# Ensure the variable has the right type
model_var_type <- class(pos_model$var.summary[[var]])
data_var_type <- class(prediction_subset[[var]])
if(!identical(model_var_type, data_var_type)) {
log_warn(paste("Variable type mismatch for", var, ":",
"model expects", model_var_type, "but got", data_var_type))
# Convert to correct type
if(model_var_type == "numeric") {
prediction_subset[[var]] <- as.numeric(prediction_subset[[var]])
} else if(model_var_type == "factor") {
prediction_subset[[var]] <- as.factor(prediction_subset[[var]])
}
}
# Handle NAs
if(any(is.na(prediction_subset[[var]]))) {
log_info(paste("Replacing NAs in", var))
if(is.numeric(prediction_subset[[var]])) {
prediction_subset[[var]] <- replace_na_with_quartile(prediction_subset[[var]])
} else {
# For non-numeric, use most common value
most_common <- names(sort(table(prediction_subset[[var]], useNA = "no"), decreasing = TRUE))[1]
prediction_subset[[var]][is.na(prediction_subset[[var]])] <- most_common
}
}
}
}
# Make predictions with explicit try-catch
base_predictions <- tryCatch({
# Debug output
log_info(paste("Attempting prediction for threshold", threshold, "with", nrow(prediction_subset), "rows"))
# Explicit call to mgcv::predict.gam to avoid method dispatch issues
mgcv::predict.gam(pos_model, newdata = prediction_subset, type = "response")
}, error = function(e) {
log_warn(paste("Prediction call failed:", e$message))
# Try alternative prediction approach with one row at a time
log_info("Trying row-by-row prediction as fallback")
result <- numeric(nrow(prediction_subset))
for(j in 1:nrow(prediction_subset)) {
single_row <- prediction_subset[j,, drop = FALSE]
result[j] <- tryCatch({
mgcv::predict.gam(pos_model, newdata = single_row, type = "response")
}, error = function(e2) {
log_warn(paste("Failed on row", j, ":", e2$message))
threshold/100  # Default value based on threshold
})
}
return(result)
})
# Store predictions
position_preds[[paste0(prob_col, "_base")]] <- base_predictions
# Apply adjustments if available - COMMENTED OUT: Remove double-dipping
# if(adj_name %in% names(position_adjustments)) {
#   # Get adjustments
#   pos_adj <- position_adjustments[[adj_name]]
#
#   # Join with predictions
#   position_preds <- position_preds %>%
#     left_join(pos_adj, by = participant_col) %>%
#     mutate(
#       # Replace NAs with zeros
#       period_effect = replace_na(period_effect, 0),
#
#       # Apply adjustments
#       period_adjustment = period_effect,
#
#       # Calculate adjusted probabilities
#       adjusted_prob = get(paste0(prob_col, "_base")) + period_adjustment,
#
#       # Ensure probabilities are between 0 and 1
#       adjusted_prob = pmin(pmax(adjusted_prob, 0), 1)
#     )
#
#   # Use adjusted probability as final
#   position_preds[[prob_col]] <- position_preds$adjusted_prob
#
#   # Clean up temporary columns
#   position_preds <- position_preds %>%
#     dplyr::select(-period_effect, -period_adjustment, -adjusted_prob)
# } else {
# Use base prediction without adjustments
position_preds[[prob_col]] <- position_preds[[paste0(prob_col, "_base")]]
# }
# Clean up base prediction column
position_preds <- position_preds %>%
dplyr::select(-paste0(prob_col, "_base"))
# Convert to percentage and round
position_preds[[prob_col]] <- round(position_preds[[prob_col]] * 100, 1)
log_info(paste("Made predictions with adjustments for position threshold", threshold))
}, error = function(e) {
log_warn(paste("Complete failure for threshold", threshold, ":", e$message))
# Set a reasonable default based on threshold (1% for top1, 3% for top3, etc.)
position_preds[[prob_col]] <- rep(threshold, nrow(position_preds))
})
} else {
log_warn(paste("No model found for threshold", threshold))
position_preds[[prob_col]] <- NA
}
}
# Normalize position probabilities to ensure they sum to the correct totals
position_preds <- normalize_position_probabilities(position_preds, race_prob_col, position_thresholds)
# Add verification logging for each threshold
log_info(sprintf("Race %d position probability sums after normalization:", i))
for(threshold in position_thresholds) {
prob_col <- paste0("prob_top", threshold)
if(prob_col %in% names(position_preds)) {
sum_val <- sum(position_preds[[prob_col]], na.rm = TRUE)
log_info(sprintf("  %s: %.2f%% (should be %d%%)",
prob_col, sum_val, 100 * threshold))
}
}
# Store position predictions for this race
position_predictions[[i]] <- position_preds
# Check if probabilities are getting lost
log_info(paste("Race", i, "probability check:"))
prob_summary <- startlist_prepared %>%
group_by(if(!is_relay) Nation else NULL) %>%
summarise(
mean_prob = mean(get(race_prob_col), na.rm = TRUE),
sum_prob = sum(get(race_prob_col), na.rm = TRUE),
n = n()
) %>%
arrange(desc(sum_prob))
# Prepare startlist points predictions (original functionality)
race_dfs[[i]] <- startlist_prepared %>%
mutate(
Base_Prediction = predict(model, newdata = .),
) %>%
left_join(skier_adjustments, by = participant_col) %>%
mutate(
# Regular adjustments
period_effect = replace_na(period_effect, 0),
elevation_effect = replace_na(elevation_effect, 0),
# Volatility metrics
prediction_volatility = replace_na(prediction_volatility, 0),
consistency_score = replace_na(consistency_score, 0),
upside_potential = replace_na(upside_potential, 0),
downside_risk = replace_na(downside_risk, 0),
volatility_ratio = replace_na(volatility_ratio, 1),
n_recent_races = replace_na(n_recent_races, 0),
# Using existing adjustment approach (disabled for relay teams since team compositions change)
period_adjustment = if(is_relay) 0 else period_effect,
elevation_adjustment = if(is_relay) 0 else elevation_effect,
# Base prediction and adjustments (period and elevation adjustments disabled for relay teams)
Predicted_Points = Base_Prediction + period_adjustment + elevation_adjustment,
Predicted_Points = pmax(pmin(Predicted_Points, 100), 0),
# Apply race probability to predictions
Race_Prob = get(race_prob_col),
Final_Prediction = Predicted_Points * Race_Prob,
# Different scoring scenarios - adjusted by race probability
confidence_factor = pmin(n_recent_races / 10, 1),
scaled_upside_potential = upside_potential * (Predicted_Points/100),
scaled_downside_potential = downside_risk * (Predicted_Points/100),
# Safe prediction (downside)
Safe_Prediction = pmax(
(Predicted_Points - (prediction_volatility * 1.5 * confidence_factor)) * Race_Prob,
0
),
# Upside prediction
Upside_Prediction = pmin(
(Predicted_Points + (prediction_volatility * 1.5 * confidence_factor)) * Race_Prob,
100 * Race_Prob  # Cap at 100 * probability
)
) %>%
dplyr::select(all_of(participant_col),
if(!is_relay) "Nation" else NULL,
Base_Prediction, period_adjustment, elevation_adjustment,
prediction_volatility, volatility_ratio, confidence_factor,
Final_Prediction, Safe_Prediction, Upside_Prediction,
race_prob_col)
# Extra check to ensure race probability column exists and is properly named
if(!race_prob_col %in% names(race_dfs[[i]])) {
log_warn(paste("Race probability column", race_prob_col, "not in final race_dfs!"))
# Try to fix
if("Race_Prob" %in% names(race_dfs[[i]])) {
log_info("Renaming Race_Prob column to correct race probability column name")
race_dfs[[i]][[race_prob_col]] <- race_dfs[[i]][["Race_Prob"]]
}
}
}
# Get number of races from races dataframe
n_races <- nrow(races)
# Combine all race predictions (points)
final_predictions <- combine_predictions(race_dfs, startlist, is_relay = is_relay)
log_info(paste("Final predictions calculated for", if(is_relay) "relay" else gender))
# Create post predictions for blog (points)
post_predictions <- create_post_predictions(final_predictions, n_races, gender, is_relay = is_relay)
# Combine all position predictions into one dataframe
all_position_predictions <- bind_rows(position_predictions)
# Format position results
formatted_position_results <- format_position_results(all_position_predictions, race_date, gender, is_relay, relay_type)
# Create folder path based on race date
race_folder <- format(race_date, "%Y%m%d")
dir_path <- paste0("~/blog/daehl-e/content/post/biathlon/drafts/race-picks/", race_folder)
# Create directory if it doesn't exist
if (!dir.exists(dir_path)) {
dir.create(dir_path, recursive = TRUE)
}
# Save points predictions to Excel
if(is_relay) {
relay_type_short <- gsub(" ", "_", tolower(relay_type))
if(is.null(gender) || gender == "") {
file_name <- paste0(relay_type_short, ".xlsx")
} else {
file_name <- paste0(gender, "_", relay_type_short, ".xlsx")
}
} else {
file_name <- paste0(gender, ".xlsx")
}
file_path <- file.path(dir_path, file_name)
write.xlsx(post_predictions, file = file_path)
log_info(paste("Saved predictions to", file_path))
return(list(
full_predictions = final_predictions,
post_predictions = post_predictions,
position_predictions = all_position_predictions,
formatted_position_results = formatted_position_results
))
}
# Main workflow function
run_integrated_predictions_workflow <- function() {
log_info("Running integrated predictions workflow (points and position probabilities)")
# First calculate race probabilities
log_info("Calculating race probabilities")
prob_results <- calculate_race_probabilities()
log_info("Updating startlist variables with calculated probabilities")
# Individual events startlists
men_startlist <- prob_results$men
ladies_startlist <- prob_results$ladies
# Relay startlists
men_relay_startlist <- prob_results$men_relay
ladies_relay_startlist <- prob_results$ladies_relay
mixed_relay_startlist <- prob_results$mixed_relay
single_mixed_relay_startlist <- prob_results$single_mixed_relay
# Log the sizes of the startlists
log_info(paste("Men's startlist has", nrow(men_startlist), "entries"))
log_info(paste("Ladies' startlist has", nrow(ladies_startlist), "entries"))
log_info(paste("Men's relay startlist has", nrow(men_relay_startlist), "entries"))
log_info(paste("Ladies' relay startlist has", nrow(ladies_relay_startlist), "entries"))
log_info(paste("Mixed relay startlist has", nrow(mixed_relay_startlist), "entries"))
log_info(paste("Single mixed relay startlist has", nrow(single_mixed_relay_startlist), "entries"))
# Create relay chronos if we have relay races
if(nrow(relays) + nrow(mixed_relays) + nrow(single_mixed_relays) > 0) {
log_info("Creating relay chronos")
create_relay_chronos()
}
# Results containers
all_results <- list()
men_races <- men_races %>%
dplyr::filter(!racetype %in% c("Relay", "Mixed Relay", "Single Mixed Relay"))
log_info(paste("After filtering out relays:", nrow(men_races), "men's individual races remain"))
ladies_races <- ladies_races %>%
dplyr::filter(!racetype %in% c("Relay", "Mixed Relay", "Single Mixed Relay"))
log_info(paste("After filtering out relays:", nrow(ladies_races), "ladies' individual races remain"))
# Run for men if races exist
if(nrow(men_races) > 0 && nrow(men_startlist) > 0) {
log_info("Processing men's predictions")
# Make a copy of the startlist to avoid global state issues
men_startlist_copy <- men_startlist
all_results$men <- predict_races("men", is_relay = FALSE, startlist_override = men_startlist_copy)
} else {
log_info("No men's races scheduled or no startlist available")
}
# Run for ladies if races exist
if(nrow(ladies_races) > 0 && nrow(ladies_startlist) > 0) {
log_info("Processing ladies' predictions")
# Make a copy of the startlist to avoid global state issues
ladies_startlist_copy <- ladies_startlist
all_results$ladies <- predict_races("ladies", is_relay = FALSE, startlist_override = ladies_startlist_copy)
} else {
log_info("No ladies' races scheduled or no startlist available")
}
# Run for relay events (with tracking to avoid duplicate processing)
processed_relays <- list()
# Men's relay
if(nrow(relays) > 0 && nrow(men_relay_startlist) > 0 && !("men_relay" %in% names(processed_relays))) {
log_info("Processing men's relay predictions")
# Make a copy of the startlist to avoid global state issues
men_relay_startlist_copy <- men_relay_startlist
all_results$men_relay <- predict_races("men", is_relay = TRUE, relay_type = "Relay",
startlist_override = men_relay_startlist_copy)
processed_relays$men_relay <- TRUE
} else if(nrow(relays) > 0) {
log_info("No men's relay startlist available or already processed")
}
# Ladies' relay
if(nrow(relays) > 0 && nrow(ladies_relay_startlist) > 0 && !("ladies_relay" %in% names(processed_relays))) {
log_info("Processing ladies' relay predictions")
# Make a copy of the startlist to avoid global state issues
ladies_relay_startlist_copy <- ladies_relay_startlist
all_results$ladies_relay <- predict_races("ladies", is_relay = TRUE, relay_type = "Relay",
startlist_override = ladies_relay_startlist_copy)
processed_relays$ladies_relay <- TRUE
} else if(nrow(relays) > 0) {
log_info("No ladies' relay startlist available or already processed")
}
# Mixed relay
if(nrow(mixed_relays) > 0 && nrow(mixed_relay_startlist) > 0) {
log_info("Processing mixed relay predictions")
# Make a copy of the startlist to avoid global state issues
mixed_relay_startlist_copy <- mixed_relay_startlist
all_results$mixed_relay <- predict_races(NULL, is_relay = TRUE, relay_type = "Mixed Relay",
startlist_override = mixed_relay_startlist_copy)
} else if(nrow(mixed_relays) > 0) {
log_info("No mixed relay startlist available")
}
# Single mixed relay
if(nrow(single_mixed_relays) > 0 && nrow(single_mixed_relay_startlist) > 0) {
log_info("Processing single mixed relay predictions")
# Make a copy of the startlist to avoid global state issues
single_mixed_relay_startlist_copy <- single_mixed_relay_startlist
all_results$single_mixed_relay <- predict_races(NULL, is_relay = TRUE, relay_type = "Single Mixed Relay",
startlist_override = single_mixed_relay_startlist_copy)
} else if(nrow(single_mixed_relays) > 0) {
log_info("No single mixed relay startlist available")
}
# Create top contenders summary
#top_contenders <- create_top_contenders_summary(all_results, race_date)
#all_results$top_contenders <- top_contenders
log_info("Prediction workflow with position probabilities complete")
return(all_results)
}
# Run the integrated predictions workflow
run_integrated_predictions_workflow()
