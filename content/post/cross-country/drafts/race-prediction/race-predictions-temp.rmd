---
title: "Race Predictions"
author: "Syver Johansen"
date: "2024-10-19"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(arrow)
library(AER)
library(ggplot2)
library(effects)
library(segmented)
```

## Data Setup



```{r setup}
#M_chrono <- read_feather('/Users/syverjohansen/ski/elo/python/ski/polars/excel365/mens_merged.feather')
M_chrono <- read.csv('/Users/syverjohansen/ski/elo/python/ski/polars/excel365/men_chrono.csv')
# Step Two: Create a column called WC Points that maps place to world cup points from a list
wc_points <- c(100,95,90,85,80,75,72,69,66,63,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
stage_points <- c(50, 47, 44, 41, 38, 35, 32, 30, 28, 26, 24, 22, 20, 18, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1)
tds_points <- c(300, 285, 270, 255, 240, 216, 207, 198, 189, 180, 174, 168, 162, 156, 150, 144, 138, 132, 126, 120, 114, 108, 102, 96, 90, 84, 78, 72, 66, 60, 57, 54, 51, 48, 45, 42, 39, 36, 33, 30, 27, 24, 21, 18, 15, 12, 9, 6, 3)

# Function to safely fetch points based on Place
get_points <- function(place, points_list) {
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

# Apply points logic based on Event and Distance
df <- M_chrono %>%
  mutate(Points = case_when(
    TRUE ~ map_int(Place, ~ get_points(.x, wc_points))
  ))

# Sort the df by Date, Race, and Place
df <- df %>%
  arrange(Date, Race, Place)

df <- df %>%
  group_by(Season) %>%                                    # Group by Season
  mutate(Num_Races = max(Race)) %>%                      # Get the maximum Race number for each Season
  mutate(Period = case_when(
    Num_Races <= 5 ~ 1,
    Num_Races <= 10 ~ 2,
    Num_Races <= 15 ~ 3,
    Num_Races <= 20 ~ 4,
    Num_Races <= 25 ~ 5,
    TRUE ~ ceiling((Race / (Num_Races / 5)))             # For more than 25 races, divide into 5 equal parts
  ))

# Step Three: Filter for the last five years
df <- df %>%
  filter(Season > 2014, Event %in% c("World Cup", "Nordic Opening", "Tour de Ski", "Olympic Winter Games", "World Championship", "World Cup Final", "Ski Tour Canada")) %>%
  group_by(ID, Season) %>%
  mutate(Cumulative_Points = cumsum(Points)) %>%
  ungroup()

# Function to replace NAs with the first quartile within each group
replace_na_with_quartile <- function(x) {
  quartile_1 <- quantile(x, 0.25, na.rm = TRUE)  # Calculate the first quartile, ignoring NAs
  ifelse(is.na(x), quartile_1, x)  # Replace NAs with the first quartile
}

# Apply this logic to each of the specified columns and then perform the percentage calculations
df <- df %>%
  group_by(Season, Race) %>%
  mutate(
    Distance_Pelo = replace_na_with_quartile(Distance_Pelo),
    Distance_C_Pelo = replace_na_with_quartile(Distance_C_Pelo),
    Distance_F_Pelo = replace_na_with_quartile(Distance_F_Pelo),
    Pelo = replace_na_with_quartile(Pelo),
    Sprint_Pelo = replace_na_with_quartile(Sprint_Pelo),
    Sprint_C_Pelo = replace_na_with_quartile(Sprint_C_Pelo),
    Sprint_F_Pelo = replace_na_with_quartile(Sprint_F_Pelo),
    Freestyle_Pelo = replace_na_with_quartile(Freestyle_Pelo),
    Classic_Pelo = replace_na_with_quartile(Classic_Pelo)
  ) %>%
  # Now calculate the percentages
  mutate(
    Distance_Pelo_Pct = Distance_Pelo / max(Distance_Pelo),
    Distance_C_Pelo_Pct = Distance_C_Pelo / max(Distance_C_Pelo),
    Distance_F_Pelo_Pct = Distance_F_Pelo / max(Distance_F_Pelo),
    Pelo_Pct = Pelo / max(Pelo),
    Sprint_Pelo_Pct = Sprint_Pelo / max(Sprint_Pelo),
    Sprint_C_Pelo_Pct = Sprint_C_Pelo / max(Sprint_C_Pelo),
    Sprint_F_Pelo_Pct = Sprint_F_Pelo / max(Sprint_F_Pelo),
    Freestyle_Pelo_Pct = Freestyle_Pelo / max(Freestyle_Pelo),
    Classic_Pelo_Pct = Classic_Pelo / max(Classic_Pelo)
  ) %>%
  ungroup()
df <- df %>%
  filter(! Distance %in% c("Ts", "Rel"))



```

### EDA

We are going to an EDA with Distance Classic.  

We will start with histograms of the data we are working with and progress towards scatterplots. 

We will do simple scatterplots between points and each of the Pelo_Pcts, Age, and Exp to see the relationship
```{r EDA}
library(ggplot2)
library(e1071)
df_race <- df %>%
  filter(Distance=="Sprint", Technique=="C")

df_race$Points <- df_race$Points/100
hist(df_race$Distance_C_Pelo_Pct)
boxplot(df_race$Distance_C_Pelo_Pct)
summary(df_race$Distance_C_Pelo_Pct)
skewness(df$Distance_C_Pelo_Pct)
kurtosis(df$Distance_C_Pelo_Pct)

plot(wc_points**.51)
hist(df_race$Points**.51)
boxplot(df_race$Points)
summary(df_race$Points)



model <- lm(Points~ Distance_C_Pelo_Pct, data=df_race)
summary(model)
ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points))+geom_point()


##You can clearly see a relationship between the two, let's see if 

```

```{r course-difficulty}
df_race$AltitudeCategory <- case_when(
  df_race$Altitude < 1300 ~ 0,
  #df_race$Altitude >= 1000 & df_race$Altitude <= 1500 ~ 1,
  df_race$Altitude >= 1300 ~ 1
)
# Find quartiles of Average Grade
quartiles <- quantile(df_race$`Average Grade`, probs = c(0.25, 0.75))
q1 <- quartiles[1]  # 25th percentile
q3 <- quartiles[2]  # 75th percentile

# Create categories based on quartiles
df_race$GradeCategory <- case_when(
  df_race$`Average Grade` < q3 ~ 0,                    # Below 25th percentile
  #df_race$`Average Grade` >= q1 & df_race$`Average Grade` <= q3 ~ 1,  # Between 25th and 75th
  df_race$`Average Grade` >= q3 ~ 1                     # Above 75th percentile
)
df_klaebo <- df_race[which(df_race$Skier=="Andrew Musgrave"), ]
plot(df_klaebo$AltitudeCategory, df_klaebo$Points)
plot(df_klaebo$GradeCategory, df_klaebo$Points)
summary(df_race$`Average Grade`)

altitude_aov <- aov(Points ~ AltitudeCategory, data = df_klaebo)
summary(altitude_aov)

grade_aov <- aov(Points ~ GradeCategory, data = df_klaebo)
summary(grade_aov)

pairwise.t.test(df_klaebo$Points, df_klaebo$AltitudeCategory, p.adjust.method = "bonferroni")

pairwise.t.test(df_klaebo$Points, df_klaebo$GradeCategory, p.adjust.method = "bonferroni")

df_klaebo %>%
  group_by(AltitudeCategory) %>%
  summarise(
    mean_points = mean(Points),
    sd_points = sd(Points),
    n = n()
  )

# For Grade
df_klaebo %>%
  group_by(GradeCategory) %>%
  summarise(
    mean_points = mean(Points),
    sd_points = sd(Points),
    n = n()
  )

```


```{r pts-func}
# Define wc_points vector
wc_points <- c(100,95,90,85,80,75,72,69,66,63,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)

# Define the x values (to fit against y = x)
x <- seq(1, length(wc_points))  # 1 to the length of wc_points

# Initialize an empty vector to store R² values for each z
r_squared_values <- numeric()

# Loop over z values from 0 to 1 in increments of 0.01
for (z in seq(0, 1, by = 0.01)) {
  # Transform wc_points^z
  transformed_wc_points <- wc_points^z
  
  # Fit a linear model between transformed_wc_points and x (y = x)
  model <- lm(transformed_wc_points ~ x)
  
  # Extract the R² value
  r_squared <- summary(model)$r.squared
  
  # Store the R² value
  r_squared_values <- c(r_squared_values, r_squared)
}

# Find the z value with the highest R²
best_z <- seq(0, 1, by = 0.01)[which.max(r_squared_values)]
best_r_squared <- max(r_squared_values)

# Print the result
cat("The best z value is:", best_z, "with an R² of:", best_r_squared, "\n")

# Optionally, plot R² vs z to visualize the fit
plot(seq(0, 1, by = 0.01), r_squared_values, type = "l", col = "blue", 
     xlab = "z", ylab = "R²", main = "R² vs z for wc_points^z fitting y = x")
```


## Simple Modeling
```{r simp-model}
library(quantreg)
#Linear
model <- lm(Points~ Distance_C_Pelo_Pct, data=df_race)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Log
model <- lm(log10(Points+.0001)~ Distance_C_Pelo_Pct, data=df_race)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=log10(Points+.0001))) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Square Root
model <- lm(Points**.51~ Distance_C_Pelo_Pct, data=df_race)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points**.51)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Weighted
weight <- df_race$Points
model <- lm(Points~ Distance_C_Pelo_Pct, data=df_race, weights=weight)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Quantile
weight <- df_race$Points
model <- rq(Points~ Distance_C_Pelo_Pct, data=df_race, tau=.75)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Polynomial
# Fit the polynomial regression model (degree = 3)
model_poly <- lm(Points ~ poly(Distance_C_Pelo_Pct, 3), data = df_race)

# Summary of the model
summary(model_poly)

# Generate predictions based on the polynomial model
predicted_y_poly <- predict(model_poly, newdata = df_race)

# Plot the data points and the polynomial regression line
p1 <- ggplot(df_race, aes(x = Distance_C_Pelo_Pct, y = Points)) +
  geom_point() +  # Scatter plot of actual points
  geom_line(aes(y = predicted_y_poly), col = "red") +  # Polynomial regression line
  labs(title = "Polynomial Regression (Degree 3)", x = "Distance_C_Pelo_Pct", y = "Points")

# Print the plot
print(p1)

#Tobit
library(AER)
model <- tobit(Points~ Distance_C_Pelo_Pct, data=df_race, left=.3)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#Cubic Spline
library(splines)
knots <- c(.7, .75, .8, .85, .9, .95)
model <- lm(Points~bs(Distance_C_Pelo_Pct, knots=knots, degree=3), data=df_race)
summary(model)
predicted_y <- predict(model, newdata=df_race)
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#KNN
library(FNN)
x <- df_race$Distance_C_Pelo_Pct
y <- df_race$Points
model <- knn.reg(train =as.matrix(x), y = y, k =30)
summary(model)
predicted_y <- model$pred
p1 <- ggplot(df_race, aes(x=Distance_C_Pelo_Pct, y=Points)) +
  geom_point() +
  geom_line(aes(y=predicted_y), col="red")
print(p1)

#GAM
library(mgcv)

# Fit a GAM model with a smooth spline on Distance_C_Pelo
model <- gam(Points ~ s(Distance_C_Pelo_Pct), data = df_race)

# Summary of the model
summary(model)

# Generate predictions based on the GAM model
predictions <- predict(model, newdata = df_race, se.fit=TRUE)
df_race$predicted_y <- predictions$fit
df_race$lower_ci <- predictions$fit - 1.96 * predictions$se.fit  # Lower CI
df_race$upper_ci <- predictions$fit + 1.96 * predictions$se.fit  # Upper CI

# Plot the actual data and the GAM model predictions
library(ggplot2)

# Plot the actual data, GAM predictions, and confidence intervals
p1 <- ggplot(df_race, aes(x = Distance_C_Pelo_Pct, y = Points)) +
  geom_point() +  # Scatter plot of actual points
  geom_line(aes(y = predicted_y), col = "blue") +  # GAM regression line
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2) +  # Confidence interval
  labs(title = "GAM with Confidence Interval", x = "Distance_C_Pelo_Pct", y = "Points")

# Print the plot
print(p1)





```

```{r opt-k}
find_optimal_k <- function(df, y_label, explanatory_vars, title, k_values) {
  results <- data.frame(K = k_values, R2=NA)
  print(results)
  for (i in seq_along(k_values)) {
    k <- k_values[i]
    x <- df_race$Distance_C_Pelo_Pct
      y <- df_race$Points
    model <- knn.reg(train =as.matrix(x), y = y, k =i)
    print(model)
    results$R2[i] <- model$`R2Pred`
  }

  # Plotting the R² values for different K
  kplot <- ggplot(results, aes(x = K)) +
    geom_line(aes(y = R2, color = "R²")) +
    labs(title = paste("Optimal K Selection -", title),
         x = "Number of Neighbors (K)",
         y = "R²") +
    scale_color_manual(values = c("R²" = "red")) +
    theme_minimal()
  
  # Find the optimal K (maximizing Test R²)
  optimal_k <- results$K[which.max(results$R2)]
  print(kplot)
  print(paste("Optimal K:", optimal_k))
  print(results)
  return(optimal_k)
}

k_values <- seq(1, 50)  # Trying K from 1 to 20

optimal_k <- find_optimal_k(df_race, "Points", c("Distance_C_Pelo_Pct"), "KNN(Pct_of_Max_Points) ~ Prev_Pelo", k_values)
```


##Plotting Residuals
```{r residuals}
library(gridExtra)
custom_r2 <- function(y_train, y_pred_train, y_test, y_pred_test){
    # Calculate custom weighted R² for train data
  custom_weight_train <- y_train  # Using y_train as weights
  weighted_rss_train <- sum(custom_weight_train * (y_train - y_pred_train)^2)
  weighted_tss_train <- sum(custom_weight_train * (y_train - mean(y_train))^2)
  custom_r2_train <- 1 - (weighted_rss_train / weighted_tss_train)
  
  # Calculate custom weighted R² for test data
  custom_weight_test <- y_test  # Using y_test as weights
  weighted_rss_test <- sum(custom_weight_test * (y_test - y_pred_test)^2)
  weighted_tss_test <- sum(custom_weight_test * (y_test - mean(y_test))^2)
  custom_r2_test <- 1 - (weighted_rss_test / weighted_tss_test)
  
  # Print custom R² scores

  return(list(r2_train = custom_r2_train, r2_test = custom_r2_test))
}

act_custom_rmse <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Actual), ]
  prediction_df$RMSE <- (prediction_df$Prediction-prediction_df$Actual)^2
  prediction_df <- prediction_df %>%
    filter(Actual>=.22)
  RMSE <- sqrt(mean(prediction_df$RMSE))
  
  return(RMSE)
}

act_custom_mae <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Actual), ]
  prediction_df$MAE <- abs(prediction_df$Prediction-prediction_df$Actual)
  prediction_df <- prediction_df %>%
    filter(Actual>=.22)
  MAE <- mean(prediction_df$MAE)
  
  return(MAE)
}

pred_custom_rmse <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Prediction), ]
  prediction_df$RMSE <- (prediction_df$Prediction-prediction_df$Actual)^2
  prediction_df <- prediction_df %>%
    filter(Prediction>=.22)
  RMSE <- sqrt(mean(prediction_df$RMSE))
  
  return(RMSE)
}

pred_custom_mae <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Prediction), ]
  prediction_df$MAE <- abs(prediction_df$Prediction-prediction_df$Actual)
  prediction_df <- prediction_df %>%
    filter(Prediction>=.22)
  MAE <- mean(prediction_df$MAE)
  
  return(MAE)
}


model_comp <- function(df, season, col, X_label, y_label, title){
  df_train <- df %>%
    filter(Season!=season)
  df_test <- df %>%
    filter(Season==season)

  
  custom_r2_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost"),
                               R2=NA)  # Initialize with a generic name
  colnames(custom_r2_table)[2] <- paste("R2", season, sep="_")
 # Initialize the column with NA values

  act_rmse_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost"),
                               RMSE=NA)  # Initialize with a generic name
  colnames(act_rmse_table)[2] <- paste("Actual_RMSE", season, sep="_")
  
  act_mae_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost"),
                               MAE=NA)  # Initialize with a generic name
  colnames(act_mae_table)[2] <- paste("Actual_MAE", season, sep="_")
  
  pred_rmse_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost"),
                               RMSE=NA)  # Initialize with a generic name
  colnames(pred_rmse_table)[2] <- paste("Pred_RMSE", season, sep="_")
  
  pred_mae_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost"),
                               MAE=NA)  # Initialize with a generic name
  colnames(pred_mae_table)[2] <- paste("Pred_MAE", season, sep="_")
  
  #Linear Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[1,2] <- custom_r2_test
  act_rmse_table[1,2] <- Act_RMSE
  act_mae_table[1,2] <- Act_MAE
  pred_rmse_table[1,2] <- Pred_RMSE
  pred_mae_table[1,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  
  #Log Regression
  y_train <- log10(df_train[[y_label]]+.00001)
  y_test <- log10(df_test[[y_label]]+.00001)
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- exp(predict(model, newdata = df_train))  # Predictions on training data
  y_pred_test <- exp(predict(model, newdata = df_test))    # Predictions on testing data
  y_train <- exp(y_train)
  y_test <- exp(y_test)
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(exp(y_test)))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[2,2] <- custom_r2_test
  act_rmse_table[2,2] <- Act_RMSE
  act_mae_table[2,2] <- Act_MAE
  pred_rmse_table[2,2] <- Pred_RMSE
  pred_mae_table[2,2] <- Pred_MAE
  
  print(paste("Log Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Square Root Regression
  y_train <- sqrt(df_train[[y_label]])
  y_test <- sqrt(df_test[[y_label]])
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)^2  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)^2    # Predictions on testing data
  y_train <- y_train^2
  y_test <- y_test^2
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[3,2] <- custom_r2_test
  act_rmse_table[3,2] <- Act_RMSE
  act_mae_table[3,2] <- Act_MAE
  pred_rmse_table[3,2] <- Pred_RMSE
  pred_mae_table[3,2] <- Pred_MAE
  
  print(paste("Square Root Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Weighted Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  weight = y_train
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train, weights=y_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data

  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[4,2] <- custom_r2_test
  act_rmse_table[4,2] <- Act_RMSE
  act_mae_table[4,2] <- Act_MAE
  pred_rmse_table[4,2] <- Pred_RMSE
  pred_mae_table[4,2] <- Pred_MAE
  
  print(paste("Weighted Regression Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Quantile Regression
  tau_value=.75
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  weight = y_train
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- rq(formula, data = df_train, tau = tau_value)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data

  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[5,2] <- custom_r2_test
  act_rmse_table[5,2] <- Act_RMSE
  act_mae_table[5,2] <- Act_MAE
  pred_rmse_table[5,2] <- Pred_RMSE
  pred_mae_table[5,2] <- Pred_MAE
  
  print(paste("Quantile Regression Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  print(length(y_test))
  print(length(y_pred_test))
y_test <- as.numeric(y_test)  # Ensure numeric
y_pred_test <- as.numeric(y_pred_test)
sum(is.na(y_test))  # Should return 0 if no NAs
sum(is.na(y_pred_test))
  
  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  print(plot_data)
  
# Set up the 2x2 plot layout
par(mfrow = c(2, 2))

# 1. Residuals vs Fitted
plot(fitted(model), residuals(model),
     main = "Residuals vs Fitted",
     xlab = "Fitted values",
     ylab = "Residuals")
abline(h = 0, col = "red")

# 2. Q-Q Plot of Residuals
qqnorm(residuals(model), main = "Normal Q-Q")
qqline(residuals(model), col = "red")

# 3. Scale-Location Plot (sqrt of standardized residuals vs modelted values)
sqrt_std_resid <- sqrt(abs(residuals(model)))  # Standardized residuals
plot(fitted(model), sqrt_std_resid,
     main = "Scale-Location",
     xlab = "Fitted values",
     ylab = "Sqrt |Residuals|")
abline(h = 0, col = "red")

# 4. Residuals vs Leverage
plot(seq_along(residuals(model)), residuals(model),
     main = "Residuals vs Index",
     xlab = "Index",
     ylab = "Residuals")
abline(h = 0, col = "red")


  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  
   #Polynomial Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  poly_terms <- paste0("poly(", col, ", 3)", collapse=" + ")
  formula_string <- paste(y_label, "~", poly_terms)
  
  # Print the formula for verification
  print(formula_string)
  
  # Create the formula object
  formula <- as.formula(formula_string)
  
  # Fit the polynomial regression model (degree 3)
  model <- lm(formula, data = df_train)
  
  # Print model summary
  print(summary(model))
  
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test) 
    
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[6,2] <- custom_r2_test
  act_rmse_table[6,2] <- Act_RMSE
  act_mae_table[6,2] <- Act_MAE
  pred_rmse_table[6,2] <- Pred_RMSE
  pred_mae_table[6,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)

  
    #Tobit Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- tobit(formula, data=df_train, left=.3)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[7,2] <- custom_r2_test
  act_rmse_table[7,2] <- Act_RMSE
  act_mae_table[7,2] <- Act_MAE
  pred_rmse_table[7,2] <- Pred_RMSE
  pred_mae_table[7,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  fitted_values <- fitted(model)
residuals <- residuals(model)

# 1. Residuals vs Fitted plot
p1 <- ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, col = "red") +
  labs(title = "Residuals vs Fitted", x = "Fitted values", y = "Residuals") +
  theme_minimal()

# 2. Q-Q plot of residuals
p2 <- ggplot(data = data.frame(sample = residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Q-Q plot", x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()

# 3. Scale-Location plot (square root of residuals)
p3 <- ggplot(data = data.frame(fitted = fitted_values, residuals = sqrt(abs(residuals))), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, col = "red") +
  labs(title = "Scale-Location", x = "Fitted values", y = "Sqrt(|Residuals|)") +
  theme_minimal()

# 4. Residuals vs Leverage (no hatvalues for tobit, so using fitted values as a proxy)
p4 <- ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  labs(title = "Residuals vs Leverage (approx.)", x = "Fitted values", y = "Residuals") +
  theme_minimal()

# Arrange the plots in a 2x2 grid
grid.arrange(p1, p2, p3, p4, nrow = 2)


  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  #Cubic Spline Regression
  knots <- c(.7, .75, .8, .85, .9, .95)

y_train <- df_train[[y_label]]
y_test <- df_test[[y_label]]

# Create spline terms for multiple columns
spline_terms <- sapply(col, function(c) paste("bs(", c, ", knots = c(", paste(knots, collapse = ", "), "), degree = 3)", sep = ""))
formula_string <- paste(y_label, "~", paste(spline_terms, collapse = " + "))

# Print the formula for verification
print(formula_string)

# Convert the formula string to an actual formula object
formula <- as.formula(formula_string)

# Train the model with the B-spline transformations
model <- lm(formula, data = df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[8,2] <- custom_r2_test
  act_rmse_table[8,2] <- Act_RMSE
  act_mae_table[8,2] <- Act_MAE
  pred_rmse_table[8,2] <- Pred_RMSE
  pred_mae_table[8,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #KNN Regression

  X_trn_df <- as.matrix(df_train[, col, drop = FALSE])
  y_trn_df <- as.numeric(df_train[[y_label]])
  X_tst_df <- as.matrix(df_test[, col, drop = FALSE])
  y_tst_df <- as.numeric(df_test[[y_label]])
  
  n_neighbors=30
  
  # Make predictions on both the training and test sets
  y_pred_train <- knn.reg(train = X_trn_df, test = X_trn_df, y = y_trn_df, k = n_neighbors)

  y_pred_test <- knn.reg(train = X_trn_df, test = X_tst_df, y = y_trn_df, k = n_neighbors)

  residuals_test <- y_tst_df - y_pred_train$pred
  

  
  prediction_df <- data.frame(Prediction=c(y_pred_test$pred), Actual=c(y_tst_df))

  
  custom_r2_train <- custom_r2(y_trn_df, y_pred_train$pred, y_tst_df, y_pred_test$pred)$r2_train
  custom_r2_test <- custom_r2(y_trn_df, y_pred_train$pred, y_tst_df, y_pred_test$pred)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  
  custom_r2_table[9,2] <- custom_r2_test
  act_rmse_table[9,2] <- Act_RMSE
  act_mae_table[9,2] <- Act_MAE
  pred_rmse_table[9,2] <- Pred_RMSE
  pred_mae_table[9,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  # Calculate residuals
  residuals_train <- y_trn_df - y_pred_train$pred
  residuals_test <- y_tst_df - y_pred_test$pred
  
  # Create a data frame for plotting
  plot_data_train <- data.frame(Fitted = y_pred_train$pred, Residuals = residuals_train)
  plot_data_test <- data.frame(Fitted = y_pred_test$pred, Residuals = residuals_test)
  
  # Set up the plotting area for 2x2 layout
  par(mfrow = c(2, 2))
  
  # 1. Residuals vs Fitted
  plot(plot_data_train$Fitted, plot_data_train$Residuals,
       xlab = "Fitted Values", ylab = "Residuals",
       main = "Residuals vs Fitted",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")
  
  # 2. Q-Q plot of residuals
  qqnorm(residuals_train, main = "Q-Q Plot of Residuals")
  qqline(residuals_train, col = "red")
  
  # 3. Scale-Location Plot
  sqrt_residuals <- sqrt(abs(plot_data_train$Residuals))
  plot(plot_data_train$Fitted, sqrt_residuals,
       xlab = "Fitted Values", ylab = "Sqrt |Residuals|",
       main = "Scale-Location",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")
  
  # 4. Residuals vs Leverage (not typically applicable for KNN)
  # For this plot, we can just show residuals vs fitted values again
  plot(plot_data_train$Fitted, residuals_train,
       xlab = "Fitted Values", ylab = "Residuals",
       main = "Residuals vs Fitted (Leverage Plot)",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
    #GAM Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  
  # Create the formula for the model (use s() to fit smooth terms)
  smooth_terms <- paste("s(", col, ")", collapse=" + ")  # Adding smooth terms for each predictor
  formula_string <- paste(y_label, "~", smooth_terms)
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  
  # Train the GAM model
  model <- gam(formula, data = df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[10,2] <- custom_r2_test
  act_rmse_table[10,2] <- Act_RMSE
  act_mae_table[10,2] <- Act_MAE
  pred_rmse_table[10,2] <- Pred_RMSE
  pred_mae_table[10,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  gam.check(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  
#XGBoost
library(xgboost)

# Convert data to DMatrix format
dtrain <- xgb.DMatrix(data = as.matrix(df_train[col]), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(df_test[col]), label = y_test)

# Set XGBoost parameters
params <- list(
  objective = "reg:squarederror",
  booster = "gbtree",
  eta = 0.1,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

# Train the model
model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  verbose = 0
)

# Make predictions
y_pred_train <- predict(model, dtrain)
y_pred_test <- predict(model, dtest)

# Calculate metrics
prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
Act_RMSE <- act_custom_rmse(prediction_df)
Act_MAE <- act_custom_mae(prediction_df)
Pred_RMSE <- pred_custom_rmse(prediction_df)
Pred_MAE <- pred_custom_mae(prediction_df)

# Update tables
custom_r2_table[11,2] <- custom_r2_test
act_rmse_table[11,2] <- Act_RMSE
act_mae_table[11,2] <- Act_MAE
pred_rmse_table[11,2] <- Pred_RMSE
pred_mae_table[11,2] <- Pred_MAE

# Print summary
print(paste("XGBoost Model Summary for: ", title))
print(paste("Custom R² (Train):", custom_r2_train))
print(paste("Custom R² (Test):", custom_r2_test))

# Create and display Predicted vs Actual plot
plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
p <- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = title,
       x = "Predicted Values",
       y = y_label) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

print(p)

# Optional: Cross-validation
cv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,
  nfold = 5,
  early_stopping_rounds = 10,
  verbose = 0
)

print(paste("Best iteration:", which.min(cv$evaluation_log$test_rmse_mean)))
    
  print(custom_r2_table)
  print(act_rmse_table)
  print(pred_rmse_table)
  print(act_mae_table)
  print(pred_mae_table)
  return(list(r2=custom_r2_table, actual_rmse=act_rmse_table, predicted_rmse=pred_rmse_table, actual_mae=act_mae_table, predicted_mae=pred_mae_table))
}
  
  model_comp_2015 <- model_comp(df_race, 2015, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2015")
  model_comp_2016 <- model_comp(df_race, 2016, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2016")
  model_comp_2017 <- model_comp(df_race, 2017, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2017")
  model_comp_2018 <- model_comp(df_race, 2018, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2018")
  model_comp_2019 <- model_comp(df_race, 2019, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2019")
  model_comp_2020 <- model_comp(df_race, 2020, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2020")
  model_comp_2021 <- model_comp(df_race, 2021, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2021")
  model_comp_2022 <- model_comp(df_race, 2022, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2022")
  model_comp_2023 <- model_comp(df_race, 2023, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2023")
  model_comp_2024 <- model_comp(df_race, 2024, c("Distance_C_Pelo_Pct"), "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2024")
  
  library(openxlsx)
# Sequentially merge data frames on the "Skier" column
r2_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$r2, model_comp_2016$r2, model_comp_2017$r2, model_comp_2018$r2, model_comp_2019$r2, model_comp_2020$r2, model_comp_2021$r2, 
                         model_comp_2022$r2, model_comp_2023$r2, model_comp_2024$r2))

actual_rmse_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$actual_rmse, model_comp_2016$actual_rmse, model_comp_2017$actual_rmse, model_comp_2018$actual_rmse, model_comp_2019$actual_rmse, model_comp_2020$actual_rmse, model_comp_2021$actual_rmse, model_comp_2022$actual_rmse, model_comp_2023$actual_rmse, model_comp_2024$actual_rmse))

predicted_rmse_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$predicted_rmse, model_comp_2016$predicted_rmse, model_comp_2017$predicted_rmse, model_comp_2018$predicted_rmse, model_comp_2019$predicted_rmse, model_comp_2020$predicted_rmse, model_comp_2021$predicted_rmse, model_comp_2022$predicted_rmse, model_comp_2023$predicted_rmse, model_comp_2024$predicted_rmse))

actual_mae_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$actual_mae, model_comp_2016$actual_mae, model_comp_2017$actual_mae, model_comp_2018$actual_mae, model_comp_2019$actual_mae, model_comp_2020$actual_mae, model_comp_2021$actual_mae, model_comp_2022$actual_mae, model_comp_2023$actual_mae, model_comp_2024$actual_mae))

predicted_mae_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$predicted_mae, model_comp_2016$predicted_mae, model_comp_2017$predicted_mae, model_comp_2018$predicted_mae, model_comp_2019$predicted_mae, model_comp_2020$predicted_mae, model_comp_2021$predicted_mae, model_comp_2022$predicted_mae, model_comp_2023$predicted_mae, model_comp_2024$predicted_mae))

r2_df$Avg <- rowMeans(r2_df[, seq(2, ncol(r2_df), by = 1)], na.rm = TRUE)
r2_df <- r2_df[order(-r2_df$Avg), ] 
write.xlsx(r2_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-simple-model-tests-r2.xlsx")

actual_rmse_df$Avg <- rowMeans(actual_rmse_df[, seq(2, ncol(actual_rmse_df), by = 1)], na.rm = TRUE)
actual_rmse_df <- actual_rmse_df[order(actual_rmse_df$Avg), ] 
write.xlsx(actual_rmse_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-simple-model-tests-actual_rmse.xlsx")

predicted_rmse_df$Avg <- rowMeans(predicted_rmse_df[, seq(2, ncol(predicted_rmse_df), by = 1)], na.rm = TRUE)
predicted_rmse_df <- predicted_rmse_df[order(predicted_rmse_df$Avg), ] 
write.xlsx(predicted_rmse_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-simple-model-tests-predicted_rmse.xlsx")

actual_mae_df$Avg <- rowMeans(actual_mae_df[, seq(2, ncol(actual_mae_df), by = 1)], na.rm = TRUE)
actual_mae_df <- actual_mae_df[order(actual_mae_df$Avg), ] 
write.xlsx(actual_mae_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-simple-model-tests-actual_mae.xlsx")

predicted_mae_df$Avg <- rowMeans(predicted_mae_df[, seq(2, ncol(predicted_mae_df), by = 1)], na.rm = TRUE)
predicted_mae_df <- predicted_mae_df[order(predicted_mae_df$Avg), ] 
write.xlsx(predicted_mae_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-simple-model-tests-predicted_mae.xlsx")


```




## Feature Selection

### Weighing Previous Points
```{r prev-points}
df_race <- df_race %>%
  arrange(ID, desc(Season), desc(Race))

df_klaebo <- df_race[which(df_race$Skier=="Johannes Høsflot Klæbo"), ]


df_race <- df_race %>%
  group_by(ID) %>%
  arrange(Season, Race) %>%  # Ensure proper ordering
  mutate(Prev_Points = sapply(1:n(), function(i) {
    if (i == 1) {
      return(0)  # If there are no previous races, set to 0
    }
    start_index <- max(1, i - 5)  # Look at the 5 races before this row
    
    # Calculate the average of Points from previous races
    mean(Points[start_index:(i-1)], na.rm = TRUE)
  })) %>%
  ungroup()


# Group by Skier and calculate the average of the most recent 5 races
df_race <- df_race %>%
  group_by(ID) %>%
  arrange(Season, Race) %>%  # Ensure proper ordering
  mutate(Prev_Points_Weighted = sapply(1:n(), function(i) {
    if (i == 1) {
      return(0)  # If there are no previous races, set to 0
    }
    start_index <- max(1, i - 5)  # Look at the 5 races before this row
    num_races <- i - start_index  # Number of races before the current row
    
    # Create the weights, with more recent races weighted higher
    weights <- seq(1, num_races)
    
    # Calculate weighted average of Points from previous races
    weighted.mean(Points[start_index:(i-1)], w = weights, na.rm = TRUE)
  })) %>%
  ungroup()


df_race[which(df_race$Skier=="Johannes Høsflot Klæbo"), c("Skier","Season", "Race", "Points", "Prev_Points_Weighted")]

model_comp_2024 <- model_comp(df_race, 2024, c("Distance_C_Pelo_Pct", "Prev_Points"), "Distance Classic Pelo + Prev_Points", "Points", "Comparing Distance Classic Elo and Points in 2024")
model_comp_2024 <- model_comp(df_race, 2024, c("Distance_C_Pelo_Pct", "Prev_Points_Weighted"), "Distance Classic Pelo + Prev_Points", "Points", "Comparing Distance Classic Elo and Points in 2024")

#The weighted one seemed to be significantly better!!

df_race75 <- df_race[which(df_race$Distance_C_Pelo_Pct>.75), ]
model_comp_2024 <- model_comp(df_race75, 2024, c("Distance_C_Pelo_Pct", "Prev_Points_Weighted"), "Distance Classic Pelo + Prev_Points", "Points", "Comparing Distance Classic Elo and Points in 2024")

##Doesn't seem to be any better


```

### Narrowing Elo Scores

### Recursive Selection
```{r rec-sel}
df_race75$Home <- ifelse(df_race75$Country==df_race75$Nation, 1, 0)

colnames(df_race)
explanatory_vars <- c("Pelo_Pct", "Distance_Pelo_Pct", "Distance_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Sprint_Pelo_Pct", "Sprint_C_Pelo_Pct", "Sprint_F_Pelo_Pct", "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Home", "Prev_Points_Weighted", "Points")

library(corrplot)

# Select only the columns of interest
# Subset the relevant columns using base R
correlation_vars <- df_race75[, c("Pelo_Pct", "Distance_Pelo_Pct", "Distance_C_Pelo_Pct", "Distance_F_Pelo_Pct",
                                "Sprint_Pelo_Pct", "Sprint_C_Pelo_Pct", "Sprint_F_Pelo_Pct", "Classic_Pelo_Pct",
                                "Freestyle_Pelo_Pct", "Home", "Prev_Points", "Points")]

# Compute the correlation matrix
cor_matrix <- cor(correlation_vars, use = "complete.obs")

# Create the correlation plot
corrplot(cor_matrix, method = "circle", type = "full", tl.col = "black", tl.cex = 0.8, 
         addCoef.col = "black", number.cex = 0.7)

library(DataExplorer)
plot_correlation(correlation_vars)


library(caret)
control <- rfeControl(functions = rfFuncs, # random forest
                      method = "repeatedcv", # repeated cv
                      repeats = 5, # number of repeats
                      number = 5) # number of folds

# Define explanatory variables
explanatory_vars <- c("Pelo_Pct", "Distance_Pelo_Pct", "Distance_C_Pelo_Pct",
                       "Distance_F_Pelo_Pct", "Sprint_Pelo_Pct",
                       "Sprint_C_Pelo_Pct", "Sprint_F_Pelo_Pct",
                       "Classic_Pelo_Pct", "Freestyle_Pelo_Pct",
                       "Home", "Prev_Points_Weighted")

#explanatory_vars <- c("Distance_C_Pelo_Pct")



# Select the explanatory variables and convert to data frame
x <- df_race75[ , explanatory_vars, drop = FALSE]

# Target variable
y <- df_race75$Points

# Training: 80%; Test: 20%
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[inTrain]
y_test  <- y[-inTrain]

train_data <- df_race75 %>% filter(Season < 2024)

# Filter testing data for season 2024
test_data <- df_race75 %>% filter(Season == 2024)

# Target variable for training
y_train <- train_data$Points  # Use Points as the target variable for training

# Explanatory variables for training
x_train <- train_data[ , explanatory_vars, drop = FALSE] 
# Target variable for testing
y_test <- test_data$Points  # Use Points as the target variable for testing

# Explanatory variables for testing
x_test <- test_data[ , explanatory_vars, drop = FALSE] 

sample_indices <- sample(nrow(x_train), 1000)

# Create the small training dataset
x_train_small <- x_train[sample_indices, ]  # Use the sampled indices to subset x_train
y_train_small <- y_train[sample_indices]

# Run RFE
library(randomForest)
result_rfe1 <- rfe(x = x_train_small, 
                   y = y_train_small, 
                   sizes = c(1:length(explanatory_vars)),
                   rfeControl = control)

# Print the results
result_rfe1

# Print the selected features
predictors(result_rfe1)

# Print the results visually
ggplot(data = result_rfe1, metric = "MAE") + theme_bw()
ggplot(data = result_rfe1, metric = "RMSE") + theme_bw()

varimp_data <- data.frame(feature = row.names(varImp(result_rfe1))[1:8],
                          importance = varImp(result_rfe1)[1:8, 1])

ggplot(data = varimp_data, 
       aes(x = reorder(feature, -importance), y = importance, fill = feature)) +
  geom_bar(stat="identity") + labs(x = "Features", y = "Variable Importance") + 
  geom_text(aes(label = round(importance, 2)), vjust=1.6, color="white", size=4) + 
  theme_bw() + theme(legend.position = "none")

postResample(predict(result_rfe1, x_test), y_test)

```


```{r for-sel}
# Assuming your response variable is 'Points' and your dataframe is 'train_data'

# Step 1: Install and load the leaps package
library(leaps)

# Step 2: Prepare your data
# Make sure you have a data frame with your response variable and explanatory variables
response_variable <- "Points"
explanatory_vars <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
                      "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
                      "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", 
                      "Pelo_Pct", "Home")

# Step 3: Create a formula for the model
formula <- as.formula(paste(response_variable, "~", paste(explanatory_vars, collapse = " + ")))

# Step 4: Perform forward selection
forward_selection <- regsubsets(formula, data = train_data, nbest = 1, method = "forward")

# Step 5: Summary of the forward selection
summary(forward_selection)

best_model <- which.max
(summary(forward_selection)$adjr2)  # Index of the best model based on adjusted R-squared
selected_vars <- names(coef(forward_selection, best_model))
selected_vars  # This will give you the selected variable names


```

```{r back-sel}
# Step 1: Install and load the leaps package
library(leaps)

# Step 2: Prepare your data
response_variable <- "Points"
explanatory_vars <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
                      "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
                      "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", 
                      "Pelo_Pct", "Home")

# Step 3: Create aformula for the model
formula <- as.formula(paste(response_variable, "~", paste(explanatory_vars, collapse = " + ")))

# Step 4: Perform backward selection
backward_selection <- regsubsets(formula, data = train_data, nbest = 1, method = "backward")

# Step 5: Summary of the backward selection
summary(backward_selection)

best_model <- which.max(summary(backward_selection)$adjr2)  # Index of the best model based on adjusted R-squared
selected_vars <- names(coef(backward_selection, best_model))
selected_vars  # This will give you the selected variable names


```

```{r exhaustive-search}
# Step 1: Install and load the leaps package
library(leaps)

# Step 2: Prepare your data
response_variable <- "Points"
explanatory_vars <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
                      "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
                      "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", 
                      "Pelo_Pct", "Home")

# Step 3: Create a formula for the model
formula <- as.formula(paste(response_variable, "~", paste(explanatory_vars, collapse = " + ")))

# Step 4: Perform exhaustive search
exhaustive_selection <- regsubsets(formula, data = train_data, nbest = 1, method = "exhaustive")

# Step 5: Summary of the exhaustive search
summary_exhaustive <- summary(exhaustive_selection)

# Step 6: Evaluate the results
# For example, you can look for the model with the highest adjusted R-squared
best_model_index <- which.max(summary_exhaustive$adjr2)
best_selected_vars <- names(coef(exhaustive_selection, best_model_index))

# Display the best selected variables
best_selected_vars



# Example to find the best model based on BIC
best_bic_model_index <- which.min(summary_exhaustive$bic)
best_bic_selected_vars <- names(coef(exhaustive_selection, best_bic_model_index))

# Display the best BIC selected variables
best_bic_selected_vars


```


## Model Selection

### Exhaustive Model
```{r exhaustive-model}
library(quantreg)
library(gridExtra)
custom_r2 <- function(y_train, y_pred_train, y_test, y_pred_test){
    # Calculate custom weighted R² for train data
  custom_weight_train <- y_train  # Using y_train as weights
  weighted_rss_train <- sum(custom_weight_train * (y_train - y_pred_train)^2)
  weighted_tss_train <- sum(custom_weight_train * (y_train - mean(y_train))^2)
  custom_r2_train <- 1 - (weighted_rss_train / weighted_tss_train)
  
  # Calculate custom weighted R² for test data
  custom_weight_test <- y_test  # Using y_test as weights
  weighted_rss_test <- sum(custom_weight_test * (y_test - y_pred_test)^2)
  weighted_tss_test <- sum(custom_weight_test * (y_test - mean(y_test))^2)
  custom_r2_test <- 1 - (weighted_rss_test / weighted_tss_test)
  
  # Print custom R² scores

  return(list(r2_train = custom_r2_train, r2_test = custom_r2_test))
}

act_custom_rmse <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Actual), ]
  prediction_df$RMSE <- (prediction_df$Prediction-prediction_df$Actual)^2
  prediction_df <- prediction_df %>%
    filter(Actual>=.22)
  RMSE <- sqrt(mean(prediction_df$RMSE))
  
  return(RMSE)
}

act_custom_mae <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Actual), ]
  prediction_df$MAE <- abs(prediction_df$Prediction-prediction_df$Actual)
  prediction_df <- prediction_df %>%
    filter(Actual>=.22)
  MAE <- mean(prediction_df$MAE)
  
  return(MAE)
}

pred_custom_rmse <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Prediction), ]
  prediction_df$RMSE <- (prediction_df$Prediction-prediction_df$Actual)^2
  prediction_df <- prediction_df %>%
    filter(Prediction>=.22)
  RMSE <- sqrt(mean(prediction_df$RMSE))
  
  return(RMSE)
}

pred_custom_mae <- function(prediction_df){
  #Want to know how close I am to actual results
  prediction_df <- prediction_df[order(-prediction_df$Prediction), ]
  prediction_df$MAE <- abs(prediction_df$Prediction-prediction_df$Actual)
  prediction_df <- prediction_df %>%
    filter(Prediction>=.22)
  MAE <- mean(prediction_df$MAE)
  
  return(MAE)
}


model_comp <- function(df, season, col, X_label, y_label, title){
  df_train <- df %>%
    filter(Season!=season)
  df_test <- df %>%
    filter(Season==season)
  custom_r2_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost", "Random Forest"),
                               R2=NA)  # Initialize with a generic name
  colnames(custom_r2_table)[2] <- paste("R2", season, sep="_")
 # Initialize the column with NA values

  act_rmse_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost", "Random Forest"),
                               RMSE=NA)  # Initialize with a generic name
  colnames(act_rmse_table)[2] <- paste("Actual_RMSE", season, sep="_")
  
  act_mae_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost", "Random Forest"),
                               MAE=NA)  # Initialize with a generic name
  colnames(act_mae_table)[2] <- paste("Actual_MAE", season, sep="_")
  
  pred_rmse_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost", "Random Forest"),
                               RMSE=NA)  # Initialize with a generic name
  colnames(pred_rmse_table)[2] <- paste("Pred_RMSE", season, sep="_")
  
  pred_mae_table <- data.frame(Model=c("Linear", "Log", "Square Root", "Weighted", "Quantile", 
                                       "Polynomial", "Tobit", "Spline", "KNN", "GAM", "XGBoost", "Random Forest"),
                               MAE=NA)  # Initialize with a generic name
  colnames(pred_mae_table)[2] <- paste("Pred_MAE", season, sep="_")
  
  #Linear Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[1,2] <- custom_r2_test
  act_rmse_table[1,2] <- Act_RMSE
  act_mae_table[1,2] <- Act_MAE
  pred_rmse_table[1,2] <- Pred_RMSE
  pred_mae_table[1,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  
  #Log Regression
  y_train <- log10(df_train[[y_label]]+.00001)
  y_test <- log10(df_test[[y_label]]+.00001)
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- exp(predict(model, newdata = df_train))  # Predictions on training data
  y_pred_test <- exp(predict(model, newdata = df_test))    # Predictions on testing data
  y_train <- exp(y_train)
  y_test <- exp(y_test)
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(exp(y_test)))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[2,2] <- custom_r2_test
  act_rmse_table[2,2] <- Act_RMSE
  act_mae_table[2,2] <- Act_MAE
  pred_rmse_table[2,2] <- Pred_RMSE
  pred_mae_table[2,2] <- Pred_MAE
  
  print(paste("Log Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Square Root Regression
  y_train <- sqrt(df_train[[y_label]])
  y_test <- sqrt(df_test[[y_label]])
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)^2  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)^2    # Predictions on testing data
  y_train <- y_train^2
  y_test <- y_test^2
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[3,2] <- custom_r2_test
  act_rmse_table[3,2] <- Act_RMSE
  act_mae_table[3,2] <- Act_MAE
  pred_rmse_table[3,2] <- Pred_RMSE
  pred_mae_table[3,2] <- Pred_MAE
  
  print(paste("Square Root Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Weighted Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  weight = y_train
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- lm(formula, data=df_train, weights=y_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data

  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[4,2] <- custom_r2_test
  act_rmse_table[4,2] <- Act_RMSE
  act_mae_table[4,2] <- Act_MAE
  pred_rmse_table[4,2] <- Pred_RMSE
  pred_mae_table[4,2] <- Pred_MAE
  
  print(paste("Weighted Regression Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #Quantile Regression
  tau_value=.75
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  weight = y_train
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- rq(formula, data = df_train, tau = tau_value)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data

  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  print(prediction_df)
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[5,2] <- custom_r2_test
  act_rmse_table[5,2] <- Act_RMSE
  act_mae_table[5,2] <- Act_MAE
  pred_rmse_table[5,2] <- Pred_RMSE
  pred_mae_table[5,2] <- Pred_MAE
  
  print(paste("Quantile Regression Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  print(length(y_test))
  print(length(y_pred_test))
y_test <- as.numeric(y_test)  # Ensure numeric
y_pred_test <- as.numeric(y_pred_test)
sum(is.na(y_test))  # Should return 0 if no NAs
sum(is.na(y_pred_test))
  
  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  print(plot_data)
  
# Set up the 2x2 plot layout
par(mfrow = c(2, 2))

# 1. Residuals vs Fitted
plot(fitted(model), residuals(model),
     main = "Residuals vs Fitted",
     xlab = "Fitted values",
     ylab = "Residuals")
abline(h = 0, col = "red")

# 2. Q-Q Plot of Residuals
qqnorm(residuals(model), main = "Normal Q-Q")
qqline(residuals(model), col = "red")

# 3. Scale-Location Plot (sqrt of standardized residuals vs modelted values)
sqrt_std_resid <- sqrt(abs(residuals(model)))  # Standardized residuals
plot(fitted(model), sqrt_std_resid,
     main = "Scale-Location",
     xlab = "Fitted values",
     ylab = "Sqrt |Residuals|")
abline(h = 0, col = "red")

# 4. Residuals vs Leverage
plot(seq_along(residuals(model)), residuals(model),
     main = "Residuals vs Index",
     xlab = "Index",
     ylab = "Residuals")
abline(h = 0, col = "red")


  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  
   #Polynomial Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  poly_terms <- paste0("poly(", col, ", 3)", collapse=" + ")
  formula_string <- paste(y_label, "~", poly_terms)
  
  # Print the formula for verification
  print(formula_string)
  
  # Create the formula object
  formula <- as.formula(formula_string)
  
  # Fit the polynomial regression model (degree 3)
  model <- lm(formula, data = df_train)
  
  # Print model summary
  print(summary(model))
  
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test) 
    
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[6,2] <- custom_r2_test
  act_rmse_table[6,2] <- Act_RMSE
  act_mae_table[6,2] <- Act_MAE
  pred_rmse_table[6,2] <- Pred_RMSE
  pred_mae_table[6,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)

  
    #Tobit Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  formula_string <- paste(y_label, "~", paste(col, collapse=" + "))
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  model <- tobit(formula, data=df_train, left=.3)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[7,2] <- custom_r2_test
  act_rmse_table[7,2] <- Act_RMSE
  act_mae_table[7,2] <- Act_MAE
  pred_rmse_table[7,2] <- Pred_RMSE
  pred_mae_table[7,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  fitted_values <- fitted(model)
residuals <- residuals(model)

# 1. Residuals vs Fitted plot
p1 <- ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, col = "red") +
  labs(title = "Residuals vs Fitted", x = "Fitted values", y = "Residuals") +
  theme_minimal()

# 2. Q-Q plot of residuals
p2 <- ggplot(data = data.frame(sample = residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Q-Q plot", x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()

# 3. Scale-Location plot (square root of residuals)
p3 <- ggplot(data = data.frame(fitted = fitted_values, residuals = sqrt(abs(residuals))), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, col = "red") +
  labs(title = "Scale-Location", x = "Fitted values", y = "Sqrt(|Residuals|)") +
  theme_minimal()

# 4. Residuals vs Leverage (no hatvalues for tobit, so using fitted values as a proxy)
p4 <- ggplot(data = data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  labs(title = "Residuals vs Leverage (approx.)", x = "Fitted values", y = "Residuals") +
  theme_minimal()

# Arrange the plots in a 2x2 grid
grid.arrange(p1, p2, p3, p4, nrow = 2)


  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  #Cubic Spline Regression
  knots <- c(.7, .75, .8, .85, .9, .95)

y_train <- df_train[[y_label]]
y_test <- df_test[[y_label]]

# Create spline terms for multiple columns
spline_terms <- sapply(col, function(c) paste("bs(", c, ", knots = c(", paste(knots, collapse = ", "), "), degree = 3)", sep = ""))
formula_string <- paste(y_label, "~", paste(spline_terms, collapse = " + "))

# Print the formula for verification
print(formula_string)

# Convert the formula string to an actual formula object
formula <- as.formula(formula_string)

# Train the model with the B-spline transformations
model <- lm(formula, data = df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[8,2] <- custom_r2_test
  act_rmse_table[8,2] <- Act_RMSE
  act_mae_table[8,2] <- Act_MAE
  pred_rmse_table[8,2] <- Pred_RMSE
  pred_mae_table[8,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  plot(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)  
  
  #KNN Regression

  X_trn_df <- as.matrix(df_train[, col, drop = FALSE])
  y_trn_df <- as.numeric(df_train[[y_label]])
  X_tst_df <- as.matrix(df_test[, col, drop = FALSE])
  y_tst_df <- as.numeric(df_test[[y_label]])
  
  n_neighbors=30
  
  # Make predictions on both the training and test sets
  y_pred_train <- knn.reg(train = X_trn_df, test = X_trn_df, y = y_trn_df, k = n_neighbors)

  y_pred_test <- knn.reg(train = X_trn_df, test = X_tst_df, y = y_trn_df, k = n_neighbors)

  residuals_test <- y_tst_df - y_pred_train$pred
  

  
  prediction_df <- data.frame(Prediction=c(y_pred_test$pred), Actual=c(y_tst_df))

  
  custom_r2_train <- custom_r2(y_trn_df, y_pred_train$pred, y_tst_df, y_pred_test$pred)$r2_train
  custom_r2_test <- custom_r2(y_trn_df, y_pred_train$pred, y_tst_df, y_pred_test$pred)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  
  custom_r2_table[9,2] <- custom_r2_test
  act_rmse_table[9,2] <- Act_RMSE
  act_mae_table[9,2] <- Act_MAE
  pred_rmse_table[9,2] <- Pred_RMSE
  pred_mae_table[9,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  # Calculate residuals
  residuals_train <- y_trn_df - y_pred_train$pred
  residuals_test <- y_tst_df - y_pred_test$pred
  
  # Create a data frame for plotting
  plot_data_train <- data.frame(Fitted = y_pred_train$pred, Residuals = residuals_train)
  plot_data_test <- data.frame(Fitted = y_pred_test$pred, Residuals = residuals_test)
  
  # Set up the plotting area for 2x2 layout
  par(mfrow = c(2, 2))
  
  # 1. Residuals vs Fitted
  plot(plot_data_train$Fitted, plot_data_train$Residuals,
       xlab = "Fitted Values", ylab = "Residuals",
       main = "Residuals vs Fitted",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")
  
  # 2. Q-Q plot of residuals
  qqnorm(residuals_train, main = "Q-Q Plot of Residuals")
  qqline(residuals_train, col = "red")
  
  # 3. Scale-Location Plot
  sqrt_residuals <- sqrt(abs(plot_data_train$Residuals))
  plot(plot_data_train$Fitted, sqrt_residuals,
       xlab = "Fitted Values", ylab = "Sqrt |Residuals|",
       main = "Scale-Location",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")
  
  # 4. Residuals vs Leverage (not typically applicable for KNN)
  # For this plot, we can just show residuals vs fitted values again
  plot(plot_data_train$Fitted, residuals_train,
       xlab = "Fitted Values", ylab = "Residuals",
       main = "Residuals vs Fitted (Leverage Plot)",
       pch = 19, col = "blue")
  abline(h = 0, lty = 2, col = "red")

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
    #GAM Regression
  y_train <- df_train[[y_label]]
  y_test <- df_test[[y_label]]
  
  # Create the formula for the model (use s() to fit smooth terms)
  smooth_terms <- paste("s(", col, ")", collapse=" + ")  # Adding smooth terms for each predictor
  formula_string <- paste(y_label, "~", smooth_terms)
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  
  # Train the GAM model
  model <- gam(formula, data = df_train)
  print(summary(model))  # Print model summary
  # Make predictions
  y_pred_train <- predict(model, newdata = df_train)  # Predictions on training data
  y_pred_test <- predict(model, newdata = df_test)    # Predictions on testing data
  
  prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
  custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
  custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
  Act_RMSE <- act_custom_rmse(prediction_df)
  Act_MAE <- act_custom_mae(prediction_df)
  Pred_RMSE <- pred_custom_rmse(prediction_df)
  Pred_MAE <- pred_custom_mae(prediction_df)
  
  
  custom_r2_table[10,2] <- custom_r2_test
  act_rmse_table[10,2] <- Act_RMSE
  act_mae_table[10,2] <- Act_MAE
  pred_rmse_table[10,2] <- Pred_RMSE
  pred_mae_table[10,2] <- Pred_MAE
  
  print(paste("Linear Model Summary for: ", title))
  print(paste("Custom R² (Train):", custom_r2_train))
  print(paste("Custom R² (Test):", custom_r2_test))

  plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
  
  par(mfrow = c(2, 2))
  gam.check(model)

  
  # ggplot for Predicted vs Actual
  p1<- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = title,
         x = "Predicted Values",
         y = y_label) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
  
  print(p1)
  
  
#XGBoost
library(xgboost)

# Convert data to DMatrix format
  col <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
"Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
"Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", "Pelo_Pct")
dtrain <- xgb.DMatrix(data = as.matrix(df_train[col]), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(df_test[col]), label = y_test)

# Set XGBoost parameters
# params <- list(
#   objective = "reg:squarederror",
#   eval_metric = "rmse",
#   booster = "gbtree",
#   eta = 0.1,
#   max_depth = 6,
#   min_child_weight = 1,
#   subsample = 0.8,
#   colsample_bytree = 0.8
# )

params <- list(
  booster = "gblinear",
  objective = "reg:squarederror",
  eval_metric = "rmse",
  lambda = 0.1,        # L2 regularization
  alpha = 0,          # L1 regularization
  lambda_bias = 0,    # L2 regularization on bias
  eta = 0.3          # Learning rate
)

# Train the model
model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  verbose = 0
)

# Make predictions
y_pred_train <- predict(model, dtrain)
y_pred_test <- predict(model, dtest)

# Calculate metrics
prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
Act_RMSE <- act_custom_rmse(prediction_df)
Act_MAE <- act_custom_mae(prediction_df)
Pred_RMSE <- pred_custom_rmse(prediction_df)
Pred_MAE <- pred_custom_mae(prediction_df)

# Update tables
custom_r2_table[11,2] <- custom_r2_test
act_rmse_table[11,2] <- Act_RMSE
act_mae_table[11,2] <- Act_MAE
pred_rmse_table[11,2] <- Pred_RMSE
pred_mae_table[11,2] <- Pred_MAE

# Print summary
print(paste("XGBoost Model Summary for: ", title))
print(paste("Custom R² (Train):", custom_r2_train))
print(paste("Custom R² (Test):", custom_r2_test))

# Create and display Predicted vs Actual plot
plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
p <- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = title,
       x = "Predicted Values",
       y = y_label) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

print(p)

# Optional: Cross-validation
cv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,
  nfold = 5,
  early_stopping_rounds = 10,
  verbose = 0
)

print(paste("Best iteration:", which.min(cv$evaluation_log$test_rmse_mean)))

# Random Forest
# Convert data format (keeping this line for consistency with your framework)
col <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
         "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
         "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", "Pelo_Pct")


# Train the model
model <- randomForest(
  formula = as.formula(paste("Points ~", paste(col, collapse = " + "))),
  data = df_train,
  ntree = 500,
  importance = TRUE
)

# Make predictions
y_pred_train <- predict(model, newdata = df_train)
y_pred_test <- predict(model, newdata = df_test)

# Calculate metrics
prediction_df <- data.frame(Prediction=c(y_pred_test), Actual=c(y_test))
custom_r2_train <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_train
custom_r2_test <- custom_r2(y_train, y_pred_train, y_test, y_pred_test)$r2_test
Act_RMSE <- act_custom_rmse(prediction_df)
Act_MAE <- act_custom_mae(prediction_df)
Pred_RMSE <- pred_custom_rmse(prediction_df)
Pred_MAE <- pred_custom_mae(prediction_df)

# Update tables
custom_r2_table[12,2] <- custom_r2_test
act_rmse_table[12,2] <- Act_RMSE
act_mae_table[12,2] <- Act_MAE
pred_rmse_table[1,2] <- Pred_RMSE
pred_mae_table[12,2] <- Pred_MAE

# Print summary
print(paste("Random Forest Model Summary for: ", title))
print(paste("Custom R² (Train):", custom_r2_train))
print(paste("Custom R² (Test):", custom_r2_test))

# Error rate vs number of trees plot
error_df <- data.frame(
  Trees = 1:model$ntree,
  Error = model$mse
)

p1 <- ggplot(error_df, aes(x = Trees, y = sqrt(Error))) +
  geom_line() +
  labs(
    x = "Number of trees",
    y = "RMSE (out-of-bag)",
    title = "Random Forest Learning Curve"
  ) +
  theme_minimal()

print(p1)

# Variable importance plot
importance_df <- as.data.frame(importance(model))
importance_df$Feature <- rownames(importance_df)
importance_df <- importance_df %>%
  arrange(desc(IncNodePurity))

p2 <- ggplot(importance_df, aes(x = reorder(Feature, IncNodePurity), y = IncNodePurity)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    x = "Features",
    y = "Importance (Node Purity Increase)",
    title = "Feature Importance in Random Forest Model"
  ) +
  theme_minimal()

print(p2)

# Actual vs Predicted plot
plot_data <- data.frame(Actual = y_test, Predicted = y_pred_test)
p3 <- ggplot(plot_data, aes(x = Predicted, y = Actual)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = title,
       x = "Predicted Values",
       y = y_label) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

print(p3)

# Print top 5 most important variables
print("Top 5 Most Important Variables:")
print(head(importance_df[order(-importance_df$IncNodePurity), ], 5))

    
  print(custom_r2_table)
  print(act_rmse_table)
  print(pred_rmse_table)
  print(act_mae_table)
  print(pred_mae_table)
  return(list(r2=custom_r2_table, actual_rmse=act_rmse_table, predicted_rmse=pred_rmse_table, actual_mae=act_mae_table, predicted_mae=pred_mae_table))
  

}
  explanatory_vars <- best_bic_selected_vars[2:length(best_bic_selected_vars)]
  
explanatory_vars2 <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
                      "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
                      "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", 
                      "Pelo_Pct", "Home")
  model_comp_2015 <- model_comp(df_race75, 2015, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2015")
  model_comp_2016 <- model_comp(df_race75, 2016, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2016")
  model_comp_2017 <- model_comp(df_race75, 2017, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2017")
  model_comp_2018 <- model_comp(df_race75, 2018, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2018")
  model_comp_2019 <- model_comp(df_race75, 2019, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2019")
  model_comp_2020 <- model_comp(df_race75, 2020, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2020")
  model_comp_2021 <- model_comp(df_race75, 2021, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2021")
  model_comp_2022 <- model_comp(df_race75, 2022, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2022")
  model_comp_2023 <- model_comp(df_race75, 2023, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2023")
  model_comp_2024 <- model_comp(df_race75, 2024, explanatory_vars, "Distance Classic Pelo", "Points", "Comparing Distance Classic Elo and Points in 2024")
  
  library(openxlsx)
# Sequentially merge data frames on the "Skier" column
r2_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$r2, model_comp_2016$r2, model_comp_2017$r2, model_comp_2018$r2, model_comp_2019$r2, model_comp_2020$r2, model_comp_2021$r2, 
                         model_comp_2022$r2, model_comp_2023$r2, model_comp_2024$r2))

actual_rmse_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$actual_rmse, model_comp_2016$actual_rmse, model_comp_2017$actual_rmse, model_comp_2018$actual_rmse, model_comp_2019$actual_rmse, model_comp_2020$actual_rmse, model_comp_2021$actual_rmse, model_comp_2022$actual_rmse, model_comp_2023$actual_rmse, model_comp_2024$actual_rmse))

predicted_rmse_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$predicted_rmse, model_comp_2016$predicted_rmse, model_comp_2017$predicted_rmse, model_comp_2018$predicted_rmse, model_comp_2019$predicted_rmse, model_comp_2020$predicted_rmse, model_comp_2021$predicted_rmse, model_comp_2022$predicted_rmse, model_comp_2023$predicted_rmse, model_comp_2024$predicted_rmse))

actual_mae_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$actual_mae, model_comp_2016$actual_mae, model_comp_2017$actual_mae, model_comp_2018$actual_mae, model_comp_2019$actual_mae, model_comp_2020$actual_mae, model_comp_2021$actual_mae, model_comp_2022$actual_mae, model_comp_2023$actual_mae, model_comp_2024$actual_mae))

predicted_mae_df <- Reduce(function(x, y) merge(x, y, by = "Model", all = TRUE), 
                    list(model_comp_2015$predicted_mae, model_comp_2016$predicted_mae, model_comp_2017$predicted_mae, model_comp_2018$predicted_mae, model_comp_2019$predicted_mae, model_comp_2020$predicted_mae, model_comp_2021$predicted_mae, model_comp_2022$predicted_mae, model_comp_2023$predicted_mae, model_comp_2024$predicted_mae))



r2_df$Avg <- rowMeans(r2_df[, seq(2, ncol(r2_df), by = 1)], na.rm = TRUE)
r2_df <- r2_df[order(-r2_df$Avg), ] 
write.xlsx(r2_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-model-exhaustive-tests-r2.xlsx")

actual_rmse_df$Avg <- rowMeans(actual_rmse_df[, seq(2, ncol(actual_rmse_df), by = 1)], na.rm = TRUE)
actual_rmse_df <- actual_rmse_df[order(actual_rmse_df$Avg), ] 
write.xlsx(actual_rmse_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-model-exhaustive-tests-actual_rmse.xlsx")

predicted_rmse_df$Avg <- rowMeans(predicted_rmse_df[, seq(2, ncol(predicted_rmse_df), by = 1)], na.rm = TRUE)
predicted_rmse_df <- predicted_rmse_df[order(predicted_rmse_df$Avg), ] 
write.xlsx(predicted_rmse_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-model-exhaustive-tests-predicted_rmse.xlsx")

actual_mae_df$Avg <- rowMeans(actual_mae_df[, seq(2, ncol(actual_mae_df), by = 1)], na.rm = TRUE)
actual_mae_df <- actual_mae_df[order(actual_mae_df$Avg), ] 
write.xlsx(actual_mae_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-model-resursive-tests-actual_mae.xlsx")

predicted_mae_df$Avg <- rowMeans(predicted_mae_df[, seq(2, ncol(predicted_mae_df), by = 1)], na.rm = TRUE)
predicted_mae_df <- predicted_mae_df[order(predicted_mae_df$Avg), ] 
write.xlsx(predicted_mae_df, file = "/Users/syverjohansen/blog/daehl-e/content/post/drafts/race-prediction/men-model-exhaustive-tests-predicted_mae.xlsx")

```


###XGBoost
```{r XGBoost-test}
  df_train <- df_race75 %>%
    filter(Season!=2024)
  df_test <- df_race75 %>%
    filter(Season==2024)
# Extract explanatory variables and convert to matrix
x_train <- as.matrix(df_train %>% dplyr::select(explanatory_vars))  # Assuming Points is your target
x_test <- as.matrix(df_test %>% dplyr::select(explanatory_vars))

# Extract the target variable (Points) as a numeric vector
y_train <- df_train$Points
y_test <- df_test$Points
# Set parameters for regression
params <- list(
  objective = "reg:squarederror",  # For regression tasks
  eval_metric = "rmse"             # Root mean squared error as evaluation metric
)

# Convert data to DMatrix format, which is optimized for XGBoost
dtrain <- xgb.DMatrix(data = x_train, label = y_train)
dtest <- xgb.DMatrix(data = x_test, label = y_test)

# Train the XGBoost model
model_xgb <- xgb.train(params = params, 
                       data = dtrain, 
                       nrounds = 100,     # Number of boosting rounds
                       watchlist = list(train = dtrain, test = dtest), 
                       early_stopping_rounds = 10,  # Stop if no improvement after 10 rounds
                       verbose = 1)
y_pred <- predict(model_xgb, x_test)
# Calculate RMSE
rmse <- sqrt(mean((y_pred - y_test)^2))
print(paste("RMSE:", rmse))

# Calculate R²
r_squared <- 1 - (sum((y_pred - y_test)^2) / sum((mean(y_test) - y_test)^2))
print(paste("R²:", r_squared))

```

###Tensor Flow
```{r tensor}
library(randomForest)
library(ggplot2)
library(dplyr)
  explanatory_vars <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
"Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", "Pelo_Pct")
# Split data into train and test
train_data <- df_race75[df_race75$Season != 2024, ]
test_data <- df_race75[df_race75$Season == 2024, ]

# Create the random forest model using your specific variables
rf_model <- randomForest(
  formula = as.formula(paste("Points ~", paste(explanatory_vars, collapse = " + "))),
  data = train_data,
  ntree = 500,
  importance = TRUE
)

# Plot OOB error rate vs number of trees
error_df <- data.frame(
  Trees = 1:rf_model$ntree,
  Error = rf_model$mse
)

p1 <- ggplot(error_df, aes(x = Trees, y = sqrt(Error))) +
  geom_line() +
  labs(
    x = "Number of trees",
    y = "RMSE (out-of-bag)",
    title = "Random Forest Learning Curve"
  ) +
  theme_minimal()

print(p1)

# Variable importance plot
importance_df <- as.data.frame(importance(rf_model))
importance_df$Feature <- rownames(importance_df)

# Sort by IncNodePurity
importance_df <- importance_df %>%
  arrange(desc(IncNodePurity))

p2 <- ggplot(importance_df, aes(x = reorder(Feature, IncNodePurity), y = IncNodePurity)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    x = "Features",
    y = "Importance (Node Purity Increase)",
    title = "Feature Importance in Random Forest Model"
  ) +
  theme_minimal()

print(p2)

# Model evaluation on test set
predictions <- predict(rf_model, newdata = test_data)
test_rmse <- sqrt(mean((test_data$Points - predictions)^2))
test_r2 <- 1 - sum((test_data$Points - predictions)^2) / 
           sum((test_data$Points - mean(test_data$Points))^2)

print(paste("Test RMSE:", round(test_rmse, 4)))
print(paste("Test R²:", round(test_r2, 4)))

# Print top 5 most important variables
print("Top 5 Most Important Variables:")
print(head(importance_df[order(-importance_df$IncNodePurity), ], 5))

# Plot actual vs predicted
prediction_df <- data.frame(
  Actual = test_data$Points,
  Predicted = predictions
)

p3 <- ggplot(prediction_df, aes(x = Predicted, y = Actual)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    x = "Predicted Points",
    y = "Actual Points",
    title = "Actual vs Predicted Points - 2024 Season"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

print(p3)

# Optional: Add residual plot
prediction_df$Residuals <- prediction_df$Actual - prediction_df$Predicted

p4 <- ggplot(prediction_df, aes(x = Predicted, y = Residuals)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    x = "Predicted Points",
    y = "Residuals",
    title = "Residual Plot - 2024 Season"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

print(p4)
```


## Results Examination

###Adjusting for Altitude, Course, and Period
```{r adjustments-period}
col <- col[2:length(col)]
smooth_terms <- paste("s(", col, ")", collapse=" + ")  # Adding smooth terms for each predictor
  formula_string <- paste("Points", "~", smooth_terms)
  print(formula_string)  # Print the formula for verification
  formula <- as.formula(formula_string)
  
  # Train the GAM model
  model <- gam(formula, data = df_race75)
  print(summary(model))

winning_model <- model

df_race75$Predicted_Points <- predict(winning_model)
df_race75$Pts_Diff <- df_race75$Points-df_race75$Predicted_Points

df_klaebo <- df_race75[which(df_race75$Skier == "Johannes Høsflot Klæbo"), ]
plot(df_klaebo$Period, df_klaebo$Pts_Diff )
plot(df_race75$Period, df_race75$Pts_Diff)

library(ggplot2)
library(dplyr)
library(stats)

# 1. Visual Check
p1 <- ggplot(df_race75, aes(x = as.factor(Period), y = Pts_Diff)) +
  geom_boxplot(fill = "steelblue", alpha = 0.5) +
  labs(
    title = "Point Prediction Errors by Period",
    x = "Period",
    y = "Points Difference (Actual - Predicted)"
  ) +
  theme_minimal()

print(p1)

# 2. Statistical Tests

# Calculate absolute errors for each period
period_summary <- df_race75 %>%
  group_by(Period) %>%
  summarise(
    mean_abs_error = mean(abs(Pts_Diff)),
    sd_error = sd(Pts_Diff),
    n = n()
  )

print("Summary of absolute errors by period:")
print(period_summary)

# ANOVA test to see if there are significant differences between periods
anova_result <- aov(abs(Pts_Diff) ~ as.factor(Period), data = df_race75)
print("ANOVA Results:")
print(summary(anova_result))

# Specifically test Period 1 against others
df_race75$is_period1 <- df_race75$Period == 1
t_test_result <- t.test(abs(Pts_Diff) ~ is_period1, data = df_race75)
print("T-test Results (Period 1 vs Others):")
print(t_test_result)

# Effect size (Cohen's d) for Period 1 vs others
period1_mean <- mean(abs(df_race75$Pts_Diff[df_race75$Period == 1]))
others_mean <- mean(abs(df_race75$Pts_Diff[df_race75$Period != 1]))
pooled_sd <- sqrt((var(abs(df_race75$Pts_Diff[df_race75$Period == 1])) + 
                   var(abs(df_race75$Pts_Diff[df_race75$Period != 1]))) / 2)
cohens_d <- (period1_mean - others_mean) / pooled_sd

print(paste("Cohen's d (effect size):", round(cohens_d, 3)))

# Additional visualization: Error distribution by period
p2 <- ggplot(df_race75, aes(x = Pts_Diff)) +
  geom_density(aes(fill = as.factor(Period)), alpha = 0.3) +
  labs(
    title = "Distribution of Prediction Errors by Period",
    x = "Points Difference (Actual - Predicted)",
    y = "Density",
    fill = "Period"
  ) +
  theme_minimal()

print(p2)


library(ggplot2)
library(dplyr)
library(stats)

# Filter for top skiers
top_skiers_df <- df_race75 %>%
 filter(Distance_C_Pelo_Pct >= 0.9)

# 1. Visual Check 
p1 <- ggplot(top_skiers_df, aes(x = as.factor(Period), y = Pts_Diff)) +
 geom_boxplot(fill = "steelblue", alpha = 0.5) +
 labs(
   title = "Point Prediction Errors by Period (Top Classic Distance Skiers)",
   x = "Period",
   y = "Points Difference (Actual - Predicted)"
 ) +
 theme_minimal()

print(p1)

# 2. Statistical Tests
# Calculate absolute errors for each period
period_summary <- top_skiers_df %>%
 group_by(Period) %>%
 summarise(
   mean_abs_error = mean(abs(Pts_Diff)),
   sd_error = sd(Pts_Diff),
   n = n()
 )

print("Summary of absolute errors by period (Top Skiers):")
print(period_summary)

# ANOVA test
anova_result <- aov(abs(Pts_Diff) ~ as.factor(Period), data = top_skiers_df)
print("ANOVA Results (Top Skiers):")
print(summary(anova_result))

# Specifically test Period 1 against others for top skiers
top_skiers_df$is_period1 <- top_skiers_df$Period == 1
t_test_result <- t.test(abs(Pts_Diff) ~ is_period1, data = top_skiers_df)
print("T-test Results (Period 1 vs Others, Top Skiers):")
print(t_test_result)

# Effect size (Cohen's d) for Period 1 vs others
period1_mean <- mean(abs(top_skiers_df$Pts_Diff[top_skiers_df$Period == 1]))
others_mean <- mean(abs(top_skiers_df$Pts_Diff[top_skiers_df$Period != 1]))
pooled_sd <- sqrt((var(abs(top_skiers_df$Pts_Diff[top_skiers_df$Period == 1])) + 
                  var(abs(top_skiers_df$Pts_Diff[top_skiers_df$Period != 1]))) / 2)
cohens_d <- (period1_mean - others_mean) / pooled_sd

print(paste("Cohen's d (effect size) for top skiers:", round(cohens_d, 3)))

# Additional visualization: Error distribution by period
p2 <- ggplot(top_skiers_df, aes(x = Pts_Diff)) +
 geom_density(aes(fill = as.factor(Period)), alpha = 0.3) +
 labs(
   title = "Distribution of Prediction Errors by Period (Top Classic Distance Skiers)",
   x = "Points Difference (Actual - Predicted)",
   y = "Density",
   fill = "Period"
 ) +
 theme_minimal()

print(p2)

# Compare sample sizes
print("Number of observations in each period for top skiers:")
print(table(top_skiers_df$Period))


library(dplyr)
library(stats)

# Function to test significance for a single skier
test_skier_significance <- function(skier_data) {
  if (nrow(skier_data) < 2 || !any(skier_data$Period == 1) || 
      all(skier_data$Period == 1)) {
    return(list(p_value = 1, mean_diff = 0))
  }
  
  t_result <- t.test(
    abs(skier_data$Pts_Diff[skier_data$Period == 1]),
    abs(skier_data$Pts_Diff[skier_data$Period != 1])
  )
  
  mean_p1 <- mean(abs(skier_data$Pts_Diff[skier_data$Period == 1]))
  mean_other <- mean(abs(skier_data$Pts_Diff[skier_data$Period != 1]))
  
  return(list(p_value = t_result$p.value, mean_diff = mean_p1 - mean_other))
}

# Filter for top skiers
top_skiers_df <- df_race75 %>%
  filter(Sprint_C_Pelo_Pct >= 0.75)

# Get significance results for each skier
skier_results <- top_skiers_df %>%
  group_by(Skier) %>%
  group_modify(~{
    result <- test_skier_significance(.x)
    data.frame(
      p_value = result$p_value,
      mean_diff = result$mean_diff
    )
  }) %>%
  ungroup()

# Identify skiers with significant differences
significant_skiers <- skier_results %>%
  filter(p_value < 0.2) %>%
  arrange(p_value)

print("Skiers with significant Period 1 differences (p < 0.2):")
print(significant_skiers)

# Create filtered dataset with only significant skiers
significant_skiers_df <- top_skiers_df %>%
  filter(Skier %in% significant_skiers$Skier)

# Run analysis on significant skiers only
if(nrow(significant_skiers_df) > 0) {
  # ANOVA on significant skiers
  anova_result <- aov(abs(Pts_Diff) ~ as.factor(Period), data = significant_skiers_df)
  print("ANOVA Results (Significant Skiers Only):")
  print(summary(anova_result))
  
  # T-test for Period 1 vs others
  significant_skiers_df$is_period1 <- significant_skiers_df$Period == 1
  t_test_result <- t.test(abs(Pts_Diff) ~ is_period1, data = significant_skiers_df)
  print("T-test Results (Period 1 vs Others, Significant Skiers Only):")
  print(t_test_result)
  
  # Effect size for significant skiers
  period1_mean <- mean(abs(significant_skiers_df$Pts_Diff[significant_skiers_df$Period == 1]))
  others_mean <- mean(abs(significant_skiers_df$Pts_Diff[significant_skiers_df$Period != 1]))
  pooled_sd <- sqrt((var(abs(significant_skiers_df$Pts_Diff[significant_skiers_df$Period == 1])) + 
                     var(abs(significant_skiers_df$Pts_Diff[significant_skiers_df$Period != 1]))) / 2)
  cohens_d <- (period1_mean - others_mean) / pooled_sd
  
  print(paste("Cohen's d (effect size) for significant skiers:", round(cohens_d, 3)))
  
  # Visualization for significant skiers
  library(ggplot2)
  p <- ggplot(significant_skiers_df, aes(x = as.factor(Period), y = abs(Pts_Diff))) +
    geom_boxplot(fill = "steelblue", alpha = 0.5) +
    labs(
      title = "Point Prediction Errors by Period (Significant Skiers Only)",
      x = "Period",
      y = "Absolute Points Difference"
    ) +
    theme_minimal()
  
  print(p)
  
  # Summary statistics
  period_summary <- significant_skiers_df %>%
    group_by(Period) %>%
    summarise(
      mean_abs_error = mean(abs(Pts_Diff)),
      sd_error = sd(Pts_Diff),
      n = n()
    )
  
  print("Summary by period (Significant Skiers Only):")
  print(period_summary)
} else {
  print("No skiers showed significant differences at p < 0.2")
}
```



###Altitude and Elevation
```{r alt-elev}
library(dplyr)

df_race75 <- df_race75 %>%
  arrange(Date) %>%  # Ensure chronological order
  group_by(Skier) %>%
  mutate(
    row_id = row_number(),  # Add row number within each group
    
    # Calculate p-values using cumulative data
    altitude_p = purrr::map_dbl(row_id, function(r) {
      if(r <= 1) return(1)
      # Get prior data using logical indexing
      prior_alt_1 <- (Points - Predicted_Points)[AltitudeCategory == 1 & row_id < r]
      prior_alt_0 <- (Points - Predicted_Points)[AltitudeCategory == 0 & row_id < r]
      
      # Check minimum observations
      if(length(prior_alt_1) < 3 || length(prior_alt_0) < 3) return(1)
      
      # Perform t-test
      tryCatch({
        t.test(prior_alt_1, prior_alt_0)$p.value
      }, error = function(e) 1)
    }),
    
    grade_p = purrr::map_dbl(row_id, function(r) {
      if(r <= 1) return(1)
      # Get prior data using logical indexing
      prior_grade_1 <- (Points - Predicted_Points)[GradeCategory == 1 & row_id < r]
      prior_grade_0 <- (Points - Predicted_Points)[GradeCategory == 0 & row_id < r]
      
      # Check minimum observations
      if(length(prior_grade_1) < 3 || length(prior_grade_0) < 3) return(1)
      
      # Perform t-test
      tryCatch({
        t.test(prior_grade_1, prior_grade_0)$p.value
      }, error = function(e) 1)
    }),
    
    # Calculate corrections using prior data - FIXED THIS PART
    altitude_correction = purrr::map_dbl(row_id, function(r) {
      if(altitude_p[r] >= 0.05 || AltitudeCategory[r] != 1) return(0)
      prior_diff <- (Points - Predicted_Points)[AltitudeCategory == 1 & row_id < r]
      if(length(prior_diff) > 0) mean(prior_diff) else 0
    }),
    
    grade_correction = purrr::map_dbl(row_id, function(r) {
      if(grade_p[r] >= 0.05 || GradeCategory[r] != 1) return(0)
      prior_diff <- (Points - Predicted_Points)[GradeCategory == 1 & row_id < r]
      if(length(prior_diff) > 0) mean(prior_diff) else 0
    })
  ) %>%
  ungroup()

# Calculate adjusted predictions
df_race75$Course_Adjusted <- df_race75$Predicted_Points + 
                            df_race75$altitude_correction + 
                            df_race75$grade_correction
df_race75$Course_Adjusted <- pmin(pmax(df_race75$Course_Adjusted, 0), 1)


# Summary statistics
significance_summary <- df_race75 %>%
  group_by(Skier) %>%
  summarise(
    n_races = n(),
    pct_altitude_significant = mean(altitude_p < 0.05, na.rm = TRUE) * 100,
    pct_grade_significant = mean(grade_p < 0.05, na.rm = TRUE) * 100,
    mean_altitude_correction = mean(altitude_correction[altitude_correction != 0], na.rm = TRUE),
    mean_grade_correction = mean(grade_correction[grade_correction != 0], na.rm = TRUE)
  ) %>%
  filter(pct_altitude_significant > 0 | pct_grade_significant > 0) %>%
  arrange(desc(pct_altitude_significant + pct_grade_significant))

print("Skiers with significant course effects:")
print(significance_summary)

# Example for a specific skier
df_klaebo <- df_race75[which(df_race75$Skier == "Andrew Musgrave"), ]

print("Overall Error Statistics:")
print(paste("Mean Original Error:", mean(df_race75$Points - df_race75$Predicted_Points)))
print(paste("Mean Course-Adjusted Error:", mean(df_race75$Points - df_race75$Course_Adjusted)))
# Calculate R² and RMSE
print("Overall R² Statistics:")
print(paste("Original R²:", 1 - sum((df_race75$Points - df_race75$Predicted_Points)^2) / 
            sum((df_race75$Points - mean(df_race75$Points))^2)))
print(paste("Course-Adjusted R²:", 1 - sum((df_race75$Points - df_race75$Course_Adjusted)^2) / 
            sum((df_race75$Points - mean(df_race75$Points))^2)))

print("Overall RMSE Statistics:")
print(paste("Original RMSE:", sqrt(mean((df_race75$Points - df_race75$Predicted_Points)^2))))
print(paste("Course-Adjusted RMSE:", sqrt(mean((df_race75$Points - df_race75$Course_Adjusted)^2))))

print("Klæbo-specific Error Statistics:")
print(paste("Mean Original Error:", mean(df_klaebo$Points - df_klaebo$Predicted_Points)))
print(paste("Mean Course-Adjusted Error:", mean(df_klaebo$Points - df_klaebo$Course_Adjusted)))

# Add some diagnostic information
print("Correction Statistics:")
print(paste("Number of non-zero altitude corrections:", sum(df_race75$altitude_correction != 0)))
print(paste("Number of non-zero grade corrections:", sum(df_race75$grade_correction != 0)))
print(paste("Mean altitude correction (when applied):", 
            mean(df_race75$altitude_correction[df_race75$altitude_correction != 0], na.rm = TRUE)))
print(paste("Mean grade correction (when applied):", 
            mean(df_race75$grade_correction[df_race75$grade_correction != 0], na.rm = TRUE)))
```

###Period Adjustments
```{r period-adjustments}
library(dplyr)

df_race75 <- df_race75 %>%
  arrange(Date) %>%  
  group_by(Skier) %>%
  mutate(
    row_id = row_number(),
    
    # Calculate p-values for each period
    period_p = purrr::map_dbl(row_id, function(r) {
      if(r <= 1) return(1)
      # Get prior data using logical indexing
      prior_period_curr <- (Points - Course_Adjusted)[Period == Period[r] & row_id < r]
      prior_period_other <- (Points - Course_Adjusted)[Period != Period[r] & row_id < r]
      
      # Check minimum observations
      if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
      
      # Perform t-test
      tryCatch({
        t.test(prior_period_curr, prior_period_other)$p.value
      }, error = function(e) 1)
    }),
    
    # Calculate corrections using prior data
    period_correction = purrr::map_dbl(row_id, function(r) {
      if(period_p[r] >= 0.05) return(0)
      prior_diff <- (Points - Course_Adjusted)[Period == Period[r] & row_id < r]
      if(length(prior_diff) > 0) mean(prior_diff) else 0
    })
  ) %>%
  ungroup()

# Calculate adjusted predictions
df_race75$Period_Adjusted <- df_race75$Course_Adjusted + df_race75$period_correction
df_race75$Period_Adjusted <- pmin(pmax(df_race75$Period_Adjusted, 0), 1)

# Summary statistics by skier
significance_summary <- df_race75 %>%
  group_by(Skier) %>%
  summarise(
    n_races = n(),
    pct_period_significant = mean(period_p < 0.05, na.rm = TRUE) * 100,
    mean_period_correction = mean(period_correction[period_correction != 0], na.rm = TRUE)
  ) %>%
  filter(pct_period_significant > 0) %>%
  arrange(desc(pct_period_significant))

print("Skiers with significant period effects:")
print(significance_summary)

# Example for Musgrave
df_musgrave <- df_race75[which(df_race75$Skier == "Andrew Musgrave"), ]

# Overall statistics
print("Overall Error Statistics:")
print(paste("Mean Original Error:", mean(df_race75$Points - df_race75$Course_Adjusted)))
print(paste("Mean Period-Adjusted Error:", mean(df_race75$Points - df_race75$Period_Adjusted)))
# Calculate R² and RMSE
print("Overall R² Statistics:")
print(paste("Course-Adjusted R²:", 1 - sum((df_race75$Points - df_race75$Course_Adjusted)^2) / 
            sum((df_race75$Points - mean(df_race75$Points))^2)))
print(paste("Period-Adjusted R²:", 1 - sum((df_race75$Points - df_race75$Period_Adjusted)^2) / 
            sum((df_race75$Points - mean(df_race75$Points))^2)))

print("Overall RMSE Statistics:")
print(paste("Course-Adjusted RMSE:", sqrt(mean((df_race75$Points - df_race75$Course_Adjusted)^2))))
print(paste("Period-Adjusted RMSE:", sqrt(mean((df_race75$Points - df_race75$Period_Adjusted)^2))))


# Musgrave-specific statistics
print("Musgrave-specific Error Statistics:")
print(paste("Mean Original Error:", mean(df_musgrave$Points - df_musgrave$Course_Adjusted)))
print(paste("Mean Period-Adjusted Error:", mean(df_musgrave$Points - df_musgrave$Period_Adjusted)))

# Period-specific corrections
period_stats <- df_race75 %>%
  group_by(Period) %>%
  summarise(
    n_corrections = sum(period_correction != 0),
    mean_correction = mean(period_correction[period_correction != 0], na.rm = TRUE),
    pct_significant = mean(period_p < 0.05, na.rm = TRUE) * 100
  )

print("\nPeriod-specific Statistics:")
print(period_stats)

# Additional diagnostic information
print("\nCorrection Statistics:")
print(paste("Number of non-zero period corrections:", sum(df_race75$period_correction != 0)))
print(paste("Mean period correction (when applied):", 
            mean(df_race75$period_correction[df_race75$period_correction != 0], na.rm = TRUE)))

# Musgrave's period-specific performance
musgrave_by_period <- df_musgrave %>%
  group_by(Period) %>%
  summarise(
    n_races = n(),
    mean_error = mean(Points - Course_Adjusted),
    mean_adjusted_error = mean(Points - Period_Adjusted),
    pct_significant = mean(period_p < 0.05, na.rm = TRUE) * 100
  )

print("\nMusgrave's Period-specific Performance:")
print(musgrave_by_period)
```

###Mass Start Adjustments
```{r mass-start-adjustments}
df_race75 <- df_race75 %>%
  arrange(Date) %>%  
  group_by(Skier) %>%
  mutate(
    row_id = row_number(),
    
    # Calculate p-values for mass starts
    ms_p = purrr::map_dbl(row_id, function(r) {
      if(r <= 1) return(1)
      # Get prior data using logical indexing
      prior_ms_curr <- (Points - Period_Adjusted)[MS == MS[r] & row_id < r]
      prior_ms_other <- (Points - Period_Adjusted)[MS != MS[r] & row_id < r]
      
      # Check minimum observations
      if(length(prior_ms_curr) < 3 || length(prior_ms_other) < 3) return(1)
      
      # Perform t-test
      tryCatch({
        t.test(prior_ms_curr, prior_ms_other)$p.value
      }, error = function(e) 1)
    }),
    
    # Calculate corrections using prior data
    ms_correction = purrr::map_dbl(row_id, function(r) {
      if(ms_p[r] >= 0.05) return(0)
      prior_diff <- (Points - Period_Adjusted)[MS == MS[r] & row_id < r]
      if(length(prior_diff) > 0) mean(prior_diff) else 0
    })
  ) %>%
  ungroup()

# Calculate adjusted predictions
df_race75$MS_Adjusted <- df_race75$Period_Adjusted + df_race75$ms_correction
df_race75$MS_Adjusted <- pmin(pmax(df_race75$MS_Adjusted, 0), 1)

print("Overall Error Statistics:")
print(paste("Mean Period-Adjusted Error:", mean(df_race75$Points - df_race75$Period_Adjusted)))
print(paste("Mean MS-Adjusted Error:", mean(df_race75$Points - df_race75$MS_Adjusted)))

# Calculate R² and RMSE
print("Overall R² Statistics:")
print(paste("Period-Adjusted R²:", 1 - sum((df_race75$Points - df_race75$Period_Adjusted)^2) / 
             sum((df_race75$Points - mean(df_race75$Points))^2)))
print(paste("MS-Adjusted R²:", 1 - sum((df_race75$Points - df_race75$MS_Adjusted)^2) / 
             sum((df_race75$Points - mean(df_race75$Points))^2)))

print("Overall RMSE Statistics:")
print(paste("Period-Adjusted RMSE:", sqrt(mean((df_race75$Points - df_race75$Period_Adjusted)^2))))
print(paste("MS-Adjusted RMSE:", sqrt(mean((df_race75$Points - df_race75$MS_Adjusted)^2))))

# Mass Start specific stats
ms_stats <- df_race75 %>%
  group_by(MS) %>%
  summarise(
    n_corrections = sum(ms_correction != 0),
    mean_correction = mean(ms_correction[ms_correction != 0], na.rm = TRUE),
    pct_significant = mean(ms_p < 0.05, na.rm = TRUE) * 100
  )

print("\nMass Start vs Interval Start Statistics:")
print(ms_stats)

ms_significance_summary <- df_race75 %>%
 group_by(Skier) %>%
 summarise(
   n_races = n(),
   pct_ms_significant = mean(ms_p < 0.05, na.rm = TRUE) * 100,
   mean_ms_correction = mean(ms_correction[ms_correction != 0], na.rm = TRUE)
 ) %>%
 filter(pct_ms_significant > 0) %>%
 arrange(desc(pct_ms_significant))

print("Skiers with significant mass start effects:")
print(ms_significance_summary)

# Additional diagnostic information
print("\nCorrection Statistics:")
print(paste("Number of non-zero mass start corrections:", sum(df_race75$ms_correction != 0)))
print(paste("Mean mass start correction (when applied):", 
           mean(df_race75$ms_correction[df_race75$ms_correction != 0], na.rm = TRUE)))

ms_type_stats <- df_race75 %>%
  group_by(Skier, MS) %>%
  summarise(
    n_races = n(),
    avg_correction = mean(ms_correction[ms_correction != 0], na.rm = TRUE),
    n_corrections = sum(ms_correction != 0)
  ) %>%
  filter(n_corrections > 0) %>%
  arrange(desc(abs(avg_correction)))

print("\nCorrections by start type (MS=1 is mass start, MS=0 is interval):")
print(ms_type_stats)


```

### Final Adjustments
```{r final-adjustments-measure}
# For MS_Adjusted
ms_errors <- df_race75 %>% 
 group_by(Skier) %>% 
 filter(n() >= 5) %>% 
 summarise(
   n_races = n(),
   mean_error = mean(abs(Points - MS_Adjusted))
 ) %>%
 filter(mean_error > 0.1) %>%
 arrange(desc(mean_error))

# For Period_Adjusted
period_errors <- df_race75 %>% 
 group_by(Skier) %>% 
 filter(n() >= 5) %>% 
 summarise(
   n_races = n(),
   mean_error = mean(abs(Points - Period_Adjusted))
 ) %>%
 filter(mean_error > 0.1) %>%
 arrange(desc(mean_error))

# For Course_Adjusted
course_errors <- df_race75 %>% 
 group_by(Skier) %>% 
 filter(n() >= 5) %>% 
 summarise(
   n_races = n(),
   mean_error = mean(abs(Points - Course_Adjusted))
 ) %>%
 filter(mean_error > 0.1) %>%
 arrange(desc(mean_error))

# For Original Predictions
original_errors <- df_race75 %>% 
 group_by(Skier) %>% 
 filter(n() >= 5) %>% 
 summarise(
   n_races = n(),
   mean_error = mean(abs(Points - Predicted_Points))
 ) %>%
 filter(mean_error > 0.1) %>%
 arrange(desc(mean_error))

print("Skiers with mean error > 0.1 after Period Adjustment:")
print(ms_errors)
print("Skiers with mean error > 0.1 after Period Adjustment:")
print(period_errors)
print("\nSkiers with mean error > 0.1 after Course Adjustment:")
print(course_errors)
print("\nSkiers with mean error > 0.1 in Original Predictions:")
print(original_errors)
```
```{r final-adjustments}
df_race75 <- df_race75 %>%
  arrange(Date) %>%
  group_by(Skier) %>%
  mutate(
    recent_correction = purrr::map_dbl(row_number(), function(r) {
      if(r <= 3) return(0)
      # Get last 3 races' errors
      recent_errors <- (Points - Period_Adjusted)[(r-3):(r-1)]
      # Weights: most recent race gets weight 3, second most recent gets 2, etc.
      weights <- 3:1
      # Calculate weighted mean error
      sum(recent_errors * weights) / sum(weights)
    })
  ) %>%
  ungroup()

df_race75$Final_Adjusted <- df_race75$Period_Adjusted + df_race75$recent_correction

final_errors <- df_race75 %>% 
  group_by(Skier) %>% 
  filter(n() >= 5) %>% 
  summarise(
    n_races = n(),
    mean_error = mean(abs(Points - Final_Adjusted))
  ) %>%
  filter(mean_error > 0.1) %>%
  arrange(desc(mean_error))

print(paste("Number of skiers with mean error > 0.1 after final adjustment:", nrow(final_errors)))
print("\nSkiers with mean error > 0.1 after final adjustment:")
print(final_errors)

# Compare with original count
original_errors <- df_race75 %>% 
  group_by(Skier) %>% 
  filter(n() >= 5) %>% 
  summarise(
    n_races = n(),
    mean_error = mean(abs(Points - Period_Adjusted))
  ) %>%
  filter(mean_error > 0.1) %>%
  arrange(desc(mean_error))

print(paste("\nNumber of skiers with mean error > 0.1 before adjustment:", nrow(original_errors)))
#These don't seem to help

display_vars <- c(explanatory_vars, "Skier", "MS", "Points", "Predicted_Points", "Course_Adjusted", "Period_Adjusted", "MS_Adjusted")
df_skier = df_race75[df_race75$Skier=="Iivo Niskanen", display_vars]
options(tibble.width = Inf)
options(tibble.print_max = Inf)
print(df_skier, width=Inf)
```


