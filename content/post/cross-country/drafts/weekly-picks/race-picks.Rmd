---
title: "Race Day Predictions"
author: "Syver Johansen"
date: "2025-03-15"
output: html_document
---

# Daily Race Predictions

This RMarkdown document implements predictions for tomorrow's cross-country skiing races.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Load Required Libraries and Setup

```{r libraries}
# Load required libraries
library(dplyr)
library(tidyr)
library(openxlsx)
library(arrow)
library(mgcv)
library(leaps)
library(logger)
library(purrr)
library(lubridate)

# Define points systems
wc_points <- c(100,95,90,85,80,75,72,69,66,63,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
stage_points <- c(50,47,44,41,38,35,32,30,28,26,24,22,20,18,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
tds_points <- c(300,285,270,255,240,216,207,198,189,180,174,168,162,156,150,144,138,132,126,120,114,108,102,96,90,84,78,72,66,60,57,54,51,48,45,42,39,36,33,30,27,24,21,18,15,12,9,6,3)

# Function to replace NAs with first quartile value
replace_na_with_quartile <- function(x) {
  if(all(is.na(x))) return(rep(0, length(x)))
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  ifelse(is.na(x), q1, x)
}

# Set up logging
log_dir <- "~/ski/elo/python/ski/polars/excel365/race-predictions"
if (!dir.exists(log_dir)) {
  dir.create(log_dir, recursive = TRUE)
}

log_threshold(DEBUG)
log_appender(appender_file(file.path(log_dir, "race_picks_processing.log")))
log_info("Starting race predictions process")
```

## Load Race Data for Tomorrow

```{r load_races}
# Read in the race schedule from races.csv with proper date parsing
log_info("Reading races data")
races_data <- read.csv("~/ski/elo/python/ski/polars/excel365/races.csv", 
                     stringsAsFactors = FALSE) %>%
  mutate(Date = mdy(Date)) # Use lubridate's mdy function to parse MM/DD/YY format

# Find races scheduled for tomorrow
tomorrow_date <- Sys.Date() + 1
log_info(paste("Looking for races on:", tomorrow_date))

# Filter races for tomorrow
tomorrow_races <- races_data %>%
  filter(Date == tomorrow_date) %>%
  arrange(Sex)

# Check if any races are scheduled for tomorrow
if(nrow(tomorrow_races) == 0) {
  log_info("No races scheduled for tomorrow")
  stop("No races scheduled for tomorrow")
} else {
  log_info(paste("Found", nrow(tomorrow_races), "races scheduled for tomorrow"))
  print(tomorrow_races)
}

# Determine which genders are racing
men_racing <- any(tomorrow_races$Sex == "M")
ladies_racing <- any(tomorrow_races$Sex == "L")

log_info(paste("Men racing tomorrow:", men_racing))
log_info(paste("Ladies racing tomorrow:", ladies_racing))

# Create race dataframes for men and ladies if they are racing
if(men_racing) {
  men_races <- tomorrow_races %>%
    filter(Sex == "M") %>%
    select(Distance, Technique, MS, Elevation, Period, Pursuit, Stage) %>%
    rename(distance = Distance, technique = Technique, 
           ms = MS, altitude = Elevation, period = Period)
  
  log_info(paste("Found", nrow(men_races), "men's races"))
}

if(ladies_racing) {
  ladies_races <- tomorrow_races %>%
    filter(Sex == "L") %>%
    select(Distance, Technique, MS, Elevation, Period, Pursuit, Stage) %>%
    rename(distance = Distance, technique = Technique, 
           ms = MS, altitude = Elevation, period = Period)
  
  log_info(paste("Found", nrow(ladies_races), "ladies' races"))
}
```

## Load Startlists for Tomorrow's Races

```{r load_startlists}
# Load startlists based on which genders are racing
if(men_racing) {
  log_info("Loading men's startlist")
  men_startlist <- read.csv("~/ski/elo/python/ski/polars/excel365/startlist_races_men.csv", 
                          stringsAsFactors = FALSE)
  log_info(paste("Loaded", nrow(men_startlist), "skiers in men's startlist"))
}

if(ladies_racing) {
  log_info("Loading ladies' startlist")
  ladies_startlist <- read.csv("~/ski/elo/python/ski/polars/excel365/startlist_races_ladies.csv", 
                             stringsAsFactors = FALSE)
  log_info(paste("Loaded", nrow(ladies_startlist), "skiers in ladies' startlist"))
}
```

## Data Preprocessing Functions

```{r preprocess}
get_points <- function(place, points_list) {
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

preprocess_data <- function(df) {
    # Load races data to determine points systems for historical races
    races_data <- read.csv("~/ski/elo/python/ski/polars/excel365/races.csv", 
                         stringsAsFactors = FALSE) %>%
      mutate(Date = as.Date(Date, format="%m/%d/%y"))
    
    # Determine points system based on tomorrow's race
    # Find if tomorrow's race is a stage race
    is_stage_race <- any(!is.na(tomorrow_races$Stage) & tomorrow_races$Stage == 1)
    
    # Select the appropriate points system
    global_points_system <- if(is_stage_race) {
      log_info("Using STAGE points system for tomorrow's races")
      stage_points
    } else {
      log_info("Using WORLD CUP points system for tomorrow's races") 
      wc_points
    }
    
    # Calculate points using historical data with the global points system
    df_with_points <- df %>%
        # Add points based on the global points system
        mutate(
          Points = mapply(function(place) {
            if (place >= 1 && place <= length(global_points_system)) {
              return(global_points_system[place])
            }
            return(0)
          }, Place)
        ) %>%
        # Sort
        arrange(Season, Race, Place)
    
    # Calculate weighted previous points for each race type/technique combination
    df_with_points <- df_with_points %>%
      # Create a race type column that distinguishes between sprint and distance
      mutate(RaceType = ifelse(Distance == "Sprint", "Sprint", "Distance")) %>%
      # Group by ID and the broader race type category
      group_by(ID, RaceType, Technique) %>%
      arrange(Season, Race) %>%
      mutate(Prev_Points_Weighted = sapply(1:n(), function(j) {
        if (j == 1) return(0)
        start_index <- max(1, j - 5)
        num_races <- j - start_index
        weights <- seq(1, num_races)
        weighted.mean(Points[start_index:(j-1)], w = weights, na.rm = TRUE)
      })) %>%
      ungroup()
    
    # Check if Pelo columns exist, if not create them
    pelo_cols <- c("Distance_Pelo", "Distance_C_Pelo", "Distance_F_Pelo",
                   "Pelo", "Sprint_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo",
                   "Freestyle_Pelo", "Classic_Pelo")
    
    # Make sure these columns exist (create if missing)
    for (col in pelo_cols) {
      if (!col %in% names(df_with_points)) {
        log_info(paste("Creating missing column:", col))
        df_with_points[[col]] <- 0
      }
    }
    
    # Now apply other preprocessing steps and filter for recent data
    processed_df <- df_with_points %>%
        # Add period
        group_by(Season) %>%
        mutate(
            Num_Races = max(Race),
            Period = case_when(
                Num_Races <= 5 ~ 1,
                Num_Races <= 10 ~ 2,
                Num_Races <= 15 ~ 3,
                Num_Races <= 20 ~ 4,
                Num_Races <= 25 ~ 5,
                TRUE ~ ceiling((Race / (Num_Races / 5)))
            )
        ) %>%
        ungroup() %>%
        # Filter relevant races and add cumulative points
        filter(
            Season >= max(Season-10),
            Event %in% c("World Cup", "Nordic Opening", "Tour de Ski", 
                        "Olympic Winter Games", "World Championship", 
                        "World Cup Final", "Ski Tour Canada")
        ) %>%
        group_by(ID, Season) %>%
        mutate(Cumulative_Points = cumsum(Points)) %>%
        ungroup() %>%
        # Handle NAs and calculate percentages
        group_by(Season, Race) %>%
        mutate(
            across(
                all_of(pelo_cols),
                ~replace_na_with_quartile(.x)
            )
        ) %>%
        # Calculate percentages for each Pelo column
        mutate(
            across(
                all_of(pelo_cols),
                ~{
                    max_val <- max(.x, na.rm = TRUE)
                    if (max_val == 0) return(rep(0, length(.x)))
                    .x / max_val
                },
                .names = "{.col}_Pct"
            )
        ) %>%
        ungroup() %>%
        # Filter out team sprint and relay
        filter(!Distance %in% c("Ts", "Rel"))
    
    # Ensure all required Pelo_Pct columns exist
    pct_cols <- paste0(pelo_cols, "_Pct")
    for (col in pct_cols) {
      if (!col %in% names(processed_df)) {
        log_info(paste("Creating missing percentage column:", col))
        processed_df[[col]] <- 0
      }
    }
    
    return(processed_df)
}

# Function to prepare startlist data with ELO information
prepare_startlist_data <- function(startlist, race_df, pelo_col) {
    # Print some debug info
    log_info(paste("Preparing startlist data for", pelo_col))
    
    # Keep only essential columns from startlist
    base_df <- startlist %>%
        dplyr::select(Skier, ID, Nation, Price)
    
    # Get all required Elo columns and their corresponding Pelo names
    elo_cols <- c("Distance_Elo", "Distance_C_Elo", "Distance_F_Elo",
                  "Elo", "Sprint_Elo", "Sprint_C_Elo", "Sprint_F_Elo",
                  "Freestyle_Elo", "Classic_Elo")
    
    pelo_cols <- c("Distance_Pelo", "Distance_C_Pelo", "Distance_F_Pelo",
                   "Pelo", "Sprint_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo",
                   "Freestyle_Pelo", "Classic_Pelo")
    
    # Get most recent Elo values
    most_recent_elos <- race_df %>%
        filter(Skier %in% base_df$Skier) %>%
        group_by(Skier) %>%
        arrange(Date, Season, Race) %>%
        slice_tail(n = 1) %>%
        ungroup() %>%
        dplyr::select(Skier, any_of(elo_cols))
    
    # Debug: Check elo columns
    log_info(paste("Available elo columns:", paste(names(most_recent_elos), collapse=", ")))
    
    # Get recent points for specific race type
    recent_points <- race_df %>%
        filter(Skier %in% base_df$Skier) %>%
        filter(
            if(grepl("^Sprint", pelo_col)) {
                Distance == "Sprint" & 
                Technique == substr(pelo_col, 8, 8)
            } else {
                Distance != "Sprint" & 
                (Technique == substr(pelo_col, 10, 10) | substr(pelo_col, 10, 10) == "")  # Allow empty technique
            }
        ) %>%
        group_by(Skier) %>%
        arrange(Season, Race) %>%
        slice_tail(n = 5) %>%
        summarise(
            Prev_Points_Weighted = if(n() > 0) 
                weighted.mean(Points, w = seq_len(n()), na.rm = TRUE) 
                else 0
        )
    
    # Combine all data
    result_df <- base_df %>%
        left_join(most_recent_elos, by = "Skier") %>%
        left_join(recent_points, by = "Skier")
    
    # Ensure we have all the required Pelo_Pct columns for model prediction
    for(i in seq_along(pelo_cols)) {
        pelo_pct_col <- paste0(pelo_cols[i], "_Pct")
        if(!pelo_pct_col %in% names(result_df)) {
            log_info(paste("Creating missing Pelo Pct column:", pelo_pct_col))
            result_df[[pelo_pct_col]] <- 0.5  # Default to 0.5 (middle value)
        }
    }
    
    # Calculate max values for normalization - only for available columns
    available_elo_cols <- intersect(names(race_df), elo_cols)
    if(length(available_elo_cols) > 0) {
        max_values <- race_df %>%
            summarise(across(all_of(available_elo_cols), ~max(.x, na.rm = TRUE)))
        
        # Calculate both Elo and Pelo percentages for available columns
        for(i in seq_along(elo_cols)) {
            elo_col <- elo_cols[i]
            pelo_col_i <- pelo_cols[i]
            
            # Check if column exists in both datasets
            if(elo_col %in% names(result_df) && elo_col %in% names(max_values)) {
                max_val <- max_values[[elo_col]]
                # Only calculate if max value is not zero or NA
                if(!is.na(max_val) && max_val > 0) {
                    # Calculate the percentage
                    pct_value <- result_df[[elo_col]] / max_val
                    
                    # Assign to both Elo and Pelo percentage columns
                    result_df[[paste0(elo_col, "_Pct")]] <- pct_value
                    result_df[[paste0(pelo_col_i, "_Pct")]] <- pct_value
                    
                    log_info(paste("Calculated percentage for", elo_col))
                }
            }
        }
    } else {
        log_info("No Elo columns available in race data for percentage calculation")
    }
    
    # Replace NAs with first quartile
    result_df <- result_df %>%
        mutate(
            across(
                ends_with("_Pct"),
                ~replace_na_with_quartile(.x)
            ),
            Prev_Points_Weighted = replace_na(Prev_Points_Weighted, 0)
        )
    
    return(result_df)
}
```

## Create Post Predictions Function

```{r post_predictions}
create_post_predictions <- function(final_predictions, n_races) {
    # Select columns dynamically based on number of races
    select_cols <- c("Skier", "Nation")
    for(i in 1:n_races) {
        select_cols <- c(select_cols,
                        paste0("Race", i, "_Points"),
                        paste0("Race", i, "_Safe"),
                        paste0("Race", i, "_Upside"),
                        paste0("Race", i, "_Confidence"))
    }
    select_cols <- c(select_cols,
                    "Total_Points", "Total_Safe", "Total_Upside",
                    "Avg_Confidence")
    
    post_predictions <- final_predictions %>%
        dplyr::select(all_of(select_cols)) %>%
        arrange(desc(Total_Points))
    
    return(post_predictions)
}
```

## Generate Position Probability Functions

```{r position_probabilities}
# Normalization function for position probabilities
normalize_position_probabilities <- function(predictions, position_thresholds) {
  # Make a copy to avoid modifying the original data frame
  normalized <- predictions
  
  # Log initial sums before any modifications
  log_info("Position probability sums BEFORE normalization:")
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    if(prob_col %in% names(normalized)) {
      initial_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
      log_info(sprintf("  %s: %.2f%% (target: %d%%)", 
                       prob_col, initial_sum, 100 * threshold))
    }
  }
  
  # For each threshold, adjust and normalize probabilities
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    
    # Calculate the current sum
    current_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
    
    # Target sum should be 100 * threshold (e.g., 100% for top 1, 300% for top 3)
    target_sum <- 100 * threshold
    
    # Normalize only if current sum is not zero to avoid division by zero
    if(current_sum > 0) {
      # Apply scaling factor to adjust the probabilities
      scaling_factor <- target_sum / current_sum
      normalized[[prob_col]] <- normalized[[prob_col]] * scaling_factor
      
      # Cap individual probabilities at 100%
      over_hundred <- which(normalized[[prob_col]] > 100)
      if(length(over_hundred) > 0) {
        log_info(sprintf("  Capping %d skiers with >100%% probability for %s", 
                         length(over_hundred), prob_col))
        
        # Calculate excess probability that needs to be redistributed
        excess <- sum(normalized[[prob_col]][over_hundred] - 100)
        
        # Cap values at 100%
        normalized[[prob_col]][over_hundred] <- 100
        
        # Redistribute the excess to other skiers proportionally
        under_hundred <- which(normalized[[prob_col]] < 100)
        if(length(under_hundred) > 0 && excess > 0) {
          # Get current sum of under-100 probabilities
          under_sum <- sum(normalized[[prob_col]][under_hundred])
          
          # Calculate scaling factor for redistribution
          if(under_sum > 0) {
            redistrib_factor <- (under_sum + excess) / under_sum
            normalized[[prob_col]][under_hundred] <- normalized[[prob_col]][under_hundred] * redistrib_factor
            
            # Recursively cap again if needed (unlikely but possible)
            if(any(normalized[[prob_col]][under_hundred] > 100)) {
              log_info("  Recursive capping needed after redistribution")
              # This is a simplification - in practice you might want a more robust approach
              normalized[[prob_col]][normalized[[prob_col]] > 100] <- 100
            }
          }
        }
      }
      
      log_info(sprintf("  %s normalization: applied scaling factor of %.4f", 
                       prob_col, scaling_factor))
    } else {
      # If sum is zero, distribute evenly among all skiers
      log_warn(paste("Zero sum for", prob_col, "- distributing evenly"))
      normalized[[prob_col]] <- target_sum / nrow(normalized)
    }
    
    # Final check to ensure we're close to the target sum
    final_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
    if(abs(final_sum - target_sum) > 1) {  # Allow for small rounding differences
      log_warn(sprintf("  %s sum after capping: %.2f%% (target: %.2f%%)", 
                       prob_col, final_sum, target_sum))
    }
  }
  
  # Log final sums after all adjustments
  log_info("Position probability sums AFTER normalization:")
  for(threshold in position_thresholds) {
    prob_col <- paste0("prob_top", threshold)
    if(prob_col %in% names(normalized)) {
      final_sum <- sum(normalized[[prob_col]], na.rm = TRUE)
      log_info(sprintf("  %s: %.2f%% (target: %d%%)", 
                       prob_col, final_sum, 100 * threshold))
    }
  }
  
  # Return normalized probabilities
  return(normalized)
}

# Helper function to format position probability results
format_position_results <- function(position_results, race_date, gender) {
  # Create a more reader-friendly version
  formatted_results <- position_results %>%
    mutate(
      Win = prob_top1,
      Podium = prob_top3,
      Top5 = prob_top5,
      Top10 = prob_top10,
      Top30 = prob_top30
    ) %>%
    select(Skier, Nation, Race, Win, Podium, Top5, Top10, Top30) %>%
    arrange(Race, desc(Win))
  
  # Create directory for output
  date_folder <- format(race_date, "%Y%m%d")
  dir_path <- paste0(
    "/Users/syverjohansen/blog/daehl-e/content/post/cross-country/drafts/race-picks/", 
    date_folder
  )
  
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  # Split by race
  races <- unique(formatted_results$Race)
  race_dfs <- list()
  
  for(race_num in races) {
    race_df <- formatted_results %>%
      filter(Race == race_num) %>%
      select(-Race) 
    
    sheet_name <- paste0(
      ifelse(gender == "men", "Men", "Ladies"),
      " Race ", race_num
    )
    
    race_dfs[[sheet_name]] <- race_df
  }
  
  # Save to Excel
  output_file <- file.path(
    dir_path,
    paste0(ifelse(gender == "men", "men", "ladies"), "_position_probabilities.xlsx")
  )
  
  write.xlsx(race_dfs, output_file)
  
  log_info(paste("Formatted position probabilities saved to", output_file))
  
  return(race_dfs)
}
```

## Race Prediction Function

```{r predict_races}
predict_races <- function(gender) {
  # Load chronological data
  chrono_path <- ifelse(gender == "men", 
                     "~/ski/elo/python/ski/polars/excel365/men_chrono_elevation.csv",
                     "~/ski/elo/python/ski/polars/excel365/ladies_chrono_elevation.csv")
  
  # Get appropriate startlist and races
  startlist <- if(gender == "men") men_startlist else ladies_startlist
  races <- if(gender == "men") men_races else ladies_races
  
  log_info(paste("Processing", gender, "data"))
  
  # Read chronos
  df <- read.csv(chrono_path, stringsAsFactors = FALSE) %>%
    mutate(Date = as.Date(Date)) %>%
    preprocess_data()
  
  # Initialize results list
  race_predictions <- list()
  race_dfs <- list()
  position_predictions <- list() # List to store position probabilities for each race
  
  # Define position thresholds
  position_thresholds <- c(1, 3, 5, 10, 30)  # Win, Podium, Top 5, Top 10, Top 30
  
  # Process each race
  for(i in 1:nrow(races)) {
    log_info(sprintf("Processing %s race %d: %s %s", gender, i, races$distance[i], races$technique[i]))
    
    # Get race info for determining points system
    race_info <- tomorrow_races %>%
      filter(Sex == ifelse(gender == "men", "M", "L")) %>%
      slice(i)
    
    # Check if this is a stage race
    is_stage_race <- !is.null(race_info$Stage) && race_info$Stage == 1
    
    # Use the appropriate points system
    points_system <- if(is_stage_race) stage_points else wc_points
    
    log_info(paste("Using", if(is_stage_race) "stage points" else "World Cup points", "for this race"))
    
    # Filter base dataset for race type
    race_df <- df %>%
      {if(races$distance[i] == "Sprint") {
        if(races$technique[i] == "") {
          filter(., Distance == "Sprint")  # Don't filter by technique if it's empty
        } else {
          filter(., Distance == "Sprint", Technique == races$technique[i])
        }
      } else {
        if(races$technique[i] == "") {
          filter(., Distance != "Sprint")  # Don't filter by technique if it's empty
        } else {
          filter(., Distance != "Sprint", Technique == races$technique[i])
        }
      }}

    # Add altitude categories for historical data
    race_df <- race_df %>%
      mutate(
        AltitudeCategory = ifelse(Elevation >= 1300, 1, 0)
      )        

    # Get relevant Pelo column
    pelo_col <- case_when(
      races$distance[i] == "Sprint" & races$technique[i] == "C" ~ "Sprint_C_Pelo_Pct",
      races$distance[i] == "Sprint" & races$technique[i] == "F" ~ "Sprint_F_Pelo_Pct",
      races$distance[i] != "Sprint" & races$technique[i] == "C" ~ "Distance_C_Pelo_Pct",
      races$distance[i] != "Sprint" & races$technique[i] == "F" ~ "Distance_F_Pelo_Pct",
      races$distance[i] != "Sprint" & races$technique[i] == "" ~ "Distance_Pelo_Pct",
      races$distance[i] == "Sprint" & races$technique[i] == "" ~ "Sprint_Pelo_Pct",
      TRUE ~ "Pelo_Pct"
    )
    
    # Filter for top performers and add previous points
    race_df_75 <- race_df %>%
      filter(get(pelo_col) > 0.75) %>%
      group_by(ID) %>%
      arrange(Season, Race) %>%
      ungroup()
      
    # Feature selection and model fitting for points prediction
    response_variable <- "Points"
    explanatory_vars <- c("Prev_Points_Weighted", "Distance_Pelo_Pct", "Sprint_Pelo_Pct", 
                        "Sprint_C_Pelo_Pct", "Distance_F_Pelo_Pct", "Distance_C_Pelo_Pct", 
                        "Classic_Pelo_Pct", "Freestyle_Pelo_Pct", "Sprint_F_Pelo_Pct", "Pelo_Pct")
    
    # Create and fit model for points
# Create and fit model for points
    formula <- as.formula(paste(response_variable, "~", paste(explanatory_vars, collapse = " + ")))
    exhaustive_selection <- regsubsets(formula, data = race_df_75, nbest = 1, method = "exhaustive")
    summary_exhaustive <- summary(exhaustive_selection)
    best_bic_vars <- names(coef(exhaustive_selection, which.min(summary_exhaustive$bic)))
    smooth_terms <- paste("s(", best_bic_vars[-1], ")", collapse=" + ")
    gam_formula <- as.formula(paste("Points ~", smooth_terms))
    
    model <- gam(gam_formula, data = race_df_75)
    
    # Calculate adjustments for historical data step by step
    race_df_75 <- race_df_75 %>%
      arrange(Date) %>%
      group_by(Skier) %>%
      mutate(
        row_id = row_number()
      ) %>%
      ungroup() %>%
      # Step 1: Initial predictions
      mutate(
        Initial_Prediction = predict(model, newdata = .)
      ) %>%
      group_by(Skier) %>%
      mutate(
        Prediction_Diff = Points - Initial_Prediction
      ) %>%
      # Step 2: Calculate altitude p-values and effects
      mutate(
        altitude_p = purrr::map_dbl(row_id, function(r) {
          if(r <= 1) return(1)
          prior_alt_curr <- Prediction_Diff[AltitudeCategory == AltitudeCategory[r] & row_id < r]
          prior_alt_other <- Prediction_Diff[AltitudeCategory != AltitudeCategory[r] & row_id < r]
          if(length(prior_alt_curr) < 3 || length(prior_alt_other) < 3) return(1)
          tryCatch({
            t.test(prior_alt_curr, prior_alt_other)$p.value
          }, error = function(e) 1)
        }),
        altitude_correction = ifelse(altitude_p < 0.05,
                                   mean(Prediction_Diff[AltitudeCategory == AltitudeCategory], na.rm = TRUE),
                                   0)
      ) %>%
      # Step 3: Calculate course-adjusted predictions
      mutate(
        Course_Adjusted = Initial_Prediction + altitude_correction,
        Course_Diff = Points - Course_Adjusted
      ) %>%
      # Step 4: Calculate Period adjustments
      mutate(
        period_p = purrr::map_dbl(row_id, function(r) {
          if(r <= 1) return(1)
          prior_period_curr <- Course_Diff[Period == Period[r] & row_id < r]
          prior_period_other <- Course_Diff[Period != Period[r] & row_id < r]
          if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
          tryCatch({
            t.test(prior_period_curr, prior_period_other)$p.value
          }, error = function(e) 1)
        }),
        period_correction = ifelse(period_p < 0.05,
                                mean(Course_Diff[Period == Period], na.rm = TRUE),
                                0),
        Period_Adjusted = Course_Adjusted + period_correction,
        Period_Diff = Points - Period_Adjusted
      ) %>%
      # Step 5: Calculate Mass Start adjustments
      mutate(
        ms_p = purrr::map_dbl(row_id, function(r) {
          if(r <= 1) return(1)
          prior_ms_curr <- Period_Diff[MS == MS[r] & row_id < r]
          prior_ms_other <- Period_Diff[MS != MS[r] & row_id < r]
          if(length(prior_ms_curr) < 3 || length(prior_ms_other) < 3) return(1)
          tryCatch({
            t.test(prior_ms_curr, prior_ms_other)$p.value
          }, error = function(e) 1)
        }),
        ms_correction = ifelse(ms_p < 0.05,
                            mean(Period_Diff[MS == MS], na.rm = TRUE),
                            0),
      ) %>%
      ungroup()
    
    # Create position probability models using the same variables as points model
    position_models <- list()
    position_adjustments <- list()  # To store adjustments for each threshold
    
    # Feature selection - use the same explanatory variables as the points model
    position_feature_vars <- explanatory_vars  # Use the same variables defined for points
    
    # Create models for each position threshold
    for(threshold in position_thresholds) {
      log_info(paste("Creating model for top", threshold, "positions"))
      
      # Create binary outcome variable for position threshold
      race_df$position_achieved <- race_df$Place <= threshold
      
      # Create formula for regsubsets using the same explanatory variables as the points model
      pos_formula <- as.formula(paste("position_achieved ~", paste(position_feature_vars, collapse = " + ")))
      
      # Use regsubsets to select best features for this position threshold
      tryCatch({
        pos_selection <- regsubsets(pos_formula, data = race_df, nbest = 1, method = "exhaustive")
        pos_summary <- summary(pos_selection)
        pos_best_bic_vars <- names(coef(pos_selection, which.min(pos_summary$bic)))
        
        # Create smooth terms for GAM using best BIC variables (remove intercept)
        pos_smooth_terms <- paste("s(", pos_best_bic_vars[-1], ")", collapse=" + ")
        pos_gam_formula <- as.formula(paste("position_achieved ~", pos_smooth_terms))
        
        # Fit the position model with binomial family
        position_model <- gam(pos_gam_formula,
                            data = race_df,
                            family = binomial,
                            method = "REML")

        # Calculate Brier score for model evaluation
        predicted_probs <- predict(position_model, newdata = race_df, type = "response")
        brier_score <- mean((race_df$position_achieved - predicted_probs)^2, na.rm = TRUE)
        log_info(paste("Brier score for threshold", threshold, ":", round(brier_score, 4)))
        
        # Log selected variables
        log_info(paste("Variables selected for", threshold, "position model:", 
                      paste(pos_best_bic_vars[-1], collapse=", ")))
        
        # Store the model
        position_models[[paste0("threshold_", threshold)]] <- position_model
        
        # Calculate adjustments for altitude, period, and mass start for this threshold
        position_df <- race_df %>%
          arrange(Date) %>%
          group_by(Skier) %>%
          mutate(
            row_id = row_number()
          ) %>%
          ungroup()
        
        # Add predictions separately (outside of mutate)
        position_df$initial_prob <- predict(position_model, newdata = position_df, type = "response")
        
        # Continue with the rest of the operations
        position_df <- position_df %>%
          group_by(Skier) %>%
          mutate(
            prob_diff = as.numeric(position_achieved) - initial_prob,
            
            # Calculate altitude adjustments
            altitude_p = purrr::map_dbl(row_id, function(r) {
              if(r <= 1) return(1)
              prior_alt_curr <- prob_diff[AltitudeCategory == AltitudeCategory[r] & row_id < r]
              prior_alt_other <- prob_diff[AltitudeCategory != AltitudeCategory[r] & row_id < r]
              if(length(prior_alt_curr) < 3 || length(prior_alt_other) < 3) return(1)
              tryCatch({
                t.test(prior_alt_curr, prior_alt_other)$p.value
              }, error = function(e) 1)
            }),
            altitude_correction = ifelse(altitude_p < 0.05,
                                       mean(prob_diff[AltitudeCategory == AltitudeCategory], na.rm = TRUE),
                                       0),
            altitude_adjusted = pmin(pmax(initial_prob + altitude_correction, 0), 1),
            altitude_diff = as.numeric(position_achieved) - altitude_adjusted
          ) %>%
          # Calculate period adjustments
          mutate(
            period_p = purrr::map_dbl(row_id, function(r) {
              if(r <= 1) return(1)
              prior_period_curr <- altitude_diff[Period == Period[r] & row_id < r]
              prior_period_other <- altitude_diff[Period != Period[r] & row_id < r]
              if(length(prior_period_curr) < 3 || length(prior_period_other) < 3) return(1)
              tryCatch({
                t.test(prior_period_curr, prior_period_other)$p.value
              }, error = function(e) 1)
            }),
            period_correction = ifelse(period_p < 0.05,
                                    mean(altitude_diff[Period == Period], na.rm = TRUE),
                                    0),
            period_adjusted = pmin(pmax(altitude_adjusted + period_correction, 0), 1),
            period_diff = as.numeric(position_achieved) - period_adjusted
          ) %>%
          # Calculate mass start adjustments
          mutate(
            ms_p = purrr::map_dbl(row_id, function(r) {
              if(r <= 1) return(1)
              prior_ms_curr <- period_diff[MS == MS[r] & row_id < r]
              prior_ms_other <- period_diff[MS != MS[r] & row_id < r]
              if(length(prior_ms_curr) < 3 || length(prior_ms_other) < 3) return(1)
              tryCatch({
                t.test(prior_ms_curr, prior_ms_other)$p.value
              }, error = function(e) 1)
            }),
            ms_correction = ifelse(ms_p < 0.05,
                                mean(period_diff[MS == MS], na.rm = TRUE),
                                0)
          ) %>%
          ungroup()
        
        # Get final adjustments for each skier
        skier_pos_adjustments <- position_df %>%
          group_by(Skier) %>%
          summarise(
            altitude_effect = last(altitude_correction),
            period_effect = last(period_correction),
            ms_effect = last(ms_correction)
          )
        
        # Store adjustments for this threshold
        position_adjustments[[paste0("threshold_", threshold)]] <- skier_pos_adjustments
        
      }, error = function(e) {
        log_warn(paste("Error in position model for threshold", threshold, ":", e$message))
        
        # Create a simpler fallback model with just the pelo column
        fallback_vars <- c("Prev_Points_Weighted", pelo_col)
        fallback_vars <- fallback_vars[fallback_vars %in% names(race_df)]
        
        if(length(fallback_vars) > 0) {
          fallback_terms <- paste("s(", fallback_vars, ")", collapse=" + ")
          fallback_formula <- as.formula(paste("position_achieved ~", fallback_terms))
          
          position_models[[paste0("threshold_", threshold)]] <- gam(
            fallback_formula,
            data = race_df,
            family = binomial,
            method = "REML"
          )
          
          # Create empty adjustments object since we can't calculate them for the fallback model
          empty_adjustments <- data.frame(Skier = unique(race_df$Skier))
          empty_adjustments$altitude_effect <- 0
          empty_adjustments$period_effect <- 0
          empty_adjustments$ms_effect <- 0
          position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
          
          log_info(paste("Created fallback model for threshold", threshold, 
                        "using variables:", paste(fallback_vars, collapse=", ")))
        } else {
          # Last resort fallback - just use the pelo column
          fallback_formula <- as.formula(paste("position_achieved ~ s(", pelo_col, ")"))
          position_models[[paste0("threshold_", threshold)]] <- gam(
            fallback_formula,
            data = race_df,
            family = binomial,
            method = "REML"
          )
          
          # Create empty adjustments object
          empty_adjustments <- data.frame(Skier = unique(race_df$Skier))
          empty_adjustments$altitude_effect <- 0
          empty_adjustments$period_effect <- 0
          empty_adjustments$ms_effect <- 0
          position_adjustments[[paste0("threshold_", threshold)]] <- empty_adjustments
          
          log_info(paste("Created last-resort fallback model for threshold", threshold, 
                        "using only", pelo_col))
        }
      })
    }
    
    # Calculate volatility metrics using recent races
    race_df_75 <- race_df_75 %>%
      group_by(Skier) %>%
      arrange(Date) %>%  # Ensure chronological order
      mutate(
        # Create rolling window calculations for last 10 races
        recent_prediction_volatility = slider::slide_dbl(
          Points - Initial_Prediction,
          sd,
          .before = 9,  # Look at current race plus 9 previous
          .complete = FALSE  # Allow partial windows
        ),
        
        recent_consistency_score = slider::slide_dbl(
          abs(Points - Initial_Prediction),
          mean,
          .before = 9,
          .complete = FALSE
        ),
        
        recent_upside_potential = slider::slide_dbl(
          Points - Initial_Prediction,
          ~quantile(.x, 0.9, na.rm = TRUE),
          .before = 9,
          .complete = FALSE
        ),
        
        recent_downside_risk = slider::slide_dbl(
          Points - Initial_Prediction,
          ~quantile(.x, 0.1, na.rm = TRUE),
          .before = 9,
          .complete = FALSE
        )
      ) %>%
      mutate(
        recent_volatility_ratio = recent_upside_potential / abs(recent_downside_risk)
      ) %>%
      ungroup()
    
    # Get final adjustments for each skier
    skier_adjustments <- race_df_75 %>%
      group_by(Skier) %>%
      summarise(
        altitude_effect = last(altitude_correction),
        period_effect = last(period_correction),
        ms_effect = last(ms_correction),
        
        # Recent volatility metrics
        prediction_volatility = last(recent_prediction_volatility),
        consistency_score = last(recent_consistency_score),
        upside_potential = last(recent_upside_potential),
        downside_risk = last(recent_downside_risk),
        volatility_ratio = last(recent_volatility_ratio),
        
        # Add number of recent races for confidence
        n_recent_races = sum(!is.na(tail(Points, 10)))
      )
    
    # Prepare startlist data
    startlist_prepared <- prepare_startlist_data(startlist, race_df, pelo_col)
    
    # Make position probability predictions with adjustments
    position_preds <- data.frame(
      Skier = startlist_prepared$Skier,
      Nation = startlist_prepared$Nation,
      Race = i
    )
    
    # Make predictions for each threshold
    for(threshold in position_thresholds) {
      model_name <- paste0("threshold_", threshold)
      adj_name <- paste0("threshold_", threshold)
      prob_col <- paste0("prob_top", threshold)
      
      if(model_name %in% names(position_models)) {
        tryCatch({
          # Get the model
          pos_model <- position_models[[model_name]]
          
          # Check what variables the model actually needs
          model_vars <- names(pos_model$var.summary)
          log_info(paste("Model for threshold", threshold, "requires variables:", paste(model_vars, collapse=", ")))
          
          # Create a clean subset of prediction data with only required variables
          prediction_subset <- startlist_prepared
          
          # Explicitly check for each variable
          for(var in model_vars) {
            if(!(var %in% names(prediction_subset))) {
              log_warn(paste("Missing required variable:", var, "- adding with default values"))
              # Add missing variable with appropriate default value
              prediction_subset[[var]] <- 0
            } else {
              # Ensure the variable has the right type
              model_var_type <- class(pos_model$var.summary[[var]])
              data_var_type <- class(prediction_subset[[var]])
              
              if(!identical(model_var_type, data_var_type)) {
                log_warn(paste("Variable type mismatch for", var, ":", 
                              "model expects", model_var_type, "but got", data_var_type))
                # Convert to correct type
                if(model_var_type == "numeric") {
                  prediction_subset[[var]] <- as.numeric(prediction_subset[[var]])
                } else if(model_var_type == "factor") {
                  prediction_subset[[var]] <- as.factor(prediction_subset[[var]])
                }
              }
              
              # Handle NAs
              if(any(is.na(prediction_subset[[var]]))) {
                log_info(paste("Replacing NAs in", var))
                if(is.numeric(prediction_subset[[var]])) {
                  prediction_subset[[var]] <- replace_na_with_quartile(prediction_subset[[var]])
                } else {
                  # For non-numeric, use most common value
                  most_common <- names(sort(table(prediction_subset[[var]], useNA = "no"), decreasing = TRUE))[1]
                  prediction_subset[[var]][is.na(prediction_subset[[var]])] <- most_common
                }
              }
            }
          }
          
          # Make predictions with explicit try-catch
          base_predictions <- tryCatch({
            # Debug output
            log_info(paste("Attempting prediction for threshold", threshold, "with", nrow(prediction_subset), "rows"))
            
            # Explicit call to mgcv::predict.gam to avoid method dispatch issues
            mgcv::predict.gam(pos_model, newdata = prediction_subset, type = "response")
          }, error = function(e) {
            log_warn(paste("Prediction call failed:", e$message))
            
            # Try alternative prediction approach with one row at a time
            log_info("Trying row-by-row prediction as fallback")
            result <- numeric(nrow(prediction_subset))
            
            for(i in 1:nrow(prediction_subset)) {
              single_row <- prediction_subset[i,, drop = FALSE]
              result[i] <- tryCatch({
                mgcv::predict.gam(pos_model, newdata = single_row, type = "response")
              }, error = function(e2) {
                log_warn(paste("Failed on row", i, ":", e2$message))
                threshold/100  # Default value based on threshold
              })
            }
            return(result)
          })
          
          # Store predictions
          position_preds[[paste0(prob_col, "_base")]] <- base_predictions
          
          # Apply adjustments if available
          if(adj_name %in% names(position_adjustments)) {
            # Get adjustments
            pos_adj <- position_adjustments[[adj_name]]
            
            # Join with predictions
            position_preds <- position_preds %>%
              left_join(pos_adj, by = "Skier") %>%
              mutate(
                # Replace NAs with zeros
                altitude_effect = replace_na(altitude_effect, 0),
                period_effect = replace_na(period_effect, 0),
                ms_effect = replace_na(ms_effect, 0),
                
                # Apply adjustments
                altitude_adjustment = altitude_effect,
                period_adjustment = period_effect,
                ms_adjustment = ms_effect,
                
                # Calculate adjusted probabilities
                adjusted_prob = get(paste0(prob_col, "_base")) + 
                             altitude_adjustment + period_adjustment + ms_adjustment,
                
                # Ensure probabilities are between 0 and 1
                adjusted_prob = pmin(pmax(adjusted_prob, 0), 1)
              )
            
            # Use adjusted probability as final
            position_preds[[prob_col]] <- position_preds$adjusted_prob
            
            # Clean up temporary columns
            position_preds <- position_preds %>%
              select(-altitude_effect, -period_effect, -ms_effect,
                    -altitude_adjustment, -period_adjustment, -ms_adjustment, -adjusted_prob)
          } else {
            # Use base prediction if no adjustments
            position_preds[[prob_col]] <- position_preds[[paste0(prob_col, "_base")]]
          }
          
          # Clean up base prediction column
          position_preds <- position_preds %>%
            select(-paste0(prob_col, "_base"))
          
          # Convert to percentage and round
          position_preds[[prob_col]] <- round(position_preds[[prob_col]] * 100, 1)
          
          log_info(paste("Made predictions with adjustments for position threshold", threshold))
          
        }, error = function(e) {
          log_warn(paste("Complete failure for threshold", threshold, ":", e$message))
          # Set a reasonable default based on threshold (1% for top1, 3% for top3, etc.)
          position_preds[[prob_col]] <- rep(threshold, nrow(position_preds))
        })
      } else {
        log_warn(paste("No model found for threshold", threshold))
        position_preds[[prob_col]] <- NA
      }
    }
    
    # Normalize position probabilities to ensure they sum to the correct totals
    position_preds <- normalize_position_probabilities(position_preds, position_thresholds)
    
    # Store position predictions for this race
    position_predictions[[i]] <- position_preds
    
    # Prepare startlist points predictions
    race_dfs[[i]] <- startlist_prepared %>%
      mutate(
        Base_Prediction = predict(model, newdata = .),
      ) %>%
      left_join(skier_adjustments, by = "Skier") %>%
      mutate(
        # Regular adjustments
        altitude_effect = replace_na(altitude_effect, 0),
        period_effect = replace_na(period_effect, 0),
        ms_effect = replace_na(ms_effect, 0),
        
        # Volatility metrics
        prediction_volatility = replace_na(prediction_volatility, 0),
        consistency_score = replace_na(consistency_score, 0),
        upside_potential = replace_na(upside_potential, 0),
        downside_risk = replace_na(downside_risk, 0),
        volatility_ratio = replace_na(volatility_ratio, 1),
        n_recent_races = replace_na(n_recent_races, 0),
        
        # Using your existing adjustment approach
        altitude_adjustment = altitude_effect,
        period_adjustment = period_effect,
        ms_adjustment = ms_effect,
        
        # Base prediction and adjustments
        Predicted_Points = Base_Prediction + altitude_adjustment + 
                         period_adjustment + ms_adjustment,
        Predicted_Points = pmax(pmin(Predicted_Points, 100), 0),
        
        # Final prediction
        Final_Prediction = Predicted_Points,
        
        # Different scoring scenarios
        confidence_factor = pmin(n_recent_races / 10, 1),
        scaled_upside_potential = upside_potential * (Predicted_Points/100),
        scaled_downside_potential = downside_risk * (Predicted_Points/100),
        
        # Safe prediction (downside)
        Safe_Prediction = pmax(
          Predicted_Points - (prediction_volatility * 1.5 * confidence_factor), 
          0
        ),
        Safe_Prediction = pmax(
          Predicted_Points - (abs(scaled_downside_potential) * volatility_ratio * confidence_factor), 
          0
        ),
        
        # Upside prediction
        Upside_Prediction = pmin(
          Predicted_Points + (prediction_volatility * 1.5 * confidence_factor), 
          100
        ),
        Upside_Prediction = pmin(
          Predicted_Points + (scaled_upside_potential * volatility_ratio * confidence_factor), 
          100
        )
      ) %>%
      dplyr::select(Skier, Nation, 
                   Base_Prediction, altitude_adjustment, 
                   period_adjustment, ms_adjustment,
                   prediction_volatility, volatility_ratio, confidence_factor,
                   Final_Prediction, Safe_Prediction, Upside_Prediction)
    
    # Apply pursuit handling if needed
    if(races$Pursuit[i] == 1) {
      # Create a temporary points system based on the stage flag
      temp_points_system <- if(is_stage_race) stage_points else wc_points
      
      # Get startlist points
      startlist_points <- startlist %>%
        mutate(
          # Use the appropriate points system
          startlist_points = case_when(
            row_number() <= length(temp_points_system) ~ temp_points_system[row_number()],
            TRUE ~ 0
          )
        ) %>%
        select(Skier, startlist_points)
      
      # Apply pursuit logic - average predicted points with startlist points
      race_dfs[[i]] <- race_dfs[[i]] %>%
        left_join(startlist_points, by = "Skier") %>%
        mutate(
          startlist_points = replace_na(startlist_points, 0),
          # Weighted average of predicted points and startlist points
          Final_Prediction = (Predicted_Points + startlist_points) / 2,
          Safe_Prediction = (Safe_Prediction + startlist_points) / 2,
          Upside_Prediction = (Upside_Prediction + startlist_points) / 2
        ) %>%
        select(-startlist_points)
      
      log_info(paste("Applied pursuit logic to race", i))
    }
  }

  # Get number of races from races dataframe
  n_races <- nrow(races)
  
  # Combine all race predictions (points)
  final_predictions <- combine_predictions(race_dfs, n_races)
  
  log_info(paste("Final predictions calculated for", gender))
  
  # Create post predictions for blog (points)
  post_predictions <- create_post_predictions(final_predictions, n_races)
  
  # Combine all position predictions into one dataframe
  all_position_predictions <- bind_rows(position_predictions)
  
  # Create formatted position probabilities
  formatted_position_results <- format_position_results(all_position_predictions, tomorrow_date, gender)
  
  # Create folder path based on tomorrow's date
  date_folder <- format(tomorrow_date, "%Y%m%d")
  dir_path <- paste0("/Users/syverjohansen/blog/daehl-e/content/post/cross-country/drafts/race-picks/", date_folder)
  
  # Create directory if it doesn't exist
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  # Save points predictions to Excel
  points_file_path <- file.path(dir_path, paste0(ifelse(gender == "men", "men", "ladies"), "-points.xlsx"))
  write.xlsx(post_predictions, file = points_file_path)
  
  log_info(paste("Saved", gender, "points predictions to", points_file_path))
  
  # Return both points and position predictions
  return(list(
    full_predictions = final_predictions,
    post_predictions = post_predictions,
    position_predictions = all_position_predictions,
    formatted_position_results = formatted_position_results
  ))
}

# Function to combine race predictions
combine_predictions <- function(race_dfs, n_races) {
  log_info("Combining race predictions")
  
  # Start with first race
  log_info("Starting with first race data")
  final_predictions <- race_dfs[[1]] %>%
    rename(
      Race1_Base = Base_Prediction,
      Race1_Altitude = altitude_adjustment,
      Race1_Period = period_adjustment,
      Race1_MS = ms_adjustment,
      Race1_Points = Final_Prediction,
      Race1_Safe = Safe_Prediction,
      Race1_Upside = Upside_Prediction,
      Race1_Volatility = prediction_volatility,
      Race1_Ratio = volatility_ratio,
      Race1_Confidence = confidence_factor
    )
  
  # Add remaining races dynamically
  if(n_races > 1) {
    for(i in 2:n_races) {
      log_info(paste("Adding race", i, "to combined predictions"))
      
      final_predictions <- final_predictions %>%
        left_join(
          race_dfs[[i]] %>%
            rename(
              !!paste0("Race", i, "_Base") := Base_Prediction,
              !!paste0("Race", i, "_Altitude") := altitude_adjustment,
              !!paste0("Race", i, "_Period") := period_adjustment,
              !!paste0("Race", i, "_MS") := ms_adjustment,
              !!paste0("Race", i, "_Points") := Final_Prediction,
              !!paste0("Race", i, "_Safe") := Safe_Prediction,
              !!paste0("Race", i, "_Upside") := Upside_Prediction,
              !!paste0("Race", i, "_Volatility") := prediction_volatility,
              !!paste0("Race", i, "_Ratio") := volatility_ratio,
              !!paste0("Race", i, "_Confidence") := confidence_factor
            ) %>%
            dplyr::select(Skier, 
                        !!paste0("Race", i, "_Base"),
                        !!paste0("Race", i, "_Altitude"),
                        !!paste0("Race", i, "_Period"),
                        !!paste0("Race", i, "_MS"),
                        !!paste0("Race", i, "_Points"),
                        !!paste0("Race", i, "_Safe"),
                        !!paste0("Race", i, "_Upside"),
                        !!paste0("Race", i, "_Volatility"),
                        !!paste0("Race", i, "_Ratio"),
                        !!paste0("Race", i, "_Confidence")),
          by = "Skier"
        )
    }
  }
  
# Create expressions for summing columns dynamically
  sum_expr <- function(prefix, n_races) {
    syms <- paste0("Race", 1:n_races, "_", prefix)
    parse(text = paste(syms, collapse = " + "))
  }
  
  avg_expr <- function(prefix, n_races) {
    syms <- paste0("Race", 1:n_races, "_", prefix)
    parse(text = paste0("(", paste(syms, collapse = " + "), ")/", n_races))
  }
  
  # Calculate totals dynamically based on number of races
  log_info("Calculating totals")
  final_predictions <- final_predictions %>%
    mutate(
      Total_Points = eval(sum_expr("Points", n_races)),
      Total_Altitude = eval(sum_expr("Altitude", n_races)),
      Total_Period = eval(sum_expr("Period", n_races)),
      Total_MS = eval(sum_expr("MS", n_races)),
      Total_Safe = eval(sum_expr("Safe", n_races)),
      Total_Upside = eval(sum_expr("Upside", n_races)),
      Avg_Volatility = eval(avg_expr("Volatility", n_races)),
      Avg_Confidence = eval(avg_expr("Confidence", n_races))
    ) %>%
    arrange(desc(Total_Points))
  
  # Select columns dynamically based on number of races
  select_cols <- c("Skier", "Nation")
  for(i in 1:n_races) {
    select_cols <- c(select_cols,
                    paste0("Race", i, "_Base"),
                    paste0("Race", i, "_Altitude"),
                    paste0("Race", i, "_Period"),
                    paste0("Race", i, "_MS"),
                    paste0("Race", i, "_Points"),
                    paste0("Race", i, "_Safe"),
                    paste0("Race", i, "_Upside"),
                    paste0("Race", i, "_Volatility"),
                    paste0("Race", i, "_Ratio"),
                    paste0("Race", i, "_Confidence"))
  }
  select_cols <- c(select_cols,
                  "Total_Points", "Total_Safe", "Total_Upside",
                  "Total_Altitude", 
                  "Total_Period", "Total_MS",
                  "Avg_Volatility", "Avg_Confidence")
  
  log_info("Returning final predictions")
  final_predictions %>%
    dplyr::select(all_of(select_cols))
}
```

## Create Top Contenders Summary

```{r top_contenders}
# Function to create top contenders summary
create_top_contenders_summary <- function(men_results, ladies_results) {
  # Create directory for output
  date_folder <- format(tomorrow_date, "%Y%m%d")
  dir_path <- paste0(
    "/Users/syverjohansen/blog/daehl-e/content/post/cross-country/drafts/race-picks/", 
    date_folder
  )
  
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  top_contenders <- list()
  
  # Process men's results if available
  if(!is.null(men_results)) {
    men_positions <- men_results$position_predictions
    men_races <- unique(men_positions$Race)
    
    for(race_num in men_races) {
      race_df <- men_positions %>%
        filter(Race == race_num)
      
      # Top 5 for win probability
      win_contenders <- race_df %>%
        arrange(desc(prob_top1)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top1) %>%
        rename(`Win%` = prob_top1)
      
      sheet_name <- paste0("Men Race ", race_num, " - Win")
      top_contenders[[sheet_name]] <- win_contenders
      
      # Top 5 for podium probability
      podium_contenders <- race_df %>%
        arrange(desc(prob_top3)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top3) %>%
        rename(`Podium%` = prob_top3)
      
      sheet_name <- paste0("Men Race ", race_num, " - Podium")
      top_contenders[[sheet_name]] <- podium_contenders
      
      # Top 5 for Top-5 probability
      top5_contenders <- race_df %>%
        arrange(desc(prob_top5)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top5) %>%
        rename(`Top5%` = prob_top5)
      
      sheet_name <- paste0("Men Race ", race_num, " - Top5")
      top_contenders[[sheet_name]] <- top5_contenders
    }
  }
  
  # Process ladies' results if available
  if(!is.null(ladies_results)) {
    ladies_positions <- ladies_results$position_predictions
    ladies_races <- unique(ladies_positions$Race)
    
    for(race_num in ladies_races) {
      race_df <- ladies_positions %>%
        filter(Race == race_num)
      
      # Top 5 for win probability
      win_contenders <- race_df %>%
        arrange(desc(prob_top1)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top1) %>%
        rename(`Win%` = prob_top1)
      
      sheet_name <- paste0("Ladies Race ", race_num, " - Win")
      top_contenders[[sheet_name]] <- win_contenders
      
      # Top 5 for podium probability
      podium_contenders <- race_df %>%
        arrange(desc(prob_top3)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top3) %>%
        rename(`Podium%` = prob_top3)
      
      sheet_name <- paste0("Ladies Race ", race_num, " - Podium")
      top_contenders[[sheet_name]] <- podium_contenders
      
      # Top 5 for Top-5 probability
      top5_contenders <- race_df %>%
        arrange(desc(prob_top5)) %>%
        head(5) %>%
        select(Skier, Nation, prob_top5) %>%
        rename(`Top5%` = prob_top5)
      
      sheet_name <- paste0("Ladies Race ", race_num, " - Top5")
      top_contenders[[sheet_name]] <- top5_contenders
    }
  }
  
  # Save to Excel if we have any contenders
  if(length(top_contenders) > 0) {
    output_file <- file.path(dir_path, "top_contenders.xlsx")
    write.xlsx(top_contenders, output_file)
    
    log_info(paste("Top contenders summary saved to", output_file))
  } else {
    log_warn("No top contenders data available")
  }
  
  return(top_contenders)
}
```

## Run the Predictions

```{r run_predictions}
# Initialize results
men_results <- NULL
ladies_results <- NULL

# Run predictions for men if they are racing
if(men_racing) {
  log_info("Processing men's predictions")
  men_results <- predict_races("men")
}
men_results
# Run predictions for ladies if they are racing
if(ladies_racing) {
  log_info("Processing ladies predictions")
  ladies_results <- predict_races("ladies")
}

# Create top contenders summary
top_contenders <- create_top_contenders_summary(men_results, ladies_results)
```

## Generate Summary Report

```{r summary}
# Generate a summary of the entire process including position probabilities
summary_results <- function(men_results, ladies_results) {
  # Display summary
  cat("=============================================================\n")
  cat("               RACE PREDICTIONS SUMMARY REPORT               \n")
  cat("=============================================================\n\n")
  
  cat("Race Date:", format(tomorrow_date, "%B %d, %Y"), "\n")
  
  if(men_racing) {
    cat("Men's races:", nrow(men_races), "\n")
    cat("Men's startlist size:", nrow(men_startlist), "skiers\n")
    
    # Get top win probability for men
    men_top_win <- men_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top1)) %>%
      slice(1)
    
    cat("\nMEN'S TOP CONTENDERS:\n")
    cat("Top win probability:", men_top_win$Skier, "(", men_top_win$Nation, ") -", men_top_win$prob_top1, "%\n")
    
    # Show top 5 contenders for win
    cat("\nTop 5 Men's Win Probabilities (Race 1):\n")
    men_top5_win <- men_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top1)) %>%
      head(5) %>%
      select(Skier, Nation, prob_top1)
    
    print(men_top5_win)
    
    # Show top 5 contenders for podium
    cat("\nTop 5 Men's Podium Probabilities (Race 1):\n")
    men_top5_podium <- men_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top3)) %>%
      head(5) %>%
      select(Skier, Nation, prob_top3)
    
    print(men_top5_podium)
  } else {
    cat("No men's races tomorrow\n")
  }
  
  if(ladies_racing) {
    cat("\nLadies' races:", nrow(ladies_races), "\n")
    cat("Ladies' startlist size:", nrow(ladies_startlist), "skiers\n")
    
    # Get top win probability for ladies
    ladies_top_win <- ladies_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top1)) %>%
      slice(1)
    
    cat("\nLADIES' TOP CONTENDERS:\n")
    cat("Top win probability:", ladies_top_win$Skier, "(", ladies_top_win$Nation, ") -", ladies_top_win$prob_top1, "%\n")
    
    # Show top 5 contenders for win
    cat("\nTop 5 Ladies' Win Probabilities (Race 1):\n")
    ladies_top5_win <- ladies_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top1)) %>%
      head(5) %>%
      select(Skier, Nation, prob_top1)
    
    print(ladies_top5_win)
    
    # Show top 5 contenders for podium
    cat("\nTop 5 Ladies' Podium Probabilities (Race 1):\n")
    ladies_top5_podium <- ladies_results$position_predictions %>%
      filter(Race == 1) %>%
      arrange(desc(prob_top3)) %>%
      head(5) %>%
      select(Skier, Nation, prob_top3)
    
    print(ladies_top5_podium)
  } else {
    cat("\nNo ladies' races tomorrow\n")
  }
  
  cat("\n=============================================================\n")
  cat("Race predictions process complete. Results saved to:\n")
  cat(paste0("/Users/syverjohansen/blog/daehl-e/content/post/cross-country/drafts/race-picks/", 
            format(tomorrow_date, "%Y%m%d"), "/\n"))
  cat("=============================================================\n")
}

# Generate summary
summary_results(men_results, ladies_results)
```

## Done!

Race predictions have been generated for tomorrow's races and saved to the output directory. The process included:
1. Loading race data for tomorrow's events
2. Processing historical race data to build prediction models
3. Generating points predictions for all skiers
4. Calculating position probabilities (win, podium, top 5, top 10, top 30)
5. Creating summary reports and Excel files with the predictions

These predictions will be useful for race analysis, betting guidance, and fantasy team selection.