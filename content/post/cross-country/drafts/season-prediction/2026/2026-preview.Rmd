---
title: "2026 Cross-Country Season Preview"
author: "Syver Johansen"
date: "2025-01-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## 2026 Cross-Country Season Preview

This preview analyzes the upcoming 2026 cross-country skiing season, including points predictions, Klaebo dominance scenarios, Russian return impact, and breakthrough potential candidates.

### Load Libraries

```{r load-packages, message=FALSE, warning=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(readr)
library(ggplot2)
library(openxlsx)
library(moments)  # for skewness/kurtosis
library(mgcv)     # for GAM models
library(glmnet)   # for LASSO feature selection
library(Boruta)   # for Boruta feature selection
library(leaps)    # for exhaustive search
library(MASS)     # for polr (ordinal logistic regression)
```

### Load Data

```{r load-data}
# Load men's and ladies chrono data from CSV files
cat("=== DATA LOADING & VALIDATION ===\n")

# Check if files exist before loading
men_file <- '/Users/syverjohansen/ski/elo/python/ski/polars/excel365/men_chrono.csv'
ladies_file <- '/Users/syverjohansen/ski/elo/python/ski/polars/excel365/ladies_chrono.csv'

if (!file.exists(men_file)) stop("Men's data file not found: ", men_file)
if (!file.exists(ladies_file)) stop("Ladies data file not found: ", ladies_file)

cat("✓ Data files exist\n")

# Load data with error handling
tryCatch({
  M_chrono <- read_csv(men_file, show_col_types = FALSE)
  cat("✓ Men's data loaded:", nrow(M_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load men's data: ", e$message)
})

tryCatch({
  L_chrono <- read_csv(ladies_file, show_col_types = FALSE)
  cat("✓ Ladies data loaded:", nrow(L_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load ladies data: ", e$message)
})

# Validate required columns exist
required_cols <- c("Skier", "Date", "Season", "Event", "City", "Distance", "Place", "Race", "ID")
missing_men <- setdiff(required_cols, names(M_chrono))
missing_ladies <- setdiff(required_cols, names(L_chrono))

if (length(missing_men) > 0) {
  stop("Missing required columns in men's data: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing required columns in ladies data: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required columns present in both datasets\n")

# Check for completely empty datasets
if (nrow(M_chrono) == 0) stop("Men's dataset is empty")
if (nrow(L_chrono) == 0) stop("Ladies dataset is empty")

# Validate data types and ranges
cat("\n--- Data Quality Checks ---\n")

# Check Place column (should be positive integers)
invalid_places_m <- sum(is.na(M_chrono$Place) | M_chrono$Place < 0 | !is.finite(M_chrono$Place))
invalid_places_l <- sum(is.na(L_chrono$Place) | L_chrono$Place < 0 | !is.finite(L_chrono$Place))

cat("Men's invalid Place values:", invalid_places_m, "\n")
cat("Ladies invalid Place values:", invalid_places_l, "\n")

if (invalid_places_m > nrow(M_chrono) * 0.1) {
  warning("More than 10% of men's Place values are invalid")
}
if (invalid_places_l > nrow(L_chrono) * 0.1) {
  warning("More than 10% of ladies Place values are invalid")
}

# Check for missing Skier names
missing_skiers_m <- sum(is.na(M_chrono$Skier) | M_chrono$Skier == "")
missing_skiers_l <- sum(is.na(L_chrono$Skier) | L_chrono$Skier == "")

cat("Men's missing Skier names:", missing_skiers_m, "\n")
cat("Ladies missing Skier names:", missing_skiers_l, "\n")

if (missing_skiers_m > 0) warning("Men's data has missing skier names")
if (missing_skiers_l > 0) warning("Ladies data has missing skier names")

# Date validation
date_errors_m <- sum(is.na(M_chrono$Date))
date_errors_l <- sum(is.na(L_chrono$Date))

cat("Men's invalid dates:", date_errors_m, "\n")
cat("Ladies invalid dates:", date_errors_l, "\n")

# Define excluded athletes - remove them from all analysis
excluded_men <- c("Jonas Baumann", "Pål Golberg", "Mikael Gunnulfsen", "Renaud Jay", "Roman Schaad")
excluded_ladies <- c("Therese Johaug", "Victoria Carl")

cat("\n--- Athlete Exclusion ---\n")
cat("Excluding men:", paste(excluded_men, collapse = ", "), "\n")
cat("Excluding ladies:", paste(excluded_ladies, collapse = ", "), "\n")

# Count how many records will be excluded
excluded_count_m <- sum(M_chrono$Skier %in% excluded_men)
excluded_count_l <- sum(L_chrono$Skier %in% excluded_ladies)

cat("Men's records to exclude:", excluded_count_m, "\n")
cat("Ladies records to exclude:", excluded_count_l, "\n")

# Filter out excluded athletes from raw data
M_chrono_original_rows <- nrow(M_chrono)
L_chrono_original_rows <- nrow(L_chrono)

M_chrono <- M_chrono %>%
  filter(!Skier %in% excluded_men)

L_chrono <- L_chrono %>%
  filter(!Skier %in% excluded_ladies)

# Verify exclusion worked correctly
actual_excluded_m <- M_chrono_original_rows - nrow(M_chrono)
actual_excluded_l <- L_chrono_original_rows - nrow(L_chrono)

if (actual_excluded_m != excluded_count_m) {
  warning("Mismatch in men's exclusion: expected ", excluded_count_m, ", actual ", actual_excluded_m)
}
if (actual_excluded_l != excluded_count_l) {
  warning("Mismatch in ladies exclusion: expected ", excluded_count_l, ", actual ", actual_excluded_l)
}

cat("✓ Men's data after exclusion:", nrow(M_chrono), "rows\n")
cat("✓ Ladies data after exclusion:", nrow(L_chrono), "rows\n")

# World Cup points mapping with validation
cat("\n--- Points System Validation ---\n")

wc_points <- c(100,95,90,85,80,75,72,69,66,63,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
stage_points <- c(50,47,44,41,38,35,32,30,28,26,24,22,20,18,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
tds_points <- c(300,285,270,255,240,216,207,198,189,180,174,168,162,156,150,144,138,132,126,120,114,108,102,96,90,84,78,72,66,60,57,54,51,48,45,42,39,36,33,30,27,24,21,18,15,12,9,6,3)

# Validate points arrays
if (length(wc_points) != 50) stop("World Cup points array should have 50 values")
if (length(stage_points) != 30) stop("Stage points array should have 30 values")  
if (length(tds_points) != 49) stop("Tour de Ski points array should have 49 values")

# Check points are in descending order
if (!all(diff(wc_points) <= 0)) stop("World Cup points not in descending order")
if (!all(diff(stage_points) <= 0)) stop("Stage points not in descending order")
if (!all(diff(tds_points) <= 0)) stop("Tour de Ski points not in descending order")

cat("✓ Points systems validated (WC:", length(wc_points), ", Stage:", length(stage_points), ", TdS:", length(tds_points), ")\n")

# Function to safely fetch points based on Place with validation
get_points <- function(place, points_list) {
  if (is.na(place) || !is.finite(place)) {
    return(0)
  }
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

# Test the get_points function
test_cases <- c(1, 10, 50, 51, -1, NA, Inf)
cat("Testing get_points function:\n")
for (test_place in test_cases) {
  result <- get_points(test_place, wc_points)
  cat(sprintf("  Place %s -> %s points\n", 
              ifelse(is.na(test_place), "NA", as.character(test_place)), result))
}

cat("\n=== DATA LOADING COMPLETE ===\n")
cat(sprintf("Final dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_chrono), nrow(L_chrono)))
cat(sprintf("Men's unique skiers: %d\n", length(unique(M_chrono$Skier))))
cat(sprintf("Ladies unique skiers: %d\n", length(unique(L_chrono$Skier))))
cat(sprintf("Men's season range: %s - %s\n", min(M_chrono$Season, na.rm = TRUE), max(M_chrono$Season, na.rm = TRUE)))
cat(sprintf("Ladies season range: %s - %s\n", min(L_chrono$Season, na.rm = TRUE), max(L_chrono$Season, na.rm = TRUE)))
```

### Data Processing

```{r process-data}
cat("=== DATA PROCESSING & VALIDATION ===\n")

# Function to process chrono data (works for both men and ladies)
process_chrono_data <- function(chrono_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Processing %s Data ---\n", data_name))
  
  # Input validation
  if (nrow(chrono_df) == 0) {
    stop(sprintf("%s dataset is empty", data_name))
  }
  
  # Check for required columns before processing
  required_cols <- c("Event", "City", "Place", "Distance", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(chrono_df))
  if (length(missing_cols) > 0) {
    stop(sprintf("Missing required columns in %s data: %s", data_name, paste(missing_cols, collapse = ", ")))
  }
  
  original_rows <- nrow(chrono_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Add World Cup points based on Event and Distance
  cat("Adding World Cup points...\n")
  df <- chrono_df %>%
    mutate(Points = case_when(
      Event == "Tour de Ski" & City == "Tour de Ski" ~ map_int(Place, ~ get_points(.x, tds_points)),
      Event == "Tour de Ski" ~ map_int(Place, ~ get_points(.x, stage_points)),
      TRUE ~ map_int(Place, ~ get_points(.x, wc_points))
    ))
  
  # Validate points assignment
  points_na <- sum(is.na(df$Points))
  points_negative <- sum(df$Points < 0, na.rm = TRUE)
  
  if (points_na > 0) {
    warning(sprintf("%s: %d rows have NA points", data_name, points_na))
  }
  if (points_negative > 0) {
    warning(sprintf("%s: %d rows have negative points", data_name, points_negative))
  }
  
  cat(sprintf("Points range: %d - %d\n", min(df$Points, na.rm = TRUE), max(df$Points, na.rm = TRUE)))
  
  # Count events before filtering
  event_counts_before <- table(df$Event)
  cat("Events before filtering:\n")
  print(event_counts_before)
  
  # Filter for relevant events and sort by Date, Race, Place
  cat("Filtering for relevant events...\n")
  relevant_events <- c("Offseason", "World Cup", "Nordic Opening", "Tour de Ski", "World Cup Final", "Ski Tour Canada")
  
  df <- df %>%
    filter(Event %in% relevant_events) %>%
    arrange(Date, Race, Place) %>%
    group_by(ID, Season) %>%
    mutate(
      Cumulative_Points = cumsum(Points),
      Races_in_Season = n()
    ) %>%
    ungroup()
  
  filtered_rows <- nrow(df)
  cat(sprintf("After event filtering: %d rows (removed %d rows)\n", filtered_rows, original_rows - filtered_rows))
  
  # Count events after filtering
  event_counts_after <- table(df$Event)
  cat("Events after filtering:\n")
  print(event_counts_after)
  
  # Validate cumulative points calculation
  invalid_cumulative <- df %>%
    group_by(ID, Season) %>%
    mutate(expected_cumulative = cumsum(Points)) %>%
    ungroup() %>%
    filter(Cumulative_Points != expected_cumulative) %>%
    nrow()
  
  if (invalid_cumulative > 0) {
    warning(sprintf("%s: %d rows have incorrect cumulative points", data_name, invalid_cumulative))
  } else {
    cat("✓ Cumulative points calculation validated\n")
  }
  
  # Remove team events (relays and team sprints)
  cat("Removing team events (Ts, Rel)...\n")
  before_team_filter <- nrow(df)
  
  team_event_counts <- table(df$Distance[df$Distance %in% c("Ts", "Rel")])
  if (length(team_event_counts) > 0) {
    cat("Team events to remove:\n")
    print(team_event_counts)
  }
  
  df <- df %>%
    filter(!Distance %in% c("Ts", "Rel"))
  
  after_team_filter <- nrow(df)
  cat(sprintf("After team event removal: %d rows (removed %d team events)\n", 
              after_team_filter, before_team_filter - after_team_filter))
  
  # Calculate maximum possible points per season 
  cat("Calculating maximum possible points per season...\n")
  max_points_per_season <- df %>%
    group_by(Season, Date, Race) %>%
    summarise(Max_Race_Points = max(Points), .groups = 'drop') %>%
    group_by(Season) %>%
    summarise(Max_Points = sum(Max_Race_Points), .groups = 'drop')
  
  # Validate max points calculation
  if (nrow(max_points_per_season) == 0) {
    stop(sprintf("%s: No seasons found for max points calculation", data_name))
  }
  
  # Check for seasons with zero max points
  zero_max_seasons <- max_points_per_season %>% filter(Max_Points == 0)
  if (nrow(zero_max_seasons) > 0) {
    warning(sprintf("%s: %d seasons have zero max points", data_name, nrow(zero_max_seasons)))
    print(zero_max_seasons)
  }
  
  cat(sprintf("Max points range by season: %d - %d\n", 
              min(max_points_per_season$Max_Points), max(max_points_per_season$Max_Points)))
  
  # Join max points and calculate percentage
  cat("Calculating percentage of maximum points...\n")
  before_join <- nrow(df)
  
  df <- df %>%
    left_join(max_points_per_season, by = "Season") %>%
    mutate(Pct_of_Max_Points = Cumulative_Points / Max_Points)
  
  after_join <- nrow(df)
  if (before_join != after_join) {
    warning(sprintf("%s: Row count changed during max points join: %d -> %d", data_name, before_join, after_join))
  }
  
  # Validate percentage calculations
  pct_na <- sum(is.na(df$Pct_of_Max_Points))
  pct_negative <- sum(df$Pct_of_Max_Points < 0, na.rm = TRUE)
  pct_over_one <- sum(df$Pct_of_Max_Points > 1, na.rm = TRUE)
  
  if (pct_na > 0) {
    warning(sprintf("%s: %d rows have NA percentage of max points", data_name, pct_na))
  }
  if (pct_negative > 0) {
    warning(sprintf("%s: %d rows have negative percentage of max points", data_name, pct_negative))
  }
  if (pct_over_one > 0) {
    warning(sprintf("%s: %d rows have percentage > 100%% of max points", data_name, pct_over_one))
  }
  
  cat(sprintf("Percentage range: %.3f - %.3f\n", 
              min(df$Pct_of_Max_Points, na.rm = TRUE), max(df$Pct_of_Max_Points, na.rm = TRUE)))
  
  # Final validation checks
  cat("\n--- Final Validation ---\n")
  
  # Check for required columns in output
  expected_output_cols <- c("Points", "Cumulative_Points", "Races_in_Season", "Max_Points", "Pct_of_Max_Points")
  missing_output_cols <- setdiff(expected_output_cols, names(df))
  if (length(missing_output_cols) > 0) {
    stop(sprintf("%s: Missing expected output columns: %s", data_name, paste(missing_output_cols, collapse = ", ")))
  }
  
  # Summary statistics
  cat(sprintf("✓ Processing complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(df), 100 * nrow(df) / original_rows))
  cat(sprintf("Unique skiers: %d\n", length(unique(df$Skier))))
  cat(sprintf("Seasons covered: %d (%s - %s)\n", 
              length(unique(df$Season)), min(df$Season), max(df$Season)))
  cat(sprintf("Average races per season per skier: %.1f\n", mean(df$Races_in_Season)))
  
  return(df)
}

# Process both datasets with validation
cat("\n=== PROCESSING MEN'S DATA ===\n")
tryCatch({
  M_processed <- process_chrono_data(M_chrono, "Men's")
}, error = function(e) {
  stop("Failed to process men's data: ", e$message)
})

cat("\n=== PROCESSING LADIES DATA ===\n")
tryCatch({
  L_processed <- process_chrono_data(L_chrono, "Ladies")
}, error = function(e) {
  stop("Failed to process ladies data: ", e$message)
})

# Cross-validation between datasets
cat("\n=== CROSS-DATASET VALIDATION ===\n")

# Compare season ranges
men_seasons <- sort(unique(M_processed$Season))
ladies_seasons <- sort(unique(L_processed$Season))

cat("Men's seasons:", paste(range(men_seasons), collapse = " - "), "(", length(men_seasons), "seasons )\n")
cat("Ladies seasons:", paste(range(ladies_seasons), collapse = " - "), "(", length(ladies_seasons), "seasons )\n")

# Check for season overlap
common_seasons <- intersect(men_seasons, ladies_seasons)
cat("Common seasons:", length(common_seasons), "\n")

if (length(common_seasons) == 0) {
  warning("No common seasons between men's and ladies data")
}

# Compare event distributions
men_events <- table(M_processed$Event)
ladies_events <- table(L_processed$Event)

cat("\nEvent distribution comparison:\n")
all_events <- sort(unique(c(names(men_events), names(ladies_events))))

for (event in all_events) {
  men_count <- ifelse(event %in% names(men_events), men_events[event], 0)
  ladies_count <- ifelse(event %in% names(ladies_events), ladies_events[event], 0)
  cat(sprintf("  %s: Men %d, Ladies %d\n", event, men_count, ladies_count))
}

cat("\n=== DATA PROCESSING COMPLETE ===\n")
cat(sprintf("Final dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_processed), nrow(L_processed)))

# Sample specific skiers for validation
cat("\n--- Sample Skier Data ---\n")

# Check if Klaebo exists in men's data
klaebo_data <- M_processed %>% filter(Skier == "Johannes Høsflot Klæbo")
if (nrow(klaebo_data) > 0) {
  cat("Sample: Johannes Høsflot Klæbo data found -", nrow(klaebo_data), "rows\n")
  cat("Seasons:", paste(sort(unique(klaebo_data$Season)), collapse = ", "), "\n")
} else {
  cat("Warning: Johannes Høsflot Klæbo not found in processed data\n")
}

# Check if Diggins exists in ladies data  
diggins_data <- L_processed %>% filter(Skier == "Jessie Diggins")
if (nrow(diggins_data) > 0) {
  cat("Sample: Jessie Diggins data found -", nrow(diggins_data), "rows\n")
  cat("Seasons:", paste(sort(unique(diggins_data$Season)), collapse = ", "), "\n")
} else {
  cat("Warning: Jessie Diggins not found in processed data\n")
}
```

### ELO Data Preparation

```{r elo-prep}
cat("=== ELO DATA PREPARATION & VALIDATION ===\n")

# Function to replace NAs with first quartile within each group - with validation
replace_na_with_quartile <- function(x, var_name = "Unknown") {
  if (length(x) == 0) {
    warning(sprintf("Empty vector passed to replace_na_with_quartile for %s", var_name))
    return(x)
  }
  
  # Count NAs before replacement
  na_count_before <- sum(is.na(x))
  
  # Calculate quartile (handle all-NA case)
  if (all(is.na(x))) {
    warning(sprintf("All values are NA for %s - cannot calculate quartile", var_name))
    return(x)
  }
  
  quartile_1 <- quantile(x, 0.25, na.rm = TRUE)
  
  # Validate quartile calculation
  if (is.na(quartile_1) || !is.finite(quartile_1)) {
    warning(sprintf("Invalid quartile calculated for %s: %s", var_name, quartile_1))
    return(x)
  }
  
  result <- ifelse(is.na(x), quartile_1, x)
  na_count_after <- sum(is.na(result))
  
  if (na_count_before > 0) {
    cat(sprintf("  %s: Replaced %d NAs with Q1 = %.3f (remaining NAs: %d)\n", 
                var_name, na_count_before - na_count_after, quartile_1, na_count_after))
  }
  
  return(result)
}

# Function to prepare ELO data for modeling - with comprehensive validation
prepare_elo_data <- function(processed_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Preparing ELO Data for %s ---\n", data_name))
  
  # Input validation
  if (nrow(processed_df) == 0) {
    stop(sprintf("%s processed dataset is empty", data_name))
  }
  
  original_rows <- nrow(processed_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Check for offseason data
  offseason_count <- sum(processed_df$Event == "Offseason", na.rm = TRUE)
  cat(sprintf("Offseason events available: %d\n", offseason_count))
  
  if (offseason_count == 0) {
    stop(sprintf("%s: No offseason data found for ELO preparation", data_name))
  }
  
  # Check for required ELO columns before processing
  required_elo_cols <- c("Pelo", "Sprint_Pelo", "Distance_Pelo", "Freestyle_Pelo", "Classic_Pelo", 
                         "Sprint_C_Pelo", "Sprint_F_Pelo", "Distance_F_Pelo", "Distance_C_Pelo")
  
  available_elo_cols <- intersect(required_elo_cols, names(processed_df))
  missing_elo_cols <- setdiff(required_elo_cols, names(processed_df))
  
  cat(sprintf("Available ELO columns: %d/%d\n", length(available_elo_cols), length(required_elo_cols)))
  if (length(missing_elo_cols) > 0) {
    cat("Missing ELO columns:", paste(missing_elo_cols, collapse = ", "), "\n")
    warning(sprintf("%s: Missing some ELO columns - proceeding with available columns", data_name))
  }
  
  # Filter for offseason data and create previous season ELO values
  cat("Filtering for offseason data and creating lag features...\n")
  
  elo_df <- processed_df %>%
    filter(Event == "Offseason") %>%
    arrange(ID, Season)
  
  filtered_rows <- nrow(elo_df)
  cat(sprintf("After offseason filter: %d rows (%.1f%% of input)\n", 
              filtered_rows, 100 * filtered_rows / original_rows))
  
  if (filtered_rows == 0) {
    stop(sprintf("%s: No rows remaining after offseason filtering", data_name))
  }
  
  # Create lag features with validation
  cat("Creating lag features...\n")
  
  elo_df <- elo_df %>%
    group_by(ID) %>%
    mutate(
      Prev_Pelo = if("Pelo" %in% names(.)) lag(Pelo) else NA_real_,
      Prev_Sprint = if("Sprint_Pelo" %in% names(.)) lag(Sprint_Pelo) else NA_real_,
      Prev_Sprint_C = if("Sprint_C_Pelo" %in% names(.)) lag(Sprint_C_Pelo) else NA_real_,
      Prev_Sprint_F = if("Sprint_F_Pelo" %in% names(.)) lag(Sprint_F_Pelo) else NA_real_,
      Prev_Distance = if("Distance_Pelo" %in% names(.)) lag(Distance_Pelo) else NA_real_,
      Prev_Distance_F = if("Distance_F_Pelo" %in% names(.)) lag(Distance_F_Pelo) else NA_real_,
      Prev_Distance_C = if("Distance_C_Pelo" %in% names(.)) lag(Distance_C_Pelo) else NA_real_,
      Prev_F = if("Freestyle_Pelo" %in% names(.)) lag(Freestyle_Pelo) else NA_real_,
      Prev_C = if("Classic_Pelo" %in% names(.)) lag(Classic_Pelo) else NA_real_,
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
    ) %>%
    ungroup()
  
  # Validate lag feature creation
  lag_features <- paste0("Prev_", c("Pelo", "Sprint", "Sprint_C", "Sprint_F", "Distance", 
                                    "Distance_F", "Distance_C", "F", "C", "Pct_of_Max_Points"))
  
  created_lag_features <- intersect(lag_features, names(elo_df))
  cat(sprintf("Created lag features: %d/%d\n", length(created_lag_features), length(lag_features)))
  
  # Apply season filter
  cat("Applying season filter (> 2015)...\n")
  before_season_filter <- nrow(elo_df)
  
  elo_df <- elo_df %>%
    filter(Season > 2015)
  
  after_season_filter <- nrow(elo_df)
  cat(sprintf("After season filter: %d rows (removed %d rows from ≤2015)\n", 
              after_season_filter, before_season_filter - after_season_filter))
  
  if (after_season_filter == 0) {
    stop(sprintf("%s: No rows remaining after season filtering (>2015)", data_name))
  }
  
  # Validate season range
  season_range <- range(elo_df$Season, na.rm = TRUE)
  cat(sprintf("Final season range: %.0f - %.0f\n", season_range[1], season_range[2]))
  
  # Handle missing values by replacing with quartiles within each season
  cat("\n--- Missing Value Treatment ---\n")
  
  # Count NAs before treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_before <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_before) > 0) {
    cat("NAs before treatment:\n")
    print(na_summary_before)
  } else {
    cat("No NAs found in lag features\n")
  }
  
  # Apply quartile replacement by season
  cat("Applying quartile replacement by season...\n")
  
  elo_df <- elo_df %>%
    group_by(Season) %>%
    mutate(
      Prev_Distance = if("Prev_Distance" %in% names(.)) replace_na_with_quartile(Prev_Distance, "Prev_Distance") else Prev_Distance,
      Prev_Distance_C = if("Prev_Distance_C" %in% names(.)) replace_na_with_quartile(Prev_Distance_C, "Prev_Distance_C") else Prev_Distance_C,
      Prev_Distance_F = if("Prev_Distance_F" %in% names(.)) replace_na_with_quartile(Prev_Distance_F, "Prev_Distance_F") else Prev_Distance_F,
      Prev_Pelo = if("Prev_Pelo" %in% names(.)) replace_na_with_quartile(Prev_Pelo, "Prev_Pelo") else Prev_Pelo,
      Prev_Sprint = if("Prev_Sprint" %in% names(.)) replace_na_with_quartile(Prev_Sprint, "Prev_Sprint") else Prev_Sprint,
      Prev_Sprint_C = if("Prev_Sprint_C" %in% names(.)) replace_na_with_quartile(Prev_Sprint_C, "Prev_Sprint_C") else Prev_Sprint_C,
      Prev_Sprint_F = if("Prev_Sprint_F" %in% names(.)) replace_na_with_quartile(Prev_Sprint_F, "Prev_Sprint_F") else Prev_Sprint_F,
      Prev_F = if("Prev_F" %in% names(.)) replace_na_with_quartile(Prev_F, "Prev_F") else Prev_F,
      Prev_C = if("Prev_C" %in% names(.)) replace_na_with_quartile(Prev_C, "Prev_C") else Prev_C,
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate missing value treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_after <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_after) > 0) {
    cat("Remaining NAs after treatment:\n")
    print(na_summary_after)
    warning(sprintf("%s: Some NAs remain after quartile replacement", data_name))
  } else {
    cat("✓ All NAs successfully treated\n")
  }
  
  # Final validation checks
  cat("\n--- Final Validation ---\n")
  
  # Check for infinite values
  numeric_cols <- select_if(elo_df, is.numeric) %>% names()
  if (length(numeric_cols) > 0) {
    inf_check <- elo_df[numeric_cols] %>%
      summarise_all(~ sum(!is.finite(.))) %>%
      gather(variable, inf_count) %>%
      filter(inf_count > 0)
  } else {
    inf_check <- data.frame(variable = character(0), inf_count = numeric(0))
  }
  
  if (nrow(inf_check) > 0) {
    cat("Infinite values found:\n")
    print(inf_check)
    warning(sprintf("%s: Contains infinite values", data_name))
  } else {
    cat("✓ No infinite values detected\n")
  }
  
  # Validate key relationships
  if ("Age" %in% names(elo_df)) {
    age_issues <- elo_df %>%
      filter(Age < 15 | Age > 50) %>%
      nrow()
    
    if (age_issues > 0) {
      warning(sprintf("%s: %d rows with unusual ages (<15 or >50)", data_name, age_issues))
    }
    
    cat(sprintf("Age range: %.0f - %.0f\n", min(elo_df$Age, na.rm = TRUE), max(elo_df$Age, na.rm = TRUE)))
  }
  
  # Summary statistics
  cat(sprintf("✓ ELO preparation complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(elo_df), 100 * nrow(elo_df) / original_rows))
  cat(sprintf("Unique skiers: %d\n", length(unique(elo_df$Skier))))
  cat(sprintf("Seasons: %d (%s)\n", 
              length(unique(elo_df$Season)), paste(sort(unique(elo_df$Season)), collapse = ", ")))
  
  return(elo_df)
}

# Prepare ELO data for both men and ladies with comprehensive validation
cat("\n=== PREPARING MEN'S ELO DATA ===\n")
tryCatch({
  M_elo <- prepare_elo_data(M_processed, "Men's")
}, error = function(e) {
  stop("Failed to prepare men's ELO data: ", e$message)
})

cat("\n=== PREPARING LADIES ELO DATA ===\n")
tryCatch({
  L_elo <- prepare_elo_data(L_processed, "Ladies")
}, error = function(e) {
  stop("Failed to prepare ladies ELO data: ", e$message)
})

# Cross-validation between ELO datasets
cat("\n=== ELO CROSS-DATASET VALIDATION ===\n")

# Compare available seasons
men_elo_seasons <- sort(unique(M_elo$Season))
ladies_elo_seasons <- sort(unique(L_elo$Season))

cat("Men's ELO seasons:", paste(range(men_elo_seasons), collapse = " - "), 
    "(", length(men_elo_seasons), "seasons )\n")
cat("Ladies ELO seasons:", paste(range(ladies_elo_seasons), collapse = " - "), 
    "(", length(ladies_elo_seasons), "seasons )\n")

common_elo_seasons <- intersect(men_elo_seasons, ladies_elo_seasons)
cat("Common ELO seasons:", length(common_elo_seasons), "\n")

# Compare column availability
men_elo_cols <- names(M_elo)
ladies_elo_cols <- names(L_elo)
common_cols <- intersect(men_elo_cols, ladies_elo_cols)

cat(sprintf("Column comparison: Men %d, Ladies %d, Common %d\n", 
            length(men_elo_cols), length(ladies_elo_cols), length(common_cols)))

# Identify unique columns
men_only_cols <- setdiff(men_elo_cols, ladies_elo_cols)
ladies_only_cols <- setdiff(ladies_elo_cols, men_elo_cols)

if (length(men_only_cols) > 0) {
  cat("Men-only columns:", paste(men_only_cols, collapse = ", "), "\n")
}
if (length(ladies_only_cols) > 0) {
  cat("Ladies-only columns:", paste(ladies_only_cols, collapse = ", "), "\n")
}

# Validate key modeling variables exist
key_modeling_vars <- c("Skier", "Season", "Age", "Pct_of_Max_Points", "Prev_Pelo", "Prev_Distance", "Prev_Sprint")
men_key_vars <- intersect(key_modeling_vars, names(M_elo))
ladies_key_vars <- intersect(key_modeling_vars, names(L_elo))

cat("Men's key variables:", paste(men_key_vars, collapse = ", "), "\n")
cat("Ladies key variables:", paste(ladies_key_vars, collapse = ", "), "\n")

if (length(men_key_vars) < length(key_modeling_vars)) {
  warning("Men's dataset missing some key modeling variables")
}
if (length(ladies_key_vars) < length(key_modeling_vars)) {
  warning("Ladies dataset missing some key modeling variables")
}

# Sample specific skiers for validation
cat("\n--- Sample ELO Skier Data ---\n")

if ("Skier" %in% names(M_elo)) {
  # Check for breakthrough candidate
  anger_data <- M_elo %>% filter(Skier == "Edvin Anger")
  if (nrow(anger_data) > 0) {
    cat("Sample: Edvin Anger ELO data found -", nrow(anger_data), "rows\n")
    cat("Seasons:", paste(sort(unique(anger_data$Season)), collapse = ", "), "\n")
    
    # Show sample data if key vars available
    if (length(men_key_vars) >= 3) {
      sample_cols <- head(men_key_vars, 5)
      available_sample_cols <- intersect(sample_cols, names(anger_data))
      if (length(available_sample_cols) > 0) {
        sample_data <- anger_data[available_sample_cols] %>% head(5)
        cat("Sample data structure:\n")
        print(sample_data)
      }
    }
  } else {
    cat("Note: Edvin Anger not found in men's ELO data\n")
  }
}

cat("\n=== ELO DATA PREPARATION COMPLETE ===\n")
cat(sprintf("Final ELO datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))
```

### Season Points Prediction Model

```{r comprehensive-feature-selection}
cat("=== COMPREHENSIVE FEATURE SELECTION & VALIDATION ===\n")

# Comprehensive Feature Selection using multiple methods with validation
# Following the methodology from previous season preview

cat("\n--- Training Data Preparation ---\n")

# Input validation for ELO datasets
if (nrow(M_elo) == 0) {
  stop("Men's ELO dataset is empty")
}
if (nrow(L_elo) == 0) {
  stop("Ladies ELO dataset is empty")
}

cat(sprintf("Input datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))

# Prepare training data - include more historical seasons to capture early breakthroughs
# Use data from 2016+ to include breakthrough seasons like Klæbo 2018
cat("Filtering training data (2016-2025, non-NA Pct_of_Max_Points)...\n")

# Check available seasons before filtering
men_seasons_available <- sort(unique(M_elo$Season))
ladies_seasons_available <- sort(unique(L_elo$Season))

cat(sprintf("Men's available seasons: %s\n", paste(range(men_seasons_available), collapse = " - ")))
cat(sprintf("Ladies available seasons: %s\n", paste(range(ladies_seasons_available), collapse = " - ")))

# Apply training filters with validation
train_men <- M_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

train_ladies <- L_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

# Validate training datasets
if (nrow(train_men) == 0) {
  stop("No men's training data remains after filtering")
}
if (nrow(train_ladies) == 0) {
  stop("No ladies training data remains after filtering")
}

cat(sprintf("Training datasets: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Check season coverage in training data
train_men_seasons <- sort(unique(train_men$Season))
train_ladies_seasons <- sort(unique(train_ladies$Season))

cat(sprintf("Men's training seasons: %s (%d seasons)\n", 
            paste(train_men_seasons, collapse = ", "), length(train_men_seasons)))
cat(sprintf("Ladies training seasons: %s (%d seasons)\n", 
            paste(train_ladies_seasons, collapse = ", "), length(train_ladies_seasons)))

if (length(train_men_seasons) < 3) {
  warning("Men's training data has fewer than 3 seasons - may affect model robustness")
}
if (length(train_ladies_seasons) < 3) {
  warning("Ladies training data has fewer than 3 seasons - may affect model robustness")
}

# Define and validate potential features
cat("\n--- Feature Validation ---\n")

all_features <- c("Prev_Pelo", "Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", 
                  "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_C", "Prev_F", 
                  "Prev_Pct_of_Max_Points", "Age")

# Check feature availability in training datasets
men_available_features <- intersect(all_features, names(train_men))
ladies_available_features <- intersect(all_features, names(train_ladies))

cat(sprintf("Men's available features: %d/%d\n", length(men_available_features), length(all_features)))
cat(sprintf("Ladies available features: %d/%d\n", length(ladies_available_features), length(all_features)))

# Report missing features
men_missing_features <- setdiff(all_features, men_available_features)
ladies_missing_features <- setdiff(all_features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some features missing from ladies training data")
}

# Update feature lists to only include available features
all_features_men <- men_available_features
all_features_ladies <- ladies_available_features

if (length(all_features_men) < 3) {
  stop("Insufficient features for men's modeling (need at least 3)")
}
if (length(all_features_ladies) < 3) {
  stop("Insufficient features for ladies modeling (need at least 3)")
}

# Validate feature data quality
cat("\n--- Feature Data Quality Checks ---\n")

# Check for missing values in features
men_feature_na_counts <- sapply(train_men[all_features_men], function(x) sum(is.na(x)))
ladies_feature_na_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(is.na(x)))

if (any(men_feature_na_counts > 0)) {
  cat("Men's features with NAs:\n")
  print(men_feature_na_counts[men_feature_na_counts > 0])
  warning("Men's training data contains missing values in features")
}
if (any(ladies_feature_na_counts > 0)) {
  cat("Ladies features with NAs:\n")
  print(ladies_feature_na_counts[ladies_feature_na_counts > 0])
  warning("Ladies training data contains missing values in features")
}

# Check for infinite values
men_feature_inf_counts <- sapply(train_men[all_features_men], function(x) sum(!is.finite(x)))
ladies_feature_inf_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(!is.finite(x)))

if (any(men_feature_inf_counts > 0)) {
  cat("Men's features with infinite values:\n")
  print(men_feature_inf_counts[men_feature_inf_counts > 0])
  warning("Men's training data contains infinite values")
}
if (any(ladies_feature_inf_counts > 0)) {
  cat("Ladies features with infinite values:\n")
  print(ladies_feature_inf_counts[ladies_feature_inf_counts > 0])
  warning("Ladies training data contains infinite values")
}

# Check target variable quality
men_target_na <- sum(is.na(train_men$Pct_of_Max_Points))
ladies_target_na <- sum(is.na(train_ladies$Pct_of_Max_Points))

if (men_target_na > 0) {
  warning(sprintf("Men's target variable has %d NA values", men_target_na))
}
if (ladies_target_na > 0) {
  warning(sprintf("Ladies target variable has %d NA values", ladies_target_na))
}

cat(sprintf("Target variable ranges: Men %.3f-%.3f, Ladies %.3f-%.3f\n",
            min(train_men$Pct_of_Max_Points, na.rm = TRUE), max(train_men$Pct_of_Max_Points, na.rm = TRUE),
            min(train_ladies$Pct_of_Max_Points, na.rm = TRUE), max(train_ladies$Pct_of_Max_Points, na.rm = TRUE)))

cat("\n=== COMPREHENSIVE FEATURE SELECTION FOR MEN ===\n")

# 1. CORRELATION ANALYSIS with validation
cat("1. CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient features for correlation analysis\n")
    cor_matrix_men <- NULL
    high_cor_men <- data.frame()
  } else {
    cor_matrix_men <- cor(train_men[all_features_men], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_men))) {
      warning("Correlation matrix contains NA values")
    }
    
    high_cor_men <- which(abs(cor_matrix_men) > 0.7 & upper.tri(cor_matrix_men), arr.ind = TRUE)
    if(nrow(high_cor_men) > 0) {
      cat("High correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_men)) {
        row_name <- rownames(cor_matrix_men)[high_cor_men[i,1]]
        col_name <- colnames(cor_matrix_men)[high_cor_men[i,2]]
        cor_val <- cor_matrix_men[high_cor_men[i,1], high_cor_men[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in correlation analysis:", e$message, "\n")
  cor_matrix_men <- NULL
  high_cor_men <- data.frame()
})

# 2. LASSO REGULARIZATION with validation
cat("2. LASSO REGULARIZATION:\n")
lasso_selected_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_men <- as.matrix(train_men[all_features_men])
  y_men <- train_men$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_men))) {
    warning("Non-finite values in feature matrix for LASSO")
  }
  if (any(!is.finite(y_men))) {
    warning("Non-finite values in target variable for LASSO")
  }
  
  cv_lasso_men <- cv.glmnet(x_men, y_men, alpha = 1, nfolds = 5)
  best_lambda_men <- cv_lasso_men$lambda.min
  lasso_coef_men <- coef(cv_lasso_men, s = best_lambda_men)
  
  lasso_selected_men <- rownames(lasso_coef_men)[lasso_coef_men[,1] != 0]
  lasso_selected_men <- lasso_selected_men[lasso_selected_men != "(Intercept)"]  # Remove intercept
  
  cat("LASSO selected features:\n")
  if (length(lasso_selected_men) > 0) {
    cat(paste("  ", lasso_selected_men, collapse = "\n"), "\n")
    cat("Coefficients:\n")
    significant_coefs <- lasso_coef_men[lasso_coef_men[,1] != 0, , drop = FALSE]
    print(round(significant_coefs, 4))
  } else {
    cat("  No features selected by LASSO\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_men))
  
}, error = function(e) {
  cat("Error in LASSO regularization:", e$message, "\n")
  lasso_selected_men <- character(0)
})

# 3. BORUTA ALGORITHM with validation
cat("3. BORUTA ALGORITHM:\n")
boruta_confirmed_men <- character(0)
boruta_tentative_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for Boruta
  boruta_data_men <- train_men[c(all_features_men, "Pct_of_Max_Points")]
  
  # Check for complete cases
  complete_cases <- complete.cases(boruta_data_men)
  n_complete <- sum(complete_cases)
  
  if (n_complete < nrow(boruta_data_men)) {
    cat(sprintf("Warning: Using %d complete cases out of %d total\n", n_complete, nrow(boruta_data_men)))
    boruta_data_men <- boruta_data_men[complete_cases, ]
  }
  
  if (nrow(boruta_data_men) < 10) {
    cat("Insufficient complete cases for Boruta analysis\n")
  } else {
    boruta_men <- Boruta(Pct_of_Max_Points ~ ., data = boruta_data_men, 
                         doTrace = 0, maxRuns = 100)
    
    boruta_confirmed_men <- names(boruta_men$finalDecision[boruta_men$finalDecision == "Confirmed"])
    boruta_tentative_men <- names(boruta_men$finalDecision[boruta_men$finalDecision == "Tentative"])
    
    cat("Boruta confirmed features:\n")
    if (length(boruta_confirmed_men) > 0) {
      cat(paste("  ", boruta_confirmed_men, collapse = "\n"), "\n")
    } else {
      cat("  None\n")
    }
    
    cat("Boruta tentative features:\n")
    if (length(boruta_tentative_men) > 0) {
      cat(paste("  ", boruta_tentative_men, collapse = "\n"), "\n")
    } else {
      cat("  None\n")
    }
  }
  
}, error = function(e) {
  cat("Error in Boruta algorithm:", e$message, "\n")
  boruta_confirmed_men <- character(0)
  boruta_tentative_men <- character(0)
})

# 4. EXHAUSTIVE SEARCH WITH AIC with validation
cat("4. EXHAUSTIVE SEARCH (AIC-based):\n")
best_aic_men <- Inf
best_features_men <- character(0)
tryCatch({
  
  max_features <- min(5, length(all_features_men))
  min_features <- max(2, min(length(all_features_men), 2))
  
  if (max_features < min_features) {
    cat("Insufficient features for exhaustive search\n")
  } else {
    cat(sprintf("Testing %d to %d feature combinations...\n", min_features, max_features))
    
    total_combinations <- 0
    successful_models <- 0
    
    for(k in min_features:max_features) {
      if (k > length(all_features_men)) break
      
      feature_combinations <- combn(all_features_men, k, simplify = FALSE)
      total_combinations <- total_combinations + length(feature_combinations)
      
      for(features in feature_combinations) {
        # Test with linear model for AIC comparison
        formula_str <- paste("Pct_of_Max_Points ~", paste(features, collapse = " + "))
        tryCatch({
          temp_model <- lm(as.formula(formula_str), data = train_men)
          model_aic <- AIC(temp_model)
          
          if(is.finite(model_aic) && model_aic < best_aic_men) {
            best_aic_men <- model_aic
            best_features_men <- features
          }
          successful_models <- successful_models + 1
        }, error = function(e) {})
      }
    }
    
    cat(sprintf("Tested %d combinations, %d successful models\n", total_combinations, successful_models))
    
    if (length(best_features_men) > 0) {
      cat(sprintf("Best AIC: %.2f\n", best_aic_men))
      cat("Best feature combination:\n")
      cat(paste("  ", best_features_men, collapse = "\n"), "\n")
    } else {
      cat("No successful feature combinations found\n")
    }
  }
  
}, error = function(e) {
  cat("Error in exhaustive search:", e$message, "\n")
  best_features_men <- character(0)
})

cat("\n=== COMPREHENSIVE FEATURE SELECTION FOR LADIES ===\n")

# Repeat for Ladies with validation
# 1. CORRELATION ANALYSIS with validation
cat("1. CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient features for correlation analysis\n")
    cor_matrix_ladies <- NULL
    high_cor_ladies <- data.frame()
  } else {
    cor_matrix_ladies <- cor(train_ladies[all_features_ladies], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_ladies))) {
      warning("Correlation matrix contains NA values")
    }
    
    high_cor_ladies <- which(abs(cor_matrix_ladies) > 0.7 & upper.tri(cor_matrix_ladies), arr.ind = TRUE)
    if(nrow(high_cor_ladies) > 0) {
      cat("High correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_ladies)) {
        row_name <- rownames(cor_matrix_ladies)[high_cor_ladies[i,1]]
        col_name <- colnames(cor_matrix_ladies)[high_cor_ladies[i,2]]
        cor_val <- cor_matrix_ladies[high_cor_ladies[i,1], high_cor_ladies[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in correlation analysis:", e$message, "\n")
  cor_matrix_ladies <- NULL
  high_cor_ladies <- data.frame()
})

# 2. LASSO REGULARIZATION with validation
cat("2. LASSO REGULARIZATION:\n")
lasso_selected_ladies <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_ladies <- as.matrix(train_ladies[all_features_ladies])
  y_ladies <- train_ladies$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_ladies))) {
    warning("Non-finite values in feature matrix for LASSO")
  }
  if (any(!is.finite(y_ladies))) {
    warning("Non-finite values in target variable for LASSO")
  }
  
  cv_lasso_ladies <- cv.glmnet(x_ladies, y_ladies, alpha = 1, nfolds = 5)
  best_lambda_ladies <- cv_lasso_ladies$lambda.min
  lasso_coef_ladies <- coef(cv_lasso_ladies, s = best_lambda_ladies)
  
  lasso_selected_ladies <- rownames(lasso_coef_ladies)[lasso_coef_ladies[,1] != 0]
  lasso_selected_ladies <- lasso_selected_ladies[lasso_selected_ladies != "(Intercept)"]  # Remove intercept
  
  cat("LASSO selected features:\n")
  if (length(lasso_selected_ladies) > 0) {
    cat(paste("  ", lasso_selected_ladies, collapse = "\n"), "\n")
    cat("Coefficients:\n")
    significant_coefs <- lasso_coef_ladies[lasso_coef_ladies[,1] != 0, , drop = FALSE]
    print(round(significant_coefs, 4))
  } else {
    cat("  No features selected by LASSO\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_ladies))
  
}, error = function(e) {
  cat("Error in LASSO regularization:", e$message, "\n")
  lasso_selected_ladies <- character(0)
})

# 3. BORUTA ALGORITHM with validation
cat("3. BORUTA ALGORITHM:\n")
boruta_confirmed_ladies <- character(0)
boruta_tentative_ladies <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for Boruta
  boruta_data_ladies <- train_ladies[c(all_features_ladies, "Pct_of_Max_Points")]
  
  # Check for complete cases
  complete_cases <- complete.cases(boruta_data_ladies)
  n_complete <- sum(complete_cases)
  
  if (n_complete < nrow(boruta_data_ladies)) {
    cat(sprintf("Warning: Using %d complete cases out of %d total\n", n_complete, nrow(boruta_data_ladies)))
    boruta_data_ladies <- boruta_data_ladies[complete_cases, ]
  }
  
  if (nrow(boruta_data_ladies) < 10) {
    cat("Insufficient complete cases for Boruta analysis\n")
  } else {
    boruta_ladies <- Boruta(Pct_of_Max_Points ~ ., data = boruta_data_ladies, 
                           doTrace = 0, maxRuns = 100)
    
    boruta_confirmed_ladies <- names(boruta_ladies$finalDecision[boruta_ladies$finalDecision == "Confirmed"])
    boruta_tentative_ladies <- names(boruta_ladies$finalDecision[boruta_ladies$finalDecision == "Tentative"])
    
    cat("Boruta confirmed features:\n")
    if (length(boruta_confirmed_ladies) > 0) {
      cat(paste("  ", boruta_confirmed_ladies, collapse = "\n"), "\n")
    } else {
      cat("  None\n")
    }
    
    cat("Boruta tentative features:\n")
    if (length(boruta_tentative_ladies) > 0) {
      cat(paste("  ", boruta_tentative_ladies, collapse = "\n"), "\n")
    } else {
      cat("  None\n")
    }
  }
  
}, error = function(e) {
  cat("Error in Boruta algorithm:", e$message, "\n")
  boruta_confirmed_ladies <- character(0)
  boruta_tentative_ladies <- character(0)
})

# 4. EXHAUSTIVE SEARCH WITH AIC with validation
cat("4. EXHAUSTIVE SEARCH (AIC-based):\n")
best_aic_ladies <- Inf
best_features_ladies <- character(0)
tryCatch({
  
  max_features <- min(5, length(all_features_ladies))
  min_features <- max(2, min(length(all_features_ladies), 2))
  
  if (max_features < min_features) {
    cat("Insufficient features for exhaustive search\n")
  } else {
    cat(sprintf("Testing %d to %d feature combinations...\n", min_features, max_features))
    
    total_combinations <- 0
    successful_models <- 0
    
    for(k in min_features:max_features) {
      if (k > length(all_features_ladies)) break
      
      feature_combinations <- combn(all_features_ladies, k, simplify = FALSE)
      total_combinations <- total_combinations + length(feature_combinations)
      
      for(features in feature_combinations) {
        formula_str <- paste("Pct_of_Max_Points ~", paste(features, collapse = " + "))
        tryCatch({
          temp_model <- lm(as.formula(formula_str), data = train_ladies)
          model_aic <- AIC(temp_model)
          
          if(is.finite(model_aic) && model_aic < best_aic_ladies) {
            best_aic_ladies <- model_aic
            best_features_ladies <- features
          }
          successful_models <- successful_models + 1
        }, error = function(e) {})
      }
    }
    
    cat(sprintf("Tested %d combinations, %d successful models\n", total_combinations, successful_models))
    
    if (length(best_features_ladies) > 0) {
      cat(sprintf("Best AIC: %.2f\n", best_aic_ladies))
      cat("Best feature combination:\n")
      cat(paste("  ", best_features_ladies, collapse = "\n"), "\n")
    } else {
      cat("No successful feature combinations found\n")
    }
  }
  
}, error = function(e) {
  cat("Error in exhaustive search:", e$message, "\n")
  best_features_ladies <- character(0)
})

# FEATURE SELECTION CONSENSUS with validation
cat("\n=== FEATURE SELECTION CONSENSUS ===\n")

# Compile results from all methods with validation
all_methods_men <- list(
  LASSO = lasso_selected_men,
  Boruta_Confirmed = boruta_confirmed_men,
  Boruta_Tentative = boruta_tentative_men,
  AIC_Best = best_features_men
)

all_methods_ladies <- list(
  LASSO = lasso_selected_ladies,
  Boruta_Confirmed = boruta_confirmed_ladies,
  Boruta_Tentative = boruta_tentative_ladies,
  AIC_Best = best_features_ladies
)

# Validate method results
cat("Method results summary:\n")
cat("Men:\n")
for (method_name in names(all_methods_men)) {
  features <- all_methods_men[[method_name]]
  if (length(features) > 0) {
    cat(sprintf("  %s: %d features (%s)\n", method_name, length(features), paste(features, collapse = ", ")))
  } else {
    cat(sprintf("  %s: No features selected\n", method_name))
  }
}

cat("Ladies:\n")
for (method_name in names(all_methods_ladies)) {
  features <- all_methods_ladies[[method_name]]
  if (length(features) > 0) {
    cat(sprintf("  %s: %d features (%s)\n", method_name, length(features), paste(features, collapse = ", ")))
  } else {
    cat(sprintf("  %s: No features selected\n", method_name))
  }
}

# Find consensus features (appearing in multiple methods)
cat("\n--- Consensus Analysis ---\n")

# Handle empty method results
men_all_features <- unlist(all_methods_men)
ladies_all_features <- unlist(all_methods_ladies)

if (length(men_all_features) > 0) {
  consensus_men <- table(men_all_features)
  cat("Men's feature consensus (count across methods):\n")
  consensus_sorted_men <- sort(consensus_men, decreasing = TRUE)
  for (i in 1:length(consensus_sorted_men)) {
    cat(sprintf("  %s: %d methods\n", names(consensus_sorted_men)[i], consensus_sorted_men[i]))
  }
} else {
  cat("No features selected by any method for men\n")
  consensus_men <- table(character(0))
}

if (length(ladies_all_features) > 0) {
  consensus_ladies <- table(ladies_all_features)
  cat("Ladies feature consensus (count across methods):\n")
  consensus_sorted_ladies <- sort(consensus_ladies, decreasing = TRUE)
  for (i in 1:length(consensus_sorted_ladies)) {
    cat(sprintf("  %s: %d methods\n", names(consensus_sorted_ladies)[i], consensus_sorted_ladies[i]))
  }
} else {
  cat("No features selected by any method for ladies\n")
  consensus_ladies <- table(character(0))
}

# Select final features based on consensus
cat("\n--- Final Feature Selection ---\n")

# Primary selection: features appearing in 2+ methods
final_features_men <- names(consensus_men[consensus_men >= 2])
final_features_ladies <- names(consensus_ladies[consensus_ladies >= 2])

cat(sprintf("Men's consensus features (≥2 methods): %d features\n", length(final_features_men)))
if (length(final_features_men) > 0) {
  cat(paste("  ", final_features_men, collapse = "\n"), "\n")
}

cat(sprintf("Ladies consensus features (≥2 methods): %d features\n", length(final_features_ladies)))
if (length(final_features_ladies) > 0) {
  cat(paste("  ", final_features_ladies, collapse = "\n"), "\n")
}

# Fallback strategies with validation
if(length(final_features_men) == 0) {
  cat("No men's consensus features found, applying fallback strategy...\n")
  
  # Try single-method features first
  if (length(best_features_men) > 0) {
    final_features_men <- best_features_men
    cat("Using AIC best features for men\n")
  } else if (length(lasso_selected_men) > 0) {
    final_features_men <- lasso_selected_men
    cat("Using LASSO features for men\n")
  } else if (length(boruta_confirmed_men) > 0) {
    final_features_men <- boruta_confirmed_men
    cat("Using Boruta confirmed features for men\n")
  } else {
    # Ultimate fallback to core features
    core_features_men <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Distance", "Prev_Sprint"), all_features_men)
    if (length(core_features_men) > 0) {
      final_features_men <- core_features_men
      cat("Using core features for men\n")
    } else {
      # Last resort - use first 3 available features
      final_features_men <- head(all_features_men, min(3, length(all_features_men)))
      cat("Using first available features for men\n")
    }
  }
}

if(length(final_features_ladies) == 0) {
  cat("No ladies consensus features found, applying fallback strategy...\n")
  
  # Try single-method features first
  if (length(best_features_ladies) > 0) {
    final_features_ladies <- best_features_ladies
    cat("Using AIC best features for ladies\n")
  } else if (length(lasso_selected_ladies) > 0) {
    final_features_ladies <- lasso_selected_ladies
    cat("Using LASSO features for ladies\n")
  } else if (length(boruta_confirmed_ladies) > 0) {
    final_features_ladies <- boruta_confirmed_ladies
    cat("Using Boruta confirmed features for ladies\n")
  } else {
    # Ultimate fallback to core features
    core_features_ladies <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Distance", "Prev_Sprint"), all_features_ladies)
    if (length(core_features_ladies) > 0) {
      final_features_ladies <- core_features_ladies
      cat("Using core features for ladies\n")
    } else {
      # Last resort - use first 3 available features
      final_features_ladies <- head(all_features_ladies, min(3, length(all_features_ladies)))
      cat("Using first available features for ladies\n")
    }
  }
}

# Final validation
if (length(final_features_men) == 0) {
  stop("No final features selected for men - cannot proceed with modeling")
}
if (length(final_features_ladies) == 0) {
  stop("No final features selected for ladies - cannot proceed with modeling")
}

cat("\n=== FINAL SELECTED FEATURES ===\n")
cat("Men:\n")
cat(paste("  ", final_features_men, collapse = "\n"), "\n")
cat("Ladies:\n")
cat(paste("  ", final_features_ladies, collapse = "\n"), "\n")

# Validate final features are in training data
men_feature_check <- all(final_features_men %in% names(train_men))
ladies_feature_check <- all(final_features_ladies %in% names(train_ladies))

if (!men_feature_check) {
  missing_men_features <- setdiff(final_features_men, names(train_men))
  warning(sprintf("Some final men's features not in training data: %s", paste(missing_men_features, collapse = ", ")))
}
if (!ladies_feature_check) {
  missing_ladies_features <- setdiff(final_features_ladies, names(train_ladies))
  warning(sprintf("Some final ladies features not in training data: %s", paste(missing_ladies_features, collapse = ", ")))
}

cat(sprintf("\nFeature selection complete: Men %d features, Ladies %d features\n", 
            length(final_features_men), length(final_features_ladies)))
```

### GAM Model Building

```{r gam-model}
cat("=== GAM MODEL BUILDING & VALIDATION ===\n")

# Build GAM models using consensus-selected features with comprehensive validation

cat("\n--- GAM Model Construction ---\n")

# Validate inputs for GAM model building
if (!exists("final_features_men") || !exists("final_features_ladies")) {
  stop("Final features not defined - ensure feature selection completed successfully")
}

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure data preparation completed successfully")
}

cat(sprintf("Input validation: Men %d features, Ladies %d features\n", 
            length(final_features_men), length(final_features_ladies)))

cat(sprintf("Training data: Men %d rows, Ladies %d rows\n", 
            nrow(train_men), nrow(train_ladies)))

# Build GAM formula for Men using validated features
cat("\n--- Men's GAM Model ---\n")
men_gam_model <- NULL
tryCatch({
  if(length(final_features_men) > 0) {
    # Validate features exist in training data
    missing_features_men <- setdiff(final_features_men, names(train_men))
    if (length(missing_features_men) > 0) {
      cat("Warning: Missing features in men's training data:", paste(missing_features_men, collapse = ", "), "\n")
      final_features_men <- intersect(final_features_men, names(train_men))
    }
    
    if (length(final_features_men) > 0) {
      smooth_terms_men <- paste("s(", final_features_men, ")", collapse = " + ")
      gam_formula_men <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_men))
      cat("Men's GAM Formula (Validated Features):\n")
      print(gam_formula_men)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_men) * min_obs_per_feature
      if (nrow(train_men) < required_obs) {
        warning(sprintf("Limited observations for men's GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_men), length(final_features_men), required_obs))
      }
      
      # Build GAM with error handling
      men_gam_model <- gam(gam_formula_men, data = train_men)
      cat(sprintf("✓ Men's GAM model built successfully with %d features\n", length(final_features_men)))
      
    } else {
      cat("No valid features for men's GAM - using fallback\n")
      stop("No valid features available")
    }
  } else {
    cat("No features selected for men - using fallback\n")
    stop("No features available")
  }
}, error = function(e) {
  cat("Error building men's GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_men <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Distance", "Prev_Sprint"), names(train_men))
  if (length(core_features_men) >= 2) {
    fallback_formula_men <- paste("Pct_of_Max_Points ~", paste("s(", core_features_men, ")", collapse = " + "))
    men_gam_model <- gam(as.formula(fallback_formula_men), data = train_men)
    final_features_men <- core_features_men
    cat("✓ Men's GAM fallback model built with core features\n")
  } else {
    stop("Cannot build men's GAM model - insufficient core features available")
  }
})

# Build GAM formula for Ladies using validated features
cat("\n--- Ladies GAM Model ---\n")
ladies_gam_model <- NULL
tryCatch({
  if(length(final_features_ladies) > 0) {
    # Validate features exist in training data
    missing_features_ladies <- setdiff(final_features_ladies, names(train_ladies))
    if (length(missing_features_ladies) > 0) {
      cat("Warning: Missing features in ladies training data:", paste(missing_features_ladies, collapse = ", "), "\n")
      final_features_ladies <- intersect(final_features_ladies, names(train_ladies))
    }
    
    if (length(final_features_ladies) > 0) {
      smooth_terms_ladies <- paste("s(", final_features_ladies, ")", collapse = " + ")
      gam_formula_ladies <- as.formula(paste("Pct_of_Max_Points ~", smooth_terms_ladies))
      cat("Ladies GAM Formula (Validated Features):\n")
      print(gam_formula_ladies)
      
      # Check for sufficient data points per feature
      min_obs_per_feature <- 10
      required_obs <- length(final_features_ladies) * min_obs_per_feature
      if (nrow(train_ladies) < required_obs) {
        warning(sprintf("Limited observations for ladies GAM (%d obs, %d features, recommend %d+ obs)", 
                       nrow(train_ladies), length(final_features_ladies), required_obs))
      }
      
      # Build GAM with error handling
      ladies_gam_model <- gam(gam_formula_ladies, data = train_ladies)
      cat(sprintf("✓ Ladies GAM model built successfully with %d features\n", length(final_features_ladies)))
      
    } else {
      cat("No valid features for ladies GAM - using fallback\n")
      stop("No valid features available")
    }
  } else {
    cat("No features selected for ladies - using fallback\n")
    stop("No features available")
  }
}, error = function(e) {
  cat("Error building ladies GAM model:", e$message, "\n")
  cat("Attempting fallback to core features...\n")
  
  # Fallback to proven core features
  core_features_ladies <- intersect(c("Prev_Pct_of_Max_Points", "Prev_Distance", "Prev_Sprint"), names(train_ladies))
  if (length(core_features_ladies) >= 2) {
    fallback_formula_ladies <- paste("Pct_of_Max_Points ~", paste("s(", core_features_ladies, ")", collapse = " + "))
    ladies_gam_model <- gam(as.formula(fallback_formula_ladies), data = train_ladies)
    final_features_ladies <- core_features_ladies
    cat("✓ Ladies GAM fallback model built with core features\n")
  } else {
    stop("Cannot build ladies GAM model - insufficient core features available")
  }
})

# Validate model objects were created
if (is.null(men_gam_model)) {
  stop("Failed to build men's GAM model")
}
if (is.null(ladies_gam_model)) {
  stop("Failed to build ladies GAM model")
}

# Model performance evaluation with validation
cat("\n=== GAM MODEL PERFORMANCE EVALUATION ===\n")

# Men's GAM Model Performance
cat("--- Men's GAM Model Performance ---\n")
tryCatch({
  men_summary <- summary(men_gam_model)
  
  # Validate summary components exist
  if (is.null(men_summary$dev.expl)) {
    warning("Men's GAM deviance explained not available")
    men_dev_expl <- NA
  } else {
    men_dev_expl <- men_summary$dev.expl * 100
  }
  
  if (is.null(men_summary$r.sq)) {
    warning("Men's GAM R-squared not available")
    men_r_sq <- NA
  } else {
    men_r_sq <- men_summary$r.sq
  }
  
  if (is.null(men_gam_model$gcv.ubre)) {
    warning("Men's GAM GCV score not available")
    men_gcv <- NA
  } else {
    men_gcv <- men_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", men_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", men_r_sq))
  cat(sprintf("GCV Score: %.4f\n", men_gcv))
  
  # Validate model performance
  if (!is.na(men_dev_expl) && men_dev_expl < 10) {
    warning("Men's GAM has very low deviance explained (<10%)")
  }
  if (!is.na(men_r_sq) && men_r_sq < 0.1) {
    warning("Men's GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(men_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(men_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating men's GAM performance:", e$message, "\n")
})

# Ladies GAM Model Performance
cat("\n--- Ladies GAM Model Performance ---\n")
tryCatch({
  ladies_summary <- summary(ladies_gam_model)
  
  # Validate summary components exist
  if (is.null(ladies_summary$dev.expl)) {
    warning("Ladies GAM deviance explained not available")
    ladies_dev_expl <- NA
  } else {
    ladies_dev_expl <- ladies_summary$dev.expl * 100
  }
  
  if (is.null(ladies_summary$r.sq)) {
    warning("Ladies GAM R-squared not available")
    ladies_r_sq <- NA
  } else {
    ladies_r_sq <- ladies_summary$r.sq
  }
  
  if (is.null(ladies_gam_model$gcv.ubre)) {
    warning("Ladies GAM GCV score not available")
    ladies_gcv <- NA
  } else {
    ladies_gcv <- ladies_gam_model$gcv.ubre
  }
  
  cat(sprintf("Deviance Explained: %.2f%%\n", ladies_dev_expl))
  cat(sprintf("Adjusted R-squared: %.3f\n", ladies_r_sq))
  cat(sprintf("GCV Score: %.4f\n", ladies_gcv))
  
  # Validate model performance
  if (!is.na(ladies_dev_expl) && ladies_dev_expl < 10) {
    warning("Ladies GAM has very low deviance explained (<10%)")
  }
  if (!is.na(ladies_r_sq) && ladies_r_sq < 0.1) {
    warning("Ladies GAM has very low R-squared (<0.1)")
  }
  
  # Model fit statistics
  cat(sprintf("Observations: %d\n", nrow(ladies_gam_model$model)))
  cat(sprintf("Effective degrees of freedom: %.1f\n", sum(ladies_gam_model$edf)))
  
}, error = function(e) {
  cat("Error evaluating ladies GAM performance:", e$message, "\n")
})

# Feature importance from GAM (edf values) with validation
cat("\n--- Feature Importance Analysis ---\n")

# Men's Feature Importance
cat("Men's GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(men_summary$s.table) && nrow(men_summary$s.table) > 0) {
    men_edf <- men_summary$s.table[,"edf"]
    names(men_edf) <- rownames(men_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(men_edf))) {
      warning("Some men's GAM EDF values are NA")
      men_edf <- men_edf[!is.na(men_edf)]
    }
    
    if (length(men_edf) > 0) {
      edf_sorted <- sort(men_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features (high EDF suggests non-linear relationship)
      high_edf_features <- names(men_edf[men_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for men's model\n")
    }
  } else {
    cat("No smooth terms in men's GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing men's feature importance:", e$message, "\n")
})

# Ladies Feature Importance
cat("Ladies GAM Feature Importance (Effective Degrees of Freedom):\n")
tryCatch({
  if (!is.null(ladies_summary$s.table) && nrow(ladies_summary$s.table) > 0) {
    ladies_edf <- ladies_summary$s.table[,"edf"]
    names(ladies_edf) <- rownames(ladies_summary$s.table)
    
    # Validate EDF values
    if (any(is.na(ladies_edf))) {
      warning("Some ladies GAM EDF values are NA")
      ladies_edf <- ladies_edf[!is.na(ladies_edf)]
    }
    
    if (length(ladies_edf) > 0) {
      edf_sorted <- sort(ladies_edf, decreasing = TRUE)
      for (i in 1:length(edf_sorted)) {
        cat(sprintf("  %s: %.3f\n", names(edf_sorted)[i], edf_sorted[i]))
      }
      
      # Identify most complex features
      high_edf_features <- names(ladies_edf[ladies_edf > 3])
      if (length(high_edf_features) > 0) {
        cat("Features with non-linear relationships (EDF > 3):", paste(high_edf_features, collapse = ", "), "\n")
      }
    } else {
      cat("No valid EDF values for ladies model\n")
    }
  } else {
    cat("No smooth terms in ladies GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing ladies feature importance:", e$message, "\n")
})

# Model diagnostics with validation
cat("\n=== GAM MODEL DIAGNOSTICS ===\n")

# Men's GAM Model Diagnostics
cat("--- Men's GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_men <- gam.check(men_gam_model, sub.caption = "Men's GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_men)) {
    # Check for model convergence issues
    if ("converged" %in% names(men_gam_model) && !men_gam_model$converged) {
      warning("Men's GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(men_summary)) {
      basis_dims <- men_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Men's GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Men's GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating men's GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})

# Ladies GAM Model Diagnostics
cat("--- Ladies GAM Model Diagnostics ---\n")
tryCatch({
  par(mfrow = c(2, 2))
  gam_check_ladies <- gam.check(ladies_gam_model, sub.caption = "Ladies GAM Diagnostics")
  
  # Extract and validate diagnostic information
  if (!is.null(gam_check_ladies)) {
    # Check for model convergence issues
    if ("converged" %in% names(ladies_gam_model) && !ladies_gam_model$converged) {
      warning("Ladies GAM model did not converge properly")
    }
    
    # Check basis dimensions
    if ("p.table" %in% names(ladies_summary)) {
      basis_dims <- ladies_summary$s.table[,"k-index"]
      low_basis <- names(basis_dims[basis_dims < 0.1])
      if (length(low_basis) > 0) {
        warning(paste("Ladies GAM features with potentially insufficient basis dimensions:", 
                     paste(low_basis, collapse = ", ")))
      }
    }
  }
  
  cat("✓ Ladies GAM diagnostic plots generated\n")
  
}, error = function(e) {
  cat("Error generating ladies GAM diagnostics:", e$message, "\n")
})

# Reset plotting parameters
par(mfrow = c(1, 1))

# Predict for 2026 season using 2025 ELO values with comprehensive validation
cat("\n=== 2026 SEASON PREDICTIONS ===\n")

# Validate prediction data availability
cat("--- Prediction Data Preparation ---\n")

# Check for 2025 ELO data
men_2025 <- M_elo %>% filter(Season == 2025)
ladies_2025 <- L_elo %>% filter(Season == 2025)

cat(sprintf("2025 prediction data: Men %d rows, Ladies %d rows\n", nrow(men_2025), nrow(ladies_2025)))

if (nrow(men_2025) == 0) {
  warning("No men's 2025 ELO data available for 2026 predictions")
}
if (nrow(ladies_2025) == 0) {
  warning("No ladies 2025 ELO data available for 2026 predictions")
}

# Men's 2026 Predictions
cat("\n--- Men's 2026 Predictions ---\n")
men_pred_data <- NULL
if(nrow(men_2025) > 0) {
  tryCatch({
    # Create prediction data with current 2025 ELO values mapped to "previous" feature names
    # This is because our model was trained to use "Prev_*" as predictors
    men_pred_data <- men_2025 %>%
      mutate(
        # Map current 2025 ELO values to previous year feature names for prediction
        Prev_Pelo = if("Pelo" %in% names(.)) Pelo else NA_real_,
        Prev_Distance = if("Distance_Pelo" %in% names(.)) Distance_Pelo else NA_real_,
        Prev_Distance_C = if("Distance_C_Pelo" %in% names(.)) Distance_C_Pelo else NA_real_,
        Prev_Distance_F = if("Distance_F_Pelo" %in% names(.)) Distance_F_Pelo else NA_real_,
        Prev_Sprint = if("Sprint_Pelo" %in% names(.)) Sprint_Pelo else NA_real_,
        Prev_Sprint_C = if("Sprint_C_Pelo" %in% names(.)) Sprint_C_Pelo else NA_real_,
        Prev_Sprint_F = if("Sprint_F_Pelo" %in% names(.)) Sprint_F_Pelo else NA_real_,
        Prev_C = if("Classic_Pelo" %in% names(.)) Classic_Pelo else NA_real_,
        Prev_F = if("Freestyle_Pelo" %in% names(.)) Freestyle_Pelo else NA_real_,
        Prev_Pct_of_Max_Points = if("Pct_of_Max_Points" %in% names(.)) Pct_of_Max_Points else NA_real_
      )
    
    # Validate prediction features are available
    required_features <- final_features_men
    available_pred_features <- intersect(required_features, names(men_pred_data))
    missing_pred_features <- setdiff(required_features, names(men_pred_data))
    
    cat(sprintf("Required features for prediction: %d\n", length(required_features)))
    cat(sprintf("Available prediction features: %d\n", length(available_pred_features)))
    
    if (length(missing_pred_features) > 0) {
      cat("Missing prediction features:", paste(missing_pred_features, collapse = ", "), "\n")
      warning("Some prediction features missing for men's 2026 predictions")
    }
    
    if (length(available_pred_features) == 0) {
      stop("No prediction features available for men's model")
    }
    
    # Check for missing values in prediction features
    pred_na_counts <- sapply(men_pred_data[required_features], function(x) sum(is.na(x)))
    if (any(pred_na_counts > 0)) {
      cat("Prediction features with missing values:\n")
      for (feat in names(pred_na_counts[pred_na_counts > 0])) {
        cat(sprintf("  %s: %d NAs\n", feat, pred_na_counts[feat]))
      }
      warning("Men's prediction data contains missing values")
    }
    
    # Generate predictions
    men_pred_data$Predicted_Pct_2026 <- predict(men_gam_model, men_pred_data)
    
    # Validate predictions
    pred_na_count <- sum(is.na(men_pred_data$Predicted_Pct_2026))
    pred_infinite_count <- sum(!is.finite(men_pred_data$Predicted_Pct_2026))
    
    if (pred_na_count > 0) {
      warning(sprintf("Men's predictions contain %d NA values", pred_na_count))
    }
    if (pred_infinite_count > 0) {
      warning(sprintf("Men's predictions contain %d infinite values", pred_infinite_count))
    }
    
    # Remove invalid predictions for display
    valid_predictions <- men_pred_data[is.finite(men_pred_data$Predicted_Pct_2026), ]
    
    if (nrow(valid_predictions) > 0) {
      cat(sprintf("Generated %d valid predictions (out of %d total)\n", 
                  nrow(valid_predictions), nrow(men_pred_data)))
      
      # Select columns dynamically based on final selected features
      display_cols <- c("Skier", "Nation", "Age")
      
      # Show current 2025 values being used as predictors
      current_features <- gsub("Prev_", "", final_features_men)
      available_features <- intersect(current_features, names(men_pred_data))
      
      if(length(available_features) > 0) {
        display_cols <- c(display_cols, available_features)
      }
      display_cols <- c(display_cols, "Predicted_Pct_2026")
      
      # Ensure all display columns exist
      display_cols <- intersect(display_cols, names(valid_predictions))
      
      if (length(display_cols) >= 2) {  # At least Skier and Predicted_Pct_2026
        men_pred_summary <- valid_predictions[display_cols] %>%
          arrange(desc(Predicted_Pct_2026)) %>%
          head(10)
        
        cat("Top 10 Men's 2026 Predictions (using 2025 ELO values):\n")
        print(men_pred_summary)
        
        # Show prediction distribution
        pred_mean <- mean(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        pred_sd <- sd(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        pred_range <- range(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        
        cat(sprintf("Men's 2026 predictions - Mean: %.4f, SD: %.4f, Range: %.4f - %.4f\n", 
                    pred_mean, pred_sd, pred_range[1], pred_range[2]))
        
        # Check for unrealistic predictions
        if (pred_mean > 1 || any(valid_predictions$Predicted_Pct_2026 > 1.5, na.rm = TRUE)) {
          warning("Some men's predictions exceed realistic bounds (>100% of max points)")
        }
        if (pred_mean < 0 || any(valid_predictions$Predicted_Pct_2026 < 0, na.rm = TRUE)) {
          warning("Some men's predictions are negative")
        }
      } else {
        cat("Insufficient columns available for prediction display\n")
      }
    } else {
      cat("No valid predictions generated for men\n")
    }
    
  }, error = function(e) {
    cat("Error generating men's 2026 predictions:", e$message, "\n")
    men_pred_data <- NULL
  })
} else {
  cat("No men's 2025 data available for predictions\n")
}

# Ladies 2026 Predictions
cat("\n--- Ladies 2026 Predictions ---\n")
ladies_pred_data <- NULL
if(nrow(ladies_2025) > 0) {
  tryCatch({
    # Create prediction data with current 2025 ELO values mapped to "previous" feature names
    ladies_pred_data <- ladies_2025 %>%
      mutate(
        # Map current 2025 ELO values to previous year feature names for prediction
        Prev_Pelo = if("Pelo" %in% names(.)) Pelo else NA_real_,
        Prev_Distance = if("Distance_Pelo" %in% names(.)) Distance_Pelo else NA_real_,
        Prev_Distance_C = if("Distance_C_Pelo" %in% names(.)) Distance_C_Pelo else NA_real_,
        Prev_Distance_F = if("Distance_F_Pelo" %in% names(.)) Distance_F_Pelo else NA_real_,
        Prev_Sprint = if("Sprint_Pelo" %in% names(.)) Sprint_Pelo else NA_real_,
        Prev_Sprint_C = if("Sprint_C_Pelo" %in% names(.)) Sprint_C_Pelo else NA_real_,
        Prev_Sprint_F = if("Sprint_F_Pelo" %in% names(.)) Sprint_F_Pelo else NA_real_,
        Prev_C = if("Classic_Pelo" %in% names(.)) Classic_Pelo else NA_real_,
        Prev_F = if("Freestyle_Pelo" %in% names(.)) Freestyle_Pelo else NA_real_,
        Prev_Pct_of_Max_Points = if("Pct_of_Max_Points" %in% names(.)) Pct_of_Max_Points else NA_real_
      )
    
    # Validate prediction features are available
    required_features <- final_features_ladies
    available_pred_features <- intersect(required_features, names(ladies_pred_data))
    missing_pred_features <- setdiff(required_features, names(ladies_pred_data))
    
    cat(sprintf("Required features for prediction: %d\n", length(required_features)))
    cat(sprintf("Available prediction features: %d\n", length(available_pred_features)))
    
    if (length(missing_pred_features) > 0) {
      cat("Missing prediction features:", paste(missing_pred_features, collapse = ", "), "\n")
      warning("Some prediction features missing for ladies 2026 predictions")
    }
    
    if (length(available_pred_features) == 0) {
      stop("No prediction features available for ladies model")
    }
    
    # Check for missing values in prediction features
    pred_na_counts <- sapply(ladies_pred_data[required_features], function(x) sum(is.na(x)))
    if (any(pred_na_counts > 0)) {
      cat("Prediction features with missing values:\n")
      for (feat in names(pred_na_counts[pred_na_counts > 0])) {
        cat(sprintf("  %s: %d NAs\n", feat, pred_na_counts[feat]))
      }
      warning("Ladies prediction data contains missing values")
    }
    
    # Generate predictions
    ladies_pred_data$Predicted_Pct_2026 <- predict(ladies_gam_model, ladies_pred_data)
    
    # Validate predictions
    pred_na_count <- sum(is.na(ladies_pred_data$Predicted_Pct_2026))
    pred_infinite_count <- sum(!is.finite(ladies_pred_data$Predicted_Pct_2026))
    
    if (pred_na_count > 0) {
      warning(sprintf("Ladies predictions contain %d NA values", pred_na_count))
    }
    if (pred_infinite_count > 0) {
      warning(sprintf("Ladies predictions contain %d infinite values", pred_infinite_count))
    }
    
    # Remove invalid predictions for display
    valid_predictions <- ladies_pred_data[is.finite(ladies_pred_data$Predicted_Pct_2026), ]
    
    if (nrow(valid_predictions) > 0) {
      cat(sprintf("Generated %d valid predictions (out of %d total)\n", 
                  nrow(valid_predictions), nrow(ladies_pred_data)))
      
      # Select columns dynamically based on final selected features
      display_cols <- c("Skier", "Nation", "Age")
      
      # Show current 2025 values being used as predictors
      current_features <- gsub("Prev_", "", final_features_ladies)
      available_features <- intersect(current_features, names(ladies_pred_data))
      
      if(length(available_features) > 0) {
        display_cols <- c(display_cols, available_features)
      }
      display_cols <- c(display_cols, "Predicted_Pct_2026")
      
      # Ensure all display columns exist
      display_cols <- intersect(display_cols, names(valid_predictions))
      
      if (length(display_cols) >= 2) {  # At least Skier and Predicted_Pct_2026
        ladies_pred_summary <- valid_predictions[display_cols] %>%
          arrange(desc(Predicted_Pct_2026)) %>%
          head(10)
        
        cat("Top 10 Ladies 2026 Predictions (using 2025 ELO values):\n")
        print(ladies_pred_summary)
        
        # Show prediction distribution
        pred_mean <- mean(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        pred_sd <- sd(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        pred_range <- range(valid_predictions$Predicted_Pct_2026, na.rm = TRUE)
        
        cat(sprintf("Ladies 2026 predictions - Mean: %.4f, SD: %.4f, Range: %.4f - %.4f\n", 
                    pred_mean, pred_sd, pred_range[1], pred_range[2]))
        
        # Check for unrealistic predictions
        if (pred_mean > 1 || any(valid_predictions$Predicted_Pct_2026 > 1.5, na.rm = TRUE)) {
          warning("Some ladies predictions exceed realistic bounds (>100% of max points)")
        }
        if (pred_mean < 0 || any(valid_predictions$Predicted_Pct_2026 < 0, na.rm = TRUE)) {
          warning("Some ladies predictions are negative")
        }
      } else {
        cat("Insufficient columns available for prediction display\n")
      }
    } else {
      cat("No valid predictions generated for ladies\n")
    }
    
  }, error = function(e) {
    cat("Error generating ladies 2026 predictions:", e$message, "\n")
    ladies_pred_data <- NULL
  })
} else {
  cat("No ladies 2025 data available for predictions\n")
}

# Export predictions to Excel
cat("\n=== EXPORTING PREDICTIONS TO EXCEL ===\n")

tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  # Prepare Men's World Cup Predictions
  if (!is.null(men_pred_data) && nrow(men_pred_data) > 0) {
    men_worldcup <- men_pred_data %>%
      filter(!is.na(Predicted_Pct_2026), is.finite(Predicted_Pct_2026)) %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Predicted_Pct_2026) %>%
      arrange(desc(Predicted_Pct_2026)) %>%
      mutate(
        Age = round(Age, 0),
        `Percent of Max Points 2025` = round(Pct_of_Max_Points * 100, 2),
        `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2)
      ) %>%
      dplyr::select(Skier, Nation, Age, `Percent of Max Points 2025`, `Predicted Percent 2026`)
    
    cat(sprintf("Processed %d men's predictions for export\n", nrow(men_worldcup)))
  } else {
    men_worldcup <- data.frame()
    cat("No men's prediction data available for export\n")
  }
  
  # Prepare Ladies World Cup Predictions
  if (!is.null(ladies_pred_data) && nrow(ladies_pred_data) > 0) {
    ladies_worldcup <- ladies_pred_data %>%
      filter(!is.na(Predicted_Pct_2026), is.finite(Predicted_Pct_2026)) %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Predicted_Pct_2026) %>%
      arrange(desc(Predicted_Pct_2026)) %>%
      mutate(
        Age = round(Age, 0),
        `Percent of Max Points 2025` = round(Pct_of_Max_Points * 100, 2),
        `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2)
      ) %>%
      dplyr::select(Skier, Nation, Age, `Percent of Max Points 2025`, `Predicted Percent 2026`)
    
    cat(sprintf("Processed %d ladies predictions for export\n", nrow(ladies_worldcup)))
  } else {
    ladies_worldcup <- data.frame()
    cat("No ladies prediction data available for export\n")
  }
  
  # Create separate Excel files for men and ladies
  # Men's Excel file
  if (nrow(men_worldcup) > 0) {
    men_wb <- createWorkbook()
    addWorksheet(men_wb, "Men_Predictions_2026")
    writeData(men_wb, "Men_Predictions_2026", men_worldcup, startRow = 1, startCol = 1)
    
    # Style the worksheet
    addStyle(men_wb, "Men_Predictions_2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(men_worldcup))
    setColWidths(men_wb, "Men_Predictions_2026", cols = 1:ncol(men_worldcup), widths = "auto")
    
    # Save men's workbook
    men_output_file <- "excel365/Men_WorldCup_Predictions_2026.xlsx"
    saveWorkbook(men_wb, men_output_file, overwrite = TRUE)
    
    cat(sprintf("✓ Men's Excel file saved: %s\n", men_output_file))
    cat(sprintf("Men's export: %d athletes, Top predicted: %s (%.2f%%)\n", 
                nrow(men_worldcup), men_worldcup$Skier[1], men_worldcup$`Predicted Percent 2026`[1]))
  }
  
  # Ladies Excel file
  if (nrow(ladies_worldcup) > 0) {
    ladies_wb <- createWorkbook()
    addWorksheet(ladies_wb, "Ladies_Predictions_2026")
    writeData(ladies_wb, "Ladies_Predictions_2026", ladies_worldcup, startRow = 1, startCol = 1)
    
    # Style the worksheet
    addStyle(ladies_wb, "Ladies_Predictions_2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(ladies_worldcup))
    setColWidths(ladies_wb, "Ladies_Predictions_2026", cols = 1:ncol(ladies_worldcup), widths = "auto")
    
    # Save ladies workbook
    ladies_output_file <- "excel365/Ladies_WorldCup_Predictions_2026.xlsx"
    saveWorkbook(ladies_wb, ladies_output_file, overwrite = TRUE)
    
    cat(sprintf("✓ Ladies Excel file saved: %s\n", ladies_output_file))
    cat(sprintf("Ladies export: %d athletes, Top predicted: %s (%.2f%%)\n", 
                nrow(ladies_worldcup), ladies_worldcup$Skier[1], ladies_worldcup$`Predicted Percent 2026`[1]))
  }
  
  if (nrow(men_worldcup) == 0 && nrow(ladies_worldcup) == 0) {
    cat("No prediction data available for Excel export\n")
  }
  
}, error = function(e) {
  cat("Error exporting predictions to Excel:", e$message, "\n")
})

cat("\n✓ 2026 season predictions completed\n")
```

### Odds Setup and Calculations

```{r odds-setup}
cat("=== ODDS SETUP & VALIDATION ===\n")

# Validate training data availability for odds calculations
cat("\n--- Training Data Validation for Odds ---\n")

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure previous sections completed successfully")
}

if (nrow(train_men) == 0) {
  stop("Men's training data is empty")
}
if (nrow(train_ladies) == 0) {
  stop("Ladies training data is empty") 
}

cat(sprintf("Training data for odds: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Validate required columns exist
required_odds_cols <- c("Pct_of_Max_Points", "Season")
missing_men_cols <- setdiff(required_odds_cols, names(train_men))
missing_ladies_cols <- setdiff(required_odds_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop(sprintf("Men's training data missing required columns for odds: %s", paste(missing_men_cols, collapse = ", ")))
}
if (length(missing_ladies_cols) > 0) {
  stop(sprintf("Ladies training data missing required columns for odds: %s", paste(missing_ladies_cols, collapse = ", ")))
}

# Add Place column based on rankings within each season with validation
cat("\n--- Season Ranking Calculation ---\n")

tryCatch({
  df_place <- train_men %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
  
  cat(sprintf("✓ Men's place rankings calculated: %d rows\n", nrow(df_place)))
}, error = function(e) {
  stop("Failed to calculate men's place rankings: ", e$message)
})

tryCatch({
  df_place_ladies <- train_ladies %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
    
  cat(sprintf("✓ Ladies place rankings calculated: %d rows\n", nrow(df_place_ladies)))
}, error = function(e) {
  stop("Failed to calculate ladies place rankings: ", e$message)
})

# Validate Place column creation
place_na_men <- sum(is.na(df_place$Place))
place_na_ladies <- sum(is.na(df_place_ladies$Place))

if (place_na_men > 0) {
  warning(sprintf("Men's Place column has %d NA values", place_na_men))
}
if (place_na_ladies > 0) {
  warning(sprintf("Ladies Place column has %d NA values", place_na_ladies))
}

# Validate ranking ranges
men_place_range <- range(df_place$Place, na.rm = TRUE)
ladies_place_range <- range(df_place_ladies$Place, na.rm = TRUE)

cat(sprintf("Men's Place range: %d - %d\n", men_place_range[1], men_place_range[2]))
cat(sprintf("Ladies Place range: %d - %d\n", ladies_place_range[1], ladies_place_range[2]))

# Debug and validate season rankings
cat("\n--- Season Ranking Validation ---\n")

# Check ladies data distribution
cat("Ladies Pct_of_Max_Points distribution:\n")
ladies_pct_summary <- summary(train_ladies$Pct_of_Max_Points)
print(ladies_pct_summary)

# Validate no negative or extreme values
if (any(train_ladies$Pct_of_Max_Points < 0, na.rm = TRUE)) {
  warning("Ladies data contains negative Pct_of_Max_Points values")
}
if (any(train_ladies$Pct_of_Max_Points > 2, na.rm = TRUE)) {
  warning("Ladies data contains very high Pct_of_Max_Points values (>200%)")
}

cat("Ladies Place distribution:\n")
ladies_place_table <- table(df_place_ladies$Place)
print(head(ladies_place_table, 10))

cat("Ladies seasons distribution:\n")
ladies_season_table <- table(df_place_ladies$Season)
print(ladies_season_table)

# Check for balanced season representation
if (any(ladies_season_table < 5)) {
  seasons_low_n <- names(ladies_season_table[ladies_season_table < 5])
  warning(sprintf("Ladies seasons with <5 observations: %s", paste(seasons_low_n, collapse = ", ")))
}

# Sample rankings validation
cat("Sample ladies season rankings (first 15):\n")
sample_rankings <- df_place_ladies %>% 
  arrange(Season, Place) %>% 
  dplyr::select(Season, Skier, Pct_of_Max_Points, Place) %>%
  head(15)
print(sample_rankings)

# Create categorical outcomes for different cutoffs with validation
cat("\n--- Categorical Outcome Creation ---\n")

tryCatch({
  df_place <- df_place %>%
    mutate(
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Men's categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create men's categorical outcomes: ", e$message)
})

tryCatch({
  df_place_ladies <- df_place_ladies %>%
    mutate(
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Ladies categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create ladies categorical outcomes: ", e$message)
})

# Validate categorical outcome creation
cat("\n--- Categorical Outcome Validation ---\n")

# Check TopThree creation for ladies
cat("Ladies Place vs TopThree validation:\n")
topthree_crosstab <- table(df_place_ladies$Place, df_place_ladies$TopThree, useNA = "always")
print(topthree_crosstab[1:min(10, nrow(topthree_crosstab)), ])

# Validate factor levels
expected_levels <- c("0", "1")
targets <- c("TopThree", "Top5", "Top10", "Top30")

for (target in targets) {
  men_levels <- levels(df_place[[target]])
  ladies_levels <- levels(df_place_ladies[[target]])
  
  if (!all(expected_levels %in% men_levels)) {
    warning(sprintf("Men's %s missing expected levels: %s", target, paste(setdiff(expected_levels, men_levels), collapse = ", ")))
  }
  if (!all(expected_levels %in% ladies_levels)) {
    warning(sprintf("Ladies %s missing expected levels: %s", target, paste(setdiff(expected_levels, ladies_levels), collapse = ", ")))
  }
  
  # Check for class imbalance
  men_table <- table(df_place[[target]])
  ladies_table <- table(df_place_ladies[[target]])
  
  men_minority_pct <- min(men_table) / sum(men_table) * 100
  ladies_minority_pct <- min(ladies_table) / sum(ladies_table) * 100
  
  cat(sprintf("%s class balance: Men %.1f%% minority, Ladies %.1f%% minority\n", 
              target, men_minority_pct, ladies_minority_pct))
  
  if (men_minority_pct < 5) {
    warning(sprintf("Men's %s has severe class imbalance (<5%% minority class)", target))
  }
  if (ladies_minority_pct < 5) {
    warning(sprintf("Ladies %s has severe class imbalance (<5%% minority class)", target))
  }
}

# Sample TopThree values
cat("First 20 ladies Place and TopThree values:\n")
sample_topthree <- df_place_ladies %>% 
  dplyr::select(Skier, Season, Place, TopThree) %>% 
  head(20)
print(sample_topthree)

# Prepare 2025 prediction data with validation
cat("\n--- 2025 Prediction Data Preparation ---\n")

# Validate prediction data exists
if (!exists("men_pred_data") || is.null(men_pred_data)) {
  warning("Men's 2026 prediction data not available from previous section")
  men_pred_data <- data.frame()
}
if (!exists("ladies_pred_data") || is.null(ladies_pred_data)) {
  warning("Ladies 2026 prediction data not available from previous section") 
  ladies_pred_data <- data.frame()
}

# Men's prediction data preparation
pred_data_men <- NULL
if (nrow(men_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Distance_Pelo", "Distance_C_Pelo", 
                           "Distance_F_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo", "Sprint_Pelo", 
                           "Classic_Pelo", "Freestyle_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(men_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(men_pred_data))
    
    cat(sprintf("Men's prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing men's prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_men <- men_pred_data[available_pred_cols]
      
      # Rename to match training data feature names
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Distance" = "Distance_Pelo", 
                     "Prev_Distance_C" = "Distance_C_Pelo", "Prev_Distance_F" = "Distance_F_Pelo",
                     "Prev_Sprint_C" = "Sprint_C_Pelo", "Prev_Sprint_F" = "Sprint_F_Pelo", 
                     "Prev_Sprint" = "Sprint_Pelo", "Prev_C" = "Classic_Pelo", 
                     "Prev_F" = "Freestyle_Pelo", "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_men)) {
          names(pred_data_men)[names(pred_data_men) == rename_map[old_name]] <- old_name
        }
      }
      
      cat(sprintf("✓ Men's prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_men), ncol(pred_data_men)))
    } else {
      warning("Insufficient columns for men's prediction data preparation")
      pred_data_men <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing men's prediction data:", e$message, "\n")
    pred_data_men <- data.frame()
  })
} else {
  cat("No men's prediction data available\n")
  pred_data_men <- data.frame()
}

# Ladies prediction data preparation  
pred_data_ladies <- NULL
if (nrow(ladies_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data
    expected_pred_cols <- c("Skier", "Nation", "Pelo", "Distance_Pelo", "Distance_C_Pelo", 
                           "Distance_F_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo", "Sprint_Pelo", 
                           "Classic_Pelo", "Freestyle_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(ladies_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(ladies_pred_data))
    
    cat(sprintf("Ladies prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing ladies prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_ladies <- ladies_pred_data[available_pred_cols]
      
      # Rename to match training data feature names
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Distance" = "Distance_Pelo", 
                     "Prev_Distance_C" = "Distance_C_Pelo", "Prev_Distance_F" = "Distance_F_Pelo",
                     "Prev_Sprint_C" = "Sprint_C_Pelo", "Prev_Sprint_F" = "Sprint_F_Pelo", 
                     "Prev_Sprint" = "Sprint_Pelo", "Prev_C" = "Classic_Pelo", 
                     "Prev_F" = "Freestyle_Pelo", "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_ladies)) {
          names(pred_data_ladies)[names(pred_data_ladies) == rename_map[old_name]] <- old_name
        }
      }
      
      cat(sprintf("✓ Ladies prediction data prepared: %d rows, %d columns\n", 
                  nrow(pred_data_ladies), ncol(pred_data_ladies)))
    } else {
      warning("Insufficient columns for ladies prediction data preparation")
      pred_data_ladies <- data.frame()
    }
    
  }, error = function(e) {
    cat("Error preparing ladies prediction data:", e$message, "\n")
    pred_data_ladies <- data.frame()
  })
} else {
  cat("No ladies prediction data available\n")
  pred_data_ladies <- data.frame()
}

# Set backwards compatibility default
if (nrow(pred_data_men) > 0) {
  pred_data <- pred_data_men
  cat("Using men's prediction data as default for backwards compatibility\n")
} else if (nrow(pred_data_ladies) > 0) {
  pred_data <- pred_data_ladies
  cat("Using ladies prediction data as fallback default\n")
} else {
  pred_data <- data.frame()
  warning("No prediction data available for odds calculations")
}

# Final validation summary
cat("\n--- Final Data Summary ---\n")
cat("Training data with places and outcomes:\n")
cat(sprintf("  Men: %d rows, columns: %s\n", nrow(df_place), paste(head(names(df_place), 10), collapse = ", ")))
cat(sprintf("  Ladies: %d rows, columns: %s\n", nrow(df_place_ladies), paste(head(names(df_place_ladies), 10), collapse = ", ")))

cat("Prediction data for odds:\n")
if (nrow(pred_data_men) > 0) {
  cat(sprintf("  Men: %d rows, columns: %s\n", nrow(pred_data_men), paste(head(names(pred_data_men), 10), collapse = ", ")))
}
if (nrow(pred_data_ladies) > 0) {
  cat(sprintf("  Ladies: %d rows, columns: %s\n", nrow(pred_data_ladies), paste(head(names(pred_data_ladies), 10), collapse = ", ")))
}

cat("\n✓ Odds setup validation completed\n")
```

### Feature Selection for Odds Models

```{r non-ml-feat}
cat("=== FEATURE SELECTION FOR ODDS MODELS & VALIDATION ===\n")

# Load required libraries with validation
cat("\n--- Library Loading ---\n")
tryCatch({
  library(leaps)
  cat("✓ leaps library loaded\n")
}, error = function(e) {
  stop("Failed to load leaps library: ", e$message)
})

tryCatch({
  library(caret)
  cat("✓ caret library loaded\n")
}, error = function(e) {
  stop("Failed to load caret library: ", e$message)
})

# Validate input data availability
cat("\n--- Input Data Validation ---\n")

if (!exists("df_place") || !exists("df_place_ladies")) {
  stop("Training data with places not available - ensure odds-setup section completed successfully")
}

if (nrow(df_place) == 0) {
  stop("Men's training data with places is empty")
}
if (nrow(df_place_ladies) == 0) {
  stop("Ladies training data with places is empty")
}

cat(sprintf("Training data with outcomes: Men %d rows, Ladies %d rows\n", nrow(df_place), nrow(df_place_ladies)))

# Define and validate features for odds models
cat("\n--- Feature Definition & Validation ---\n")

features <- c("Prev_Pelo", "Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", 
              "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_F", "Prev_C", "Prev_Pct_of_Max_Points")

# Check feature availability in training data
men_available_features <- intersect(features, names(df_place))
ladies_available_features <- intersect(features, names(df_place_ladies))

cat(sprintf("Men's available features: %d/%d\n", length(men_available_features), length(features)))
cat(sprintf("Ladies available features: %d/%d\n", length(ladies_available_features), length(features)))

men_missing_features <- setdiff(features, men_available_features)
ladies_missing_features <- setdiff(features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some features missing from ladies training data")
}

# Update feature lists to only include available features
features_men <- men_available_features
features_ladies <- ladies_available_features

if (length(features_men) < 3) {
  stop("Insufficient features for men's odds modeling (need at least 3)")
}
if (length(features_ladies) < 3) {
  stop("Insufficient features for ladies odds modeling (need at least 3)")
}

# Function to evaluate binary logistic model with validation
evaluate_glm <- function(feature_set, data, target, gender_label = "Unknown") {
  tryCatch({
    # Validate inputs
    if (length(feature_set) == 0) {
      return(Inf)
    }
    
    # Check if features exist in data
    missing_features <- setdiff(feature_set, names(data))
    if (length(missing_features) > 0) {
      return(Inf)
    }
    
    # Check if target exists and has variation
    if (!target %in% names(data)) {
      return(Inf)
    }
    
    target_table <- table(data[[target]])
    if (length(target_table) < 2 || any(target_table < 5)) {
      return(Inf)  # Skip if not enough levels or insufficient observations
    }
    
    # Build and evaluate model
    formula_str <- as.formula(paste(target, "~", paste(feature_set, collapse = " + ")))
    model <- glm(formula_str, family = binomial, data = data)
    
    # Validate model convergence
    if (!model$converged) {
      return(Inf)
    }
    
    aic_value <- AIC(model)
    
    # Validate AIC value
    if (!is.finite(aic_value)) {
      return(Inf)
    }
    
    return(aic_value)
  }, error = function(e) {
    return(Inf)
  })
}

# Exhaustive feature search function with validation
exhaustive_feature_search <- function(target, data_df, gender_label, available_features) {
  cat(sprintf("Searching %s features for %s...\n", gender_label, target))
  
  # Validate inputs
  if (!target %in% names(data_df)) {
    cat(sprintf("Target %s not found in %s data\n", target, gender_label))
    return(list(features = character(0), aic = Inf))
  }
  
  if (length(available_features) < 2) {
    cat(sprintf("Insufficient features for %s %s search\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  }
  
  best_aic <- Inf
  best_features <- NULL
  total_combinations <- 0
  successful_models <- 0
  
  # Search through feature combinations (2-5 features)
  max_features <- min(5, length(available_features))
  
  for(i in 2:max_features) {
    if (i > length(available_features)) break
    
    combinations <- combn(available_features, i, simplify = FALSE)
    total_combinations <- total_combinations + length(combinations)
    
    for(feature_set in combinations) {
      aic <- evaluate_glm(feature_set, data_df, target, gender_label)
      if(is.finite(aic)) {
        successful_models <- successful_models + 1
        if(aic < best_aic) {
          best_aic <- aic
          best_features <- feature_set
        }
      }
    }
  }
  
  cat(sprintf("  Tested %d combinations, %d successful models\n", total_combinations, successful_models))
  
  if (is.null(best_features)) {
    cat(sprintf("  No successful models found for %s %s\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  } else {
    cat(sprintf("  Best %s %s features: %s (AIC: %.2f)\n", 
                gender_label, target, paste(best_features, collapse = ", "), best_aic))
  }
  
  return(list(features = best_features, aic = best_aic))
}

# Debug and validate data structure
cat("\n--- Data Structure Validation ---\n")

# Check target variable distributions
targets <- c("TopThree", "Top5", "Top10", "Top30")
for (target in targets) {
  if (target %in% names(df_place)) {
    men_table <- table(df_place[[target]])
    cat(sprintf("Men's %s distribution: %s\n", target, paste(names(men_table), men_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Men's %s target not found", target))
  }
  
  if (target %in% names(df_place_ladies)) {
    ladies_table <- table(df_place_ladies[[target]])
    cat(sprintf("Ladies %s distribution: %s\n", target, paste(names(ladies_table), ladies_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Ladies %s target not found", target))
  }
}

cat(sprintf("Men's data dimensions: %d rows × %d columns\n", nrow(df_place), ncol(df_place)))
cat(sprintf("Ladies data dimensions: %d rows × %d columns\n", nrow(df_place_ladies), ncol(df_place_ladies)))

# Validate sufficient data for modeling
min_obs_per_class <- 10
for (target in targets) {
  if (target %in% names(df_place)) {
    men_min_class <- min(table(df_place[[target]]))
    if (men_min_class < min_obs_per_class) {
      warning(sprintf("Men's %s has insufficient minority class observations (%d < %d)", 
                     target, men_min_class, min_obs_per_class))
    }
  }
  
  if (target %in% names(df_place_ladies)) {
    ladies_min_class <- min(table(df_place_ladies[[target]]))
    if (ladies_min_class < min_obs_per_class) {
      warning(sprintf("Ladies %s has insufficient minority class observations (%d < %d)", 
                     target, ladies_min_class, min_obs_per_class))
    }
  }
}

# Perform exhaustive feature search with validation
cat("\n=== EXHAUSTIVE FEATURE SEARCH ===\n")

# Initialize result storage
best_features_odds_men <- list()
best_features_odds_ladies <- list()

# Men's feature search
cat("\n--- Men's Feature Search ---\n")
for(target in targets) {
  if (target %in% names(df_place)) {
    result <- exhaustive_feature_search(target, df_place, "Men's", features_men)
    best_features_odds_men[[target]] <- result
  } else {
    cat(sprintf("Skipping men's %s - target not available\n", target))
    best_features_odds_men[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Ladies feature search  
cat("\n--- Ladies Feature Search ---\n")
for(target in targets) {
  if (target %in% names(df_place_ladies)) {
    result <- exhaustive_feature_search(target, df_place_ladies, "Ladies", features_ladies)
    best_features_odds_ladies[[target]] <- result
  } else {
    cat(sprintf("Skipping ladies %s - target not available\n", target))
    best_features_odds_ladies[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Validate search results
cat("\n--- Feature Search Validation ---\n")

for(target in targets) {
  men_result <- best_features_odds_men[[target]]
  ladies_result <- best_features_odds_ladies[[target]]
  
  cat(sprintf("%s results:\n", target))
  
  if (length(men_result$features) > 0) {
    cat(sprintf("  Men: %s (AIC: %.2f)\n", paste(men_result$features, collapse = ", "), men_result$aic))
  } else {
    cat("  Men: No successful model found\n")
  }
  
  if (length(ladies_result$features) > 0) {
    cat(sprintf("  Ladies: %s (AIC: %.2f)\n", paste(ladies_result$features, collapse = ", "), ladies_result$aic))
  } else {
    cat("  Ladies: No successful model found\n")
  }
}

# Check for any successful models
successful_men_targets <- sum(sapply(best_features_odds_men, function(x) length(x$features) > 0))
successful_ladies_targets <- sum(sapply(best_features_odds_ladies, function(x) length(x$features) > 0))

cat(sprintf("Successful models: Men %d/%d targets, Ladies %d/%d targets\n", 
            successful_men_targets, length(targets), successful_ladies_targets, length(targets)))

if (successful_men_targets == 0) {
  warning("No successful men's odds models found")
}
if (successful_ladies_targets == 0) {
  warning("No successful ladies odds models found")
}

# Maintain backwards compatibility
best_features_odds <- best_features_odds_men

cat("\n✓ Feature selection for odds models completed\n")

```

### Statistical Model Odds

```{r statistical-odds}
cat("=== STATISTICAL ODDS VALIDATION ===\n")

# Input validation for feature sets
if (!exists("best_features_odds_men") || !is.list(best_features_odds_men)) {
  stop("best_features_odds_men object not found or invalid")
}
if (!exists("best_features_odds_ladies") || !is.list(best_features_odds_ladies)) {
  stop("best_features_odds_ladies object not found or invalid")
}

# Required outcome categories
required_outcomes <- c("TopThree", "Top5", "Top10", "Top30")
missing_men <- setdiff(required_outcomes, names(best_features_odds_men))
missing_ladies <- setdiff(required_outcomes, names(best_features_odds_ladies))

if (length(missing_men) > 0) {
  stop("Missing outcome categories in men's features: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing outcome categories in ladies features: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required outcome categories present\n")

tryCatch({
  # Use best features from exhaustive search for men
  topthree_features_men <- best_features_odds_men[["TopThree"]]$features
  top5_features_men <- best_features_odds_men[["Top5"]]$features
  top10_features_men <- best_features_odds_men[["Top10"]]$features
  top30_features_men <- best_features_odds_men[["Top30"]]$features
  
  # Validate men's features
  if (length(topthree_features_men) == 0) stop("No features found for men's TopThree")
  if (length(top5_features_men) == 0) stop("No features found for men's Top5")
  if (length(top10_features_men) == 0) stop("No features found for men's Top10")
  if (length(top30_features_men) == 0) stop("No features found for men's Top30")
  
  cat("Men's feature counts - TopThree:", length(topthree_features_men), 
      "Top5:", length(top5_features_men), 
      "Top10:", length(top10_features_men), 
      "Top30:", length(top30_features_men), "\n")
  
}, error = function(e) {
  stop("Error extracting men's features: ", e$message)
})

tryCatch({
  # Use best features from exhaustive search for ladies
  topthree_features_ladies <- best_features_odds_ladies[["TopThree"]]$features
  top5_features_ladies <- best_features_odds_ladies[["Top5"]]$features
  top10_features_ladies <- best_features_odds_ladies[["Top10"]]$features
  top30_features_ladies <- best_features_odds_ladies[["Top30"]]$features
  
  # Validate ladies features
  if (length(topthree_features_ladies) == 0) stop("No features found for ladies TopThree")
  if (length(top5_features_ladies) == 0) stop("No features found for ladies Top5")
  if (length(top10_features_ladies) == 0) stop("No features found for ladies Top10")
  if (length(top30_features_ladies) == 0) stop("No features found for ladies Top30")
  
  cat("Ladies feature counts - TopThree:", length(topthree_features_ladies), 
      "Top5:", length(top5_features_ladies), 
      "Top10:", length(top10_features_ladies), 
      "Top30:", length(top30_features_ladies), "\n")
  
}, error = function(e) {
  stop("Error extracting ladies features: ", e$message)
})

# Create formulas with validation
cat("\n--- Formula Creation ---\n")
tryCatch({
  # Create formulas for men's models
  topthree_formula_men <- as.formula(paste("TopThree ~", paste(topthree_features_men, collapse = " + ")))
  top5_formula_men <- as.formula(paste("Top5 ~", paste(top5_features_men, collapse = " + ")))
  top10_formula_men <- as.formula(paste("Top10 ~", paste(top10_features_men, collapse = " + ")))
  top30_formula_men <- as.formula(paste("Top30 ~", paste(top30_features_men, collapse = " + ")))
  
  # Validate formula creation
  if (!inherits(topthree_formula_men, "formula")) stop("Failed to create TopThree formula for men")
  if (!inherits(top5_formula_men, "formula")) stop("Failed to create Top5 formula for men")
  if (!inherits(top10_formula_men, "formula")) stop("Failed to create Top10 formula for men")
  if (!inherits(top30_formula_men, "formula")) stop("Failed to create Top30 formula for men")
  
  cat("✓ Men's formulas created successfully\n")
  
}, error = function(e) {
  stop("Error creating men's formulas: ", e$message)
})

tryCatch({
  # Create formulas for ladies models
  topthree_formula_ladies <- as.formula(paste("TopThree ~", paste(topthree_features_ladies, collapse = " + ")))
  top5_formula_ladies <- as.formula(paste("Top5 ~", paste(top5_features_ladies, collapse = " + ")))
  top10_formula_ladies <- as.formula(paste("Top10 ~", paste(top10_features_ladies, collapse = " + ")))
  top30_formula_ladies <- as.formula(paste("Top30 ~", paste(top30_features_ladies, collapse = " + ")))
  
  # Validate formula creation
  if (!inherits(topthree_formula_ladies, "formula")) stop("Failed to create TopThree formula for ladies")
  if (!inherits(top5_formula_ladies, "formula")) stop("Failed to create Top5 formula for ladies")
  if (!inherits(top10_formula_ladies, "formula")) stop("Failed to create Top10 formula for ladies")
  if (!inherits(top30_formula_ladies, "formula")) stop("Failed to create Top30 formula for ladies")
  
  cat("✓ Ladies formulas created successfully\n")
  
}, error = function(e) {
  stop("Error creating ladies formulas: ", e$message)
})

print("=== MEN'S OPTIMIZED MODEL FORMULAS ===")
print(topthree_formula_men)
print(top5_formula_men)
print(top10_formula_men)
print(top30_formula_men)

print("=== LADIES OPTIMIZED MODEL FORMULAS ===")
print(topthree_formula_ladies)
print(top5_formula_ladies)
print(top10_formula_ladies)
print(top30_formula_ladies)

# Maintain backwards compatibility
topthree_features <- topthree_features_men
top5_features <- top5_features_men
top10_features <- top10_features_men
top30_features <- top30_features_men
topthree_formula <- topthree_formula_men
top5_formula <- top5_formula_men
top10_formula <- top10_formula_men
top30_formula <- top30_formula_men

# Add Distance_C and Distance_F if they're not already there
# if(!"Prev_Distance_C" %in% names(pred_data)) {
#   pred_data <- pred_data %>%
#     mutate(Prev_Distance_C = Prev_Distance)
# }
# 
# if(!"Prev_Distance_F" %in% names(pred_data)) {
#   pred_data <- pred_data %>%
#     mutate(Prev_Distance_F = Prev_Distance)
# }

# Validate data availability for modeling
cat("\n--- Model Training Data Validation ---\n")
if (!exists("df_place") || !is.data.frame(df_place)) {
  stop("df_place dataset not found or invalid")
}
if (nrow(df_place) == 0) {
  stop("df_place dataset is empty")
}

# Check for required target variables
required_targets <- c("TopThree", "Top5", "Top10", "Top30")
missing_targets <- setdiff(required_targets, names(df_place))
if (length(missing_targets) > 0) {
  stop("Missing target variables in df_place: ", paste(missing_targets, collapse = ", "))
}

# Validate target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place[[target]], useNA = "always")
  cat("Target", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for target ", target, " - model may be unstable")
  }
}

# Fit models with optimal feature sets and validation
cat("\n--- Model Training ---\n")
tryCatch({
  place_model <- glm(topthree_formula, family = binomial, data = df_place)
  
  # Validate model convergence
  if (!place_model$converged) {
    warning("TopThree model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(place_model)))) {
    warning("TopThree model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ TopThree model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting TopThree model: ", e$message)
})

tryCatch({
  top5_model <- glm(top5_formula, family = binomial, data = df_place)
  
  if (!top5_model$converged) warning("Top5 model did not converge")
  if (any(is.na(coef(top5_model)))) warning("Top5 model has NA coefficients")
  cat("✓ Top5 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top5 model: ", e$message)
})

tryCatch({
  top10_model <- glm(top10_formula, family = binomial, data = df_place)
  
  if (!top10_model$converged) warning("Top10 model did not converge")
  if (any(is.na(coef(top10_model)))) warning("Top10 model has NA coefficients")
  cat("✓ Top10 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top10 model: ", e$message)
})

tryCatch({
  top30_model <- glm(top30_formula, family = binomial, data = df_place)
  
  if (!top30_model$converged) warning("Top30 model did not converge")
  if (any(is.na(coef(top30_model)))) warning("Top30 model has NA coefficients")
  cat("✓ Top30 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting Top30 model: ", e$message)
})

# Validate prediction data
cat("\n--- Prediction Data Validation ---\n")
if (!exists("pred_data") || !is.data.frame(pred_data)) {
  stop("pred_data dataset not found or invalid")
}
if (nrow(pred_data) == 0) {
  stop("pred_data dataset is empty")
}

# Check for required features in prediction data
all_required_features <- unique(c(topthree_features_men, top5_features_men, top10_features_men, top30_features_men))
missing_pred_features <- setdiff(all_required_features, names(pred_data))
if (length(missing_pred_features) > 0) {
  warning("Missing features in prediction data: ", paste(missing_pred_features, collapse = ", "))
}

cat("Prediction dataset has", nrow(pred_data), "observations and", ncol(pred_data), "variables\n")

# Get predicted probabilities with validation
cat("\n--- Model Predictions ---\n")
tryCatch({
  top3_probs <- predict(place_model, pred_data, type = "response")
  
  # Validate predictions
  if (any(is.na(top3_probs))) {
    warning("NA predictions detected for TopThree - ", sum(is.na(top3_probs)), " out of ", length(top3_probs))
  }
  if (any(top3_probs < 0 | top3_probs > 1, na.rm = TRUE)) {
    warning("Invalid probability values for TopThree (outside 0-1 range)")
  }
  
  cat("✓ TopThree predictions generated - Range: [", round(min(top3_probs, na.rm = TRUE), 4), ", ", 
      round(max(top3_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating TopThree predictions: ", e$message)
})

tryCatch({
  top5_probs <- predict(top5_model, pred_data, type = "response")
  
  if (any(is.na(top5_probs))) warning("NA predictions for Top5")
  if (any(top5_probs < 0 | top5_probs > 1, na.rm = TRUE)) warning("Invalid Top5 probabilities")
  
  cat("✓ Top5 predictions generated - Range: [", round(min(top5_probs, na.rm = TRUE), 4), ", ", 
      round(max(top5_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top5 predictions: ", e$message)
})

tryCatch({
  top10_probs <- predict(top10_model, pred_data, type = "response")
  
  if (any(is.na(top10_probs))) warning("NA predictions for Top10")
  if (any(top10_probs < 0 | top10_probs > 1, na.rm = TRUE)) warning("Invalid Top10 probabilities")
  
  cat("✓ Top10 predictions generated - Range: [", round(min(top10_probs, na.rm = TRUE), 4), ", ", 
      round(max(top10_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top10 predictions: ", e$message)
})

tryCatch({
  top30_probs <- predict(top30_model, pred_data, type = "response")
  
  if (any(is.na(top30_probs))) warning("NA predictions for Top30")
  if (any(top30_probs < 0 | top30_probs > 1, na.rm = TRUE)) warning("Invalid Top30 probabilities")
  
  cat("✓ Top30 predictions generated - Range: [", round(min(top30_probs, na.rm = TRUE), 4), ", ", 
      round(max(top30_probs, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating Top30 predictions: ", e$message)
})

# ========== NORMALIZATION FOR MEN'S ODDS ==========
cat("\n--- Normalizing Probabilities ---\n")

# Normalize probabilities so they sum to expected totals
# Win probabilities should sum to 100% (1.0)
total_win_prob <- sum(top3_probs * 0.33, na.rm = TRUE)
if (total_win_prob > 0) {
  win_probs_normalized <- (top3_probs * 0.33) / total_win_prob
} else {
  win_probs_normalized <- top3_probs * 0.33
}

# Top3 probabilities should sum to 300% (3.0) since 3 positions
total_top3_prob <- sum(top3_probs, na.rm = TRUE)
if (total_top3_prob > 0) {
  top3_probs_normalized <- (top3_probs / total_top3_prob) * 3.0
} else {
  top3_probs_normalized <- top3_probs
}

# Top5 probabilities should sum to 500% (5.0)
total_top5_prob <- sum(top5_probs, na.rm = TRUE)
if (total_top5_prob > 0) {
  top5_probs_normalized <- (top5_probs / total_top5_prob) * 5.0
} else {
  top5_probs_normalized <- top5_probs
}

# Top10 probabilities should sum to 1000% (10.0)
total_top10_prob <- sum(top10_probs, na.rm = TRUE)
if (total_top10_prob > 0) {
  top10_probs_normalized <- (top10_probs / total_top10_prob) * 10.0
} else {
  top10_probs_normalized <- top10_probs
}

# Top30 probabilities should sum to 3000% (30.0)
total_top30_prob <- sum(top30_probs, na.rm = TRUE)
if (total_top30_prob > 0) {
  top30_probs_normalized <- (top30_probs / total_top30_prob) * 30.0
} else {
  top30_probs_normalized <- top30_probs
}

cat("Normalization applied:\n")
cat("Win probs sum:", round(sum(win_probs_normalized, na.rm = TRUE), 3), "(target: 1.0)\n")
cat("Top3 probs sum:", round(sum(top3_probs_normalized, na.rm = TRUE), 3), "(target: 3.0)\n")
cat("Top5 probs sum:", round(sum(top5_probs_normalized, na.rm = TRUE), 3), "(target: 5.0)\n")
cat("Top10 probs sum:", round(sum(top10_probs_normalized, na.rm = TRUE), 3), "(target: 10.0)\n")
cat("Top30 probs sum:", round(sum(top30_probs_normalized, na.rm = TRUE), 3), "(target: 30.0)\n")

# Create results dataframe with validation
cat("\n--- Results DataFrame Creation ---\n")

# Validate required columns in pred_data
required_id_cols <- c("Skier", "Nation")
missing_id_cols <- setdiff(required_id_cols, names(pred_data))
if (length(missing_id_cols) > 0) {
  stop("Missing identification columns in pred_data: ", paste(missing_id_cols, collapse = ", "))
}

tryCatch({
  # Create results dataframe with all probabilities (USING NORMALIZED VALUES)
  # Note: Since TopThree is now binary, we don't have separate win/second/third probs
  results <- data.frame(
    Skier = pred_data$Skier,
    Nation = pred_data$Nation,
    Top3_Prob = top3_probs_normalized,  # Normalized Top3 probability
    Win_Prob = win_probs_normalized,    # Normalized win probability
    Second_Prob = win_probs_normalized, # Normalized (same as win for approximation)
    Third_Prob = win_probs_normalized,  # Normalized (same as win for approximation)
    Top5_Prob = top5_probs_normalized,  # Normalized Top5 probability
    Top10_Prob = top10_probs_normalized, # Normalized Top10 probability
    Top30_Prob = top30_probs_normalized, # Normalized Top30 probability
    Outside_Prob = 1 - (top30_probs_normalized / 30.0)  # Adjusted for normalization
  )
  
  # Validate results dataframe
  if (nrow(results) == 0) stop("Results dataframe is empty")
  if (any(is.na(results$Skier))) warning("Missing skier names in results")
  
  # Check probability consistency
  invalid_prob_consistency <- sum(results$Top3_Prob > results$Top5_Prob | 
                                  results$Top5_Prob > results$Top10_Prob | 
                                  results$Top10_Prob > results$Top30_Prob, na.rm = TRUE)
  
  if (invalid_prob_consistency > 0) {
    warning("Probability inconsistency detected in ", invalid_prob_consistency, " cases (P(smaller) > P(larger))")
  }
  
  cat("✓ Results dataframe created with", nrow(results), "skiers\n")
  cat("Probability ranges - Top3: [", round(min(results$Top3_Prob, na.rm = TRUE), 4), ", ", 
      round(max(results$Top3_Prob, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error creating results dataframe: ", e$message)
})

# Calculate decimal and American odds with validation
cat("\n--- Odds Calculation ---\n")
tryCatch({
  results <- results %>%
    mutate(
      Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
      Win_American_Odds = ifelse(Win_Prob >= 0.5,
                                -Win_Prob/(1-Win_Prob) * 100,
                                (1-Win_Prob)/Win_Prob * 100),
      Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
      Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                                 -Top3_Prob/(1-Top3_Prob) * 100,
                                 (1-Top3_Prob)/Top3_Prob * 100),
      Top5_Decimal_Odds = ifelse(Top5_Prob > 0, 1 / Top5_Prob, Inf),
      Top5_American_Odds = ifelse(Top5_Prob >= 0.5,
                                 -Top5_Prob/(1-Top5_Prob) * 100,
                                 (1-Top5_Prob)/Top5_Prob * 100),
      Top10_Decimal_Odds = ifelse(Top10_Prob > 0, 1 / Top10_Prob, Inf),
      Top10_American_Odds = ifelse(Top10_Prob >= 0.5,
                                  -Top10_Prob/(1-Top10_Prob) * 100,
                                  (1-Top10_Prob)/Top10_Prob * 100),
      Top30_Decimal_Odds = ifelse(Top30_Prob > 0, 1 / Top30_Prob, Inf),
      Top30_American_Odds = ifelse(Top30_Prob >= 0.5,
                                  -Top30_Prob/(1-Top30_Prob) * 100,
                                  (1-Top30_Prob)/Top30_Prob * 100)
    ) %>%
    # Format probabilities and odds with validation
    mutate(
      Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
      Second_Prob = ifelse(is.na(Second_Prob), "N/A", sprintf("%.1f%%", Second_Prob * 100)),
      Third_Prob = ifelse(is.na(Third_Prob), "N/A", sprintf("%.1f%%", Third_Prob * 100)),
      Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
      Top5_Prob = ifelse(is.na(Top5_Prob), "N/A", sprintf("%.1f%%", Top5_Prob * 100)),
      Top10_Prob = ifelse(is.na(Top10_Prob), "N/A", sprintf("%.1f%%", Top10_Prob * 100)),
      Top30_Prob = ifelse(is.na(Top30_Prob), "N/A", sprintf("%.1f%%", Top30_Prob * 100)),
      Outside_Prob = ifelse(is.na(Outside_Prob), "N/A", sprintf("%.1f%%", Outside_Prob * 100)),
      
      # Round decimal odds with Inf handling
      Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                               ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
      Top3_Decimal_Odds = ifelse(is.infinite(Top3_Decimal_Odds), 999.99, 
                                ifelse(Top3_Decimal_Odds > 999.99, 999.99, round(Top3_Decimal_Odds, 2))),
      Top5_Decimal_Odds = ifelse(is.infinite(Top5_Decimal_Odds), 999.99, 
                                ifelse(Top5_Decimal_Odds > 999.99, 999.99, round(Top5_Decimal_Odds, 2))),
      Top10_Decimal_Odds = ifelse(is.infinite(Top10_Decimal_Odds), 999.99, 
                                 ifelse(Top10_Decimal_Odds > 999.99, 999.99, round(Top10_Decimal_Odds, 2))),
      Top30_Decimal_Odds = ifelse(is.infinite(Top30_Decimal_Odds), 999.99, 
                                 ifelse(Top30_Decimal_Odds > 999.99, 999.99, round(Top30_Decimal_Odds, 2))),
      
      # Format American odds with validation
      Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                                ifelse(Win_American_Odds > 0, 
                                      sprintf("+%.0f", round(Win_American_Odds, 0)),
                                      sprintf("%.0f", round(Win_American_Odds, 0)))),
      Top3_American_Odds = ifelse(is.na(Top3_American_Odds) | is.infinite(Top3_American_Odds), "N/A",
                                 ifelse(Top3_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top3_American_Odds, 0)),
                                       sprintf("%.0f", round(Top3_American_Odds, 0)))),
      Top5_American_Odds = ifelse(is.na(Top5_American_Odds) | is.infinite(Top5_American_Odds), "N/A",
                                 ifelse(Top5_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top5_American_Odds, 0)),
                                       sprintf("%.0f", round(Top5_American_Odds, 0)))),
      Top10_American_Odds = ifelse(is.na(Top10_American_Odds) | is.infinite(Top10_American_Odds), "N/A",
                                  ifelse(Top10_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top10_American_Odds, 0)),
                                        sprintf("%.0f", round(Top10_American_Odds, 0)))),
      Top30_American_Odds = ifelse(is.na(Top30_American_Odds) | is.infinite(Top30_American_Odds), "N/A",
                                  ifelse(Top30_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top30_American_Odds, 0)),
                                        sprintf("%.0f", round(Top30_American_Odds, 0))))
    )
  
  # Validate sorting and arrange results
  numeric_win_probs <- as.numeric(sub("%", "", results$Win_Prob))
  if (any(is.na(numeric_win_probs))) {
    warning("Some Win_Prob values could not be converted to numeric for sorting")
  }
  
  results <- results %>% arrange(desc(numeric_win_probs))
  
  cat("✓ Odds calculation and formatting completed\n")
  
}, error = function(e) {
  stop("Error calculating odds: ", e$message)
})

cat("\n--- Final Results Summary ---\n")
cat("Total skiers with odds:", nrow(results), "\n")
cat("Skiers with valid Win probabilities:", sum(results$Win_Prob != "N/A"), "\n")
cat("Highest win probability:", max(numeric_win_probs, na.rm = TRUE), "%\n")

print("=== 2026 MEN'S SEASON ODDS ===")
print("Top 10 Men's Season Winner Odds:")
print(results %>% 
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      head(10))

print("Top 10 Men's Podium Finish Odds:")
print(results %>% 
      arrange(desc(as.numeric(sub("%", "", Top3_Prob)))) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      head(10))

print("Top 10 Men's Top-10 Finish Odds:")
print(results %>% 
      arrange(desc(as.numeric(sub("%", "", Top10_Prob)))) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      head(10))

# Store men's results with validation
tryCatch({
  results_men <- results
  
  # Final validation
  if (nrow(results_men) == 0) stop("No results to store")
  if (all(results_men$Win_Prob == "N/A")) warning("All win probabilities are N/A")
  
  cat("✓ Men's results stored successfully with", nrow(results_men), "skiers\n")
  
}, error = function(e) {
  stop("Error storing men's results: ", e$message)
})

# Export Men's Odds to Excel
cat("\n=== EXPORTING MEN'S ODDS TO EXCEL ===\n")

tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  if (!is.null(results_men) && nrow(results_men) > 0) {
    # Prepare data with numeric probabilities for proper sorting
    men_odds_export <- results_men %>%
      mutate(
        # Convert probability percentages to numeric for proper handling
        Win_Prob_Numeric = as.numeric(gsub("%", "", Win_Prob)),
        Top3_Prob_Numeric = as.numeric(gsub("%", "", Top3_Prob)),
        Top10_Prob_Numeric = as.numeric(gsub("%", "", Top10_Prob)),
        Top30_Prob_Numeric = as.numeric(gsub("%", "", Top30_Prob)),
        # Convert decimal odds to numeric for proper handling
        Win_Decimal_Numeric = as.numeric(Win_Decimal_Odds),
        Top3_Decimal_Numeric = as.numeric(Top3_Decimal_Odds),
        Top10_Decimal_Numeric = as.numeric(Top10_Decimal_Odds),
        Top30_Decimal_Numeric = as.numeric(Top30_Decimal_Odds)
      ) %>%
      # Create separate tables for each outcome
      arrange(desc(Win_Prob_Numeric))
    
    # Create separate Excel files for each outcome type
    
    # Win odds file
    win_data <- men_odds_export %>%
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(
        "Win Prob" = Win_Prob,
        "Win Decimal Odds" = Win_Decimal_Odds,
        "Win American Odds" = Win_American_Odds
      )
    
    win_wb <- createWorkbook()
    addWorksheet(win_wb, "Men Win Odds 2026")
    writeData(win_wb, "Men Win Odds 2026", win_data, startRow = 1, startCol = 1)
    addStyle(win_wb, "Men Win Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(win_data))
    setColWidths(win_wb, "Men Win Odds 2026", cols = 1:ncol(win_data), widths = "auto")
    saveWorkbook(win_wb, "excel365/Men_Win_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 3 odds file
    top3_data <- men_odds_export %>%
      arrange(desc(Top3_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(
        "Top 3 Prob" = Top3_Prob,
        "Top 3 Decimal Odds" = Top3_Decimal_Odds,
        "Top 3 American Odds" = Top3_American_Odds
      )
    
    top3_wb <- createWorkbook()
    addWorksheet(top3_wb, "Men Top 3 Odds 2026")
    writeData(top3_wb, "Men Top 3 Odds 2026", top3_data, startRow = 1, startCol = 1)
    addStyle(top3_wb, "Men Top 3 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top3_data))
    setColWidths(top3_wb, "Men Top 3 Odds 2026", cols = 1:ncol(top3_data), widths = "auto")
    saveWorkbook(top3_wb, "excel365/Men_Top3_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 10 odds file
    top10_data <- men_odds_export %>%
      arrange(desc(Top10_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(
        "Top 10 Prob" = Top10_Prob,
        "Top 10 Decimal Odds" = Top10_Decimal_Odds,
        "Top 10 American Odds" = Top10_American_Odds
      )
    
    top10_wb <- createWorkbook()
    addWorksheet(top10_wb, "Men Top 10 Odds 2026")
    writeData(top10_wb, "Men Top 10 Odds 2026", top10_data, startRow = 1, startCol = 1)
    addStyle(top10_wb, "Men Top 10 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top10_data))
    setColWidths(top10_wb, "Men Top 10 Odds 2026", cols = 1:ncol(top10_data), widths = "auto")
    saveWorkbook(top10_wb, "excel365/Men_Top10_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 30 odds file
    top30_data <- men_odds_export %>%
      arrange(desc(Top30_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top30_Prob, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(
        "Top 30 Prob" = Top30_Prob,
        "Top 30 Decimal Odds" = Top30_Decimal_Odds,
        "Top 30 American Odds" = Top30_American_Odds
      )
    
    top30_wb <- createWorkbook()
    addWorksheet(top30_wb, "Men Top 30 Odds 2026")
    writeData(top30_wb, "Men Top 30 Odds 2026", top30_data, startRow = 1, startCol = 1)
    addStyle(top30_wb, "Men Top 30 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top30_data))
    setColWidths(top30_wb, "Men Top 30 Odds 2026", cols = 1:ncol(top30_data), widths = "auto")
    saveWorkbook(top30_wb, "excel365/Men_Top30_Odds_2026.xlsx", overwrite = TRUE)
    
    cat("✓ Men's odds Excel files saved:\n")
    cat("  - excel365/Men_Win_Odds_2026.xlsx\n")
    cat("  - excel365/Men_Top3_Odds_2026.xlsx\n") 
    cat("  - excel365/Men_Top10_Odds_2026.xlsx\n")
    cat("  - excel365/Men_Top30_Odds_2026.xlsx\n")
    cat(sprintf("Men's odds export: %d athletes across 4 separate files\n", nrow(men_odds_export)))
    
  } else {
    cat("No men's odds data available for export\n")
  }
  
}, error = function(e) {
  cat("Error exporting men's odds to Excel:", e$message, "\n")
})
```

### Ladies Season Odds

```{r ladies-odds}
cat("=== LADIES ODDS VALIDATION ===\n")

# Validate ladies-specific formulas exist
if (!exists("topthree_formula_ladies") || !inherits(topthree_formula_ladies, "formula")) {
  stop("topthree_formula_ladies not found or invalid")
}
if (!exists("top5_formula_ladies") || !inherits(top5_formula_ladies, "formula")) {
  stop("top5_formula_ladies not found or invalid")
}
if (!exists("top10_formula_ladies") || !inherits(top10_formula_ladies, "formula")) {
  stop("top10_formula_ladies not found or invalid")
}
if (!exists("top30_formula_ladies") || !inherits(top30_formula_ladies, "formula")) {
  stop("top30_formula_ladies not found or invalid")
}
cat("✓ All ladies formulas validated\n")

# Validate ladies training data
cat("\n--- Ladies Model Training Data Validation ---\n")
if (!exists("df_place_ladies") || !is.data.frame(df_place_ladies)) {
  stop("df_place_ladies dataset not found or invalid")
}
if (nrow(df_place_ladies) == 0) {
  stop("df_place_ladies dataset is empty")
}

# Check for required target variables in ladies data
required_targets <- c("TopThree", "Top5", "Top10", "Top30")
missing_targets <- setdiff(required_targets, names(df_place_ladies))
if (length(missing_targets) > 0) {
  stop("Missing target variables in df_place_ladies: ", paste(missing_targets, collapse = ", "))
}

# Validate ladies target variable distributions
for (target in required_targets) {
  target_dist <- table(df_place_ladies[[target]], useNA = "always")
  cat("Ladies", target, "distribution:\n")
  print(target_dist)
  
  # Check for extreme class imbalance
  if (any(target_dist < 5, na.rm = TRUE)) {
    warning("Very few observations for ladies ", target, " - model may be unstable")
  }
}

cat("Ladies training data:", nrow(df_place_ladies), "observations\n")

# Fit ladies models with validation
cat("\n--- Ladies Model Training ---\n")
tryCatch({
  place_model_ladies <- glm(topthree_formula_ladies, family = binomial, data = df_place_ladies)
  
  # Validate model convergence
  if (!place_model_ladies$converged) {
    warning("Ladies TopThree model did not converge")
  }
  
  # Check for model fitting issues
  if (any(is.na(coef(place_model_ladies)))) {
    warning("Ladies TopThree model has NA coefficients - possible multicollinearity")
  }
  
  cat("✓ Ladies TopThree model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies TopThree model: ", e$message)
})

tryCatch({
  top5_model_ladies <- glm(top5_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top5_model_ladies$converged) warning("Ladies Top5 model did not converge")
  if (any(is.na(coef(top5_model_ladies)))) warning("Ladies Top5 model has NA coefficients")
  cat("✓ Ladies Top5 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top5 model: ", e$message)
})

tryCatch({
  top10_model_ladies <- glm(top10_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top10_model_ladies$converged) warning("Ladies Top10 model did not converge")
  if (any(is.na(coef(top10_model_ladies)))) warning("Ladies Top10 model has NA coefficients")
  cat("✓ Ladies Top10 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top10 model: ", e$message)
})

tryCatch({
  top30_model_ladies <- glm(top30_formula_ladies, family = binomial, data = df_place_ladies)
  
  if (!top30_model_ladies$converged) warning("Ladies Top30 model did not converge")
  if (any(is.na(coef(top30_model_ladies)))) warning("Ladies Top30 model has NA coefficients")
  cat("✓ Ladies Top30 model fitted successfully\n")
  
}, error = function(e) {
  stop("Error fitting ladies Top30 model: ", e$message)
})

# Validate ladies prediction data
cat("\n--- Ladies Prediction Data Validation ---\n")
if (!exists("pred_data_ladies") || !is.data.frame(pred_data_ladies)) {
  stop("pred_data_ladies dataset not found or invalid")
}
if (nrow(pred_data_ladies) == 0) {
  stop("pred_data_ladies dataset is empty")
}

# Check for required features in ladies prediction data
all_required_features <- unique(c(topthree_features_ladies, top5_features_ladies, top10_features_ladies, top30_features_ladies))
missing_pred_features <- setdiff(all_required_features, names(pred_data_ladies))
if (length(missing_pred_features) > 0) {
  warning("Missing features in ladies prediction data: ", paste(missing_pred_features, collapse = ", "))
}

cat("Ladies prediction dataset has", nrow(pred_data_ladies), "observations and", ncol(pred_data_ladies), "variables\n")

# Get predicted probabilities for ladies with validation
cat("\n--- Ladies Model Predictions ---\n")
tryCatch({
  top3_probs_ladies <- predict(place_model_ladies, pred_data_ladies, type = "response")
  
  # Validate predictions
  if (any(is.na(top3_probs_ladies))) {
    warning("NA predictions detected for ladies TopThree - ", sum(is.na(top3_probs_ladies)), " out of ", length(top3_probs_ladies))
  }
  if (any(top3_probs_ladies < 0 | top3_probs_ladies > 1, na.rm = TRUE)) {
    warning("Invalid probability values for ladies TopThree (outside 0-1 range)")
  }
  
  cat("✓ Ladies TopThree predictions generated - Range: [", round(min(top3_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top3_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies TopThree predictions: ", e$message)
})

tryCatch({
  top5_probs_ladies <- predict(top5_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top5_probs_ladies))) warning("NA predictions for ladies Top5")
  if (any(top5_probs_ladies < 0 | top5_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top5 probabilities")
  
  cat("✓ Ladies Top5 predictions generated - Range: [", round(min(top5_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top5_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top5 predictions: ", e$message)
})

tryCatch({
  top10_probs_ladies <- predict(top10_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top10_probs_ladies))) warning("NA predictions for ladies Top10")
  if (any(top10_probs_ladies < 0 | top10_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top10 probabilities")
  
  cat("✓ Ladies Top10 predictions generated - Range: [", round(min(top10_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top10_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top10 predictions: ", e$message)
})

tryCatch({
  top30_probs_ladies <- predict(top30_model_ladies, pred_data_ladies, type = "response")
  
  if (any(is.na(top30_probs_ladies))) warning("NA predictions for ladies Top30")
  if (any(top30_probs_ladies < 0 | top30_probs_ladies > 1, na.rm = TRUE)) warning("Invalid ladies Top30 probabilities")
  
  cat("✓ Ladies Top30 predictions generated - Range: [", round(min(top30_probs_ladies, na.rm = TRUE), 4), ", ", 
      round(max(top30_probs_ladies, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error generating ladies Top30 predictions: ", e$message)
})

# ========== NORMALIZATION FOR LADIES ODDS ==========
cat("\n--- Normalizing Ladies Probabilities ---\n")

# Normalize ladies probabilities
# Win probabilities should sum to 100% (1.0)
total_win_prob_ladies <- sum(top3_probs_ladies * 0.33, na.rm = TRUE)
if (total_win_prob_ladies > 0) {
  win_probs_normalized_ladies <- (top3_probs_ladies * 0.33) / total_win_prob_ladies
  second_probs_normalized_ladies <- win_probs_normalized_ladies
  third_probs_normalized_ladies <- win_probs_normalized_ladies
} else {
  win_probs_normalized_ladies <- top3_probs_ladies * 0.33
  second_probs_normalized_ladies <- top3_probs_ladies * 0.33
  third_probs_normalized_ladies <- top3_probs_ladies * 0.34
}

# Top3 probabilities should sum to 300% (3.0)
total_top3_prob_ladies <- sum(top3_probs_ladies, na.rm = TRUE)
if (total_top3_prob_ladies > 0) {
  top3_probs_normalized_ladies <- (top3_probs_ladies / total_top3_prob_ladies) * 3.0
} else {
  top3_probs_normalized_ladies <- top3_probs_ladies
}

# Top5 probabilities should sum to 500% (5.0)
total_top5_prob_ladies <- sum(top5_probs_ladies, na.rm = TRUE)
if (total_top5_prob_ladies > 0) {
  top5_probs_normalized_ladies <- (top5_probs_ladies / total_top5_prob_ladies) * 5.0
} else {
  top5_probs_normalized_ladies <- top5_probs_ladies
}

# Top10 probabilities should sum to 1000% (10.0)
total_top10_prob_ladies <- sum(top10_probs_ladies, na.rm = TRUE)
if (total_top10_prob_ladies > 0) {
  top10_probs_normalized_ladies <- (top10_probs_ladies / total_top10_prob_ladies) * 10.0
} else {
  top10_probs_normalized_ladies <- top10_probs_ladies
}

# Top30 probabilities should sum to 3000% (30.0)
total_top30_prob_ladies <- sum(top30_probs_ladies, na.rm = TRUE)
if (total_top30_prob_ladies > 0) {
  top30_probs_normalized_ladies <- (top30_probs_ladies / total_top30_prob_ladies) * 30.0
} else {
  top30_probs_normalized_ladies <- top30_probs_ladies
}

cat("Ladies Normalization applied:\n")
cat("Win probs sum:", round(sum(win_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 1.0)\n")
cat("Top3 probs sum:", round(sum(top3_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 3.0)\n")
cat("Top5 probs sum:", round(sum(top5_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 5.0)\n")
cat("Top10 probs sum:", round(sum(top10_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 10.0)\n")
cat("Top30 probs sum:", round(sum(top30_probs_normalized_ladies, na.rm = TRUE), 3), "(target: 30.0)\n")

# Create ladies results dataframe with validation
cat("\n--- Ladies Results DataFrame Creation ---\n")

# Validate required columns in pred_data_ladies
required_id_cols <- c("Skier", "Nation")
missing_id_cols <- setdiff(required_id_cols, names(pred_data_ladies))
if (length(missing_id_cols) > 0) {
  stop("Missing identification columns in pred_data_ladies: ", paste(missing_id_cols, collapse = ", "))
}

tryCatch({
  # Create ladies results dataframe with all probabilities (USING NORMALIZED VALUES)
  # Note: Since TopThree is now binary, we don't have separate win/second/third probs
  results_ladies <- data.frame(
    Skier = pred_data_ladies$Skier,
    Nation = pred_data_ladies$Nation,
    Top3_Prob = top3_probs_normalized_ladies,    # Normalized Top3 probability
    Win_Prob = win_probs_normalized_ladies,      # Normalized win probability
    Second_Prob = second_probs_normalized_ladies, # Normalized second probability
    Third_Prob = third_probs_normalized_ladies,  # Normalized third probability
    Top5_Prob = top5_probs_normalized_ladies,    # Normalized Top5 probability
    Top10_Prob = top10_probs_normalized_ladies,  # Normalized Top10 probability
    Top30_Prob = top30_probs_normalized_ladies,  # Normalized Top30 probability
    Outside_Prob = 1 - (top30_probs_normalized_ladies / 30.0)  # Adjusted for normalization
  )
  
  # Validate ladies results dataframe
  if (nrow(results_ladies) == 0) stop("Ladies results dataframe is empty")
  if (any(is.na(results_ladies$Skier))) warning("Missing skier names in ladies results")
  
  # Check probability consistency for ladies
  invalid_prob_consistency <- sum(results_ladies$Top3_Prob > results_ladies$Top5_Prob | 
                                  results_ladies$Top5_Prob > results_ladies$Top10_Prob | 
                                  results_ladies$Top10_Prob > results_ladies$Top30_Prob, na.rm = TRUE)
  
  if (invalid_prob_consistency > 0) {
    warning("Probability inconsistency detected in ", invalid_prob_consistency, " ladies cases (P(smaller) > P(larger))")
  }
  
  cat("✓ Ladies results dataframe created with", nrow(results_ladies), "skiers\n")
  cat("Ladies probability ranges - Top3: [", round(min(results_ladies$Top3_Prob, na.rm = TRUE), 4), ", ", 
      round(max(results_ladies$Top3_Prob, na.rm = TRUE), 4), "]\n")
  
}, error = function(e) {
  stop("Error creating ladies results dataframe: ", e$message)
})

# Calculate ladies decimal and American odds with validation
cat("\n--- Ladies Odds Calculation ---\n")
tryCatch({
  results_ladies <- results_ladies %>%
    mutate(
      Win_Decimal_Odds = ifelse(Win_Prob > 0, 1 / Win_Prob, Inf),
      Win_American_Odds = ifelse(Win_Prob >= 0.5,
                                -Win_Prob/(1-Win_Prob) * 100,
                                (1-Win_Prob)/Win_Prob * 100),
      Top3_Decimal_Odds = ifelse(Top3_Prob > 0, 1 / Top3_Prob, Inf),
      Top3_American_Odds = ifelse(Top3_Prob >= 0.5,
                                 -Top3_Prob/(1-Top3_Prob) * 100,
                                 (1-Top3_Prob)/Top3_Prob * 100),
      Top5_Decimal_Odds = ifelse(Top5_Prob > 0, 1 / Top5_Prob, Inf),
      Top5_American_Odds = ifelse(Top5_Prob >= 0.5,
                                 -Top5_Prob/(1-Top5_Prob) * 100,
                                 (1-Top5_Prob)/Top5_Prob * 100),
      Top10_Decimal_Odds = ifelse(Top10_Prob > 0, 1 / Top10_Prob, Inf),
      Top10_American_Odds = ifelse(Top10_Prob >= 0.5,
                                  -Top10_Prob/(1-Top10_Prob) * 100,
                                  (1-Top10_Prob)/Top10_Prob * 100),
      Top30_Decimal_Odds = ifelse(Top30_Prob > 0, 1 / Top30_Prob, Inf),
      Top30_American_Odds = ifelse(Top30_Prob >= 0.5,
                                  -Top30_Prob/(1-Top30_Prob) * 100,
                                  (1-Top30_Prob)/Top30_Prob * 100)
    ) %>%
    # Format ladies probabilities and odds with validation
    mutate(
      Win_Prob = ifelse(is.na(Win_Prob), "N/A", sprintf("%.1f%%", Win_Prob * 100)),
      Second_Prob = ifelse(is.na(Second_Prob), "N/A", sprintf("%.1f%%", Second_Prob * 100)),
      Third_Prob = ifelse(is.na(Third_Prob), "N/A", sprintf("%.1f%%", Third_Prob * 100)),
      Top3_Prob = ifelse(is.na(Top3_Prob), "N/A", sprintf("%.1f%%", Top3_Prob * 100)),
      Top5_Prob = ifelse(is.na(Top5_Prob), "N/A", sprintf("%.1f%%", Top5_Prob * 100)),
      Top10_Prob = ifelse(is.na(Top10_Prob), "N/A", sprintf("%.1f%%", Top10_Prob * 100)),
      Top30_Prob = ifelse(is.na(Top30_Prob), "N/A", sprintf("%.1f%%", Top30_Prob * 100)),
      Outside_Prob = ifelse(is.na(Outside_Prob), "N/A", sprintf("%.1f%%", Outside_Prob * 100)),
      
      # Round ladies decimal odds with Inf handling
      Win_Decimal_Odds = ifelse(is.infinite(Win_Decimal_Odds), 999.99, 
                               ifelse(Win_Decimal_Odds > 999.99, 999.99, round(Win_Decimal_Odds, 2))),
      Top3_Decimal_Odds = ifelse(is.infinite(Top3_Decimal_Odds), 999.99, 
                                ifelse(Top3_Decimal_Odds > 999.99, 999.99, round(Top3_Decimal_Odds, 2))),
      Top5_Decimal_Odds = ifelse(is.infinite(Top5_Decimal_Odds), 999.99, 
                                ifelse(Top5_Decimal_Odds > 999.99, 999.99, round(Top5_Decimal_Odds, 2))),
      Top10_Decimal_Odds = ifelse(is.infinite(Top10_Decimal_Odds), 999.99, 
                                 ifelse(Top10_Decimal_Odds > 999.99, 999.99, round(Top10_Decimal_Odds, 2))),
      Top30_Decimal_Odds = ifelse(is.infinite(Top30_Decimal_Odds), 999.99, 
                                 ifelse(Top30_Decimal_Odds > 999.99, 999.99, round(Top30_Decimal_Odds, 2))),
      
      # Format ladies American odds with validation
      Win_American_Odds = ifelse(is.na(Win_American_Odds) | is.infinite(Win_American_Odds), "N/A",
                                ifelse(Win_American_Odds > 0, 
                                      sprintf("+%.0f", round(Win_American_Odds, 0)),
                                      sprintf("%.0f", round(Win_American_Odds, 0)))),
      Top3_American_Odds = ifelse(is.na(Top3_American_Odds) | is.infinite(Top3_American_Odds), "N/A",
                                 ifelse(Top3_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top3_American_Odds, 0)),
                                       sprintf("%.0f", round(Top3_American_Odds, 0)))),
      Top5_American_Odds = ifelse(is.na(Top5_American_Odds) | is.infinite(Top5_American_Odds), "N/A",
                                 ifelse(Top5_American_Odds > 0, 
                                       sprintf("+%.0f", round(Top5_American_Odds, 0)),
                                       sprintf("%.0f", round(Top5_American_Odds, 0)))),
      Top10_American_Odds = ifelse(is.na(Top10_American_Odds) | is.infinite(Top10_American_Odds), "N/A",
                                  ifelse(Top10_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top10_American_Odds, 0)),
                                        sprintf("%.0f", round(Top10_American_Odds, 0)))),
      Top30_American_Odds = ifelse(is.na(Top30_American_Odds) | is.infinite(Top30_American_Odds), "N/A",
                                  ifelse(Top30_American_Odds > 0, 
                                        sprintf("+%.0f", round(Top30_American_Odds, 0)),
                                        sprintf("%.0f", round(Top30_American_Odds, 0))))
    )
  
  # Validate ladies sorting and arrange results
  numeric_win_probs_ladies <- as.numeric(sub("%", "", results_ladies$Win_Prob))
  if (any(is.na(numeric_win_probs_ladies))) {
    warning("Some ladies Win_Prob values could not be converted to numeric for sorting")
  }
  
  results_ladies <- results_ladies %>% arrange(desc(numeric_win_probs_ladies))
  
  cat("✓ Ladies odds calculation and formatting completed\n")
  
}, error = function(e) {
  stop("Error calculating ladies odds: ", e$message)
})

cat("\n--- Ladies Final Results Summary ---\n")
cat("Total ladies with odds:", nrow(results_ladies), "\n")
cat("Ladies with valid Win probabilities:", sum(results_ladies$Win_Prob != "N/A"), "\n")
cat("Highest ladies win probability:", max(numeric_win_probs_ladies, na.rm = TRUE), "%\n")

print("=== 2026 LADIES SEASON ODDS ===")
print("Top 10 Ladies Season Winner Odds:")
print(results_ladies %>% 
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      head(10))

print("Top 10 Ladies Podium Finish Odds:")
print(results_ladies %>% 
      arrange(desc(as.numeric(sub("%", "", Top3_Prob)))) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      head(10))

print("Top 10 Ladies Top-10 Finish Odds:")
print(results_ladies %>% 
      arrange(desc(as.numeric(sub("%", "", Top10_Prob)))) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      head(10))

# Store ladies results with validation
tryCatch({
  # Final validation before storage
  if (nrow(results_ladies) == 0) stop("No ladies results to store")
  if (all(results_ladies$Win_Prob == "N/A")) warning("All ladies win probabilities are N/A")
  
  cat("✓ Ladies results stored successfully with", nrow(results_ladies), "skiers\n")
  
}, error = function(e) {
  stop("Error storing ladies results: ", e$message)
})

# Export Ladies Odds to Excel
cat("\n=== EXPORTING LADIES ODDS TO EXCEL ===\n")

tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  if (!is.null(results_ladies) && nrow(results_ladies) > 0) {
    # Prepare data with numeric probabilities for proper sorting
    ladies_odds_export <- results_ladies %>%
      mutate(
        # Convert probability percentages to numeric for proper handling
        Win_Prob_Numeric = as.numeric(gsub("%", "", Win_Prob)),
        Top3_Prob_Numeric = as.numeric(gsub("%", "", Top3_Prob)),
        Top10_Prob_Numeric = as.numeric(gsub("%", "", Top10_Prob)),
        Top30_Prob_Numeric = as.numeric(gsub("%", "", Top30_Prob)),
        # Convert decimal odds to numeric for proper handling
        Win_Decimal_Numeric = as.numeric(Win_Decimal_Odds),
        Top3_Decimal_Numeric = as.numeric(Top3_Decimal_Odds),
        Top10_Decimal_Numeric = as.numeric(Top10_Decimal_Odds),
        Top30_Decimal_Numeric = as.numeric(Top30_Decimal_Odds)
      ) %>%
      # Create separate tables for each outcome
      arrange(desc(Win_Prob_Numeric))
    
    # Create separate Excel files for each outcome type
    
    # Win odds file
    win_data <- ladies_odds_export %>%
      dplyr::select(Skier, Nation, Win_Prob, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(
        "Win Prob" = Win_Prob,
        "Win Decimal Odds" = Win_Decimal_Odds,
        "Win American Odds" = Win_American_Odds
      )
    
    win_wb <- createWorkbook()
    addWorksheet(win_wb, "Ladies Win Odds 2026")
    writeData(win_wb, "Ladies Win Odds 2026", win_data, startRow = 1, startCol = 1)
    addStyle(win_wb, "Ladies Win Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(win_data))
    setColWidths(win_wb, "Ladies Win Odds 2026", cols = 1:ncol(win_data), widths = "auto")
    saveWorkbook(win_wb, "excel365/Ladies_Win_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 3 odds file
    top3_data <- ladies_odds_export %>%
      arrange(desc(Top3_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top3_Prob, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(
        "Top 3 Prob" = Top3_Prob,
        "Top 3 Decimal Odds" = Top3_Decimal_Odds,
        "Top 3 American Odds" = Top3_American_Odds
      )
    
    top3_wb <- createWorkbook()
    addWorksheet(top3_wb, "Ladies Top 3 Odds 2026")
    writeData(top3_wb, "Ladies Top 3 Odds 2026", top3_data, startRow = 1, startCol = 1)
    addStyle(top3_wb, "Ladies Top 3 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top3_data))
    setColWidths(top3_wb, "Ladies Top 3 Odds 2026", cols = 1:ncol(top3_data), widths = "auto")
    saveWorkbook(top3_wb, "excel365/Ladies_Top3_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 10 odds file
    top10_data <- ladies_odds_export %>%
      arrange(desc(Top10_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top10_Prob, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(
        "Top 10 Prob" = Top10_Prob,
        "Top 10 Decimal Odds" = Top10_Decimal_Odds,
        "Top 10 American Odds" = Top10_American_Odds
      )
    
    top10_wb <- createWorkbook()
    addWorksheet(top10_wb, "Ladies Top 10 Odds 2026")
    writeData(top10_wb, "Ladies Top 10 Odds 2026", top10_data, startRow = 1, startCol = 1)
    addStyle(top10_wb, "Ladies Top 10 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top10_data))
    setColWidths(top10_wb, "Ladies Top 10 Odds 2026", cols = 1:ncol(top10_data), widths = "auto")
    saveWorkbook(top10_wb, "excel365/Ladies_Top10_Odds_2026.xlsx", overwrite = TRUE)
    
    # Top 30 odds file
    top30_data <- ladies_odds_export %>%
      arrange(desc(Top30_Prob_Numeric)) %>%
      dplyr::select(Skier, Nation, Top30_Prob, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(
        "Top 30 Prob" = Top30_Prob,
        "Top 30 Decimal Odds" = Top30_Decimal_Odds,
        "Top 30 American Odds" = Top30_American_Odds
      )
    
    top30_wb <- createWorkbook()
    addWorksheet(top30_wb, "Ladies Top 30 Odds 2026")
    writeData(top30_wb, "Ladies Top 30 Odds 2026", top30_data, startRow = 1, startCol = 1)
    addStyle(top30_wb, "Ladies Top 30 Odds 2026", 
             createStyle(fgFill = "#4472C4", fontColour = "white", textDecoration = "bold"),
             rows = 1, cols = 1:ncol(top30_data))
    setColWidths(top30_wb, "Ladies Top 30 Odds 2026", cols = 1:ncol(top30_data), widths = "auto")
    saveWorkbook(top30_wb, "excel365/Ladies_Top30_Odds_2026.xlsx", overwrite = TRUE)
    
    cat("✓ Ladies odds Excel files saved:\n")
    cat("  - excel365/Ladies_Win_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top3_Odds_2026.xlsx\n") 
    cat("  - excel365/Ladies_Top10_Odds_2026.xlsx\n")
    cat("  - excel365/Ladies_Top30_Odds_2026.xlsx\n")
    cat(sprintf("Ladies odds export: %d athletes across 4 separate files\n", nrow(ladies_odds_export)))
    
  } else {
    cat("No ladies odds data available for export\n")
  }
  
}, error = function(e) {
  cat("Error exporting ladies odds to Excel:", e$message, "\n")
})
```

### Breakthrough Analysis

```{r breakout-identifier}
cat("=== BREAKTHROUGH ANALYSIS VALIDATION ===\n")

# Validate training data availability
if (!exists("train_men") || !is.data.frame(train_men)) {
  stop("train_men dataset not found or invalid")
}
if (!exists("train_ladies") || !is.data.frame(train_ladies)) {
  stop("train_ladies dataset not found or invalid")
}

if (nrow(train_men) == 0) stop("train_men dataset is empty")
if (nrow(train_ladies) == 0) stop("train_ladies dataset is empty")

cat("Training data validated - Men:", nrow(train_men), "observations, Ladies:", nrow(train_ladies), "observations\n")

# Validate required columns for breakthrough analysis
required_breakthrough_cols <- c("Skier", "Nation", "Season", "Pct_of_Max_Points", "Age")
missing_men_cols <- setdiff(required_breakthrough_cols, names(train_men))
missing_ladies_cols <- setdiff(required_breakthrough_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop("Missing required columns in train_men: ", paste(missing_men_cols, collapse = ", "))
}
if (length(missing_ladies_cols) > 0) {
  stop("Missing required columns in train_ladies: ", paste(missing_ladies_cols, collapse = ", "))
}
cat("✓ All required columns present in both datasets\n")

# Validate Pct_of_Max_Points data quality
cat("\n--- Data Quality Validation ---\n")

# Men's data validation
men_invalid_pct <- sum(is.na(train_men$Pct_of_Max_Points) | 
                      train_men$Pct_of_Max_Points < 0 | 
                      train_men$Pct_of_Max_Points > 1 | 
                      !is.finite(train_men$Pct_of_Max_Points))

ladies_invalid_pct <- sum(is.na(train_ladies$Pct_of_Max_Points) | 
                         train_ladies$Pct_of_Max_Points < 0 | 
                         train_ladies$Pct_of_Max_Points > 1 | 
                         !is.finite(train_ladies$Pct_of_Max_Points))

cat("Men's invalid Pct_of_Max_Points values:", men_invalid_pct, "\n")
cat("Ladies invalid Pct_of_Max_Points values:", ladies_invalid_pct, "\n")

if (men_invalid_pct > nrow(train_men) * 0.1) {
  warning("More than 10% of men's Pct_of_Max_Points values are invalid")
}
if (ladies_invalid_pct > nrow(train_ladies) * 0.1) {
  warning("More than 10% of ladies Pct_of_Max_Points values are invalid")
}

# Identify historical top performers with validation
cat("\n--- Historical Top Performers Analysis ---\n")

tryCatch({
  top_performers_men <- train_men %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.5,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_men) == 0) {
    warning("No men's breakthrough performers found with >50% points")
  } else {
    cat("✓ Men's breakthrough performers identified:", nrow(top_performers_men), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying men's top performers: ", e$message)
})

tryCatch({
  top_performers_ladies <- train_ladies %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.5,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_ladies) == 0) {
    warning("No ladies breakthrough performers found with >50% points")
  } else {
    cat("✓ Ladies breakthrough performers identified:", nrow(top_performers_ladies), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying ladies top performers: ", e$message)
})

# Summary and analysis with validation
cat("\n--- Breakthrough Summary Analysis ---\n")

tryCatch({
  unique_men_breakthroughs <- length(unique(top_performers_men$Skier))
  unique_ladies_breakthroughs <- length(unique(top_performers_ladies$Skier))
  
  cat("✓ Analysis completed successfully\n")
  cat("Men's breakthrough entries:", nrow(top_performers_men), "\n")
  cat("Ladies breakthrough entries:", nrow(top_performers_ladies), "\n")
  
  print("=== MEN'S HISTORICAL BREAKTHROUGH PERFORMERS (>50% of max points) ===")
  print(paste("Unique men's breakthrough skiers:", unique_men_breakthroughs))
  
  if (nrow(top_performers_men) > 0) {
    print("Recent men's breakthrough examples:")
    recent_men <- top_performers_men %>%
      arrange(desc(Season), desc(Pct_of_Max_Points)) %>%
      head(15)
    print(recent_men)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_men$Age))) {
      cat("Men's breakthrough age range:", 
          round(min(top_performers_men$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_men$Age, na.rm = TRUE), 1), "\n")
      cat("Men's mean breakthrough age:", 
          round(mean(top_performers_men$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No men's breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in men's breakthrough summary: ", e$message)
})

tryCatch({
  print("=== LADIES HISTORICAL BREAKTHROUGH PERFORMERS (>50% of max points) ===")
  print(paste("Unique ladies breakthrough skiers:", unique_ladies_breakthroughs))
  
  if (nrow(top_performers_ladies) > 0) {
    print("Recent ladies breakthrough examples:")
    recent_ladies <- top_performers_ladies %>%
      arrange(desc(Season), desc(Pct_of_Max_Points)) %>%
      head(15)
    print(recent_ladies)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_ladies$Age))) {
      cat("Ladies breakthrough age range:", 
          round(min(top_performers_ladies$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
      cat("Ladies mean breakthrough age:", 
          round(mean(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No ladies breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in ladies breakthrough summary: ", e$message)
})
```

### Breakthrough Feature Selection

```{r feat-sel-break}
cat("=== BREAKTHROUGH FEATURE SELECTION VALIDATION ===\n")

# Validate required libraries
tryCatch({
  library(caret)
  library(ggrepel)
  cat("✓ Required libraries loaded successfully\n")
}, error = function(e) {
  stop("Error loading required libraries: ", e$message)
})

# Enhanced function to evaluate predictor importance for breakthrough prediction
evaluate_breakthrough_predictors <- function(df, predictors) {
  cat("\n--- Breakthrough Predictor Evaluation ---\n")
  
  # Input validation
  if (!is.data.frame(df)) stop("Input df is not a data frame")
  if (nrow(df) == 0) stop("Input dataframe is empty")
  if (length(predictors) == 0) stop("No predictors provided")
  
  # Check required columns
  required_cols <- c("Pct_of_Max_Points", "Age")
  missing_cols <- setdiff(required_cols, names(df))
  if (length(missing_cols) > 0) {
    stop("Missing required columns: ", paste(missing_cols, collapse = ", "))
  }
  
  # Check predictor availability
  missing_predictors <- setdiff(predictors, names(df))
  if (length(missing_predictors) > 0) {
    warning("Missing predictors: ", paste(missing_predictors, collapse = ", "))
    predictors <- intersect(predictors, names(df))
  }
  
  if (length(predictors) == 0) stop("No valid predictors remain after filtering")
  cat("Using", length(predictors), "predictors for breakthrough analysis\n")
  
  # Prepare data with validation and adaptive age filtering
  tryCatch({
    # First, try broader age range to get sufficient breakthrough cases
    initial_data <- df %>%
      mutate(
        # Define breakthrough as achieving >50% in this season
        Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.5),
        Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                 labels = c("No", "Yes")),
        Age = as.numeric(Age)
      ) %>%
      filter(!is.na(Will_Breakthrough), 
             !is.na(Pct_of_Max_Points),
             !is.na(Age)) %>%
      dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
      na.omit()
    
    # Check breakthrough distribution across age ranges
    breakthrough_by_age <- initial_data %>%
      filter(Will_Breakthrough == "Yes") %>%
      summarise(
        n_breakthroughs = n(),
        min_age = min(Age, na.rm = TRUE),
        max_age = max(Age, na.rm = TRUE),
        mean_age = mean(Age, na.rm = TRUE)
      )
    
    cat("Initial breakthrough cases found:", breakthrough_by_age$n_breakthroughs, "\n")
    if (breakthrough_by_age$n_breakthroughs > 0) {
      cat("Breakthrough age range:", round(breakthrough_by_age$min_age, 1), "-", round(breakthrough_by_age$max_age, 1), "\n")
    }
    
    # If still too few cases, try lower breakthrough threshold
    if (breakthrough_by_age$n_breakthroughs < 5) {
      cat("Very few breakthrough cases at 50% threshold, trying 40% threshold\n")
      initial_data <- df %>%
        mutate(
          # Lower threshold for breakthrough
          Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.4),
          Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                   labels = c("No", "Yes")),
          Age = as.numeric(Age)
        ) %>%
        filter(!is.na(Will_Breakthrough), 
               !is.na(Pct_of_Max_Points),
               !is.na(Age)) %>%
        dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
        na.omit()
      
      # Recalculate breakthrough stats
      breakthrough_by_age <- initial_data %>%
        filter(Will_Breakthrough == "Yes") %>%
        summarise(
          n_breakthroughs = n(),
          min_age = min(Age, na.rm = TRUE),
          max_age = max(Age, na.rm = TRUE),
          mean_age = mean(Age, na.rm = TRUE)
        )
      
      cat("Breakthrough cases at 40% threshold:", breakthrough_by_age$n_breakthroughs, "\n")
    }
    
    # Adaptive age filtering based on available data
    if (breakthrough_by_age$n_breakthroughs < 10) {
      # Use all ages if very few breakthrough cases
      age_cutoff <- max(initial_data$Age, na.rm = TRUE)
      cat("Using all ages (insufficient breakthrough cases under 30)\n")
    } else if (breakthrough_by_age$n_breakthroughs < 30) {
      # Use age 35 cutoff if moderate breakthrough cases
      age_cutoff <- 35
      cat("Using age cutoff of 35 (moderate breakthrough cases)\n")
    } else {
      # Use original age 30 cutoff if sufficient cases
      age_cutoff <- 30
      cat("Using age cutoff of 30 (sufficient breakthrough cases)\n")
    }
    
    model_data <- initial_data %>%
      filter(Age <= age_cutoff) %>%
      dplyr::select(Will_Breakthrough, all_of(predictors))
    
    cat("✓ Data preparation completed with age cutoff:", age_cutoff, "\n")
    
  }, error = function(e) {
    stop("Error in data preparation: ", e$message)
  })
  
  # Validate prepared data
  if (nrow(model_data) == 0) {
    stop("No valid data remains after filtering")
  }
  
  print("Breakthrough data dimensions after filtering:")
  print(dim(model_data))
  
  # Validate class distribution
  breakthrough_dist <- table(model_data$Will_Breakthrough, useNA = "always")
  print("Breakthrough distribution:")
  print(breakthrough_dist)
  
  # Check for class imbalance with adaptive thresholds
  min_class_size <- min(breakthrough_dist[breakthrough_dist > 0])  # Exclude NA count
  breakthrough_count <- breakthrough_dist[["Yes"]]
  no_breakthrough_count <- breakthrough_dist[["No"]]
  
  cat("Breakthrough cases (Yes):", breakthrough_count, "\n")
  cat("Non-breakthrough cases (No):", no_breakthrough_count, "\n")
  
  # Adaptive validation based on data availability
  if (min_class_size < 2) {
    stop("Insufficient data for model training - need at least 2 cases per class")
  } else if (min_class_size < 5) {
    warning("Very few cases in minority class (", min_class_size, ") - model may be unstable")
  } else if (breakthrough_count < 10) {
    warning("Few breakthrough cases (", breakthrough_count, ") - consider this when interpreting results")
  }
  
  # Calculate class imbalance ratio
  imbalance_ratio <- max(breakthrough_count, no_breakthrough_count) / min(breakthrough_count, no_breakthrough_count)
  if (imbalance_ratio > 20) {
    warning("Severe class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  } else if (imbalance_ratio > 10) {
    warning("Moderate class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  }
  
  # Validate examples with error handling
  tryCatch({
    print("Sample breakthrough cases (Will_Breakthrough = Yes):")
    breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "Yes") %>% 
      head(10)
    
    if(nrow(breakthrough_examples) > 0) {
      print(breakthrough_examples)
      cat("✓ Breakthrough examples validated\n")
    } else {
      warning("No breakthrough examples found in filtered data!")
    }
    
  }, error = function(e) {
    warning("Error displaying breakthrough examples: ", e$message)
  })
  
  tryCatch({
    print("Sample non-breakthrough cases (Will_Breakthrough = No):")
    non_breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "No") %>% 
      head(5)
    print(non_breakthrough_examples)
    cat("✓ Non-breakthrough examples validated\n")
    
  }, error = function(e) {
    warning("Error displaying non-breakthrough examples: ", e$message)
  })
  
  # Set up cross-validation with validation
  cat("\n--- Model Training Setup ---\n")
  tryCatch({
    ctrl <- trainControl(
      method = "cv",
      number = 5,
      classProbs = TRUE,
      summaryFunction = twoClassSummary,
      verboseIter = FALSE
    )
    cat("✓ Cross-validation control setup completed\n")
  }, error = function(e) {
    stop("Error setting up cross-validation: ", e$message)
  })
  
  # Train logistic model with validation
  tryCatch({
    breakthrough_formula <- as.formula(paste("Will_Breakthrough ~", paste(predictors, collapse = " + ")))
    cat("Training logistic regression model with", length(predictors), "predictors\n")
    
    logistic_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "glm",
      family = "binomial",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Validate logistic model
    if (is.null(logistic_model)) {
      stop("Logistic model training failed")
    }
    
    logistic_roc <- max(logistic_model$results$ROC, na.rm = TRUE)
    if (is.na(logistic_roc) || logistic_roc < 0.5) {
      warning("Logistic model performance is poor (ROC < 0.5)")
    }
    
    cat("✓ Logistic model trained successfully - ROC:", round(logistic_roc, 3), "\n")
    
  }, error = function(e) {
    stop("Error training logistic model: ", e$message)
  })
  
  # Train Random Forest with validation
  tryCatch({
    cat("Training Random Forest model for variable importance\n")
    
    rf_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "ranger",
      trControl = ctrl,
      importance = 'impurity',
      metric = "ROC"
    )
    
    # Validate RF model
    if (is.null(rf_model)) {
      stop("Random Forest model training failed")
    }
    
    rf_roc <- max(rf_model$results$ROC, na.rm = TRUE)
    if (is.na(rf_roc) || rf_roc < 0.5) {
      warning("Random Forest model performance is poor (ROC < 0.5)")
    }
    
    cat("✓ Random Forest model trained successfully - ROC:", round(rf_roc, 3), "\n")
    
  }, error = function(e) {
    stop("Error training Random Forest model: ", e$message)
  })
  
  # Get variable importance with validation
  cat("\n--- Variable Importance Analysis ---\n")
  tryCatch({
    log_importance <- varImp(logistic_model)$importance
    rf_importance <- varImp(rf_model)$importance
    
    # Validate importance extraction
    if (is.null(log_importance) || nrow(log_importance) == 0) {
      stop("Failed to extract logistic model importance")
    }
    if (is.null(rf_importance) || nrow(rf_importance) == 0) {
      stop("Failed to extract Random Forest importance")
    }
    
    cat("✓ Variable importance extracted successfully\n")
    
  }, error = function(e) {
    stop("Error extracting variable importance: ", e$message)
  })
  
  # Combine importance scores with validation
  tryCatch({
    importance_df <- data.frame(
      Predictor = rownames(log_importance),
      Logistic_Importance = log_importance$Overall,
      RF_Importance = rf_importance$Overall
    ) %>%
      mutate(
        # Scale both importance measures before averaging
        Scaled_Log = as.numeric(scale(Logistic_Importance)),
        Scaled_RF = as.numeric(scale(RF_Importance)),
        Avg_Importance = (Scaled_Log + Scaled_RF) / 2
      ) %>%
      arrange(desc(Avg_Importance))
    
    # Validate importance combination
    if (nrow(importance_df) == 0) {
      stop("Failed to combine importance scores")
    }
    
    cat("✓ Importance scores combined successfully\n")
    
  }, error = function(e) {
    stop("Error combining importance scores: ", e$message)
  })
  
  # Identify top predictors with validation
  tryCatch({
    mean_importance <- mean(importance_df$Avg_Importance, na.rm = TRUE)
    top_predictors <- importance_df %>%
      filter(Avg_Importance > mean_importance) %>%
      pull(Predictor)
    
    if (length(top_predictors) == 0) {
      warning("No predictors above average importance - using top 3")
      top_predictors <- head(importance_df$Predictor, 3)
    }
    
    cat("✓ Top", length(top_predictors), "predictors identified\n")
    
  }, error = function(e) {
    stop("Error identifying top predictors: ", e$message)
  })
  
  # Test reduced model with validation
  tryCatch({
    cat("Training reduced model with top predictors\n")
    
    reduced_formula <- as.formula(paste("Will_Breakthrough ~", paste(top_predictors, collapse = " + ")))
    reduced_model <- train(
      reduced_formula,
      data = model_data,
      method = "glm",
      family = "binomial",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Validate reduced model
    if (is.null(reduced_model)) {
      stop("Reduced model training failed")
    }
    
    reduced_roc <- max(reduced_model$results$ROC, na.rm = TRUE)
    cat("✓ Reduced model trained successfully - ROC:", round(reduced_roc, 3), "\n")
    
  }, error = function(e) {
    stop("Error training reduced model: ", e$message)
  })
  
  # Model comparison with validation
  tryCatch({
    full_roc <- max(logistic_model$results$ROC, na.rm = TRUE)
    reduced_roc <- max(reduced_model$results$ROC, na.rm = TRUE)
    
    model_comparison <- data.frame(
      Model = c("Full", "Reduced"),
      ROC = c(full_roc, reduced_roc),
      Predictors = c(length(predictors), length(top_predictors)),
      Performance = c(
        ifelse(full_roc >= 0.7, "Good", ifelse(full_roc >= 0.6, "Fair", "Poor")),
        ifelse(reduced_roc >= 0.7, "Good", ifelse(reduced_roc >= 0.6, "Fair", "Poor"))
      )
    )
    
    cat("✓ Model comparison completed\n")
    
  }, error = function(e) {
    stop("Error creating model comparison: ", e$message)
  })
  
  # Final validation and return
  tryCatch({
    result_list <- list(
      importance = importance_df,
      top_predictors = top_predictors,
      model_comparison = model_comparison,
      reduced_model = reduced_model,
      model_data = model_data,
      logistic_model = logistic_model,
      rf_model = rf_model
    )
    
    # Validate all components exist
    missing_components <- sapply(result_list, is.null)
    if (any(missing_components)) {
      warning("Some result components are NULL: ", paste(names(missing_components)[missing_components], collapse = ", "))
    }
    
    cat("✓ Breakthrough analysis completed successfully\n")
    return(result_list)
    
  }, error = function(e) {
    stop("Error creating return object: ", e$message)
  })
}

# Get all potential predictors with validation
cat("\n--- Breakthrough Predictor Setup ---\n")

tryCatch({
  # Extract previous season features and age for men
  men_prev_features <- names(train_men)[grep("^Prev_", names(train_men))]
  breakthrough_predictors_men <- c(men_prev_features, "Age")
  breakthrough_predictors_men <- breakthrough_predictors_men[!is.na(breakthrough_predictors_men)]
  
  # Validate men's predictors
  if (length(breakthrough_predictors_men) == 0) {
    stop("No valid predictors found for men's breakthrough analysis")
  }
  
  # Check which predictors actually exist in the data
  available_men_predictors <- intersect(breakthrough_predictors_men, names(train_men))
  if (length(available_men_predictors) < length(breakthrough_predictors_men)) {
    missing_men <- setdiff(breakthrough_predictors_men, available_men_predictors)
    warning("Missing men's predictors: ", paste(missing_men, collapse = ", "))
    breakthrough_predictors_men <- available_men_predictors
  }
  
  cat("✓ Men's breakthrough predictors validated:", length(breakthrough_predictors_men), "features\n")
  
}, error = function(e) {
  stop("Error setting up men's breakthrough predictors: ", e$message)
})

tryCatch({
  # Extract previous season features and age for ladies
  ladies_prev_features <- names(train_ladies)[grep("^Prev_", names(train_ladies))]
  breakthrough_predictors_ladies <- c(ladies_prev_features, "Age")
  breakthrough_predictors_ladies <- breakthrough_predictors_ladies[!is.na(breakthrough_predictors_ladies)]
  
  # Validate ladies predictors
  if (length(breakthrough_predictors_ladies) == 0) {
    stop("No valid predictors found for ladies breakthrough analysis")
  }
  
  # Check which predictors actually exist in the data
  available_ladies_predictors <- intersect(breakthrough_predictors_ladies, names(train_ladies))
  if (length(available_ladies_predictors) < length(breakthrough_predictors_ladies)) {
    missing_ladies <- setdiff(breakthrough_predictors_ladies, available_ladies_predictors)
    warning("Missing ladies predictors: ", paste(missing_ladies, collapse = ", "))
    breakthrough_predictors_ladies <- available_ladies_predictors
  }
  
  cat("✓ Ladies breakthrough predictors validated:", length(breakthrough_predictors_ladies), "features\n")
  
}, error = function(e) {
  stop("Error setting up ladies breakthrough predictors: ", e$message)
})

print("Available men's breakthrough predictors:")
print(breakthrough_predictors_men)

print("Available ladies breakthrough predictors:")
print(breakthrough_predictors_ladies)

# Run breakthrough analysis for men with validation
cat("\n--- Men's Breakthrough Analysis Execution ---\n")
print("=== MEN'S BREAKTHROUGH ANALYSIS ===")

tryCatch({
  breakthrough_analysis_men <- evaluate_breakthrough_predictors(train_men, breakthrough_predictors_men)
  
  # Validate results
  if (is.null(breakthrough_analysis_men)) {
    stop("Men's breakthrough analysis returned NULL")
  }
  
  required_components <- c("importance", "top_predictors", "model_comparison")
  missing_components <- setdiff(required_components, names(breakthrough_analysis_men))
  if (length(missing_components) > 0) {
    warning("Missing components in men's analysis: ", paste(missing_components, collapse = ", "))
  }
  
  cat("✓ Men's breakthrough analysis completed successfully\n")
  
}, error = function(e) {
  stop("Error in men's breakthrough analysis: ", e$message)
})

# Display men's results with validation
tryCatch({
  print("Men's Breakthrough Predictor Importance Summary:")
  if (!is.null(breakthrough_analysis_men$importance) && nrow(breakthrough_analysis_men$importance) > 0) {
    print(breakthrough_analysis_men$importance)
  } else {
    print("No importance results available")
  }

  print("Top Men's Breakthrough Predictors:")
  if (!is.null(breakthrough_analysis_men$top_predictors) && length(breakthrough_analysis_men$top_predictors) > 0) {
    print(breakthrough_analysis_men$top_predictors)
  } else {
    print("No top predictors identified")
  }

  print("Men's Breakthrough Model Comparison:")
  if (!is.null(breakthrough_analysis_men$model_comparison) && nrow(breakthrough_analysis_men$model_comparison) > 0) {
    print(breakthrough_analysis_men$model_comparison)
  } else {
    print("No model comparison available")
  }
  
}, error = function(e) {
  warning("Error displaying men's results: ", e$message)
})

# Run breakthrough analysis for ladies with validation
cat("\n--- Ladies Breakthrough Analysis Execution ---\n")
print("=== LADIES BREAKTHROUGH ANALYSIS ===")

tryCatch({
  breakthrough_analysis_ladies <- evaluate_breakthrough_predictors(train_ladies, breakthrough_predictors_ladies)
  
  # Validate results
  if (is.null(breakthrough_analysis_ladies)) {
    stop("Ladies breakthrough analysis returned NULL")
  }
  
  required_components <- c("importance", "top_predictors", "model_comparison")
  missing_components <- setdiff(required_components, names(breakthrough_analysis_ladies))
  if (length(missing_components) > 0) {
    warning("Missing components in ladies analysis: ", paste(missing_components, collapse = ", "))
  }
  
  cat("✓ Ladies breakthrough analysis completed successfully\n")
  
}, error = function(e) {
  stop("Error in ladies breakthrough analysis: ", e$message)
})

# Display ladies results with validation
tryCatch({
  print("Ladies Breakthrough Predictor Importance Summary:")
  if (!is.null(breakthrough_analysis_ladies$importance) && nrow(breakthrough_analysis_ladies$importance) > 0) {
    print(breakthrough_analysis_ladies$importance)
  } else {
    print("No importance results available")
  }

  print("Top Ladies Breakthrough Predictors:")
  if (!is.null(breakthrough_analysis_ladies$top_predictors) && length(breakthrough_analysis_ladies$top_predictors) > 0) {
    print(breakthrough_analysis_ladies$top_predictors)
  } else {
    print("No top predictors identified")
  }

  print("Ladies Breakthrough Model Comparison:")
  if (!is.null(breakthrough_analysis_ladies$model_comparison) && nrow(breakthrough_analysis_ladies$model_comparison) > 0) {
    print(breakthrough_analysis_ladies$model_comparison)
  } else {
    print("No model comparison available")
  }
  
}, error = function(e) {
  warning("Error displaying ladies results: ", e$message)
})
```

### 2026 Breakthrough Predictions

```{r big-break}
cat("=== 2026 BREAKTHROUGH PREDICTIONS VALIDATION ===\n")

# Enhanced function to predict 2026 breakthrough candidates
predict_2026_breakthroughs <- function(current_data, breakthrough_model, top_predictors) {
  cat("\n--- 2026 Breakthrough Prediction Function ---\n")
  
  # Input validation
  if (!is.data.frame(current_data)) stop("current_data is not a data frame")
  if (nrow(current_data) == 0) stop("current_data is empty")
  if (is.null(breakthrough_model)) stop("breakthrough_model is NULL")
  if (is.null(top_predictors) || length(top_predictors) == 0) stop("No top_predictors provided")
  
  cat("Input validation passed\n")
  cat("Using", length(top_predictors), "top predictors for breakthrough prediction\n")
  
  # Define mapping from prev variables to current Elo variables with validation
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Sprint" = "Sprint_Pelo", 
    "Prev_Sprint_C" = "Sprint_C_Pelo",
    "Prev_Sprint_F" = "Sprint_F_Pelo",
    "Prev_Distance" = "Distance_Pelo",
    "Prev_Distance_F" = "Distance_F_Pelo", 
    "Prev_Distance_C" = "Distance_C_Pelo",
    "Prev_F" = "Freestyle_Pelo",
    "Prev_C" = "Classic_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points"
  )
  
  # Validate required columns exist
  required_cols <- c("Skier", "Season", "Pct_of_Max_Points", "Age", "Nation")
  missing_cols <- setdiff(required_cols, names(current_data))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in current_data: ", paste(missing_cols, collapse = ", "))
  }
  
  print("Using breakthrough predictors:")
  print(top_predictors)
  
  # Career history analysis with validation
  cat("\n--- Career History Analysis ---\n")
  
  tryCatch({
    # Validate Pct_of_Max_Points data quality
    invalid_pct_count <- sum(is.na(current_data$Pct_of_Max_Points) | 
                            current_data$Pct_of_Max_Points < 0 | 
                            current_data$Pct_of_Max_Points > 1 | 
                            !is.finite(current_data$Pct_of_Max_Points))
    
    if (invalid_pct_count > 0) {
      warning("Found ", invalid_pct_count, " invalid Pct_of_Max_Points values")
    }
    
    # Get current candidates (skiers who have NEVER broken through in their entire career)
    # First, identify all skiers who have ever achieved >=50%
    ever_broke_through <- current_data %>%
      filter(!is.na(Pct_of_Max_Points), is.finite(Pct_of_Max_Points)) %>%
      group_by(Skier) %>%
      summarise(
        Career_Max = max(Pct_of_Max_Points, na.rm = TRUE),
        Ever_Above_50 = any(Pct_of_Max_Points >= 0.5, na.rm = TRUE),
        Seasons_Competed = n_distinct(Season),
        .groups = 'drop'
      ) %>%
      filter(Ever_Above_50) %>%
      pull(Skier)
    
    cat("✓ Career history analysis completed\n")
    
  }, error = function(e) {
    stop("Error in career history analysis: ", e$message)
  })
  
  # Excluded skiers analysis with validation
  tryCatch({
    excluded_examples <- current_data %>%
      filter(!is.na(Pct_of_Max_Points), is.finite(Pct_of_Max_Points)) %>%
      group_by(Skier) %>%
      summarise(Career_Max = max(Pct_of_Max_Points, na.rm = TRUE), .groups = 'drop') %>%
      filter(Career_Max >= 0.5) %>%
      arrange(desc(Career_Max)) %>%
      head(15)
    
    print("Top excluded skiers (ever achieved ≥50%):")
    if (nrow(excluded_examples) > 0) {
      print(excluded_examples)
    } else {
      print("No skiers found who achieved ≥50%")
    }
    
    cat("Total excluded skiers:", length(ever_broke_through), "\n")
    
  }, error = function(e) {
    warning("Error analyzing excluded skiers: ", e$message)
  })
  
  # 2025 participation analysis with validation
  cat("\n--- 2025 Season Analysis ---\n")
  
  tryCatch({
    # Check who participated in 2025
    skiers_2025 <- current_data %>% 
      filter(Season == 2025, !is.na(Skier)) %>% 
      pull(Skier) %>% 
      unique()
    
    cat("Athletes who participated in 2025:", length(skiers_2025), "\n")
    
    if (length(skiers_2025) == 0) {
      stop("No athletes found for 2025 season")
    }
    
  }, error = function(e) {
    stop("Error analyzing 2025 participation: ", e$message)
  })
  
  # Breakthrough candidates identification with validation
  cat("\n--- Breakthrough Candidate Identification ---\n")
  
  tryCatch({
    # Get athletes who participated in 2025 season and have NEVER achieved >=50%
    current_candidates <- current_data %>%
      mutate(Age = as.numeric(Age)) %>%
      filter(!is.na(Skier),
             !is.na(Age),
             !Skier %in% ever_broke_through) %>%  # Only skiers who have NEVER achieved >=50%
      filter(Season == 2025) %>%  # Only athletes who participated in 2025
      group_by(Skier) %>%
      arrange(desc(Season)) %>%
      slice(1) %>%  # Take most recent season for each skier (should be 2025)
      ungroup()
    
    # Validate candidate data
    if (nrow(current_candidates) == 0) {
      stop("No breakthrough candidates found for 2025")
    }
    
    # Check for data quality issues in candidates
    na_age_count <- sum(is.na(current_candidates$Age))
    na_pct_count <- sum(is.na(current_candidates$Pct_of_Max_Points))
    
    if (na_age_count > 0) {
      warning("Found ", na_age_count, " candidates with missing age data")
    }
    if (na_pct_count > 0) {
      warning("Found ", na_pct_count, " candidates with missing performance data")
    }
    
    cat("✓ Breakthrough candidates identified:", nrow(current_candidates), "\n")
    
  }, error = function(e) {
    stop("Error identifying breakthrough candidates: ", e$message)
  })
  
  # Top candidates analysis with validation
  tryCatch({
    print("Top 2025 performers among breakthrough candidates:")
    top_candidates <- current_candidates %>% 
      filter(!is.na(Pct_of_Max_Points)) %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points) %>% 
      arrange(desc(Pct_of_Max_Points)) %>% 
      head(15)
    
    if (nrow(top_candidates) > 0) {
      print(top_candidates)
    } else {
      print("No candidates with valid performance data found")
    }
    
  }, error = function(e) {
    warning("Error analyzing top candidates: ", e$message)
  })
  
  # Feature analysis with validation
  tryCatch({
    print("Feature values for top 5 candidates by 2025 performance:")
    available_predictors <- intersect(top_predictors, names(current_candidates))
    
    feature_sample <- current_candidates %>%
      filter(!is.na(Pct_of_Max_Points)) %>%
      arrange(desc(Pct_of_Max_Points)) %>%
      head(5) %>%
      dplyr::select(Skier, Age, Pct_of_Max_Points, all_of(available_predictors))
    
    if (nrow(feature_sample) > 0) {
      print(feature_sample)
    } else {
      print("No candidates available for feature analysis")
    }
    
    print("Distribution of 2025 performance among candidates:")
    perf_summary <- summary(current_candidates$Pct_of_Max_Points)
    print(perf_summary)
    
  }, error = function(e) {
    warning("Error in feature analysis: ", e$message)
  })
  
  # Prediction dataset preparation with validation
  cat("\n--- Prediction Dataset Preparation ---\n")
  
  tryCatch({
    # Create prediction dataset by mapping current values to prev_ names
    prediction_data <- current_candidates
    
    # Track mapping success
    mapping_success <- 0
    mapping_failures <- character(0)
    
    for(prev_var in names(predictor_mapping)) {
      if(prev_var %in% top_predictors) {
        current_var <- predictor_mapping[prev_var]
        if(current_var %in% names(current_candidates)) {
          prediction_data[[prev_var]] <- prediction_data[[current_var]]
          mapping_success <- mapping_success + 1
        } else {
          mapping_failures <- c(mapping_failures, paste(prev_var, "->", current_var))
        }
      }
    }
    
    cat("Successful predictor mappings:", mapping_success, "\n")
    if (length(mapping_failures) > 0) {
      warning("Failed predictor mappings: ", paste(mapping_failures, collapse = ", "))
    }
    
  }, error = function(e) {
    stop("Error in prediction dataset preparation: ", e$message)
  })
  
  # Missing value imputation with validation
  tryCatch({
    cat("Handling missing values in predictors\n")
    
    for(pred in top_predictors) {
      if(pred %in% names(prediction_data)) {
        na_count <- sum(is.na(prediction_data[[pred]]))
        
        if(na_count > 0) {
          cat("Imputing", na_count, "missing values for", pred, "\n")
          
          # Try median imputation first
          pred_median <- median(prediction_data[[pred]], na.rm = TRUE)
          
          if(is.na(pred_median)) {
            # If median is NA, try mean
            pred_mean <- mean(prediction_data[[pred]], na.rm = TRUE)
            if(is.na(pred_mean)) {
              # If both fail, use 0
              impute_value <- 0
              warning("Using 0 for imputation of ", pred, " (no valid values found)")
            } else {
              impute_value <- pred_mean
            }
          } else {
            impute_value <- pred_median
          }
          
          prediction_data[[pred]] <- ifelse(is.na(prediction_data[[pred]]),
                                          impute_value,
                                          prediction_data[[pred]])
        }
      } else {
        warning("Predictor ", pred, " not found in prediction data")
      }
    }
    
    cat("✓ Missing value imputation completed\n")
    
  }, error = function(e) {
    stop("Error handling missing values: ", e$message)
  })
  
  # Model prediction with validation
  cat("\n--- Breakthrough Probability Prediction ---\n")
  
  tryCatch({
    # Validate prediction data has required predictors
    missing_predictors <- setdiff(top_predictors, names(prediction_data))
    if (length(missing_predictors) > 0) {
      warning("Missing predictors for model prediction: ", paste(missing_predictors, collapse = ", "))
    }
    
    # Make breakthrough predictions
    breakthrough_probs <- predict(breakthrough_model,
                                 newdata = prediction_data,
                                 type = "prob")
    
    # Validate prediction results
    if (is.null(breakthrough_probs)) {
      stop("Model prediction returned NULL")
    }
    
    if (!"Yes" %in% colnames(breakthrough_probs)) {
      stop("Model prediction missing 'Yes' probability column")
    }
    
    if (nrow(breakthrough_probs) != nrow(prediction_data)) {
      stop("Mismatch between prediction results and input data")
    }
    
    cat("✓ Breakthrough predictions generated for", nrow(breakthrough_probs), "candidates\n")
    
  }, error = function(e) {
    stop("Error generating breakthrough predictions: ", e$message)
  })
  
  # Prediction analysis with validation
  tryCatch({
    yes_probs <- breakthrough_probs[,"Yes"]
    
    # Validate probability values
    if (any(is.na(yes_probs))) {
      warning("Found NA values in breakthrough probabilities")
    }
    
    if (any(yes_probs < 0 | yes_probs > 1, na.rm = TRUE)) {
      warning("Found invalid probability values (outside 0-1 range)")
    }
    
    print("Distribution of breakthrough probabilities:")
    print(summary(yes_probs))
    
    max_prob <- max(yes_probs, na.rm = TRUE)
    high_prob_count <- sum(yes_probs > 0.1, na.rm = TRUE)
    medium_prob_count <- sum(yes_probs > 0.05, na.rm = TRUE)
    
    cat("Max probability:", round(max_prob * 100, 1), "%\n")
    cat("Candidates with >10% probability:", high_prob_count, "\n")
    cat("Candidates with >5% probability:", medium_prob_count, "\n")
    
  }, error = function(e) {
    warning("Error analyzing prediction results: ", e$message)
  })
  
  # Results compilation with validation
  tryCatch({
    available_predictors <- intersect(top_predictors, names(prediction_data))
    
    results <- prediction_data %>%
      dplyr::select(Skier, Nation, Age, all_of(available_predictors), Pct_of_Max_Points) %>%
      mutate(
        Breakthrough_Prob = breakthrough_probs[,"Yes"],
        Points_To_Threshold = pmax(0, 0.5 - Pct_of_Max_Points, na.rm = TRUE),
        Likelihood = case_when(
          is.na(Breakthrough_Prob) ~ "Unknown",
          Breakthrough_Prob >= 0.6 ~ "Very High",
          Breakthrough_Prob >= 0.4 ~ "High", 
          Breakthrough_Prob >= 0.25 ~ "Medium",
          Breakthrough_Prob >= 0.15 ~ "Low",
          TRUE ~ "Very Low"
        )
      ) %>%
      arrange(desc(Breakthrough_Prob))
    
    # Validate results
    if (nrow(results) == 0) {
      stop("No results generated")
    }
    
    cat("✓ Results compiled for", nrow(results), "candidates\n")
    
  }, error = function(e) {
    stop("Error compiling results: ", e$message)
  })
  
  # Under-25 analysis with validation
  tryCatch({
    results_under25 <- results %>%
      filter(!is.na(Age), Age < 25) %>%
      arrange(desc(Breakthrough_Prob))
    
    cat("Under-25 candidates:", nrow(results_under25), "\n")
    
  }, error = function(e) {
    warning("Error creating under-25 results: ", e$message)
    results_under25 <- data.frame()  # Empty fallback
  })
  
  # Final validation and return
  tryCatch({
    return_list <- list(
      all_candidates = results,
      under25_candidates = results_under25
    )
    
    # Validate return components
    if (is.null(return_list$all_candidates)) {
      stop("all_candidates is NULL")
    }
    if (is.null(return_list$under25_candidates)) {
      warning("under25_candidates is NULL - using empty dataframe")
      return_list$under25_candidates <- data.frame()
    }
    
    cat("✓ Breakthrough prediction function completed successfully\n")
    return(return_list)
    
  }, error = function(e) {
    stop("Error creating return object: ", e$message)
  })
}

# Execute breakthrough predictions with validation
cat("\n--- 2026 Breakthrough Prediction Execution ---\n")

# Make 2026 breakthrough predictions for men
tryCatch({
  cat("Generating men's breakthrough predictions\n")
  
  # Validate inputs
  if (is.null(breakthrough_analysis_men$reduced_model)) {
    stop("Men's breakthrough model is NULL")
  }
  if (is.null(breakthrough_analysis_men$top_predictors) || length(breakthrough_analysis_men$top_predictors) == 0) {
    stop("Men's top predictors are NULL or empty")
  }
  
  breakthrough_predictions_men <- predict_2026_breakthroughs(
    train_men,  # Use full training data to check career history
    breakthrough_analysis_men$reduced_model,
    breakthrough_analysis_men$top_predictors
  )
  
  # Validate results
  if (is.null(breakthrough_predictions_men)) {
    stop("Men's breakthrough predictions returned NULL")
  }
  
  cat("✓ Men's breakthrough predictions completed\n")
  
}, error = function(e) {
  stop("Error generating men's breakthrough predictions: ", e$message)
})

# Make 2026 breakthrough predictions for ladies
tryCatch({
  cat("Generating ladies breakthrough predictions\n")
  
  # Validate inputs
  if (is.null(breakthrough_analysis_ladies$reduced_model)) {
    stop("Ladies breakthrough model is NULL")
  }
  if (is.null(breakthrough_analysis_ladies$top_predictors) || length(breakthrough_analysis_ladies$top_predictors) == 0) {
    stop("Ladies top predictors are NULL or empty")
  }
  
  breakthrough_predictions_ladies <- predict_2026_breakthroughs(
    train_ladies,  # Use full training data to check career history
    breakthrough_analysis_ladies$reduced_model,
    breakthrough_analysis_ladies$top_predictors
  )
  
  # Validate results
  if (is.null(breakthrough_predictions_ladies)) {
    stop("Ladies breakthrough predictions returned NULL")
  }
  
  cat("✓ Ladies breakthrough predictions completed\n")
  
}, error = function(e) {
  stop("Error generating ladies breakthrough predictions: ", e$message)
})

print("=== 2026 MEN'S BREAKTHROUGH PREDICTIONS (ALL CANDIDATES) ===")
print("Top 15 Men's Breakthrough Candidates:")
print(breakthrough_predictions_men$all_candidates %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Breakthrough_Prob, Likelihood) %>%
      mutate(
        Pct_of_Max_Points = sprintf("%.1f%%", Pct_of_Max_Points * 100),
        Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)
      ) %>%
      head(15))

print("=== 2026 MEN'S BREAKTHROUGH PREDICTIONS (UNDER 25 ONLY) ===")
print("Top 15 Young Men's Breakthrough Candidates:")
print(breakthrough_predictions_men$under25_candidates %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Breakthrough_Prob, Likelihood) %>%
      mutate(
        Pct_of_Max_Points = sprintf("%.1f%%", Pct_of_Max_Points * 100),
        Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)
      ) %>%
      head(15))

print("Men's Breakthrough Likelihood Summary (All):")
print(table(breakthrough_predictions_men$all_candidates$Likelihood))
print("Men's Breakthrough Likelihood Summary (Under 25):")
print(table(breakthrough_predictions_men$under25_candidates$Likelihood))

print("=== 2026 LADIES BREAKTHROUGH PREDICTIONS (ALL CANDIDATES) ===")
print("Top 15 Ladies Breakthrough Candidates:")
print(breakthrough_predictions_ladies$all_candidates %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Breakthrough_Prob, Likelihood) %>%
      mutate(
        Pct_of_Max_Points = sprintf("%.1f%%", Pct_of_Max_Points * 100),
        Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)
      ) %>%
      head(15))

print("=== 2026 LADIES BREAKTHROUGH PREDICTIONS (UNDER 25 ONLY) ===")
print("Top 15 Young Ladies Breakthrough Candidates:")
print(breakthrough_predictions_ladies$under25_candidates %>%
      dplyr::select(Skier, Nation, Age, Pct_of_Max_Points, Breakthrough_Prob, Likelihood) %>%
      mutate(
        Pct_of_Max_Points = sprintf("%.1f%%", Pct_of_Max_Points * 100),
        Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)
      ) %>%
      head(15))

print("Ladies Breakthrough Likelihood Summary (All):")
print(table(breakthrough_predictions_ladies$all_candidates$Likelihood))
print("Ladies Breakthrough Likelihood Summary (Under 25):")
print(table(breakthrough_predictions_ladies$under25_candidates$Likelihood))

# High-potential breakthrough candidates for men
high_potential_men <- breakthrough_predictions_men$all_candidates %>%
  filter(Breakthrough_Prob >= 0.3) %>%
  arrange(desc(Breakthrough_Prob))

if(nrow(high_potential_men) > 0) {
  print("High-Potential Men's Breakthrough Candidates (≥30% probability):")
  print(high_potential_men %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No men's skiers with ≥30% breakthrough probability identified")
}

# High-potential breakthrough candidates for ladies
high_potential_ladies <- breakthrough_predictions_ladies$all_candidates %>%
  filter(Breakthrough_Prob >= 0.3) %>%
  arrange(desc(Breakthrough_Prob))

if(nrow(high_potential_ladies) > 0) {
  print("High-Potential Ladies Breakthrough Candidates (≥30% probability):")
  print(high_potential_ladies %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No ladies skiers with ≥30% breakthrough probability identified")
}

# Young breakthrough prospects (age ≤ 25) - using dedicated under25 dataframes
young_prospects_men <- breakthrough_predictions_men$under25_candidates %>%
  arrange(desc(Breakthrough_Prob)) %>%
  head(10)

if(nrow(young_prospects_men) > 0) {
  print("=== TOP YOUNG MEN'S BREAKTHROUGH PROSPECTS (Age ≤ 25) ===")
  print(young_prospects_men %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No young men's breakthrough prospects identified")
}

# Young breakthrough prospects (age ≤ 25) for ladies  
young_prospects_ladies <- breakthrough_predictions_ladies$under25_candidates %>%
  arrange(desc(Breakthrough_Prob)) %>%
  head(10)

if(nrow(young_prospects_ladies) > 0) {
  print("=== TOP YOUNG LADIES BREAKTHROUGH PROSPECTS (Age ≤ 25) ===")
  print(young_prospects_ladies %>%
        dplyr::select(Skier, Nation, Age, Breakthrough_Prob, Likelihood) %>%
        mutate(Breakthrough_Prob = sprintf("%.1f%%", Breakthrough_Prob * 100)))
} else {
  print("No young ladies breakthrough prospects identified")
}

# Create Excel workbooks for breakthrough candidates
library(openxlsx)

# Men's breakthrough candidates workbook
men_breakthrough_workbook <- breakthrough_predictions_men$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1)
  ) %>%
  arrange(desc(`Breakthrough Prob`))

# Ladies breakthrough candidates workbook  
ladies_breakthrough_workbook <- breakthrough_predictions_ladies$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1)
  ) %>%
  arrange(desc(`Breakthrough Prob`))

# Write Excel workbooks to files
tryCatch({
  # Create output directory if it doesn't exist
  output_dir <- "excel365"
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Write men's breakthrough candidates
  men_file <- file.path(output_dir, "mens_breakthrough_candidates_2026.xlsx")
  write.xlsx(men_breakthrough_workbook, men_file, rowNames = FALSE)
  cat("✓ Men's breakthrough candidates saved to:", men_file, "\n")
  
  # Write ladies breakthrough candidates  
  ladies_file <- file.path(output_dir, "ladies_breakthrough_candidates_2026.xlsx")
  write.xlsx(ladies_breakthrough_workbook, ladies_file, rowNames = FALSE)
  cat("✓ Ladies breakthrough candidates saved to:", ladies_file, "\n")
  
}, error = function(e) {
  warning("Error writing Excel files: ", e$message)
})

print("=== MEN'S BREAKTHROUGH CANDIDATES WORKBOOK ===")
print(men_breakthrough_workbook)

print("=== LADIES BREAKTHROUGH CANDIDATES WORKBOOK ===")
print(ladies_breakthrough_workbook)

# Create all-time breakthrough probabilities dataset
# Apply current breakthrough model to historical breakthrough seasons to get predicted probabilities

# Function to apply breakthrough model to historical data
predict_historical_breakthrough <- function(historical_data, breakthrough_model, top_predictors) {
  
  # Define mapping from prev variables to current Elo variables
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Sprint" = "Sprint_Pelo", 
    "Prev_Sprint_C" = "Sprint_C_Pelo",
    "Prev_Sprint_F" = "Sprint_F_Pelo",
    "Prev_Distance" = "Distance_Pelo",
    "Prev_Distance_F" = "Distance_F_Pelo", 
    "Prev_Distance_C" = "Distance_C_Pelo",
    "Prev_F" = "Freestyle_Pelo",
    "Prev_C" = "Classic_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points"
  )
  
  # Create prediction dataset by mapping current values to prev_ names
  prediction_data <- historical_data
  
  for(prev_var in names(predictor_mapping)) {
    if(prev_var %in% top_predictors) {
      current_var <- predictor_mapping[prev_var]
      if(current_var %in% names(historical_data)) {
        prediction_data[[prev_var]] <- prediction_data[[current_var]]
      }
    }
  }
  
  # Handle missing values with median imputation
  for(pred in top_predictors) {
    if(pred %in% names(prediction_data)) {
      na_count <- sum(is.na(prediction_data[[pred]]))
      if(na_count > 0) {
        pred_median <- median(prediction_data[[pred]], na.rm = TRUE)
        if(is.na(pred_median)) {
          pred_median <- 0
        }
        prediction_data[[pred]] <- ifelse(is.na(prediction_data[[pred]]),
                                        pred_median,
                                        prediction_data[[pred]])
      }
    }
  }
  
  # Make predictions
  tryCatch({
    breakthrough_probs <- predict(breakthrough_model,
                                 newdata = prediction_data,
                                 type = "prob")
    return(breakthrough_probs[,"Yes"])
  }, error = function(e) {
    warning("Error predicting historical breakthroughs: ", e$message)
    return(rep(0.5, nrow(prediction_data)))  # Default to 50% if prediction fails
  })
}

# Get historical breakthroughs and apply current model
# Only include skiers who had genuine breakthroughs during our data period
# (i.e., they started below 50% and then broke through to >50%)
first_year <- min(train_men$Season, na.rm = TRUE)
cat("First year in data:", first_year, "\n")

# Find skiers who have genuine breakthrough trajectories:
# 1. Started below 50% in early seasons
# 2. Then achieved >50% in a later season
genuine_breakthroughs_men <- train_men %>%
  filter(!is.na(Pct_of_Max_Points), 
         !is.na(Skier),
         !is.na(Season),
         !is.na(Age)) %>%
  group_by(Skier) %>%
  arrange(Season) %>%
  mutate(
    ever_above_50 = any(Pct_of_Max_Points > 0.5),
    first_season = min(Season),
    early_performance = ifelse(Season <= first_season + 1, Pct_of_Max_Points, NA),
    max_early_performance = max(early_performance, na.rm = TRUE)
  ) %>%
  filter(
    ever_above_50,  # Must have achieved >50% at some point
    !is.infinite(max_early_performance),  # Must have early season data
    max_early_performance <= 0.5,  # Was not already above 50% in early seasons
    Pct_of_Max_Points > 0.5  # This is a >50% season
  ) %>%
  slice(1) %>%  # Take first breakthrough season
  ungroup()

cat("Men with genuine breakthroughs:", nrow(genuine_breakthroughs_men), "\n")

historical_breakthroughs_men <- genuine_breakthroughs_men

# Apply current model to historical men's data using PREVIOUS season data
if(nrow(historical_breakthroughs_men) > 0) {
  # Get the season before breakthrough for each skier to make fair predictions
  historical_men_prev_season <- historical_breakthroughs_men %>%
    dplyr::select(Skier, breakthrough_season = Season) %>%
    mutate(prev_season = breakthrough_season - 1) %>%
    left_join(
      train_men %>%
        dplyr::select(Skier, Season, everything()),
      by = c("Skier" = "Skier", "prev_season" = "Season")
    ) %>%
    filter(!is.na(Pct_of_Max_Points))  # Only keep cases where we have previous season data
  
  if(nrow(historical_men_prev_season) > 0) {
    historical_men_probs <- predict_historical_breakthrough(
      historical_men_prev_season,
      breakthrough_analysis_men$reduced_model,
      breakthrough_analysis_men$top_predictors
    )
    
    historical_breakthroughs_men <- historical_men_prev_season %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Pct Max Points` = Pct_of_Max_Points,
        Season = breakthrough_season
      ) %>%
      mutate(
        `Pct Max Points` = round(`Pct Max Points` * 100, 1),
        `Breakthrough Prob` = round(historical_men_probs * 100, 1),
        Type = "Historical Success"
      )
  } else {
    historical_breakthroughs_men <- data.frame()
    cat("No historical men's data with previous season available\n")
  }
} else {
  historical_breakthroughs_men <- data.frame()
}

# Get historical breakthroughs for ladies and apply current model  
# Find ladies who have genuine breakthrough trajectories
genuine_breakthroughs_ladies <- train_ladies %>%
  filter(!is.na(Pct_of_Max_Points), 
         !is.na(Skier),
         !is.na(Season),
         !is.na(Age)) %>%
  group_by(Skier) %>%
  arrange(Season) %>%
  mutate(
    ever_above_50 = any(Pct_of_Max_Points > 0.5),
    first_season = min(Season),
    early_performance = ifelse(Season <= first_season + 1, Pct_of_Max_Points, NA),
    max_early_performance = max(early_performance, na.rm = TRUE)
  ) %>%
  filter(
    ever_above_50,  # Must have achieved >50% at some point
    !is.infinite(max_early_performance),  # Must have early season data
    max_early_performance <= 0.5,  # Was not already above 50% in early seasons
    Pct_of_Max_Points > 0.5  # This is a >50% season
  ) %>%
  slice(1) %>%  # Take first breakthrough season
  ungroup()

cat("Ladies with genuine breakthroughs:", nrow(genuine_breakthroughs_ladies), "\n")

historical_breakthroughs_ladies <- genuine_breakthroughs_ladies

# Apply current model to historical ladies data using PREVIOUS season data
if(nrow(historical_breakthroughs_ladies) > 0) {
  # Get the season before breakthrough for each skier to make fair predictions
  historical_ladies_prev_season <- historical_breakthroughs_ladies %>%
    dplyr::select(Skier, breakthrough_season = Season) %>%
    mutate(prev_season = breakthrough_season - 1) %>%
    left_join(
      train_ladies %>%
        dplyr::select(Skier, Season, everything()),
      by = c("Skier" = "Skier", "prev_season" = "Season")
    ) %>%
    filter(!is.na(Pct_of_Max_Points))  # Only keep cases where we have previous season data
  
  if(nrow(historical_ladies_prev_season) > 0) {
    historical_ladies_probs <- predict_historical_breakthrough(
      historical_ladies_prev_season,
      breakthrough_analysis_ladies$reduced_model,
      breakthrough_analysis_ladies$top_predictors
    )
    
    historical_breakthroughs_ladies <- historical_ladies_prev_season %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Pct Max Points` = Pct_of_Max_Points,
        Season = breakthrough_season
      ) %>%
      mutate(
        `Pct Max Points` = round(`Pct Max Points` * 100, 1),
        `Breakthrough Prob` = round(historical_ladies_probs * 100, 1),
        Type = "Historical Success"
      )
  } else {
    historical_breakthroughs_ladies <- data.frame()
    cat("No historical ladies data with previous season available\n")
  }
} else {
  historical_breakthroughs_ladies <- data.frame()
}

# Add current year predictions
current_men_predictions <- breakthrough_predictions_men$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1),
    Season = 2026,
    Type = "**2026 Prediction**"
  ) %>%
  arrange(desc(`Breakthrough Prob`)) %>%
  head(10)  # Top 10 current predictions

current_ladies_predictions <- breakthrough_predictions_ladies$all_candidates %>%
  dplyr::select(
    Name = Skier,
    Nation,
    Age,
    `Pct Max Points` = Pct_of_Max_Points,
    `Breakthrough Prob` = Breakthrough_Prob
  ) %>%
  mutate(
    `Pct Max Points` = round(`Pct Max Points` * 100, 1),
    `Breakthrough Prob` = round(`Breakthrough Prob` * 100, 1),
    Season = 2026,
    Type = "**2026 Prediction**"
  ) %>%
  arrange(desc(`Breakthrough Prob`)) %>%
  head(10)  # Top 10 current predictions

# Combine all-time breakthrough data
all_time_men <- bind_rows(historical_breakthroughs_men, current_men_predictions) %>%
  arrange(desc(`Breakthrough Prob`), Season) %>%
  dplyr::select(Name, Nation, Age, `Pct Max Points`, `Breakthrough Prob`, Season, Type)

all_time_ladies <- bind_rows(historical_breakthroughs_ladies, current_ladies_predictions) %>%
  arrange(desc(`Breakthrough Prob`), Season) %>%
  dplyr::select(Name, Nation, Age, `Pct Max Points`, `Breakthrough Prob`, Season, Type)

# Write all-time breakthrough probabilities to Excel
tryCatch({
  # Write all-time men's breakthrough probabilities
  all_time_men_file <- file.path(output_dir, "all_time_mens_breakthrough_probabilities.xlsx")
  write.xlsx(all_time_men, all_time_men_file, rowNames = FALSE)
  cat("✓ All-time men's breakthrough probabilities saved to:", all_time_men_file, "\n")
  
  # Write all-time ladies breakthrough probabilities
  all_time_ladies_file <- file.path(output_dir, "all_time_ladies_breakthrough_probabilities.xlsx")
  write.xlsx(all_time_ladies, all_time_ladies_file, rowNames = FALSE)
  cat("✓ All-time ladies breakthrough probabilities saved to:", all_time_ladies_file, "\n")
  
}, error = function(e) {
  warning("Error writing all-time Excel files: ", e$message)
})

print("=== ALL-TIME MEN'S BREAKTHROUGH PROBABILITIES ===")
print("(Historical successes + Top 2026 predictions)")
print(all_time_men)

print("=== ALL-TIME LADIES BREAKTHROUGH PROBABILITIES ===") 
print("(Historical successes + Top 2026 predictions)")
print(all_time_ladies)
```

### Age-Adjusted 2026 Predictions

```{r df82}
cat("=== DF82 COMPREHENSIVE DATASET VALIDATION ===\n")

# Enhanced function to replace NAs with the first quartile within each group
replace_na_with_quartile <- function(x) {
  tryCatch({
    if (length(x) == 0) {
      warning("Empty vector passed to replace_na_with_quartile")
      return(numeric(0))
    }
    
    if (all(is.na(x))) {
      warning("All values are NA in replace_na_with_quartile")
      return(rep(0, length(x)))
    }
    
    quartile_1 <- quantile(x, 0.25, na.rm = TRUE)
    
    if (is.na(quartile_1)) {
      warning("Quartile calculation failed, using 0 as fallback")
      quartile_1 <- 0
    }
    
    result <- ifelse(is.na(x), quartile_1, x)
    return(result)
    
  }, error = function(e) {
    warning("Error in replace_na_with_quartile: ", e$message, " - using 0 as fallback")
    return(ifelse(is.na(x), 0, x))
  })
}

# Create comprehensive df82-style dataset for age analysis
cat("Creating comprehensive dataset (df82 style)\n")

# Process men's chrono data following df82 methodology
cat("\n--- Men's Data Processing ---\n")

tryCatch({
  # Validate input data
  if (!exists("M_chrono")) stop("M_chrono data not found")
  if (nrow(M_chrono) == 0) stop("M_chrono data is empty")
  
  # Validate required columns exist
  required_cols <- c("Event", "Distance", "Place", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(M_chrono))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in M_chrono: ", paste(missing_cols, collapse = ", "))
  }
  
  # Check for ELO rating columns
  elo_cols <- c("Distance_Pelo", "Distance_C_Pelo", "Distance_F_Pelo", "Pelo", 
               "Sprint_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo", 
               "Freestyle_Pelo", "Classic_Pelo")
  missing_elo <- setdiff(elo_cols, names(M_chrono))
  if (length(missing_elo) > 0) {
    warning("Missing ELO columns in M_chrono: ", paste(missing_elo, collapse = ", "))
  }
  
  cat("✓ Input validation passed for men's data\n")
  
  # Validate points mapping functions exist
  if (!exists("get_points")) stop("get_points function not found")
  if (!exists("tds_points")) stop("tds_points lookup table not found")
  if (!exists("stage_points")) stop("stage_points lookup table not found") 
  if (!exists("wc_points")) stop("wc_points lookup table not found")
  
  df82_men <- M_chrono %>%
    mutate(Points = case_when(
      Event == "Tour de Ski" & Distance == "Stage" ~ map_int(Place, ~ get_points(.x, tds_points)),
      Event == "Tour de Ski" ~ map_int(Place, ~ get_points(.x, stage_points)),
      TRUE ~ map_int(Place, ~ get_points(.x, wc_points))
    )) %>%
    arrange(Date, Race, Place) %>%
    filter(Event %in% c("Offseason", "World Cup", "Nordic Opening", "Tour de Ski", "World Cup Final", "Ski Tour Canada")) %>%
    group_by(ID, Season) %>%
    mutate(Cumulative_Points = cumsum(Points)) %>%
    ungroup() %>%
    group_by(Season, Race) %>%
    mutate(
      Distance_Pelo = replace_na_with_quartile(Distance_Pelo),
      Distance_C_Pelo = replace_na_with_quartile(Distance_C_Pelo),
      Distance_F_Pelo = replace_na_with_quartile(Distance_F_Pelo),
      Pelo = replace_na_with_quartile(Pelo),
      Sprint_Pelo = replace_na_with_quartile(Sprint_Pelo),
      Sprint_C_Pelo = replace_na_with_quartile(Sprint_C_Pelo),
      Sprint_F_Pelo = replace_na_with_quartile(Sprint_F_Pelo),
      Freestyle_Pelo = replace_na_with_quartile(Freestyle_Pelo),
      Classic_Pelo = replace_na_with_quartile(Classic_Pelo)
    ) %>%
    ungroup() %>%
    filter(!Distance %in% c("Ts", "Rel"))
  
  # Validate processed data
  if (nrow(df82_men) == 0) stop("No data remaining after men's processing")
  
  # Check for data quality issues
  invalid_points <- sum(is.na(df82_men$Points) | df82_men$Points < 0 | !is.finite(df82_men$Points))
  if (invalid_points > 0) {
    warning("Found ", invalid_points, " invalid Points values in men's data")
  }
  
  invalid_cumulative <- sum(is.na(df82_men$Cumulative_Points) | df82_men$Cumulative_Points < 0 | !is.finite(df82_men$Cumulative_Points))
  if (invalid_cumulative > 0) {
    warning("Found ", invalid_cumulative, " invalid Cumulative_Points values in men's data")
  }
  
  cat("✓ Men's data processing completed:", nrow(df82_men), "observations\n")
  
}, error = function(e) {
  stop("Error processing men's data: ", e$message)
})

# Calculate maximum points per season with validation
cat("\n--- Men's Maximum Points Calculation ---\n")

tryCatch({
  # Validate df82_men exists and has data
  if (!exists("df82_men")) stop("df82_men not found")
  if (nrow(df82_men) == 0) stop("df82_men is empty")
  
  # Check for Place column
  if (!"Place" %in% names(df82_men)) stop("Place column missing in df82_men")
  
  first_place <- df82_men %>%
    filter(Place == 1)
  
  # Validate first place data
  if (nrow(first_place) == 0) {
    warning("No first place finishes found in men's data")
    max_points_per_season <- data.frame(Season = unique(df82_men$Season), Max_Points = 1)
  } else {
    max_points_per_season <- first_place %>%
      group_by(Season) %>%
      summarise(Max_Points = sum(Points), .groups = 'drop')
    
    # Validate max points calculation
    zero_max_seasons <- sum(max_points_per_season$Max_Points == 0, na.rm = TRUE)
    if (zero_max_seasons > 0) {
      warning("Found ", zero_max_seasons, " seasons with zero max points")
      max_points_per_season <- max_points_per_season %>%
        mutate(Max_Points = pmax(Max_Points, 1))  # Ensure minimum 1 point
    }
  }
  
  # Join and calculate percentage
  df82_men <- df82_men %>%
    left_join(max_points_per_season, by = "Season") %>%
    mutate(Pct_of_Max_Points = ifelse(Max_Points > 0, Cumulative_Points / Max_Points, 0))
  
  # Validate percentage calculations
  invalid_pct <- sum(is.na(df82_men$Pct_of_Max_Points) | 
                    df82_men$Pct_of_Max_Points < 0 | 
                    !is.finite(df82_men$Pct_of_Max_Points), na.rm = TRUE)
  if (invalid_pct > 0) {
    warning("Found ", invalid_pct, " invalid percentage values in men's data")
  }
  
  cat("✓ Men's maximum points calculation completed\n")
  cat("Seasons with max points:", nrow(max_points_per_season), "\n")
  
}, error = function(e) {
  stop("Error calculating men's maximum points: ", e$message)
})

# Create ELO dataframe with previous season values
cat("\n--- Men's ELO Dataframe Creation ---\n")

tryCatch({
  # Validate df82_men exists and has required columns
  if (!exists("df82_men")) stop("df82_men not found")
  if (nrow(df82_men) == 0) stop("df82_men is empty")
  
  required_elo_cols <- c("Event", "ID", "Season", "Pelo", "Sprint_Pelo", "Sprint_C_Pelo", 
                        "Sprint_F_Pelo", "Distance_Pelo", "Distance_F_Pelo", 
                        "Distance_C_Pelo", "Freestyle_Pelo", "Classic_Pelo", "Pct_of_Max_Points")
  missing_elo_cols <- setdiff(required_elo_cols, names(df82_men))
  if (length(missing_elo_cols) > 0) {
    stop("Missing required columns for ELO processing: ", paste(missing_elo_cols, collapse = ", "))
  }
  
  # Filter for Offseason events
  offseason_data <- df82_men %>%
    filter(Event == "Offseason")
  
  if (nrow(offseason_data) == 0) {
    warning("No Offseason events found in men's data")
    # Use all data as fallback
    offseason_data <- df82_men
  }
  
  elo_df82 <- offseason_data %>%
    arrange(ID, Season) %>%
    group_by(ID) %>%
    mutate(
      Prev_Pelo = lag(Pelo),
      Prev_Sprint = lag(Sprint_Pelo),
      Prev_Sprint_C = lag(Sprint_C_Pelo),
      Prev_Sprint_F = lag(Sprint_F_Pelo),
      Prev_Distance = lag(Distance_Pelo),
      Prev_Distance_F = lag(Distance_F_Pelo),
      Prev_Distance_C = lag(Distance_C_Pelo),
      Prev_F = lag(Freestyle_Pelo),
      Prev_C = lag(Classic_Pelo),
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
    ) %>%
    ungroup() %>%
    filter(Season > 1981)
  
  # Validate ELO dataframe
  if (nrow(elo_df82) == 0) stop("No data remaining after ELO processing")
  
  # Check for excessive missing values in previous season data
  prev_cols <- c("Prev_Pelo", "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", 
                "Prev_Distance", "Prev_Distance_F", "Prev_Distance_C", 
                "Prev_F", "Prev_C", "Prev_Pct_of_Max_Points")
  
  for (col in prev_cols) {
    if (col %in% names(elo_df82)) {
      na_count <- sum(is.na(elo_df82[[col]]))
      na_pct <- (na_count / nrow(elo_df82)) * 100
      if (na_pct > 75) {
        warning("High missing data (", round(na_pct, 1), "%) in column: ", col)
      }
    }
  }
  
  cat("✓ Men's ELO dataframe created:", nrow(elo_df82), "observations\n")
  cat("Unique IDs:", length(unique(elo_df82$ID)), "\n")
  cat("Season range:", min(elo_df82$Season), "to", max(elo_df82$Season), "\n")
  
}, error = function(e) {
  stop("Error creating men's ELO dataframe: ", e$message)
})

# Handle missing values in previous season data with validation
cat("\n--- Men's Missing Value Imputation ---\n")

tryCatch({
  # Validate elo_df82 exists
  if (!exists("elo_df82")) stop("elo_df82 not found")
  if (nrow(elo_df82) == 0) stop("elo_df82 is empty")
  
  # Count missing values before imputation
  prev_vars <- c("Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", "Prev_Pelo",
                "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_F", "Prev_C", "Prev_Pct_of_Max_Points")
  
  missing_before <- sapply(prev_vars, function(var) {
    if (var %in% names(elo_df82)) {
      sum(is.na(elo_df82[[var]]))
    } else {
      0
    }
  })
  
  cat("Missing values before imputation:\n")
  for (i in seq_along(missing_before)) {
    if (missing_before[i] > 0) {
      cat("-", names(missing_before)[i], ":", missing_before[i], "\n")
    }
  }
  
  df82_final <- elo_df82 %>%
    group_by(Season) %>%
    mutate(
      Prev_Distance = replace_na_with_quartile(Prev_Distance),
      Prev_Distance_C = replace_na_with_quartile(Prev_Distance_C),
      Prev_Distance_F = replace_na_with_quartile(Prev_Distance_F),
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Sprint = replace_na_with_quartile(Prev_Sprint),
      Prev_Sprint_C = replace_na_with_quartile(Prev_Sprint_C),
      Prev_Sprint_F = replace_na_with_quartile(Prev_Sprint_F),
      Prev_F = replace_na_with_quartile(Prev_F),
      Prev_C = replace_na_with_quartile(Prev_C),
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate final data
  if (nrow(df82_final) == 0) stop("No data remaining after missing value imputation")
  
  # Count missing values after imputation
  missing_after <- sapply(prev_vars, function(var) {
    if (var %in% names(df82_final)) {
      sum(is.na(df82_final[[var]]))
    } else {
      0
    }
  })
  
  # Check if imputation was successful
  remaining_missing <- sum(missing_after)
  if (remaining_missing > 0) {
    warning("Still have ", remaining_missing, " missing values after imputation")
  }
  
  # Validate data ranges
  numeric_cols <- c("Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", "Prev_Pelo",
                   "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_F", "Prev_C")
  
  for (col in numeric_cols) {
    if (col %in% names(df82_final)) {
      invalid_vals <- sum(!is.finite(df82_final[[col]]) | df82_final[[col]] < 0, na.rm = TRUE)
      if (invalid_vals > 0) {
        warning("Found ", invalid_vals, " invalid values in ", col)
      }
    }
  }
  
  cat("✓ Men's missing value imputation completed\n")
  cat("Final dataset:", nrow(df82_final), "observations\n")
  
}, error = function(e) {
  stop("Error handling missing values in men's data: ", e$message)
})

# Process ladies data with same methodology
cat("\n--- Ladies Data Processing ---\n")

tryCatch({
  # Validate input data
  if (!exists("L_chrono")) stop("L_chrono data not found")
  if (nrow(L_chrono) == 0) stop("L_chrono data is empty")
  
  # Validate required columns exist
  required_cols <- c("Event", "Distance", "Place", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(L_chrono))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in L_chrono: ", paste(missing_cols, collapse = ", "))
  }
  
  # Check for ELO rating columns
  elo_cols <- c("Distance_Pelo", "Distance_C_Pelo", "Distance_F_Pelo", "Pelo", 
               "Sprint_Pelo", "Sprint_C_Pelo", "Sprint_F_Pelo", 
               "Freestyle_Pelo", "Classic_Pelo")
  missing_elo <- setdiff(elo_cols, names(L_chrono))
  if (length(missing_elo) > 0) {
    warning("Missing ELO columns in L_chrono: ", paste(missing_elo, collapse = ", "))
  }
  
  cat("✓ Input validation passed for ladies data\n")
  
  df82_ladies <- L_chrono %>%
    mutate(Points = case_when(
      Event == "Tour de Ski" & Distance == "Stage" ~ map_int(Place, ~ get_points(.x, tds_points)),
      Event == "Tour de Ski" ~ map_int(Place, ~ get_points(.x, stage_points)),
      TRUE ~ map_int(Place, ~ get_points(.x, wc_points))
    )) %>%
    arrange(Date, Race, Place) %>%
    filter(Event %in% c("Offseason", "World Cup", "Nordic Opening", "Tour de Ski", "World Cup Final", "Ski Tour Canada")) %>%
    group_by(ID, Season) %>%
    mutate(Cumulative_Points = cumsum(Points)) %>%
    ungroup() %>%
    group_by(Season, Race) %>%
    mutate(
      Distance_Pelo = replace_na_with_quartile(Distance_Pelo),
      Distance_C_Pelo = replace_na_with_quartile(Distance_C_Pelo),
      Distance_F_Pelo = replace_na_with_quartile(Distance_F_Pelo),
      Pelo = replace_na_with_quartile(Pelo),
      Sprint_Pelo = replace_na_with_quartile(Sprint_Pelo),
      Sprint_C_Pelo = replace_na_with_quartile(Sprint_C_Pelo),
      Sprint_F_Pelo = replace_na_with_quartile(Sprint_F_Pelo),
      Freestyle_Pelo = replace_na_with_quartile(Freestyle_Pelo),
      Classic_Pelo = replace_na_with_quartile(Classic_Pelo)
    ) %>%
    ungroup() %>%
    filter(!Distance %in% c("Ts", "Rel"))
  
  # Validate processed data
  if (nrow(df82_ladies) == 0) stop("No data remaining after ladies processing")
  
  # Check for data quality issues
  invalid_points <- sum(is.na(df82_ladies$Points) | df82_ladies$Points < 0 | !is.finite(df82_ladies$Points))
  if (invalid_points > 0) {
    warning("Found ", invalid_points, " invalid Points values in ladies data")
  }
  
  invalid_cumulative <- sum(is.na(df82_ladies$Cumulative_Points) | df82_ladies$Cumulative_Points < 0 | !is.finite(df82_ladies$Cumulative_Points))
  if (invalid_cumulative > 0) {
    warning("Found ", invalid_cumulative, " invalid Cumulative_Points values in ladies data")
  }
  
  cat("✓ Ladies data processing completed:", nrow(df82_ladies), "observations\n")
  
}, error = function(e) {
  stop("Error processing ladies data: ", e$message)
})

# Calculate maximum points per season for ladies with validation
cat("\n--- Ladies Maximum Points Calculation ---\n")

tryCatch({
  # Validate df82_ladies exists and has data
  if (!exists("df82_ladies")) stop("df82_ladies not found")
  if (nrow(df82_ladies) == 0) stop("df82_ladies is empty")
  
  # Check for Place column
  if (!"Place" %in% names(df82_ladies)) stop("Place column missing in df82_ladies")
  
  first_place_ladies <- df82_ladies %>%
    filter(Place == 1)
  
  # Validate first place data
  if (nrow(first_place_ladies) == 0) {
    warning("No first place finishes found in ladies data")
    max_points_per_season_ladies <- data.frame(Season = unique(df82_ladies$Season), Max_Points = 1)
  } else {
    max_points_per_season_ladies <- first_place_ladies %>%
      group_by(Season) %>%
      summarise(Max_Points = sum(Points), .groups = 'drop')
    
    # Validate max points calculation
    zero_max_seasons <- sum(max_points_per_season_ladies$Max_Points == 0, na.rm = TRUE)
    if (zero_max_seasons > 0) {
      warning("Found ", zero_max_seasons, " seasons with zero max points")
      max_points_per_season_ladies <- max_points_per_season_ladies %>%
        mutate(Max_Points = pmax(Max_Points, 1))  # Ensure minimum 1 point
    }
  }
  
  # Join and calculate percentage
  df82_ladies <- df82_ladies %>%
    left_join(max_points_per_season_ladies, by = "Season") %>%
    mutate(Pct_of_Max_Points = ifelse(Max_Points > 0, Cumulative_Points / Max_Points, 0))
  
  # Validate percentage calculations
  invalid_pct <- sum(is.na(df82_ladies$Pct_of_Max_Points) | 
                    df82_ladies$Pct_of_Max_Points < 0 | 
                    !is.finite(df82_ladies$Pct_of_Max_Points), na.rm = TRUE)
  if (invalid_pct > 0) {
    warning("Found ", invalid_pct, " invalid percentage values in ladies data")
  }
  
  cat("✓ Ladies maximum points calculation completed\n")
  cat("Seasons with max points:", nrow(max_points_per_season_ladies), "\n")
  
}, error = function(e) {
  stop("Error calculating ladies maximum points: ", e$message)
})

# Create ladies ELO dataframe with previous season values
cat("\n--- Ladies ELO Dataframe Creation ---\n")

tryCatch({
  # Validate df82_ladies exists and has required columns
  if (!exists("df82_ladies")) stop("df82_ladies not found")
  if (nrow(df82_ladies) == 0) stop("df82_ladies is empty")
  
  required_elo_cols <- c("Event", "ID", "Season", "Pelo", "Sprint_Pelo", "Sprint_C_Pelo", 
                        "Sprint_F_Pelo", "Distance_Pelo", "Distance_F_Pelo", 
                        "Distance_C_Pelo", "Freestyle_Pelo", "Classic_Pelo", "Pct_of_Max_Points")
  missing_elo_cols <- setdiff(required_elo_cols, names(df82_ladies))
  if (length(missing_elo_cols) > 0) {
    stop("Missing required columns for ladies ELO processing: ", paste(missing_elo_cols, collapse = ", "))
  }
  
  # Filter for Offseason events
  offseason_data_ladies <- df82_ladies %>%
    filter(Event == "Offseason")
  
  if (nrow(offseason_data_ladies) == 0) {
    warning("No Offseason events found in ladies data")
    # Use all data as fallback
    offseason_data_ladies <- df82_ladies
  }
  
  elo_df82_ladies <- offseason_data_ladies %>%
    arrange(ID, Season) %>%
    group_by(ID) %>%
    mutate(
      Prev_Pelo = lag(Pelo),
      Prev_Sprint = lag(Sprint_Pelo),
      Prev_Sprint_C = lag(Sprint_C_Pelo),
      Prev_Sprint_F = lag(Sprint_F_Pelo),
      Prev_Distance = lag(Distance_Pelo),
      Prev_Distance_F = lag(Distance_F_Pelo),
      Prev_Distance_C = lag(Distance_C_Pelo),
      Prev_F = lag(Freestyle_Pelo),
      Prev_C = lag(Classic_Pelo),
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
    ) %>%
    ungroup() %>%
    filter(Season > 1981)
  
  # Validate ELO dataframe
  if (nrow(elo_df82_ladies) == 0) stop("No data remaining after ladies ELO processing")
  
  # Check for excessive missing values in previous season data
  prev_cols <- c("Prev_Pelo", "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", 
                "Prev_Distance", "Prev_Distance_F", "Prev_Distance_C", 
                "Prev_F", "Prev_C", "Prev_Pct_of_Max_Points")
  
  for (col in prev_cols) {
    if (col %in% names(elo_df82_ladies)) {
      na_count <- sum(is.na(elo_df82_ladies[[col]]))
      na_pct <- (na_count / nrow(elo_df82_ladies)) * 100
      if (na_pct > 75) {
        warning("High missing data (", round(na_pct, 1), "%) in column: ", col)
      }
    }
  }
  
  cat("✓ Ladies ELO dataframe created:", nrow(elo_df82_ladies), "observations\n")
  cat("Unique IDs:", length(unique(elo_df82_ladies$ID)), "\n")
  cat("Season range:", min(elo_df82_ladies$Season), "to", max(elo_df82_ladies$Season), "\n")
  
}, error = function(e) {
  stop("Error creating ladies ELO dataframe: ", e$message)
})

# Handle missing values in previous season data for ladies with validation
cat("\n--- Ladies Missing Value Imputation ---\n")

tryCatch({
  # Validate elo_df82_ladies exists
  if (!exists("elo_df82_ladies")) stop("elo_df82_ladies not found")
  if (nrow(elo_df82_ladies) == 0) stop("elo_df82_ladies is empty")
  
  # Count missing values before imputation
  prev_vars <- c("Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", "Prev_Pelo",
                "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_F", "Prev_C", "Prev_Pct_of_Max_Points")
  
  missing_before <- sapply(prev_vars, function(var) {
    if (var %in% names(elo_df82_ladies)) {
      sum(is.na(elo_df82_ladies[[var]]))
    } else {
      0
    }
  })
  
  cat("Missing values before imputation:\n")
  for (i in seq_along(missing_before)) {
    if (missing_before[i] > 0) {
      cat("-", names(missing_before)[i], ":", missing_before[i], "\n")
    }
  }
  
  df82_final_ladies <- elo_df82_ladies %>%
    group_by(Season) %>%
    mutate(
      Prev_Distance = replace_na_with_quartile(Prev_Distance),
      Prev_Distance_C = replace_na_with_quartile(Prev_Distance_C),
      Prev_Distance_F = replace_na_with_quartile(Prev_Distance_F),
      Prev_Pelo = replace_na_with_quartile(Prev_Pelo),
      Prev_Sprint = replace_na_with_quartile(Prev_Sprint),
      Prev_Sprint_C = replace_na_with_quartile(Prev_Sprint_C),
      Prev_Sprint_F = replace_na_with_quartile(Prev_Sprint_F),
      Prev_F = replace_na_with_quartile(Prev_F),
      Prev_C = replace_na_with_quartile(Prev_C),
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate final data
  if (nrow(df82_final_ladies) == 0) stop("No data remaining after ladies missing value imputation")
  
  # Count missing values after imputation
  missing_after <- sapply(prev_vars, function(var) {
    if (var %in% names(df82_final_ladies)) {
      sum(is.na(df82_final_ladies[[var]]))
    } else {
      0
    }
  })
  
  # Check if imputation was successful
  remaining_missing <- sum(missing_after)
  if (remaining_missing > 0) {
    warning("Still have ", remaining_missing, " missing values after imputation")
  }
  
  # Validate data ranges
  numeric_cols <- c("Prev_Distance", "Prev_Distance_C", "Prev_Distance_F", "Prev_Pelo",
                   "Prev_Sprint", "Prev_Sprint_C", "Prev_Sprint_F", "Prev_F", "Prev_C")
  
  for (col in numeric_cols) {
    if (col %in% names(df82_final_ladies)) {
      invalid_vals <- sum(!is.finite(df82_final_ladies[[col]]) | df82_final_ladies[[col]] < 0, na.rm = TRUE)
      if (invalid_vals > 0) {
        warning("Found ", invalid_vals, " invalid values in ", col)
      }
    }
  }
  
  cat("✓ Ladies missing value imputation completed\n")
  cat("Final dataset:", nrow(df82_final_ladies), "observations\n")
  
}, error = function(e) {
  stop("Error handling missing values in ladies data: ", e$message)
})

# Final validation and summary reporting
cat("\n--- Final DF82 Dataset Summary ---\n")

tryCatch({
  # Validate final datasets exist
  if (!exists("df82_final")) stop("df82_final not found")
  if (!exists("df82_final_ladies")) stop("df82_final_ladies not found")
  
  # Men's dataset summary
  if (nrow(df82_final) > 0) {
    cat("Men's comprehensive dataset:", nrow(df82_final), "observations\n")
    cat("Men's seasons covered:", min(df82_final$Season), "to", max(df82_final$Season), "\n")
    cat("Unique men's skiers:", length(unique(df82_final$ID)), "\n")
  } else {
    warning("Men's final dataset is empty")
  }
  
  # Ladies dataset summary
  if (nrow(df82_final_ladies) > 0) {
    cat("Ladies comprehensive dataset:", nrow(df82_final_ladies), "observations\n")
    cat("Ladies seasons covered:", min(df82_final_ladies$Season), "to", max(df82_final_ladies$Season), "\n")
    cat("Unique ladies skiers:", length(unique(df82_final_ladies$ID)), "\n")
  } else {
    warning("Ladies final dataset is empty")
  }
  
  cat("✓ DF82 dataset creation completed successfully\n")
  
}, error = function(e) {
  stop("Error in final DF82 validation: ", e$message)
})
```

```{r age-exploration}
cat("=== AGE EXPLORATION VALIDATION ===\n")

# Simple GAM-based age prediction function
predict_elo_with_age_gam <- function(df, min_exp = 20) {
  cat("\n--- GAM-based Age Prediction Function ---\n")
  
  # Filter data
  gam_data <- df %>%
    filter(!is.na(Age), Age >= 15, Age <= 40) %>%
    filter(Exp >= min_exp) %>%
    filter(!is.na(Prev_Pelo), !is.na(Pelo)) %>%
    filter(Prev_Pelo > 0, Pelo > 0)
  
  cat("GAM training data:", nrow(gam_data), "observations\n")
  
  # Fit GAM models for key ELO types
  gam_models <- list()
  
  # Pelo GAM
  if (nrow(gam_data) >= 50) {
    tryCatch({
      pelo_gam <- gam(Pelo ~ s(Age) + s(Prev_Pelo), data = gam_data)
      gam_models$Pelo <- pelo_gam
      cat("✓ Pelo GAM fitted - R²:", round(summary(pelo_gam)$r.sq, 3), "\n")
    }, error = function(e) cat("✗ Pelo GAM failed:", e$message, "\n"))
    
    # Distance GAM
    if (sum(!is.na(gam_data$Distance_Pelo) & !is.na(gam_data$Prev_Distance)) >= 50) {
      tryCatch({
        distance_gam <- gam(Distance_Pelo ~ s(Age) + s(Prev_Distance), data = gam_data)
        gam_models$Distance <- distance_gam
        cat("✓ Distance GAM fitted - R²:", round(summary(distance_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Distance GAM failed:", e$message, "\n"))
    }
    
    # Sprint GAM
    if (sum(!is.na(gam_data$Sprint_Pelo) & !is.na(gam_data$Prev_Sprint)) >= 50) {
      tryCatch({
        sprint_gam <- gam(Sprint_Pelo ~ s(Age) + s(Prev_Sprint), data = gam_data)
        gam_models$Sprint <- sprint_gam
        cat("✓ Sprint GAM fitted - R²:", round(summary(sprint_gam)$r.sq, 3), "\n")
      }, error = function(e) cat("✗ Sprint GAM failed:", e$message, "\n"))
    }
  }
  
  # Create prediction function
  predict_age_elos <- function(age, prev_pelo, prev_distance = NULL, prev_sprint = NULL) {
    predictions <- list()
    
    # Predict Pelo
    if ("Pelo" %in% names(gam_models) && !is.na(prev_pelo) && prev_pelo > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Pelo = prev_pelo)
        predictions$Predicted_Pelo <- max(0, predict(gam_models$Pelo, pred_data))
      }, error = function(e) {
        predictions$Predicted_Pelo <- prev_pelo  # Fallback
      })
    } else {
      predictions$Predicted_Pelo <- prev_pelo
    }
    
    # Predict Distance
    if ("Distance" %in% names(gam_models) && !is.na(prev_distance) && prev_distance > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Distance = prev_distance)
        predictions$Predicted_Distance <- max(0, predict(gam_models$Distance, pred_data))
      }, error = function(e) {
        predictions$Predicted_Distance <- prev_distance  # Fallback
      })
    } else {
      predictions$Predicted_Distance <- prev_distance
    }
    
    # Predict Sprint
    if ("Sprint" %in% names(gam_models) && !is.na(prev_sprint) && prev_sprint > 0) {
      tryCatch({
        pred_data <- data.frame(Age = age, Prev_Sprint = prev_sprint)
        predictions$Predicted_Sprint <- max(0, predict(gam_models$Sprint, pred_data))
      }, error = function(e) {
        predictions$Predicted_Sprint <- prev_sprint  # Fallback
      })
    } else {
      predictions$Predicted_Sprint <- prev_sprint
    }
    
    return(predictions)
  }
  
  cat("✓ GAM age prediction function created with", length(gam_models), "models\n")
  
  return(list(
    gam_models = gam_models,
    predict_function = predict_age_elos,
    training_data = gam_data
  ))
}

# GAM-based age progression analysis using data-driven smooth curves
# Fit GAM models for each ELO type: Current_ELO ~ s(Age) + s(Previous_ELO)
analyze_elo_progression_by_age_gam <- function(df, min_exp = 20) {
  
  cat("\n--- GAM-based Age Progression Analysis Function ---\n")
  
  # Input validation
  tryCatch({
    if (!is.data.frame(df)) stop("Input 'df' is not a data frame")
    if (nrow(df) == 0) stop("Input dataframe is empty")
    if (!is.numeric(min_exp) || min_exp < 0) stop("min_exp must be a non-negative number")
    
    # Check for required columns
    required_cols <- c("Age", "Exp", "Pelo", "Prev_Pelo", "Distance_Pelo", "Prev_Distance",
                      "Distance_C_Pelo", "Prev_Distance_C", "Distance_F_Pelo", "Prev_Distance_F",
                      "Sprint_Pelo", "Prev_Sprint", "Sprint_C_Pelo", "Prev_Sprint_C",
                      "Sprint_F_Pelo", "Prev_Sprint_F", "Classic_Pelo", "Prev_C",
                      "Freestyle_Pelo", "Prev_F")
    
    missing_cols <- setdiff(required_cols, names(df))
    if (length(missing_cols) > 0) {
      stop("Missing required columns: ", paste(missing_cols, collapse = ", "))
    }
    
    # Validate data quality
    na_age <- sum(is.na(df$Age))
    na_exp <- sum(is.na(df$Exp))
    
    if (na_age > nrow(df) * 0.5) {
      stop("More than 50% of Age values are missing")
    }
    if (na_exp > nrow(df) * 0.5) {
      stop("More than 50% of Exp values are missing")
    }
    
    cat("✓ Input validation passed\n")
    cat("Dataset size:", nrow(df), "observations\n")
    cat("Missing Age values:", na_age, "\n")
    cat("Missing Exp values:", na_exp, "\n")
    
  }, error = function(e) {
    stop("Input validation failed: ", e$message)
  })
  
  # All ELO rating types to analyze
  elo_types <- list(
    "Pelo" = c("Pelo", "Prev_Pelo"),
    "Distance_Pelo" = c("Distance_Pelo", "Prev_Distance"),
    "Distance_C_Pelo" = c("Distance_C_Pelo", "Prev_Distance_C"), 
    "Distance_F_Pelo" = c("Distance_F_Pelo", "Prev_Distance_F"),
    "Sprint_Pelo" = c("Sprint_Pelo", "Prev_Sprint"),
    "Sprint_C_Pelo" = c("Sprint_C_Pelo", "Prev_Sprint_C"),
    "Sprint_F_Pelo" = c("Sprint_F_Pelo", "Prev_Sprint_F"),
    "Classic_Pelo" = c("Classic_Pelo", "Prev_C"),
    "Freestyle_Pelo" = c("Freestyle_Pelo", "Prev_F")
  )
  
  # Final validation and return
  tryCatch({
    result_list <- list(
      data = df
    )
    
    # Validate return components
    if (is.null(result_list$data) || nrow(result_list$data) == 0) {
      stop("Input dataframe is NULL or empty")
    }
    
    cat("\n✓ Age analysis data preparation completed successfully\n")
    cat("Total observations:", nrow(result_list$data), "\n")
    
    return(result_list)
    
  }, error = function(e) {
    stop("Error creating return object: ", e$message)
  })
}

# Run GAM-based age progression analysis on comprehensive datasets with validation
cat("\n=== MEN'S GAM-BASED AGE PROGRESSION ANALYSIS ===\n")

tryCatch({
  # Validate input data exists
  if (!exists("df82_final")) stop("df82_final dataset not found")
  if (nrow(df82_final) == 0) stop("df82_final dataset is empty")
  
  age_analysis_men <- predict_elo_with_age_gam(df82_final)
  
  # Validate results
  if (is.null(age_analysis_men)) stop("Age analysis returned NULL for men")
  
  # Display GAM model information
  if (!is.null(age_analysis_men$gam_models) && length(age_analysis_men$gam_models) > 0) {
    cat("\nMen's GAM-based ELO prediction models:\n")
    for (model_name in names(age_analysis_men$gam_models)) {
      model <- age_analysis_men$gam_models[[model_name]]
      cat(sprintf("- %s GAM: R² = %.3f, Training obs = %d\n", 
                  model_name, summary(model)$r.sq, nrow(model$model)))
    }
  } else {
    cat("No GAM models available for men\n")
  }
  
  cat("\nMen's GAM age analysis summary:\n")
  cat("- Training observations:", nrow(age_analysis_men$training_data), "\n")
  cat("- GAM models fitted:", length(age_analysis_men$gam_models), "\n")
  
}, error = function(e) {
  stop("Error in men's age progression analysis: ", e$message)
})

cat("\n=== LADIES GAM-BASED AGE PROGRESSION ANALYSIS ===\n")

tryCatch({
  # Validate input data exists
  if (!exists("df82_final_ladies")) stop("df82_final_ladies dataset not found")
  if (nrow(df82_final_ladies) == 0) stop("df82_final_ladies dataset is empty")
  
  age_analysis_ladies <- predict_elo_with_age_gam(df82_final_ladies)
  
  # Validate results
  if (is.null(age_analysis_ladies)) stop("Age analysis returned NULL for ladies")
  
  # Display GAM model information
  if (!is.null(age_analysis_ladies$gam_models) && length(age_analysis_ladies$gam_models) > 0) {
    cat("\nLadies GAM-based ELO prediction models:\n")
    for (model_name in names(age_analysis_ladies$gam_models)) {
      model <- age_analysis_ladies$gam_models[[model_name]]
      cat(sprintf("- %s GAM: R² = %.3f, Training obs = %d\n", 
                  model_name, summary(model)$r.sq, nrow(model$model)))
    }
  } else {
    cat("No GAM models available for ladies\n")
  }
  
  cat("\nLadies GAM age analysis summary:\n")
  cat("- Training observations:", nrow(age_analysis_ladies$training_data), "\n")
  cat("- GAM models fitted:", length(age_analysis_ladies$gam_models), "\n")
  
}, error = function(e) {
  stop("Error in ladies age progression analysis: ", e$message)
})

# Use men's analysis for backwards compatibility in subsequent sections with validation
tryCatch({
  if (!exists("age_analysis_men") || is.null(age_analysis_men)) {
    stop("Men's age analysis not available for backwards compatibility")
  }
  
  age_analysis <- age_analysis_men
  cat("\n✓ Age analysis stored for backwards compatibility\n")
  
}, error = function(e) {
  warning("Could not set backwards compatibility: ", e$message)
  age_analysis <- NULL
})
```

```{r age-adjusted-2025}
cat("=== GAM-BASED AGE-ADJUSTED 2025 VALIDATION ===\n")

# Calculate GAM-based age-adjusted predictions for 2026 using 2025 ELO values
cat("\nGAM-Based Age-Adjusted 2026 Predictions\n")

# Extract GAM prediction functions from analysis with validation
tryCatch({
  # Validate age_analysis exists and has required structure
  if (!exists("age_analysis")) stop("age_analysis not found")
  if (is.null(age_analysis)) stop("age_analysis is NULL")
  if (!"predict_function" %in% names(age_analysis)) {
    stop("predict_function not found in age_analysis")
  }
  
  # Extract GAM prediction function
  age_prediction_function <- age_analysis$predict_function
  
  # Validate GAM prediction function
  if (is.null(age_prediction_function)) stop("No GAM prediction function available")
  if (!is.function(age_prediction_function)) stop("age_prediction_function is not a function")
  
  cat("✓ GAM age prediction function extracted\n")
  
}, error = function(e) {
  stop("Error extracting GAM age factors: ", e$message)
})

# Enhanced GAM-based prediction function with validation
predict_2026_with_gam_age_adjustment <- function(current_data, gam_predict_func) {
  
  cat("\n--- GAM-Based Age Adjustment Prediction Function ---\n")
  
  # Input validation
  tryCatch({
    if (!is.data.frame(current_data)) stop("current_data is not a data frame")
    if (nrow(current_data) == 0) stop("current_data is empty")
    if (!is.function(gam_predict_func)) stop("gam_predict_func is not a function")
    
    # Check for required columns in current_data
    required_cols <- c("Age", "Distance_Pelo", "Sprint_Pelo", "Classic_Pelo", 
                      "Freestyle_Pelo", "Pelo", "Skier", "Nation", "Pct_of_Max_Points")
    missing_cols <- setdiff(required_cols, names(current_data))
    if (length(missing_cols) > 0) {
      stop("Missing required columns in current_data: ", paste(missing_cols, collapse = ", "))
    }
    
    cat("✓ Input validation passed\n")
    
  }, error = function(e) {
    stop("Input validation failed: ", e$message)
  })
  
  # Data processing with validation
  tryCatch({
    # Check for missing age data before processing
    missing_age_count <- sum(is.na(current_data$Age))
    if (missing_age_count > 0) {
      warning("Found ", missing_age_count, " missing Age values in current_data")
    }
    
    predictions <- current_data %>%
      rowwise() %>%
      mutate(
        # Use GAM predictions for age-adjusted ELO values
        gam_predictions = list(gam_predict_func(
          Age, 
          Pelo, 
          Distance_Pelo, 
          Sprint_Pelo
        )),
        
        # Extract GAM predictions with fallback to current values
        Predicted_Pelo_2026 = ifelse(!is.null(gam_predictions$Predicted_Pelo) && 
                                     is.finite(gam_predictions$Predicted_Pelo), 
                                     gam_predictions$Predicted_Pelo, Pelo),
        Predicted_Distance_2026 = ifelse(!is.null(gam_predictions$Predicted_Distance) && 
                                        is.finite(gam_predictions$Predicted_Distance), 
                                        gam_predictions$Predicted_Distance, Distance_Pelo),
        Predicted_Sprint_2026 = ifelse(!is.null(gam_predictions$Predicted_Sprint) && 
                                      is.finite(gam_predictions$Predicted_Sprint), 
                                      gam_predictions$Predicted_Sprint, Sprint_Pelo),
        
        # Age progression category
        Age_Category = case_when(
          is.na(Age) ~ "Unknown",
          Age <= 23 ~ "Young (≤23)",
          Age <= 27 ~ "Prime (24-27)", 
          Age <= 31 ~ "Peak (28-31)",
          Age <= 35 ~ "Mature (32-35)",
          TRUE ~ "Veteran (36+)"
        )
      ) %>%
      ungroup() %>%
      dplyr::select(Skier, Nation, Age, Age_Category, 
             Distance_Pelo, Predicted_Distance_2026,
             Sprint_Pelo, Predicted_Sprint_2026,
             Pelo, Predicted_Pelo_2026,
             Pct_of_Max_Points, -gam_predictions)
    
    # Validate predictions
    if (nrow(predictions) == 0) stop("No predictions generated")
    
    # Check for invalid predictions
    invalid_predictions <- sum(!is.finite(predictions$Predicted_Pelo_2026), na.rm = TRUE)
    if (invalid_predictions > 0) {
      warning("Generated ", invalid_predictions, " invalid predictions")
    }
    
    # Check for predictions that are similar to current values (minimal age effect)
    minimal_change <- sum(abs(predictions$Predicted_Pelo_2026 - predictions$Pelo) < 10, na.rm = TRUE)
    if (minimal_change > 0) {
      cat(minimal_change, " athletes have minimal GAM age adjustment (<10 ELO points)\n")
    }
    
    cat("✓ GAM-based age-adjusted predictions generated:", nrow(predictions), "athletes\n")
    
    return(predictions)
    
  }, error = function(e) {
    stop("Error generating predictions: ", e$message)
  })
}

# Apply GAM-based age adjustments to 2025 data with validation
cat("\n--- GAM-Based Age Adjustment Execution ---\n")

tryCatch({
  # Validate input data exists
  if (!exists("men_pred_data")) {
    stop("men_pred_data not found")
  }
  if (!exists("age_prediction_function")) {
    stop("age_prediction_function not found") 
  }
  if (nrow(men_pred_data) == 0) {
    stop("men_pred_data is empty")
  }
  
  # Apply GAM-based age adjustments
  age_adjusted_predictions <- predict_2026_with_gam_age_adjustment(men_pred_data, age_prediction_function)
  
  # Validate results
  if (is.null(age_adjusted_predictions)) stop("GAM age adjustment function returned NULL")
  if (nrow(age_adjusted_predictions) == 0) stop("No GAM age-adjusted predictions generated")
  
  # Display top predictions with validation
  cat("\nTop 15 GAM Age-Adjusted 2026 Predictions:\n")
  tryCatch({
    top_predictions <- age_adjusted_predictions %>%
      arrange(desc(Predicted_Pelo_2026)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(Predicted_Pelo_2026 - Pelo, 0)
      ) %>%
      head(15)
    
    if (nrow(top_predictions) > 0) {
      print(top_predictions)
    } else {
      cat("No predictions to display\n")
    }
  }, error = function(e) {
    warning("Error displaying top predictions: ", e$message)
  })
  
  # Identify biggest improvers with validation (GAM predicted increase > 0)
  cat("\nBiggest Expected Improvers (GAM Age Adjustment > 0):\n")
  tryCatch({
    improvers <- age_adjusted_predictions %>%
      mutate(GAM_Change = Predicted_Pelo_2026 - Pelo) %>%
      filter(!is.na(GAM_Change), GAM_Change > 0) %>%
      arrange(desc(GAM_Change)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026, GAM_Change) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(GAM_Change, 0)
      ) %>%
      head(10)
    
    if (nrow(improvers) > 0) {
      print(improvers)
    } else {
      cat("No improvers found with GAM age predictions\n")
    }
  }, error = function(e) {
    warning("Error analyzing improvers: ", e$message)
  })
  
  # Identify biggest decliners with validation (GAM predicted decrease < 0)
  cat("\nBiggest Expected Decliners (GAM Age Adjustment < 0):\n")
  tryCatch({
    decliners <- age_adjusted_predictions %>%
      mutate(GAM_Change = Predicted_Pelo_2026 - Pelo) %>%
      filter(!is.na(GAM_Change), GAM_Change < 0) %>%
      arrange(GAM_Change) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026, GAM_Change) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(GAM_Change, 0)
      ) %>%
      head(10)
    
    if (nrow(decliners) > 0) {
      print(decliners)
    } else {
      cat("No decliners found with GAM age predictions\n")
    }
  }, error = function(e) {
    warning("Error analyzing decliners: ", e$message)
  })
  
  cat("✓ GAM-based age adjustment analysis completed successfully\n")
  
}, error = function(e) {
  cat("GAM-based age adjustment analysis failed: ", e$message, "\n")
  cat("Attempting to continue without GAM age-adjusted predictions\n")
})


# LADIES GAM-BASED AGE ADJUSTMENT
cat("\n=== LADIES GAM-BASED AGE-ADJUSTED 2026 PREDICTIONS ===\n")

tryCatch({
  # Validate ladies prediction function exists
  if (!exists("age_analysis_ladies") || is.null(age_analysis_ladies)) {
    stop("Ladies age analysis not found")
  }
  if (!"predict_function" %in% names(age_analysis_ladies)) {
    stop("Ladies predict_function not found in age_analysis_ladies")
  }
  
  # Extract ladies GAM prediction function
  age_prediction_function_ladies <- age_analysis_ladies$predict_function
  
  # Validate ladies prediction data
  if (!exists("ladies_pred_data") || is.null(ladies_pred_data) || nrow(ladies_pred_data) == 0) {
    stop("Ladies prediction data not available")
  }
  
  # Apply GAM-based age adjustments to ladies
  age_adjusted_predictions_ladies <- predict_2026_with_gam_age_adjustment(ladies_pred_data, age_prediction_function_ladies)
  
  # Validate results
  if (is.null(age_adjusted_predictions_ladies)) stop("Ladies GAM age adjustment function returned NULL")
  if (nrow(age_adjusted_predictions_ladies) == 0) stop("No ladies GAM age-adjusted predictions generated")
  
  # Display top predictions
  cat("\nTop 15 Ladies GAM Age-Adjusted 2026 Predictions:\n")
  tryCatch({
    top_predictions_ladies <- age_adjusted_predictions_ladies %>%
      arrange(desc(Predicted_Pelo_2026)) %>%
      dplyr::select(Skier, Nation, Age, Age_Category, Pelo, Predicted_Pelo_2026) %>%
      mutate(
        Pelo = round(Pelo, 0),
        Predicted_Pelo_2026 = round(Predicted_Pelo_2026, 0),
        GAM_Change = round(Predicted_Pelo_2026 - Pelo, 0)
      ) %>%
      head(15)
    
    if (nrow(top_predictions_ladies) > 0) {
      print(top_predictions_ladies)
    } else {
      cat("No ladies predictions to display\n")
    }
  }, error = function(e) {
    warning("Error displaying ladies top predictions: ", e$message)
  })
  
  cat("✓ Ladies GAM-based age adjustment analysis completed successfully\n")
  
}, error = function(e) {
  cat("Ladies GAM-based age adjustment analysis failed: ", e$message, "\n")
})


# EXCEL OUTPUTS FOR AGE-ADJUSTED PREDICTIONS
cat("\n=== EXCEL OUTPUTS FOR AGE-ADJUSTED PREDICTIONS ===\n")

tryCatch({
  # Create output directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
  }
  
  # Men's age-adjusted predictions Excel output using Log-Transform GAM
  if (exists("age_adjusted_predictions") && !is.null(age_adjusted_predictions) && nrow(age_adjusted_predictions) > 0) {
    men_age_excel <- age_adjusted_predictions %>%
      mutate(
        # Use log-transform GAM predictions if available, otherwise original GAM
        `Log-Transform GAM Predicted Elo` = if(exists("log_predictor_men") && is.function(log_predictor_men)) {
          mapply(function(age, pelo) {
            tryCatch({
              round(log_predictor_men(age, pelo), 0)
            }, error = function(e) {
              round(Predicted_Pelo_2026, 0)  # Fallback to original
            })
          }, Age, Pelo, SIMPLIFY = TRUE)
        } else {
          round(Predicted_Pelo_2026, 0)  # Use existing GAM if log-transform not available
        },
        `Predicted Elo Change` = `Log-Transform GAM Predicted Elo` - round(Pelo, 0)
      ) %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Current Elo` = Pelo,
        `Predicted Elo 2026` = `Log-Transform GAM Predicted Elo`,
        `Predicted Elo Change`
      ) %>%
      mutate(
        `Current Elo` = round(`Current Elo`, 0)
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    men_age_file <- file.path("excel365", "mens_age_adjusted_predictions_2026.xlsx")
    write.xlsx(men_age_excel, men_age_file, rowNames = FALSE)
    cat("✓ Men's age-adjusted predictions saved to:", men_age_file, "\n")
  }
  
  # Ladies age-adjusted predictions Excel output using Log-Transform GAM
  if (exists("age_adjusted_predictions_ladies") && !is.null(age_adjusted_predictions_ladies) && nrow(age_adjusted_predictions_ladies) > 0) {
    ladies_age_excel <- age_adjusted_predictions_ladies %>%
      mutate(
        # Use log-transform GAM predictions if available, otherwise original GAM
        `Log-Transform GAM Predicted Elo` = if(exists("log_predictor_ladies") && is.function(log_predictor_ladies)) {
          mapply(function(age, pelo) {
            tryCatch({
              round(log_predictor_ladies(age, pelo), 0)
            }, error = function(e) {
              round(Predicted_Pelo_2026, 0)  # Fallback to original
            })
          }, Age, Pelo, SIMPLIFY = TRUE)
        } else {
          round(Predicted_Pelo_2026, 0)  # Use existing GAM if log-transform not available
        },
        `Predicted Elo Change` = `Log-Transform GAM Predicted Elo` - round(Pelo, 0)
      ) %>%
      dplyr::select(
        Name = Skier,
        Nation,
        Age,
        `Current Elo` = Pelo,
        `Predicted Elo 2026` = `Log-Transform GAM Predicted Elo`,
        `Predicted Elo Change`
      ) %>%
      mutate(
        `Current Elo` = round(`Current Elo`, 0)
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    ladies_age_file <- file.path("excel365", "ladies_age_adjusted_predictions_2026.xlsx")
    write.xlsx(ladies_age_excel, ladies_age_file, rowNames = FALSE)
    cat("✓ Ladies age-adjusted predictions saved to:", ladies_age_file, "\n")
  }
  
}, error = function(e) {
  warning("Error creating Excel outputs: ", e$message)
})

cat("\n=== GAM MODEL DIAGNOSTICS ===\n")

# Men's GAM Model Diagnostics
cat("--- Men's GAM Model Diagnostics ---\n")
tryCatch({
  if (exists("age_analysis_men") && !is.null(age_analysis_men) && 
      "gam_models" %in% names(age_analysis_men) && 
      "Pelo" %in% names(age_analysis_men$gam_models)) {
    
    men_gam_model <- age_analysis_men$gam_models$Pelo
    men_summary <- summary(men_gam_model)
    
    par(mfrow = c(2, 2))
    gam_check_men <- gam.check(men_gam_model, sub.caption = "Men's GAM Diagnostics")
    
    # Extract and validate diagnostic information
    if (!is.null(gam_check_men)) {
      # Check for model convergence issues
      if ("converged" %in% names(men_gam_model) && !men_gam_model$converged) {
        warning("Men's GAM model did not converge properly")
      }
      
      # Check basis dimensions
      if ("s.table" %in% names(men_summary) && !is.null(men_summary$s.table)) {
        if ("k-index" %in% colnames(men_summary$s.table)) {
          basis_dims <- men_summary$s.table[,"k-index"]
          low_basis <- names(basis_dims[basis_dims < 0.1])
          if (length(low_basis) > 0) {
            warning(paste("Men's GAM features with potentially insufficient basis dimensions:", 
                         paste(low_basis, collapse = ", ")))
          }
        }
      }
    }
    
    cat("✓ Men's GAM diagnostic plots generated\n")
    cat("Men's GAM R-squared:", round(men_summary$r.sq, 3), "\n")
    cat("Men's GAM Deviance explained:", round(men_summary$dev.expl * 100, 1), "%\n")
    
  } else {
    cat("Men's GAM model not available for diagnostics\n")
  }
  
}, error = function(e) {
  cat("Error generating men's GAM diagnostics:", e$message, "\n")
  # Reset plotting parameters
  par(mfrow = c(1, 1))
})

# Ladies GAM Model Diagnostics
cat("--- Ladies GAM Model Diagnostics ---\n")
tryCatch({
  if (exists("age_analysis_ladies") && !is.null(age_analysis_ladies) && 
      "gam_models" %in% names(age_analysis_ladies) && 
      "Pelo" %in% names(age_analysis_ladies$gam_models)) {
    
    ladies_gam_model <- age_analysis_ladies$gam_models$Pelo
    ladies_summary <- summary(ladies_gam_model)
    
    par(mfrow = c(2, 2))
    gam_check_ladies <- gam.check(ladies_gam_model, sub.caption = "Ladies GAM Diagnostics")
    
    # Extract and validate diagnostic information
    if (!is.null(gam_check_ladies)) {
      # Check for model convergence issues
      if ("converged" %in% names(ladies_gam_model) && !ladies_gam_model$converged) {
        warning("Ladies GAM model did not converge properly")
      }
      
      # Check basis dimensions
      if ("s.table" %in% names(ladies_summary) && !is.null(ladies_summary$s.table)) {
        if ("k-index" %in% colnames(ladies_summary$s.table)) {
          basis_dims <- ladies_summary$s.table[,"k-index"]
          low_basis <- names(basis_dims[basis_dims < 0.1])
          if (length(low_basis) > 0) {
            warning(paste("Ladies GAM features with potentially insufficient basis dimensions:", 
                         paste(low_basis, collapse = ", ")))
          }
        }
      }
    }
    
    cat("✓ Ladies GAM diagnostic plots generated\n")
    cat("Ladies GAM R-squared:", round(ladies_summary$r.sq, 3), "\n")
    cat("Ladies GAM Deviance explained:", round(ladies_summary$dev.expl * 100, 1), "%\n")
    
  } else {
    cat("Ladies GAM model not available for diagnostics\n")
  }
  
}, error = function(e) {
  cat("Error generating ladies GAM diagnostics:", e$message, "\n")
})

# Reset plotting parameters
par(mfrow = c(1, 1))

cat("\n✓ GAM model diagnostics completed\n")

# LOG-TRANSFORM GAM MODEL (SOLVES HETEROSCEDASTICITY)
cat("\n=== LOG-TRANSFORM GAM MODEL FOR TOP PERFORMER ISSUE ===\n")

library(mgcv)

# Log-transform GAM - proven to completely solve heteroscedasticity
create_log_transform_gam <- function(df, data_name = "Unknown", min_exp = 20) {
  
  cat(sprintf("\n--- %s Log-Transform GAM ---\n", data_name))
  
  tryCatch({
    # Prepare training data
    gam_data <- df %>%
      filter(!is.na(Age), Age >= 15, Age <= 40) %>%
      filter(Exp >= min_exp) %>%
      filter(!is.na(Prev_Pelo), !is.na(Pelo)) %>%
      filter(Prev_Pelo > 0, Pelo > 0)
    
    if (nrow(gam_data) < 100) {
      cat("Insufficient data for GAM model\n")
      return(NULL)
    }
    
    cat("Training data:", nrow(gam_data), "observations\n")
    
    # Log transform both response and predictor to stabilize variance
    cat("\nFitting Log-transformed GAM (stabilizes variance completely):\n")
    gam_data_log <- gam_data %>%
      mutate(
        Log_Pelo = log(Pelo),
        Log_Prev_Pelo = log(Prev_Pelo)
      )
    
    log_gam <- gam(
      Log_Pelo ~ s(Age, k = 6) + s(Log_Prev_Pelo, k = 8),
      data = gam_data_log
    )
    
    cat("✓ Log-transformed GAM fitted successfully\n")
    cat("   R²:", round(summary(log_gam)$r.sq, 3), "\n")
    cat("   Deviance explained:", round(summary(log_gam)$dev.expl * 100, 1), "%\n")
    
    return(list(
      model = log_gam,
      training_data = gam_data,
      log_data = gam_data_log
    ))
    
  }, error = function(e) {
    cat("Error creating log-transform GAM:", e$message, "\n")
    return(NULL)
  })
}

# Create log-transform GAM prediction function
create_log_transform_predictor <- function(log_gam_result) {
  
  function(age, prev_pelo, prev_distance = NULL, prev_sprint = NULL) {
    tryCatch({
      # Log-transform prediction with back-transformation
      pred_data <- data.frame(Age = age, Log_Prev_Pelo = log(prev_pelo))
      log_pred <- predict(log_gam_result$model, pred_data)
      predicted_pelo <- max(0, exp(log_pred))  # Back-transform to original scale
      
      return(predicted_pelo)
    }, error = function(e) {
      # Fallback to previous Elo if prediction fails
      return(prev_pelo)
    })
  }
}

# Apply log-transform GAM models to men's data
cat("\n--- Men's Log-Transform GAM ---\n")
if (exists("df82_final") && !is.null(df82_final)) {
  log_gam_men <- create_log_transform_gam(df82_final, "Men")
  
  if (!is.null(log_gam_men)) {
    log_predictor_men <- create_log_transform_predictor(log_gam_men)
    cat("✓ Men's log-transform GAM predictor created\n")
  }
}

# Apply log-transform GAM models to ladies data
cat("\n--- Ladies Log-Transform GAM ---\n")
if (exists("df82_final_ladies") && !is.null(df82_final_ladies)) {
  log_gam_ladies <- create_log_transform_gam(df82_final_ladies, "Ladies")
  
  if (!is.null(log_gam_ladies)) {
    log_predictor_ladies <- create_log_transform_predictor(log_gam_ladies)
    cat("✓ Ladies log-transform GAM predictor created\n")
  }
}

cat("\n✓ Log-transform GAM models completed\n")

# DIAGNOSTIC PLOTS FOR LOG-TRANSFORM GAM MODEL
cat("\n=== DIAGNOSTIC PLOTS FOR LOG-TRANSFORM GAM ===\n")

# Function to create diagnostic plots for log-transform model
create_log_transform_diagnostics <- function(log_gam_result, data_name = "Unknown") {
  
  cat(sprintf("\n--- %s Log-Transform GAM Diagnostics ---\n", data_name))
  
  if (is.null(log_gam_result) || is.null(log_gam_result$model)) {
    cat("No log-transform GAM available for diagnostics\n")
    return(NULL)
  }
  
  model <- log_gam_result$model
  
  tryCatch({
    # Add clear title before plots
    cat(sprintf("\n🔍 %s LOG-TRANSFORM GAM DIAGNOSTICS 🔍\n", toupper(data_name)))
    cat(paste0(strrep("=", nchar(data_name) + 32), "\n"))
    
    par(mfrow = c(2, 2))
    par(oma = c(0, 0, 3, 0))  # Add outer margin for main title
    
    # Use gam.check for comprehensive diagnostics
    gam.check(model, sub.caption = "")
    
    # Add main title to the entire plot
    title(main = paste(data_name, "Log-Transform GAM Diagnostics"), outer = TRUE, cex.main = 1.5, col.main = "darkgreen")
    
    cat("✓ Log-Transform GAM diagnostics completed\n")
    cat("   R²:", round(summary(model)$r.sq, 3), "\n")
    cat("   Deviance explained:", round(summary(model)$dev.expl * 100, 1), "%\n")
    
    # Reset plotting
    par(mfrow = c(1, 1))
    
  }, error = function(e) {
    cat("Error creating log-transform diagnostics:", e$message, "\n")
    par(mfrow = c(1, 1))  # Reset on error
  })
}

# Run diagnostics for log-transform men's model
if (exists("log_gam_men") && !is.null(log_gam_men)) {
  create_log_transform_diagnostics(log_gam_men, "Men")
}

# Run diagnostics for log-transform ladies model
if (exists("log_gam_ladies") && !is.null(log_gam_ladies)) {
  create_log_transform_diagnostics(log_gam_ladies, "Ladies")
}

cat("\n✓ Log-transform GAM diagnostics completed\n")
```

### Russian Return Impact Analysis

```{r russian-return}
cat("=== RUSSIAN RETURN IMPACT ANALYSIS VALIDATION ===\n")

# Russian Return Analysis with Year-by-Year Progression (2022 -> 2026)
# Using GAM-based age adjustments and bounds estimation

# Year-by-year progression function for Russian skiers
project_russian_elo_yearly <- function(baseline_data, gam_predict_func) {
  
  cat("\n--- Year-by-Year Russian ELO Projection ---\n")
  
  # Input validation
  tryCatch({
    if (!is.data.frame(baseline_data)) stop("baseline_data is not a data frame")
    if (nrow(baseline_data) == 0) stop("baseline_data is empty")
    if (!is.function(gam_predict_func)) stop("gam_predict_func is not a function")
    
    required_cols <- c("Skier", "Nation", "Age", "Pelo", "Distance_Pelo", "Sprint_Pelo", "Season")
    missing_cols <- setdiff(required_cols, names(baseline_data))
    if (length(missing_cols) > 0) {
      stop("Missing required columns: ", paste(missing_cols, collapse = ", "))
    }
    
    cat("✓ Input validation passed\n")
    
  }, error = function(e) {
    stop("Input validation failed: ", e$message)
  })
  
  # Project each year from 2022 baseline
  yearly_projections <- baseline_data %>%
    # Start with 2022 baseline
    mutate(
      Age_2022 = Age,
      Pelo_2022 = Pelo,
      Distance_2022 = Distance_Pelo,
      Sprint_2022 = Sprint_Pelo
    ) %>%
    rowwise() %>%
    mutate(
      # 2023 projections (Age + 1)
      Age_2023 = Age_2022 + 1,
      gam_2023 = list(gam_predict_func(Age_2023, Pelo_2022, Distance_2022, Sprint_2022)),
      Pelo_2023 = ifelse(!is.null(gam_2023$Predicted_Pelo) && is.finite(gam_2023$Predicted_Pelo), 
                        gam_2023$Predicted_Pelo, Pelo_2022),
      Distance_2023 = ifelse(!is.null(gam_2023$Predicted_Distance) && is.finite(gam_2023$Predicted_Distance), 
                            gam_2023$Predicted_Distance, Distance_2022),
      Sprint_2023 = ifelse(!is.null(gam_2023$Predicted_Sprint) && is.finite(gam_2023$Predicted_Sprint), 
                          gam_2023$Predicted_Sprint, Sprint_2022),
      
      # 2024 projections (Age + 2, using 2023 values)
      Age_2024 = Age_2022 + 2,
      gam_2024 = list(gam_predict_func(Age_2024, Pelo_2023, Distance_2023, Sprint_2023)),
      Pelo_2024 = ifelse(!is.null(gam_2024$Predicted_Pelo) && is.finite(gam_2024$Predicted_Pelo), 
                        gam_2024$Predicted_Pelo, Pelo_2023),
      Distance_2024 = ifelse(!is.null(gam_2024$Predicted_Distance) && is.finite(gam_2024$Predicted_Distance), 
                            gam_2024$Predicted_Distance, Distance_2023),
      Sprint_2024 = ifelse(!is.null(gam_2024$Predicted_Sprint) && is.finite(gam_2024$Predicted_Sprint), 
                          gam_2024$Predicted_Sprint, Sprint_2023),
      
      # 2025 projections (Age + 3, using 2024 values)
      Age_2025 = Age_2022 + 3,
      gam_2025 = list(gam_predict_func(Age_2025, Pelo_2024, Distance_2024, Sprint_2024)),
      Pelo_2025 = ifelse(!is.null(gam_2025$Predicted_Pelo) && is.finite(gam_2025$Predicted_Pelo), 
                        gam_2025$Predicted_Pelo, Pelo_2024),
      Distance_2025 = ifelse(!is.null(gam_2025$Predicted_Distance) && is.finite(gam_2025$Predicted_Distance), 
                            gam_2025$Predicted_Distance, Distance_2024),
      Sprint_2025 = ifelse(!is.null(gam_2025$Predicted_Sprint) && is.finite(gam_2025$Predicted_Sprint), 
                          gam_2025$Predicted_Sprint, Sprint_2024),
      
      # 2026 projections (Age + 4, using 2025 values) 
      Age_2026 = Age_2022 + 4,
      gam_2026 = list(gam_predict_func(Age_2026, Pelo_2025, Distance_2025, Sprint_2025)),
      Pelo_2026 = ifelse(!is.null(gam_2026$Predicted_Pelo) && is.finite(gam_2026$Predicted_Pelo), 
                        gam_2026$Predicted_Pelo, Pelo_2025),
      Distance_2026 = ifelse(!is.null(gam_2026$Predicted_Distance) && is.finite(gam_2026$Predicted_Distance), 
                            gam_2026$Predicted_Distance, Distance_2025),
      Sprint_2026 = ifelse(!is.null(gam_2026$Predicted_Sprint) && is.finite(gam_2026$Predicted_Sprint), 
                          gam_2026$Predicted_Sprint, Sprint_2025)
    ) %>%
    ungroup() %>%
    dplyr::select(-gam_2023, -gam_2024, -gam_2025, -gam_2026) %>%
    # Add bounds calculations (±10% uncertainty)
    mutate(
      # Lower bounds (90% of predicted value)
      Pelo_2026_Lower = Pelo_2026 * 0.90,
      Distance_2026_Lower = Distance_2026 * 0.90,
      Sprint_2026_Lower = Sprint_2026 * 0.90,
      
      # Upper bounds (110% of predicted value)  
      Pelo_2026_Upper = Pelo_2026 * 1.10,
      Distance_2026_Upper = Distance_2026 * 1.10,
      Sprint_2026_Upper = Sprint_2026 * 1.10,
      
      # Age category in 2026
      Age_Category_2026 = case_when(
        Age_2026 <= 23 ~ "Young (≤23)",
        Age_2026 <= 27 ~ "Prime (24-27)", 
        Age_2026 <= 31 ~ "Peak (28-31)",
        Age_2026 <= 35 ~ "Mature (32-35)",
        TRUE ~ "Veteran (36+)"
      )
    )
  
  cat("✓ Year-by-year projections completed for", nrow(yearly_projections), "Russian skiers\n")
  
  return(yearly_projections)
}

# Execute Russian return analysis with year-by-year progression
tryCatch({
  # Validate required data exists
  if (!exists("df82_final")) stop("df82_final dataset not found")
  if (!exists("age_analysis") || is.null(age_analysis)) stop("age_analysis not found")
  if (!"predict_function" %in% names(age_analysis)) stop("GAM prediction function not available")
  
  # Extract Russian skiers from 2022 (last competitive season)
  cat("\n--- Extracting Russian 2022 Baseline ---\n")
  
  russian_2022_baseline <- df82_final %>%
    filter(Season == 2022, Nation == "Russia") %>%
    filter(!is.na(Age), !is.na(Pelo), !is.na(Distance_Pelo), !is.na(Sprint_Pelo)) %>%
    filter(Pelo > 0, Distance_Pelo > 0, Sprint_Pelo > 0) %>%  # Valid ELO values
    dplyr::select(Skier, Nation, Age, Pelo, Distance_Pelo, Sprint_Pelo, Classic_Pelo, 
                 Freestyle_Pelo, Season, Pct_of_Max_Points) %>%
    arrange(desc(Pelo))
  
  if (nrow(russian_2022_baseline) == 0) {
    stop("No Russian skiers found in 2022 baseline data")
  }
  
  cat("✓ Russian 2022 baseline extracted:", nrow(russian_2022_baseline), "skiers\n")
  cat("Top Russian from 2022:", russian_2022_baseline$Skier[1], 
      "- Pelo:", round(russian_2022_baseline$Pelo[1], 0), "\n")
  
  # Apply year-by-year progression using BOTH GAM and Multiplicative methods
  cat("\n=== RUNNING GAM PROJECTIONS ===\n")
  
  # Create wrapper function for log-transform GAM compatibility
  if (exists("log_predictor_men") && is.function(log_predictor_men)) {
    cat("Using log-transform GAM predictor for Russian projections\n")
    
    # Wrapper to make log-transform predictor compatible with Russian analysis
    log_gam_wrapper <- function(age, prev_pelo, prev_distance = NULL, prev_sprint = NULL) {
      predicted_pelo <- log_predictor_men(age, prev_pelo)
      
      # Return format compatible with original GAM predictor
      return(list(
        Predicted_Pelo = predicted_pelo,
        Predicted_Distance = predicted_pelo,  # Use overall Elo for distance
        Predicted_Sprint = predicted_pelo,    # Use overall Elo for sprint
        Predicted_Classic = predicted_pelo,   # Use overall Elo for classic
        Predicted_Freestyle = predicted_pelo  # Use overall Elo for freestyle
      ))
    }
    
    russian_projections_gam <- project_russian_elo_yearly(russian_2022_baseline, log_gam_wrapper)
  } else {
    cat("Log-transform GAM not available, using original GAM predictor\n")
    russian_projections_gam <- project_russian_elo_yearly(russian_2022_baseline, age_analysis$predict_function)
  }
  
  cat("\n=== RUSSIAN 2026 PROJECTIONS (GAM-BASED) ===\n")
  
  # Prepare Russian projections for display
  russian_display <- russian_projections_gam %>%
    dplyr::select(Skier, Age_2022, Age_2026, Age_Category_2026, Pelo_2022,
                 GAM_2026 = Pelo_2026, GAM_Lower = Pelo_2026_Lower, GAM_Upper = Pelo_2026_Upper) %>%
    mutate(
      GAM_Change = GAM_2026 - Pelo_2022,
      across(c(Pelo_2022, GAM_2026, GAM_Lower, GAM_Upper, GAM_Change), ~ round(.x, 0))
    ) %>%
    arrange(desc(GAM_2026))
  
  # Display top 15 Russian projections  
  russian_summary <- russian_display %>%
    dplyr::select(Skier, Age_2022, Age_2026, Age_Category_2026, Pelo_2022,
                 GAM_2026, GAM_Lower, GAM_Upper, GAM_Change) %>%
    head(15)
  
  cat("\nTop 15 Russian 2026 Projections (GAM-based with Bounds):\n")
  print(russian_summary)
  
  # Year-by-year progression for top Russians
  cat("\n=== TOP 5 RUSSIANS YEAR-BY-YEAR PROGRESSION ===\n")
  
  yearly_progression <- russian_projections_gam %>%
    arrange(desc(Pelo_2026)) %>%
    head(5) %>%
    dplyr::select(Skier, Age_2022, 
                 `2022` = Pelo_2022, `2023` = Pelo_2023, `2024` = Pelo_2024, 
                 `2025` = Pelo_2025, `2026` = Pelo_2026) %>%
    mutate(across(c(`2022`, `2023`, `2024`, `2025`, `2026`), ~ round(.x, 0)))
  print(yearly_progression)
  
  # Impact analysis - competitive level assessment
  cat("\n=== RUSSIAN COMPETITIVE IMPACT ASSESSMENT ===\n")
  
  # Competitive tiers analysis
  cat("\nRussian skiers by competitive tier in 2026:\n")
  competitive_tiers <- russian_projections_gam %>%
    mutate(
      Tier_2026 = case_when(
        Pelo_2026 >= 2200 ~ "Elite (2200+)",
        Pelo_2026 >= 2000 ~ "Top Tier (2000-2199)",
        Pelo_2026 >= 1800 ~ "Competitive (1800-1999)", 
        Pelo_2026 >= 1600 ~ "Solid (1600-1799)",
        TRUE ~ "Developing (<1600)"
      )
    ) %>%
    count(Tier_2026, name = "Count") %>%
    arrange(desc(Count))
  print(competitive_tiers)
  
  # Medal contenders analysis (>= 2200 ELO)
  cat("\n=== MEDAL CONTENDERS ANALYSIS (2200+ ELO) ===\n")
  
  # Medal contenders
  medal_contenders <- russian_projections_gam %>%
    filter(Pelo_2026 >= 2200) %>%
    arrange(desc(Pelo_2026)) %>%
    dplyr::select(Skier, Age_2026, ELO_2026 = Pelo_2026, Lower_Bound = Pelo_2026_Lower, Upper_Bound = Pelo_2026_Upper) %>%
    mutate(across(c(ELO_2026, Lower_Bound, Upper_Bound), ~ round(.x, 0)))
  
  if (nrow(medal_contenders) > 0) {
    cat("\nRussian medal contenders (2200+ ELO) with confidence bounds:\n")
    print(medal_contenders)
  } else {
    cat("\nNo Russian skiers projected as medal contenders (2200+ ELO) in 2026\n")
  }
  
  cat("\nMedal Contender Summary:\n")
  cat("Total medal contenders:", nrow(medal_contenders), "\n")
  
  cat("\n✓ Men's Russian return impact analysis completed successfully (GAM-based with bounds)\n")
  
}, error = function(e) {
  cat("Men's Russian return impact analysis failed: ", e$message, "\n")
  cat("Attempting to continue without men's Russian analysis\n")
})

# LADIES RUSSIAN RETURN ANALYSIS
cat("\n=== LADIES RUSSIAN RETURN IMPACT ANALYSIS ===\n")

tryCatch({
  # Validate required data exists
  if (!exists("df82_final_ladies")) stop("df82_final_ladies dataset not found")
  if (!exists("log_predictor_ladies")) stop("Ladies log-transform GAM predictor not found")
  
  # Extract Russian ladies from 2022 (last competitive season)
  cat("\n--- Extracting Russian Ladies 2022 Baseline ---\n")
  
  russian_2022_baseline_ladies <- df82_final_ladies %>%
    filter(Season == 2022, Nation == "Russia") %>%
    filter(!is.na(Age), !is.na(Pelo), !is.na(Distance_Pelo), !is.na(Sprint_Pelo)) %>%
    filter(Pelo > 0, Distance_Pelo > 0, Sprint_Pelo > 0) %>%  # Valid ELO values
    dplyr::select(Skier, Nation, Age, Pelo, Distance_Pelo, Sprint_Pelo, Classic_Pelo, 
                 Freestyle_Pelo, Season, Pct_of_Max_Points) %>%
    arrange(desc(Pelo))
  
  if (nrow(russian_2022_baseline_ladies) == 0) {
    stop("No Russian ladies found in 2022 baseline data")
  }
  
  cat("Russian ladies in 2022:", nrow(russian_2022_baseline_ladies), "\n")
  cat("Top Russian lady from 2022:", russian_2022_baseline_ladies$Skier[1], 
      "- Pelo:", round(russian_2022_baseline_ladies$Pelo[1], 0), "\n")
  
  # Create wrapper function for ladies log-transform GAM compatibility
  cat("\n=== RUNNING LADIES GAM PROJECTIONS ===\n")
  
  if (exists("log_predictor_ladies") && is.function(log_predictor_ladies)) {
    cat("Using log-transform GAM predictor for Russian ladies projections\n")
    
    # Wrapper to make log-transform predictor compatible with Russian analysis
    log_gam_wrapper_ladies <- function(age, prev_pelo, prev_distance = NULL, prev_sprint = NULL) {
      predicted_pelo <- log_predictor_ladies(age, prev_pelo)
      
      # Return format compatible with original GAM predictor
      return(list(
        Predicted_Pelo = predicted_pelo,
        Predicted_Distance = predicted_pelo,  # Use overall Elo for distance
        Predicted_Sprint = predicted_pelo,    # Use overall Elo for sprint
        Predicted_Classic = predicted_pelo,   # Use overall Elo for classic
        Predicted_Freestyle = predicted_pelo  # Use overall Elo for freestyle
      ))
    }
    
    russian_projections_gam_ladies <- project_russian_elo_yearly(russian_2022_baseline_ladies, log_gam_wrapper_ladies)
  } else {
    stop("Ladies log-transform GAM predictor not available")
  }
  
  cat("\n=== RUSSIAN LADIES 2026 PROJECTIONS (GAM-BASED) ===\n")
  
  # Prepare Russian ladies projections for display
  russian_display_ladies <- russian_projections_gam_ladies %>%
    dplyr::select(Skier, Age_2022, Age_2026, Age_Category_2026, Pelo_2022,
                 GAM_2026 = Pelo_2026, GAM_Lower = Pelo_2026_Lower, GAM_Upper = Pelo_2026_Upper) %>%
    mutate(
      GAM_Change = GAM_2026 - Pelo_2022,
      across(c(Pelo_2022, GAM_2026, GAM_Lower, GAM_Upper, GAM_Change), ~ round(.x, 0))
    ) %>%
    arrange(desc(GAM_2026))
  
  # Display top 15 Russian ladies projections  
  russian_summary_ladies <- russian_display_ladies %>%
    dplyr::select(Skier, Age_2022, Age_2026, Age_Category_2026, Pelo_2022,
                 GAM_2026, GAM_Lower, GAM_Upper, GAM_Change) %>%
    head(15)
  
  cat("\nTop 15 Russian Ladies 2026 Projections (GAM-based with Bounds):\n")
  print(russian_summary_ladies)
  
  # Ladies competitive tiers analysis
  cat("\n=== RUSSIAN LADIES COMPETITIVE IMPACT ASSESSMENT ===\n")
  
  # Competitive tiers analysis
  cat("\nRussian ladies by competitive tier in 2026:\n")
  competitive_tiers_ladies <- russian_projections_gam_ladies %>%
    mutate(
      Tier_2026 = case_when(
        Pelo_2026 >= 2200 ~ "Elite (2200+)",
        Pelo_2026 >= 2000 ~ "Top Tier (2000-2199)",
        Pelo_2026 >= 1800 ~ "Competitive (1800-1999)", 
        Pelo_2026 >= 1600 ~ "Solid (1600-1799)",
        TRUE ~ "Developing (<1600)"
      )
    ) %>%
    count(Tier_2026, name = "Count") %>%
    arrange(desc(Count))
  print(competitive_tiers_ladies)
  
  # Ladies medal contenders analysis (>= 2200 ELO)
  cat("\n=== LADIES MEDAL CONTENDERS ANALYSIS (2200+ ELO) ===\n")
  
  # Medal contenders
  medal_contenders_ladies <- russian_projections_gam_ladies %>%
    filter(Pelo_2026 >= 2200) %>%
    arrange(desc(Pelo_2026)) %>%
    dplyr::select(Skier, Age_2026, ELO_2026 = Pelo_2026, Lower_Bound = Pelo_2026_Lower, Upper_Bound = Pelo_2026_Upper) %>%
    mutate(across(c(ELO_2026, Lower_Bound, Upper_Bound), ~ round(.x, 0)))
  
  if (nrow(medal_contenders_ladies) > 0) {
    cat("\nRussian ladies medal contenders (2200+ ELO) with confidence bounds:\n")
    print(medal_contenders_ladies)
  } else {
    cat("\nNo Russian ladies projected as medal contenders (2200+ ELO) in 2026\n")
  }
  
  cat("\nLadies Medal Contender Summary:\n")
  cat("Total medal contenders:", nrow(medal_contenders_ladies), "\n")
  
  cat("\n✓ Ladies Russian return impact analysis completed successfully (GAM-based with bounds)\n")
  
}, error = function(e) {
  cat("Ladies Russian return impact analysis failed: ", e$message, "\n")
  cat("Attempting to continue without ladies Russian analysis\n")
})

# EXCEL OUTPUTS FOR RUSSIAN RETURN PROJECTIONS
cat("\n=== EXCEL OUTPUTS FOR RUSSIAN RETURN PROJECTIONS ===\n")

tryCatch({
  # Create output directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
  }
  
  # Men's Russian projections Excel output
  if (exists("russian_projections_gam") && !is.null(russian_projections_gam) && nrow(russian_projections_gam) > 0) {
    men_russian_excel <- russian_projections_gam %>%
      dplyr::select(
        Name = Skier,
        `Age 2022` = Age_2022,
        `Age 2026` = Age_2026,
        `Age Category 2026` = Age_Category_2026,
        `Current Elo (2022)` = Pelo_2022,
        `Predicted Elo 2026` = Pelo_2026,
        `Lower Bound` = Pelo_2026_Lower,
        `Upper Bound` = Pelo_2026_Upper,
        `Distance Elo 2026` = Distance_2026,
        `Sprint Elo 2026` = Sprint_2026
      ) %>%
      mutate(
        `Elo Change` = `Predicted Elo 2026` - `Current Elo (2022)`,
        across(c(`Current Elo (2022)`, `Predicted Elo 2026`, `Lower Bound`, `Upper Bound`, 
                 `Distance Elo 2026`, `Sprint Elo 2026`, `Elo Change`), ~ round(.x, 0))
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    men_russian_file <- file.path("excel365", "mens_russian_return_projections_2026.xlsx")
    write.xlsx(men_russian_excel, men_russian_file, rowNames = FALSE)
    cat("✓ Men's Russian return projections saved to:", men_russian_file, "\n")
  }
  
  # Ladies Russian projections Excel output
  if (exists("russian_projections_gam_ladies") && !is.null(russian_projections_gam_ladies) && nrow(russian_projections_gam_ladies) > 0) {
    ladies_russian_excel <- russian_projections_gam_ladies %>%
      dplyr::select(
        Name = Skier,
        `Age 2022` = Age_2022,
        `Age 2026` = Age_2026,
        `Age Category 2026` = Age_Category_2026,
        `Current Elo (2022)` = Pelo_2022,
        `Predicted Elo 2026` = Pelo_2026,
        `Lower Bound` = Pelo_2026_Lower,
        `Upper Bound` = Pelo_2026_Upper,
        `Distance Elo 2026` = Distance_2026,
        `Sprint Elo 2026` = Sprint_2026
      ) %>%
      mutate(
        `Elo Change` = `Predicted Elo 2026` - `Current Elo (2022)`,
        across(c(`Current Elo (2022)`, `Predicted Elo 2026`, `Lower Bound`, `Upper Bound`, 
                 `Distance Elo 2026`, `Sprint Elo 2026`, `Elo Change`), ~ round(.x, 0))
      ) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    ladies_russian_file <- file.path("excel365", "ladies_russian_return_projections_2026.xlsx")
    write.xlsx(ladies_russian_excel, ladies_russian_file, rowNames = FALSE)
    cat("✓ Ladies Russian return projections saved to:", ladies_russian_file, "\n")
  }
  
  # Combined summary Excel output
  if (exists("russian_projections_gam") && exists("russian_projections_gam_ladies")) {
    # Men's summary
    men_summary <- russian_projections_gam %>%
      dplyr::select(Name = Skier, Gender = Nation, `Current Elo` = Pelo_2022, `Predicted Elo 2026` = Pelo_2026, 
                   `Age 2026` = Age_2026, `Elo Change` = Pelo_2026) %>%
      mutate(
        Gender = "Men",
        `Elo Change` = `Predicted Elo 2026` - `Current Elo`,
        across(c(`Current Elo`, `Predicted Elo 2026`, `Elo Change`), ~ round(.x, 0))
      )
    
    # Ladies summary
    ladies_summary <- russian_projections_gam_ladies %>%
      dplyr::select(Name = Skier, Gender = Nation, `Current Elo` = Pelo_2022, `Predicted Elo 2026` = Pelo_2026, 
                   `Age 2026` = Age_2026, `Elo Change` = Pelo_2026) %>%
      mutate(
        Gender = "Ladies",
        `Elo Change` = `Predicted Elo 2026` - `Current Elo`,
        across(c(`Current Elo`, `Predicted Elo 2026`, `Elo Change`), ~ round(.x, 0))
      )
    
    # Combined dataset
    combined_russian <- bind_rows(men_summary, ladies_summary) %>%
      arrange(desc(`Predicted Elo 2026`))
    
    combined_russian_file <- file.path("excel365", "russian_return_projections_combined_2026.xlsx")
    write.xlsx(combined_russian, combined_russian_file, rowNames = FALSE)
    cat("✓ Combined Russian return projections saved to:", combined_russian_file, "\n")
  }
  
}, error = function(e) {
  warning("Error creating Russian projections Excel outputs: ", e$message)
})
```




### Klaebo Catchup Analysis

```{r klaebo-catchup}
cat("=== KLAEBO CATCHUP ANALYSIS VALIDATION ===\n")

# Analysis of what performance level other skiers would need to catch up to Klaebo
# Based on Klaebo's projected 2026 performance and historical patterns

tryCatch({
  # Validate required datasets exist
  if (!exists("men_pred_data")) {
    stop("men_pred_data not found - required for Klaebo catchup analysis")
  }
  
  if (is.null(men_pred_data) || nrow(men_pred_data) == 0) {
    stop("men_pred_data is empty")
  }
  
  # Validate required columns
  required_cols <- c("Skier", "Nation", "Age", "Predicted_Pct_2026", "Pelo")
  missing_cols <- setdiff(required_cols, names(men_pred_data))
  if (length(missing_cols) > 0) {
    stop("Missing required columns in men_pred_data: ", paste(missing_cols, collapse = ", "))
  }
  
  cat("✓ Dataset and column validation completed\n")
  
  cat("=== KLAEBO CATCHUP ANALYSIS ===\n")
  
  # Find Klaebo in predictions with validation
  klaebo_data <- tryCatch({
    klaebo_found <- men_pred_data %>% 
      filter(grepl("Klaebo|Klæbo", Skier, ignore.case = TRUE))
    
    if (nrow(klaebo_found) == 0) {
      stop("Klaebo not found in predictions data - cannot perform catchup analysis")
    }
    
    # Validate Klaebo's data completeness
    if (is.na(klaebo_found$Predicted_Pct_2026[1]) || is.na(klaebo_found$Pelo[1])) {
      stop("Klaebo has missing prediction or ELO data")
    }
    
    cat("✓ Klaebo found in predictions data\n")
    klaebo_found
    
  }, error = function(e) {
    stop("Error finding Klaebo data: ", e$message)
  })
  
  if (nrow(klaebo_data) > 0) {
    klaebo_pred <- klaebo_data$Predicted_Pct_2026[1]
    klaebo_pelo <- klaebo_data$Pelo[1]
    
    print(paste("Klaebo's projected 2026 performance:", round(klaebo_pred * 100, 1), "% of max points"))
    print(paste("Klaebo's current ELO:", round(klaebo_pelo, 0)))
    
    # Identify challengers and their required improvement
    challengers <- men_pred_data %>%
      filter(!grepl("Klaebo|Kläbo", Skier, ignore.case = TRUE)) %>%
      arrange(desc(Predicted_Pct_2026)) %>%
      mutate(
        Gap_Points = (klaebo_pred - Predicted_Pct_2026) * 100,
        Gap_ELO = klaebo_pelo - Pelo,
        Required_Improvement_Pct = Gap_Points,
        Required_Improvement_ELO = Gap_ELO,
        Catchup_Difficulty = case_when(
          Gap_Points < 2 ~ "Very Achievable",
          Gap_Points < 5 ~ "Achievable", 
          Gap_Points < 10 ~ "Challenging",
          Gap_Points < 15 ~ "Very Difficult",
          TRUE ~ "Nearly Impossible"
        )
      ) %>%
      head(15)
    
    print("\nTop 15 challengers - Required improvement to match Klaebo:")
    catchup_display <- challengers %>%
      dplyr::select(Skier, Nation, Age, Predicted_Pct_2026, Gap_Points, Gap_ELO, Catchup_Difficulty) %>%
      mutate(
        Current_Pct = round(Predicted_Pct_2026 * 100, 1),
        Gap_Points = round(Gap_Points, 1),
        Gap_ELO = round(Gap_ELO, 0)
      ) %>%
      dplyr::select(Skier, Nation, Age, Current_Pct, Gap_Points, Gap_ELO, Catchup_Difficulty) %>%
      rename(`Current %` = Current_Pct, `Gap (pts)` = Gap_Points, `Gap (ELO)` = Gap_ELO, `Difficulty` = Catchup_Difficulty)
    
    print(catchup_display)
    
    # Analyze by age groups
    print("\n=== CATCHUP ANALYSIS BY AGE GROUP ===")
    age_catchup <- challengers %>%
      mutate(
        Age_Group = case_when(
          Age <= 25 ~ "Young (≤25)",
          Age <= 29 ~ "Prime (26-29)",
          Age <= 33 ~ "Peak (30-33)",
          TRUE ~ "Veteran (34+)"
        )
      ) %>%
      group_by(Age_Group) %>%
      summarise(
        Count = n(),
        Avg_Gap_Points = mean(Gap_Points),
        Min_Gap = min(Gap_Points),
        Achievable_Count = sum(Catchup_Difficulty %in% c("Very Achievable", "Achievable")),
        .groups = 'drop'
      ) %>%
      arrange(Age_Group)
    
    print(age_catchup %>%
          mutate(
            Avg_Gap_Points = round(Avg_Gap_Points, 1),
            Min_Gap = round(Min_Gap, 1),
            Achievable_Pct = round(Achievable_Count / Count * 100, 0)
          ))
    
    # Historical precedent analysis with validation
    cat("\n=== HISTORICAL IMPROVEMENT PRECEDENTS ===\n")
    
    # Validate train_men availability
    if (!exists("train_men")) {
      warning("train_men not available - skipping historical precedent analysis")
    } else {
      tryCatch({
        if (is.null(train_men) || nrow(train_men) == 0) {
          warning("train_men is empty - skipping historical analysis")
        } else {
          # Validate required columns for historical analysis
          required_hist_cols <- c("ID", "Season", "Skier", "Nation", "Age", "Pct_of_Max_Points")
          missing_hist_cols <- setdiff(required_hist_cols, names(train_men))
          if (length(missing_hist_cols) > 0) {
            warning("Missing columns in train_men: ", paste(missing_hist_cols, collapse = ", "))
          } else {
      # Find biggest year-over-year improvements in recent history
      big_improvements <- train_men %>%
        arrange(ID, Season) %>%
        group_by(ID) %>%
        mutate(
          Prev_Pct = lag(Pct_of_Max_Points),
          Improvement = (Pct_of_Max_Points - Prev_Pct) * 100
        ) %>%
        filter(!is.na(Improvement), Season >= 2015) %>%
        ungroup() %>%
        arrange(desc(Improvement)) %>%
        head(10)
      
      print("Biggest single-season improvements (2015+):")
      print(big_improvements %>%
            dplyr::select(Skier, Nation, Season, Age, Prev_Pct, Pct_of_Max_Points, Improvement) %>%
            mutate(
              Prev_Pct = round(Prev_Pct * 100, 1),
              Current_Pct = round(Pct_of_Max_Points * 100, 1),
              Improvement = round(Improvement, 1)
            ) %>%
            rename(`Previous %` = Prev_Pct, `Season %` = Current_Pct, `Improvement` = Improvement))
      
      # Check if any improvements are sufficient to catch current gap
      sufficient_improvements <- sum(big_improvements$Improvement >= min(challengers$Gap_Points))
      print(paste("Historical precedents sufficient to close smallest gap:", sufficient_improvements, "out of 10"))
      
      cat("✓ Historical analysis completed successfully\n")
          }
        }
      }, error = function(e) {
        warning("Error in historical precedent analysis: ", e$message)
      })
    }
    
    # Nation-based catchup analysis
    print("\n=== CATCHUP POTENTIAL BY NATION ===")
    nation_catchup <- challengers %>%
      group_by(Nation) %>%
      summarise(
        Skiers = n(),
        Best_Gap = min(Gap_Points),
        Avg_Gap = mean(Gap_Points),
        Achievable_Skiers = sum(Catchup_Difficulty %in% c("Very Achievable", "Achievable")),
        .groups = 'drop'
      ) %>%
      filter(Skiers >= 2) %>%
      arrange(Best_Gap)
    
    print(nation_catchup %>%
          mutate(
            Best_Gap = round(Best_Gap, 1),
            Avg_Gap = round(Avg_Gap, 1)
          ))
    
  } else {
    cat("Klaebo not found in prediction data\n")
  }
  
  cat("✓ Processing completed successfully\n")
  
}, error = function(e) {
  stop("Error in Klaebo catchup analysis: ", e$message)
})
```

### Multiple Skiers Challenge Analysis

```{r multiple-skiers}
cat("=== MULTIPLE SKIERS CHALLENGE ANALYSIS VALIDATION ===\n")

# Analysis of combined threat from multiple skiers challenging Klaebo simultaneously  
# Examines scenarios where multiple competitors improve together

tryCatch({
  # Validate required datasets exist
  if (!exists("men_pred_data")) {
    stop("men_pred_data not found - required for multiple skiers analysis")
  }
  if (!exists("train_men")) {
    stop("train_men not found - required for multiple skiers analysis")
  }
  
  if (is.null(men_pred_data) || nrow(men_pred_data) == 0) {
    stop("men_pred_data is empty")
  }
  if (is.null(train_men) || nrow(train_men) == 0) {
    stop("train_men is empty")
  }
  
  cat("✓ Dataset validation completed\n")
  
  cat("=== MULTIPLE SKIERS CHALLENGE ANALYSIS ===\n")
  
  # Find Klaebo with validation
  klaebo_data <- tryCatch({
    klaebo_found <- men_pred_data %>% 
      filter(grepl("Klæbo|Kläbo", Skier, ignore.case = TRUE))
    
    if (nrow(klaebo_found) == 0) {
      stop("Klaebo not found in predictions data")
    }
    
    cat("✓ Klaebo found in predictions data\n")
    klaebo_found
    
  }, error = function(e) {
    stop("Error finding Klaebo: ", e$message)
  })
  
  if (nrow(klaebo_data) > 0) {
    klaebo_pred <- klaebo_data$Predicted_Pct_2026[1]
    
    # Get top challengers
    top_challengers <- men_pred_data %>%
      filter(!grepl("Klaebo|Kläbo", Skier, ignore.case = TRUE)) %>%
      arrange(desc(Predicted_Pct_2026)) %>%
      head(10) %>%
      mutate(
        Gap_to_Klaebo = (klaebo_pred - Predicted_Pct_2026) * 100,
        Current_Rank = row_number() + 1  # +1 because Klaebo is #1
      )
    
    print("Top 10 challengers and their gaps:")
    print(top_challengers %>%
          dplyr::select(Skier, Nation, Age, Predicted_Pct_2026, Gap_to_Klaebo, Current_Rank) %>%
          mutate(
            Predicted_Pct_2026 = round(Predicted_Pct_2026 * 100, 1),
            Gap_to_Klaebo = round(Gap_to_Klaebo, 1)
          ) %>%
          rename(`Predicted %` = Predicted_Pct_2026, `Gap (pts)` = Gap_to_Klaebo, `Rank` = Current_Rank))
    
    # Scenario 1: Multiple skiers improve moderately (3-7 percentage points)
    print("\n=== SCENARIO 1: MODERATE COLLECTIVE IMPROVEMENT ===")
    moderate_improvement <- 5  # 5 percentage point improvement
    
    scenario1_results <- top_challengers %>%
      mutate(
        Improved_Performance = Predicted_Pct_2026 + (moderate_improvement / 100),
        Beats_Klaebo = Improved_Performance > klaebo_pred,
        New_Gap = (klaebo_pred - Improved_Performance) * 100
      )
    
    beats_klaebo_s1 <- sum(scenario1_results$Beats_Klaebo)
    closest_threat_s1 <- scenario1_results %>% 
      filter(!Beats_Klaebo) %>% 
      arrange(desc(Improved_Performance)) %>% 
      slice_head(n = 1)
    
    print(paste("If top 10 challengers each improve by", moderate_improvement, "percentage points:"))
    print(paste("- Skiers who would beat Klaebo:", beats_klaebo_s1))
    if(nrow(closest_threat_s1) > 0) {
      print(paste("- Closest remaining threat:", closest_threat_s1$Skier, 
                  "with", round(closest_threat_s1$Improved_Performance * 100, 1), "% (gap:",
                  round(abs(closest_threat_s1$New_Gap), 1), "pts)"))
    }
    
    # Scenario 2: Young skiers improve significantly while older ones improve modestly
    print("\n=== SCENARIO 2: AGE-DIFFERENTIATED IMPROVEMENT ===")
    
    scenario2_results <- top_challengers %>%
      mutate(
        Age_Category = case_when(
          Age <= 26 ~ "Young",
          Age <= 30 ~ "Prime", 
          TRUE ~ "Veteran"
        ),
        Improvement_Points = case_when(
          Age <= 26 ~ 8,   # Young skiers: 8 point improvement
          Age <= 30 ~ 5,   # Prime skiers: 5 point improvement
          TRUE ~ 2         # Veterans: 2 point improvement
        ),
        Improved_Performance = Predicted_Pct_2026 + (Improvement_Points / 100),
        Beats_Klaebo = Improved_Performance > klaebo_pred
      )
    
    beats_klaebo_s2 <- sum(scenario2_results$Beats_Klaebo)
    winners_s2 <- scenario2_results %>% filter(Beats_Klaebo)
    
    print("Age-differentiated improvement scenario:")
    print(paste("- Young skiers (≤26): +8 points"))
    print(paste("- Prime skiers (27-30): +5 points"))
    print(paste("- Veterans (31+): +2 points"))
    print(paste("- Skiers who would beat Klaebo:", beats_klaebo_s2))
    
    if(nrow(winners_s2) > 0) {
      print("Potential winners:")
      winners_display_s2 <- winners_s2 %>%
        dplyr::select(Skier, Nation, Age, Age_Category, Improvement_Points, Improved_Performance) %>%
        mutate(Final_Pct = round(Improved_Performance * 100, 1)) %>%
        arrange(desc(Improved_Performance))
      print(winners_display_s2)
    }
    
    # Scenario 3: Nation-based improvement (training groups, coaching changes)
    print("\n=== SCENARIO 3: NATION-BASED IMPROVEMENTS ===")
    
    # Identify nations with multiple top challengers
    nation_strength <- top_challengers %>%
      group_by(Nation) %>%
      summarise(
        Count = n(),
        Best_Performance = max(Predicted_Pct_2026),
        Avg_Performance = mean(Predicted_Pct_2026),
        Best_Gap = min(Gap_to_Klaebo),
        .groups = 'drop'
      ) %>%
      filter(Count >= 2) %>%
      arrange(Best_Gap)
    
    print("Nations with multiple top challengers:")
    print(nation_strength %>%
          mutate(
            Best_Performance = round(Best_Performance * 100, 1),
            Avg_Performance = round(Avg_Performance * 100, 1),
            Best_Gap = round(Best_Gap, 1)
          ))
    
    # Simulate nation-wide improvements
    if(nrow(nation_strength) > 0) {
      top_nation <- nation_strength$Nation[1]
      nation_improvement <- 6  # 6 percentage points
      
      scenario3_results <- top_challengers %>%
        mutate(
          Gets_Nation_Boost = Nation == top_nation,
          Improvement_Points = ifelse(Gets_Nation_Boost, nation_improvement, 2), # Others get baseline 2
          Improved_Performance = Predicted_Pct_2026 + (Improvement_Points / 100),
          Beats_Klaebo = Improved_Performance > klaebo_pred
        )
      
      nation_winners <- scenario3_results %>% filter(Beats_Klaebo, Nation == top_nation)
      other_winners <- scenario3_results %>% filter(Beats_Klaebo, Nation != top_nation)
      
      print(paste("If", top_nation, "skiers improve by", nation_improvement, "points (others +2):"))
      print(paste("- Total skiers beating Klaebo:", sum(scenario3_results$Beats_Klaebo)))
      print(paste("- From", top_nation, ":", nrow(nation_winners)))
      print(paste("- From other nations:", nrow(other_winners)))
    }
    
    # Combined threat assessment
    print("\n=== COMBINED THREAT PROBABILITY ASSESSMENT ===")
    
    # Based on historical improvement patterns
    if(exists("train_men")) {
      # Calculate probability of moderate improvements based on historical data
      historical_improvements <- train_men %>%
        arrange(ID, Season) %>%
        group_by(ID) %>%
        mutate(
          Prev_Pct = lag(Pct_of_Max_Points),
          Improvement = (Pct_of_Max_Points - Prev_Pct) * 100
        ) %>%
        filter(!is.na(Improvement), Season >= 2015, Prev_Pct >= 0.2) %>% # Focus on established skiers
        ungroup()
      
      # Probability of different improvement levels
      prob_5plus <- mean(historical_improvements$Improvement >= 5, na.rm = TRUE)
      prob_8plus <- mean(historical_improvements$Improvement >= 8, na.rm = TRUE)
      prob_10plus <- mean(historical_improvements$Improvement >= 10, na.rm = TRUE)
      
      print("Historical probability of improvements (single season):")
      print(paste("- ≥5 percentage points:", round(prob_5plus * 100, 1), "%"))
      print(paste("- ≥8 percentage points:", round(prob_8plus * 100, 1), "%"))
      print(paste("- ≥10 percentage points:", round(prob_10plus * 100, 1), "%"))
      
      # Estimate probability of multiple simultaneous threats
      prob_multiple_threats <- 1 - (1 - prob_5plus)^5  # Probability at least 1 of top 5 improves significantly
      print(paste("Estimated probability of at least one top-5 challenger improving ≥5 pts:", 
                  round(prob_multiple_threats * 100, 1), "%"))
      
      # Threat level assessment
      min_gap <- min(top_challengers$Gap_to_Klaebo)
      threat_level <- case_when(
        min_gap < 3 & prob_multiple_threats > 0.4 ~ "HIGH",
        min_gap < 5 & prob_multiple_threats > 0.3 ~ "MODERATE-HIGH", 
        min_gap < 8 & prob_multiple_threats > 0.2 ~ "MODERATE",
        TRUE ~ "LOW"
      )
      
      print(paste("Overall multiple skier threat level to Klaebo:", threat_level))
    }
    
  } else {
    cat("Klaebo not found in prediction data\n")
  }
  
  cat("✓ Processing completed successfully\n")
  
}, error = function(e) {
  stop("Error in multiple skiers challenge analysis: ", e$message)
})
```

### Klaebo Missing Races Impact

```{r klaebo-missing-races}
cat("=== KLAEBO MISSING RACES IMPACT ANALYSIS VALIDATION ===\n")

# Analysis of how missing races would affect Klaebo's season outcome
# Simulates impact of injury, rest, or strategic race selection

tryCatch({
  # Validate required datasets exist
  if (!exists("men_pred_data")) {
    stop("men_pred_data not found - required for missing races analysis")
  }
  if (!exists("train_men")) {
    stop("train_men not found - required for missing races analysis")
  }
  
  if (is.null(men_pred_data) || nrow(men_pred_data) == 0) {
    stop("men_pred_data is empty")
  }
  if (is.null(train_men) || nrow(train_men) == 0) {
    stop("train_men is empty")
  }
  
  cat("✓ Dataset validation completed\n")
  
  cat("=== KLAEBO MISSING RACES IMPACT ANALYSIS ===\n")
  
  # Find Klaebo with validation
  klaebo_data <- tryCatch({
    klaebo_found <- men_pred_data %>% 
      filter(grepl("Klaebo|Klæbo", Skier, ignore.case = TRUE))
    
    if (nrow(klaebo_found) == 0) {
      stop("Klaebo not found in predictions data")
    }
    
    cat("✓ Klaebo found in predictions data\n")
    klaebo_found
    
  }, error = function(e) {
    stop("Error finding Klaebo: ", e$message)
  })
  
  if (nrow(klaebo_data) > 0) {
    klaebo_pred <- klaebo_data$Predicted_Pct_2026[1]
    
    # Estimate typical season structure and points distribution
    # Based on recent seasons' race calendars
    print("Season structure analysis:")
    
    # Approximate 2026 season structure
    total_races_estimate <- 35  # Typical World Cup season
    major_races <- 8    # Olympics, World Championships, Tour de Ski, etc.
    regular_races <- total_races_estimate - major_races
    
    # Point value estimates (based on typical distributions)
    major_race_points <- 100 * 0.7  # Assume Klaebo typically gets ~70% of max points
    regular_race_points <- 100 * 0.5  # More variable performance
    
    # Baseline season projection
    baseline_points <- (major_races * major_race_points) + (regular_races * regular_race_points)
    
    print(paste("Estimated 2026 season structure:"))
    print(paste("- Total races:", total_races_estimate))
    print(paste("- Major races:", major_races))
    print(paste("- Regular races:", regular_races))
    print(paste("- Klaebo baseline projection:", round(baseline_points), "points"))
    
    # Get top challengers for comparison
    top_challengers <- men_pred_data %>%
      filter(!grepl("Klaebo|Kläbo", Skier, ignore.case = TRUE)) %>%
      arrange(desc(Predicted_Pct_2026)) %>%
      head(5) %>%
      mutate(
        Estimated_Points = Predicted_Pct_2026 * baseline_points / klaebo_pred,
        Gap_Points = baseline_points - Estimated_Points
      )
    
    print("\nTop 5 challengers - estimated points and gaps:")
    print(top_challengers %>%
          dplyr::select(Skier, Nation, Estimated_Points, Gap_Points) %>%
          mutate(
            Estimated_Points = round(Estimated_Points, 0),
            Gap_Points = round(Gap_Points, 0)
          ))
    
    # Missing races scenarios
    print("\n=== MISSING RACES SCENARIOS ===")
    
    # Scenario 1: Missing regular races (illness, rest)
    missing_regular <- c(2, 4, 6, 8)
    
    print("Impact of missing regular races:")
    for(missed in missing_regular) {
      adjusted_points <- baseline_points - (missed * regular_race_points)
      threatened_by <- sum(top_challengers$Estimated_Points > adjusted_points)
      
      print(paste("Missing", missed, "regular races:"))
      print(paste("- Klaebo points:", round(adjusted_points, 0)))
      print(paste("- Challengers who could beat him:", threatened_by))
      
      if(threatened_by > 0) {
        threats <- top_challengers %>% 
          filter(Estimated_Points > adjusted_points) %>%
          head(3)
        print(paste("- Main threats:", paste(threats$Skier, collapse = ", ")))
      }
      print("")
    }
    
    # Scenario 2: Missing major races (injury during key periods)
    missing_major <- c(1, 2, 3)
    
    print("Impact of missing major races:")
    for(missed in missing_major) {
      adjusted_points <- baseline_points - (missed * major_race_points)
      threatened_by <- sum(top_challengers$Estimated_Points > adjusted_points)
      
      print(paste("Missing", missed, "major races:"))
      print(paste("- Klaebo points:", round(adjusted_points, 0)))
      print(paste("- Challengers who could beat him:", threatened_by))
      
      if(threatened_by > 0) {
        threats <- top_challengers %>% 
          filter(Estimated_Points > adjusted_points) %>%
          arrange(desc(Estimated_Points)) %>%
          head(3)
        print(paste("- Potential winners:", paste(paste(threats$Skier, "(", round(threats$Estimated_Points, 0), "pts)", sep=""), collapse = ", ")))
      }
      print("")
    }
    
    # Scenario 3: Strategic race dplyr::selection (focus on major events)
    print("=== STRATEGIC RACE dplyr::selectION SCENARIOS ===")
    
    # Focus on majors, skip some regulars
    strategic_major_boost <- 1.15  # 15% better performance in majors due to focus
    strategic_regular_missed <- 6   # Skip 6 regular races
    
    strategic_points <- (major_races * major_race_points * strategic_major_boost) + 
                       ((regular_races - strategic_regular_missed) * regular_race_points)
    
    print("Strategic focus on major races (+15% performance, skip 6 regular):")
    print(paste("- Total points:", round(strategic_points, 0)))
    print(paste("- Change from baseline:", round(strategic_points - baseline_points, 0)))
    
    threatened_strategic <- sum(top_challengers$Estimated_Points > strategic_points)
    print(paste("- Challengers who could beat him:", threatened_strategic))
    
    # Tour de Ski specific analysis
    print("\n=== TOUR DE SKI IMPACT ANALYSIS ===")
    
    # Tour de Ski typically worth significant points
    tds_points_estimate <- 400  # Rough estimate for winner
    klaebo_tds_performance <- tds_points_estimate * 0.8  # Assume strong but not always winning
    
    print("Tour de Ski scenarios:")
    
    # Skip Tour de Ski entirely
    no_tds_points <- baseline_points - klaebo_tds_performance
    threatened_no_tds <- sum(top_challengers$Estimated_Points > no_tds_points)
    
    print(paste("Skipping Tour de Ski entirely:"))
    print(paste("- Lost points:", round(klaebo_tds_performance, 0)))
    print(paste("- New total:", round(no_tds_points, 0)))
    print(paste("- Challengers who could beat him:", threatened_no_tds))
    
    # Poor Tour de Ski (illness, form issues)
    poor_tds_performance <- tds_points_estimate * 0.3
    poor_tds_points <- baseline_points - klaebo_tds_performance + poor_tds_performance
    threatened_poor_tds <- sum(top_challengers$Estimated_Points > poor_tds_points)
    
    print(paste("Poor Tour de Ski performance:"))
    print(paste("- Points instead of", round(klaebo_tds_performance, 0), ":", round(poor_tds_performance, 0)))
    print(paste("- New total:", round(poor_tds_points, 0)))
    print(paste("- Challengers who could beat him:", threatened_poor_tds))
    
    # Risk assessment summary
    print("\n=== RISK ASSESSMENT SUMMARY ===")
    
    # Critical thresholds
    safe_margin <- min(top_challengers$Gap_Points)
    risky_margin <- safe_margin * 0.5
    
    print(paste("Klaebo's current projected margin over #2:", round(safe_margin, 0), "points"))
    print(paste("Risk threshold (50% of margin):", round(risky_margin, 0), "points"))
    
    # Race equivalents
    regular_race_risk <- ceiling(risky_margin / regular_race_points)
    major_race_risk <- ceiling(risky_margin / major_race_points)
    
    print("\nCritical missing race thresholds:")
    print(paste("- Regular races:", regular_race_risk, "races puts season at risk"))
    print(paste("- Major races:", major_race_risk, "major race puts season at significant risk"))
    
    # Overall vulnerability assessment
    vulnerability_score <- case_when(
      regular_race_risk >= 6 ~ "LOW",
      regular_race_risk >= 4 ~ "MODERATE",
      regular_race_risk >= 2 ~ "HIGH",
      TRUE ~ "VERY HIGH"
    )
    
    print(paste("Overall vulnerability to missing races:", vulnerability_score))
    
    # Historical context
    print("\n=== HISTORICAL CONTEXT ===")
    
    # Look at Klaebo's historical missed race patterns if available
    klaebo_history <- train_men %>%
      filter(grepl("Klaebo|Kläbo", Skier, ignore.case = TRUE)) %>%
      group_by(Season) %>%
      summarise(
        Races = n(),
        Points_Total = sum(Points, na.rm = TRUE),
        Pct_Performance = mean(Pct_of_Max_Points, na.rm = TRUE),
        .groups = 'drop'
      ) %>%
      arrange(Season)
    
    if(nrow(klaebo_history) > 0) {
      print("Klaebo's recent season race counts:")
      print(klaebo_history %>%
            mutate(
              Points_Total = round(Points_Total, 0),
              Pct_Performance = round(Pct_Performance * 100, 1)
            ))
      
      avg_races <- mean(klaebo_history$Races)
      min_races <- min(klaebo_history$Races)
      
      print(paste("Average races per season:", round(avg_races, 1)))
      print(paste("Minimum races in a season:", min_races))
      
      # Performance consistency
      perf_sd <- sd(klaebo_history$Pct_Performance)
      print(paste("Performance consistency (SD):", round(perf_sd * 100, 1), "percentage points"))
    }
    
  } else {
    cat("Klaebo not found in prediction data\n")
  }
  
  cat("✓ Processing completed successfully\n")
  
}, error = function(e) {
  stop("Error in Klaebo missing races analysis: ", e$message)
})
```