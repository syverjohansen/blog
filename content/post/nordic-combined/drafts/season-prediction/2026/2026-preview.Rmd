---
title: "2026 Nordic Combined Season Preview"
author: "Syver Johansen"
date: "2025-01-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## 2026 Nordic Combined Season Preview

This preview analyzes the upcoming 2026 nordic combined season, including points predictions, breakthrough potential candidates, and competitive analysis across all disciplines.

### Load Libraries

```{r load-packages, message=FALSE, warning=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(readr)
library(ggplot2)
library(openxlsx)
library(moments)  # for skewness/kurtosis
library(mgcv)     # for GAM models
library(glmnet)   # for LASSO feature selection
library(Boruta)   # for Boruta feature selection
library(leaps)    # for exhaustive search
library(MASS)     # for polr (ordinal logistic regression)
```

### Load Data

```{r load-data}
# Load men's and ladies nordic combined chrono data from CSV files
cat("=== NORDIC COMBINED DATA LOADING & VALIDATION ===\n")

# Check if files exist before loading
men_file <- '/Users/syverjohansen/ski/elo/python/nordic-combined/polars/excel365/men_chrono.csv'
ladies_file <- '/Users/syverjohansen/ski/elo/python/nordic-combined/polars/excel365/ladies_chrono.csv'

if (!file.exists(men_file)) stop("Men's nordic combined data file not found: ", men_file)
if (!file.exists(ladies_file)) stop("Ladies nordic combined data file not found: ", ladies_file)

cat("✓ Nordic combined data files exist\n")

# Load data with error handling
tryCatch({
  M_chrono <- read_csv(men_file, show_col_types = FALSE)
  cat("✓ Men's nordic combined data loaded:", nrow(M_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load men's nordic combined data: ", e$message)
})

tryCatch({
  L_chrono <- read_csv(ladies_file, show_col_types = FALSE)
  cat("✓ Ladies nordic combined data loaded:", nrow(L_chrono), "rows\n")
}, error = function(e) {
  stop("Failed to load ladies nordic combined data: ", e$message)
})

# Validate required columns exist
required_cols <- c("Skier", "Date", "Season", "Event", "City", "RaceType", "Place", "Race", "ID")
missing_men <- setdiff(required_cols, names(M_chrono))
missing_ladies <- setdiff(required_cols, names(L_chrono))

if (length(missing_men) > 0) {
  stop("Missing required columns in men's nordic combined data: ", paste(missing_men, collapse = ", "))
}
if (length(missing_ladies) > 0) {
  stop("Missing required columns in ladies nordic combined data: ", paste(missing_ladies, collapse = ", "))
}
cat("✓ All required columns present in both nordic combined datasets\n")

# Check for completely empty datasets
if (nrow(M_chrono) == 0) stop("Men's nordic combined dataset is empty")
if (nrow(L_chrono) == 0) stop("Ladies nordic combined dataset is empty")

# Validate data types and ranges
cat("\n--- Nordic Combined Data Quality Checks ---\n")

# Check Place column (should be positive integers)
invalid_places_m <- sum(is.na(M_chrono$Place) | M_chrono$Place < 0 | !is.finite(M_chrono$Place))
invalid_places_l <- sum(is.na(L_chrono$Place) | L_chrono$Place < 0 | !is.finite(L_chrono$Place))

cat("Men's invalid Place values:", invalid_places_m, "\n")
cat("Ladies invalid Place values:", invalid_places_l, "\n")

if (invalid_places_m > nrow(M_chrono) * 0.1) {
  warning("More than 10% of men's Place values are invalid")
}
if (invalid_places_l > nrow(L_chrono) * 0.1) {
  warning("More than 10% of ladies Place values are invalid")
}

# Check for missing Skier names
missing_skiers_m <- sum(is.na(M_chrono$Skier) | M_chrono$Skier == "")
missing_skiers_l <- sum(is.na(L_chrono$Skier) | L_chrono$Skier == "")

cat("Men's missing skier names:", missing_skiers_m, "\n")
cat("Ladies missing skier names:", missing_skiers_l, "\n")

if (missing_skiers_m > nrow(M_chrono) * 0.05) {
  warning("More than 5% of men's skier names are missing")
}
if (missing_skiers_l > nrow(L_chrono) * 0.05) {
  warning("More than 5% of ladies skier names are missing")
}

# Check Season range
season_range_m <- range(M_chrono$Season, na.rm = TRUE)
season_range_l <- range(L_chrono$Season, na.rm = TRUE)

cat("Men's season range:", season_range_m[1], "to", season_range_m[2], "\n")
cat("Ladies season range:", season_range_l[1], "to", season_range_l[2], "\n")

# Expected season range (adjust based on your data)
expected_min_season <- 2010
expected_max_season <- 2025

if (season_range_m[1] < expected_min_season || season_range_m[2] > expected_max_season) {
  warning("Men's season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}
if (season_range_l[1] < expected_min_season || season_range_l[2] > expected_max_season) {
  warning("Ladies season range outside expected bounds: ", expected_min_season, "-", expected_max_season)
}

# Date validation
date_errors_m <- sum(is.na(M_chrono$Date))
date_errors_l <- sum(is.na(L_chrono$Date))

cat("Men's invalid dates:", date_errors_m, "\n")
cat("Ladies invalid dates:", date_errors_l, "\n")

# Define excluded athletes - remove them from all analysis (retired/inactive)
# 2025 Retirements - Men
excluded_men <- c("Jarl Magnus Riiber", "Espen Bjørnstad", "Jørgen Graabak")

# 2025 Retirements - Ladies  
excluded_ladies <- c("Svenja Würth", "Gyda Westvold Hansen")

cat("\n--- Nordic Combined Athlete Exclusion ---\n")
cat("Excluding men:", paste(excluded_men, collapse = ", "), "\n")
cat("Excluding ladies:", paste(excluded_ladies, collapse = ", "), "\n")

# Count how many records will be excluded
excluded_count_m <- sum(M_chrono$Skier %in% excluded_men)
excluded_count_l <- sum(L_chrono$Skier %in% excluded_ladies)

cat("Men's records to exclude:", excluded_count_m, "\n")
cat("Ladies records to exclude:", excluded_count_l, "\n")

# Filter out excluded athletes from raw data
M_chrono_original_rows <- nrow(M_chrono)
L_chrono_original_rows <- nrow(L_chrono)

M_chrono <- M_chrono %>%
  filter(!Skier %in% excluded_men)

L_chrono <- L_chrono %>%
  filter(!Skier %in% excluded_ladies)

# Verify exclusion worked correctly
actual_excluded_m <- M_chrono_original_rows - nrow(M_chrono)
actual_excluded_l <- L_chrono_original_rows - nrow(L_chrono)

if (actual_excluded_m != excluded_count_m) {
  warning("Mismatch in men's exclusion: expected ", excluded_count_m, ", actual ", actual_excluded_m)
}
if (actual_excluded_l != excluded_count_l) {
  warning("Mismatch in ladies exclusion: expected ", excluded_count_l, ", actual ", actual_excluded_l)
}

cat("✓ Men's nordic combined data after exclusion:", nrow(M_chrono), "rows\n")
cat("✓ Ladies nordic combined data after exclusion:", nrow(L_chrono), "rows\n")

# Nordic Combined World Cup points mapping with validation
cat("\n--- Nordic Combined Points System Validation ---\n")

# Nordic Combined World Cup points for individual events (top 40 get points)
nordic_combined_points <- c(100, 90, 80, 70, 60, 55, 52, 49, 46, 43, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1)

# Team events (same points distribution)
team_points <- nordic_combined_points

# Validate points arrays
if (length(nordic_combined_points) != 40) stop("Nordic combined points array should have 40 values")

# Check points are in descending order
if (!all(diff(nordic_combined_points) <= 0)) {
  stop("Nordic combined points not in descending order")
}

cat("✓ Nordic combined points system validated:\n")
cat("  - Individual events:", length(nordic_combined_points), "positions get points\n")
cat("  - Team events:", length(team_points), "positions get points\n")

# Function to safely fetch nordic combined points based on Place and RaceType
get_nordic_combined_points <- function(place, race_type = NULL) {
  if (is.na(place) || !is.finite(place)) {
    return(0)
  }
  
  # All nordic combined events use the same points system
  points_list <- nordic_combined_points
  
  if (place >= 1 && place <= length(points_list)) {
    return(points_list[place])
  }
  return(0)
}

# Test the get_nordic_combined_points function
test_cases <- c(1, 3, 10, 30, 40, 41, -1, NA, Inf)
cat("Testing get_nordic_combined_points function:\n")
for (test_place in test_cases) {
  result <- get_nordic_combined_points(test_place)
  cat(sprintf("  Place %s -> %s points\n", 
              ifelse(is.na(test_place), "NA", as.character(test_place)), result))
}

cat("\n=== NORDIC COMBINED DATA LOADING COMPLETE ===\n")
cat(sprintf("Final nordic combined dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_chrono), nrow(L_chrono)))
cat(sprintf("Men's unique nordic combined skiers: %d\n", length(unique(M_chrono$Skier))))
cat(sprintf("Ladies unique nordic combined skiers: %d\n", length(unique(L_chrono$Skier))))
cat(sprintf("Men's season range: %s - %s\n", min(M_chrono$Season, na.rm = TRUE), max(M_chrono$Season, na.rm = TRUE)))
cat(sprintf("Ladies season range: %s - %s\n", min(L_chrono$Season, na.rm = TRUE), max(L_chrono$Season, na.rm = TRUE)))
```

### Data Processing

```{r process-data}
cat("=== NORDIC COMBINED DATA PROCESSING & VALIDATION ===\n")

# Function to process nordic combined chrono data (works for both men and ladies)
process_nordic_combined_chrono_data <- function(chrono_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Processing %s Nordic Combined Data ---\n", data_name))
  
  # Input validation
  if (nrow(chrono_df) == 0) {
    stop(sprintf("%s nordic combined dataset is empty", data_name))
  }
  
  # Check for required columns before processing
  required_cols <- c("Event", "City", "Place", "RaceType", "Date", "Race", "ID", "Season")
  missing_cols <- setdiff(required_cols, names(chrono_df))
  if (length(missing_cols) > 0) {
    stop(sprintf("Missing required columns in %s nordic combined data: %s", data_name, paste(missing_cols, collapse = ", ")))
  }
  
  original_rows <- nrow(chrono_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Add Nordic Combined World Cup points
  cat("Adding Nordic Combined World Cup points...\n")
  df <- chrono_df %>%
    mutate(Points = map_int(Place, ~ get_nordic_combined_points(.x)))
  
  # Validate points assignment
  points_na <- sum(is.na(df$Points))
  points_negative <- sum(df$Points < 0, na.rm = TRUE)
  
  if (points_na > 0) {
    warning(sprintf("%s: %d rows have NA points", data_name, points_na))
  }
  if (points_negative > 0) {
    warning(sprintf("%s: %d rows have negative points", data_name, points_negative))
  }
  
  cat(sprintf("Nordic combined points range: %d - %d\n", min(df$Points, na.rm = TRUE), max(df$Points, na.rm = TRUE)))
  
  # Count events before filtering
  event_counts_before <- table(df$Event)
  cat("Events before filtering:\n")
  print(event_counts_before)
  
  # Filter for relevant nordic combined events (only World Cup and Offseason)
  cat("Filtering for relevant nordic combined events (World Cup, Offseason)...\n")
  relevant_events <- c("World Cup", "Offseason")
  
  df <- df %>%
    filter(Event %in% relevant_events) %>%
    arrange(Date, Race, Place) %>%
    group_by(ID, Season) %>%
    mutate(
      Cumulative_Points = cumsum(Points),
      Races_in_Season = n()
    ) %>%
    ungroup()
  
  filtered_rows <- nrow(df)
  cat(sprintf("After nordic combined event filtering: %d rows (removed %d rows)\n", filtered_rows, original_rows - filtered_rows))
  
  # Count events after filtering
  event_counts_after <- table(df$Event)
  cat("Nordic combined events after filtering:\n")
  print(event_counts_after)
  
  # Validate cumulative points calculation
  invalid_cumulative <- df %>%
    group_by(ID, Season) %>%
    mutate(expected_cumulative = cumsum(Points)) %>%
    ungroup() %>%
    filter(Cumulative_Points != expected_cumulative) %>%
    nrow()
  
  if (invalid_cumulative > 0) {
    warning(sprintf("%s: %d rows have incorrect cumulative points", data_name, invalid_cumulative))
  } else {
    cat("✓ Cumulative points calculation validated\n")
  }
  
  # Check nordic combined race types (Individual Large Hill, Individual Normal Hill, Team events)
  cat("Checking nordic combined race types...\n")
  racetype_counts <- table(df$RaceType)
  cat("Nordic combined race types:\n")
  print(racetype_counts)
  
  # Calculate maximum possible points per season 
  cat("Calculating maximum possible nordic combined points per season...\n")
  max_points_per_season <- df %>%
    group_by(Season, Date, Race) %>%
    summarise(Max_Race_Points = max(Points), .groups = 'drop') %>%
    group_by(Season) %>%
    summarise(Max_Points = sum(Max_Race_Points), .groups = 'drop')
  
  # Validate max points calculation
  if (nrow(max_points_per_season) == 0) {
    stop(sprintf("%s: No seasons found for nordic combined max points calculation", data_name))
  }
  
  # Check for seasons with zero max points
  zero_max_seasons <- max_points_per_season %>% filter(Max_Points == 0)
  if (nrow(zero_max_seasons) > 0) {
    warning(sprintf("%s: %d nordic combined seasons have zero max points", data_name, nrow(zero_max_seasons)))
    print(zero_max_seasons)
  }
  
  cat(sprintf("Nordic combined max points range by season: %d - %d\n", 
              min(max_points_per_season$Max_Points), max(max_points_per_season$Max_Points)))
  
  # Join max points and calculate percentage
  cat("Calculating percentage of maximum nordic combined points...\n")
  before_join <- nrow(df)
  
  df <- df %>%
    left_join(max_points_per_season, by = "Season") %>%
    mutate(Pct_of_Max_Points = Cumulative_Points / Max_Points)
  
  after_join <- nrow(df)
  if (before_join != after_join) {
    warning(sprintf("%s: Row count changed during nordic combined max points join: %d -> %d", data_name, before_join, after_join))
  }
  
  # Validate percentage calculations
  pct_na <- sum(is.na(df$Pct_of_Max_Points))
  pct_negative <- sum(df$Pct_of_Max_Points < 0, na.rm = TRUE)
  pct_over_one <- sum(df$Pct_of_Max_Points > 1, na.rm = TRUE)
  
  if (pct_na > 0) {
    warning(sprintf("%s: %d rows have NA percentage of max nordic combined points", data_name, pct_na))
  }
  if (pct_negative > 0) {
    warning(sprintf("%s: %d rows have negative percentage of max nordic combined points", data_name, pct_negative))
  }
  if (pct_over_one > 0) {
    warning(sprintf("%s: %d rows have percentage > 100%% of max nordic combined points", data_name, pct_over_one))
  }
  
  cat(sprintf("Nordic combined percentage range: %.3f - %.3f\n", 
              min(df$Pct_of_Max_Points, na.rm = TRUE), max(df$Pct_of_Max_Points, na.rm = TRUE)))
  
  # Final validation checks
  cat("\n--- Final Nordic Combined Validation ---\n")
  
  # Check for required columns in output
  expected_output_cols <- c("Points", "Cumulative_Points", "Races_in_Season", "Max_Points", "Pct_of_Max_Points")
  missing_output_cols <- setdiff(expected_output_cols, names(df))
  if (length(missing_output_cols) > 0) {
    stop(sprintf("%s: Missing expected nordic combined output columns: %s", data_name, paste(missing_output_cols, collapse = ", ")))
  }
  
  # Summary statistics
  cat(sprintf("✓ Nordic combined processing complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(df), 100 * nrow(df) / original_rows))
  cat(sprintf("Unique nordic combined athletes: %d\n", length(unique(df$Skier))))
  cat(sprintf("Nordic combined seasons covered: %d (%s - %s)\n", 
              length(unique(df$Season)), min(df$Season), max(df$Season)))
  cat(sprintf("Average nordic combined races per season per athlete: %.1f\n", mean(df$Races_in_Season)))
  
  return(df)
}

# Process both nordic combined datasets with validation
cat("\n=== PROCESSING MEN'S NORDIC COMBINED DATA ===\n")
tryCatch({
  M_processed <- process_nordic_combined_chrono_data(M_chrono, "Men's")
}, error = function(e) {
  stop("Failed to process men's nordic combined data: ", e$message)
})

cat("\n=== PROCESSING LADIES' NORDIC COMBINED DATA ===\n") 
tryCatch({
  L_processed <- process_nordic_combined_chrono_data(L_chrono, "Ladies")
}, error = function(e) {
  stop("Failed to process ladies nordic combined data: ", e$message)
})

# Cross-validation between nordic combined datasets
cat("\n=== CROSS-DATASET NORDIC COMBINED VALIDATION ===\n")

# Compare season ranges
men_seasons <- sort(unique(M_processed$Season))
ladies_seasons <- sort(unique(L_processed$Season))

cat("Men's nordic combined seasons:", paste(range(men_seasons), collapse = " - "), "(", length(men_seasons), "seasons )\n")
cat("Ladies nordic combined seasons:", paste(range(ladies_seasons), collapse = " - "), "(", length(ladies_seasons), "seasons )\n")

# Check for season overlap
common_seasons <- intersect(men_seasons, ladies_seasons)
cat("Common nordic combined seasons:", length(common_seasons), "\n")

if (length(common_seasons) == 0) {
  warning("No common seasons between men's and ladies nordic combined data")
}

# Compare event distributions
men_events <- table(M_processed$Event)
ladies_events <- table(L_processed$Event)

cat("\nNordic combined event distribution comparison:\n")
all_events <- sort(unique(c(names(men_events), names(ladies_events))))

for (event in all_events) {
  men_count <- ifelse(event %in% names(men_events), men_events[event], 0)
  ladies_count <- ifelse(event %in% names(ladies_events), ladies_events[event], 0)
  cat(sprintf("  %s: Men %d, Ladies %d\n", event, men_count, ladies_count))
}

# Test with star athletes to validate processing
cat("\n=== NORDIC COMBINED STAR ATHLETE VALIDATION ===\n")

# Test Jens Lurås Oftebro (men)
oftebro_data <- M_processed %>% 
  filter(Skier == "Jens Lurås Oftebro") %>%
  arrange(Season, Date)

if (nrow(oftebro_data) > 0) {
  cat("Jens Lurås Oftebro validation:\n")
  cat(sprintf("  Seasons: %s - %s\n", min(oftebro_data$Season), max(oftebro_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(oftebro_data)))
  cat(sprintf("  Total points: %d\n", sum(oftebro_data$Points)))
  
  # Show latest season performance
  latest_season <- max(oftebro_data$Season)
  latest_data <- oftebro_data %>% filter(Season == latest_season)
  cat(sprintf("  Latest season (%s): %d races, %d points\n", 
              latest_season, nrow(latest_data), sum(latest_data$Points)))
} else {
  cat("Jens Lurås Oftebro not found in men's data\n")
}

# Test Ida Marie Hagen (ladies)
hagen_data <- L_processed %>% 
  filter(Skier == "Ida Marie Hagen") %>%
  arrange(Season, Date)

if (nrow(hagen_data) > 0) {
  cat("Ida Marie Hagen validation:\n")
  cat(sprintf("  Seasons: %s - %s\n", min(hagen_data$Season), max(hagen_data$Season)))
  cat(sprintf("  Total races: %d\n", nrow(hagen_data)))
  cat(sprintf("  Total points: %d\n", sum(hagen_data$Points)))
  
  # Show latest season performance
  latest_season <- max(hagen_data$Season)
  latest_data <- hagen_data %>% filter(Season == latest_season)
  cat(sprintf("  Latest season (%s): %d races, %d points\n", 
              latest_season, nrow(latest_data), sum(latest_data$Points)))
} else {
  cat("Ida Marie Hagen not found in ladies data\n")
}

# Final summary of processed nordic combined data
cat("\n=== NORDIC COMBINED DATA PROCESSING COMPLETE ===\n")
cat(sprintf("Processed nordic combined dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_processed), nrow(L_processed)))

# Check if both datasets have data
if (nrow(M_processed) == 0) {
  warning("Men's processed nordic combined dataset is empty")
}
if (nrow(L_processed) == 0) {
  warning("Ladies processed nordic combined dataset is empty")
}

# Show latest season data summary
cat("\n--- Latest Season Summary ---\n")
if (nrow(M_processed) > 0) {
  latest_season_m <- max(M_processed$Season)
  latest_men <- M_processed %>% filter(Season == latest_season_m)
  cat(sprintf("Men's latest season (%s): %d athletes, %d races\n", 
              latest_season_m, length(unique(latest_men$Skier)), nrow(latest_men)))
}

if (nrow(L_processed) > 0) {
  latest_season_l <- max(L_processed$Season)
  latest_ladies <- L_processed %>% filter(Season == latest_season_l)
  cat(sprintf("Ladies latest season (%s): %d athletes, %d races\n", 
              latest_season_l, length(unique(latest_ladies$Skier)), nrow(latest_ladies)))
}
```

### ELO Data Preparation

```{r elo-prep}
cat("=== NORDIC COMBINED ELO DATA PREPARATION ===\n")

# Helper function for quartile replacement (handles NAs by replacing with 1st quartile within season)
replace_na_with_quartile <- function(x, var_name) {
  if (all(is.na(x))) {
    warning(sprintf("All values NA for %s in this season - keeping as NA", var_name))
    return(x)  # Return original NAs instead of 0
  }
  
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  if (is.na(q1)) {
    warning(sprintf("Cannot calculate quartile for %s - keeping as NA", var_name))
    return(x)  # Return original instead of 0
  }
  
  cat(sprintf("  Replacing NAs in %s with Q1 value: %.1f\n", var_name, q1))
  return(replace(x, is.na(x), q1))
}

# Function to prepare nordic combined ELO data for modeling (works for both men and ladies)
prepare_nordic_combined_elo_data <- function(processed_df, data_name = "Unknown") {
  
  cat(sprintf("\n--- Preparing %s Nordic Combined ELO Data ---\n", data_name))
  
  # Input validation
  if (nrow(processed_df) == 0) {
    stop(sprintf("%s nordic combined dataset is empty", data_name))
  }
  
  original_rows <- nrow(processed_df)
  cat(sprintf("Input: %d rows\n", original_rows))
  
  # Check for offseason data
  offseason_count <- sum(processed_df$Event == "Offseason", na.rm = TRUE)
  cat(sprintf("Offseason events available: %d\n", offseason_count))
  
  if (offseason_count == 0) {
    stop(sprintf("%s: No offseason data found for nordic combined ELO preparation", data_name))
  }
  
  # Check for required nordic combined ELO columns before processing
  required_elo_cols <- c("Pelo", "Individual_Pelo", "IndividualCompact_Pelo", "MassStart_Pelo")
  
  available_elo_cols <- intersect(required_elo_cols, names(processed_df))
  missing_elo_cols <- setdiff(required_elo_cols, names(processed_df))
  
  cat(sprintf("Available nordic combined ELO columns: %d/%d\n", length(available_elo_cols), length(required_elo_cols)))
  if (length(missing_elo_cols) > 0) {
    cat("Missing nordic combined ELO columns:", paste(missing_elo_cols, collapse = ", "), "\n")
    warning(sprintf("%s: Missing some nordic combined ELO columns - proceeding with available columns", data_name))
  }
  
  # Filter for offseason data and create previous season ELO values
  cat("Filtering for offseason data and creating lag features...\n")
  
  elo_df <- processed_df %>%
    filter(Event == "Offseason") %>%
    arrange(ID, Season)
  
  filtered_rows <- nrow(elo_df)
  cat(sprintf("After offseason filter: %d rows (%.1f%% of input)\n", 
              filtered_rows, 100 * filtered_rows / original_rows))
  
  if (filtered_rows == 0) {
    stop(sprintf("%s: No rows remaining after offseason filtering", data_name))
  }
  
  # Create lag features for nordic combined disciplines with validation
  cat("Creating nordic combined discipline lag features...\n")
  
  elo_df <- elo_df %>%
    group_by(ID) %>%
    mutate(
      Prev_Pelo = if("Pelo" %in% names(.)) lag(Pelo) else NA_real_,
      Prev_Individual = if("Individual_Pelo" %in% names(.)) lag(Individual_Pelo) else NA_real_,
      Prev_IndividualCompact = if("IndividualCompact_Pelo" %in% names(.)) lag(IndividualCompact_Pelo) else NA_real_,
      Prev_MassStart = if("MassStart_Pelo" %in% names(.)) lag(MassStart_Pelo) else NA_real_,
      Prev_Pct_of_Max_Points = lag(Pct_of_Max_Points)
    ) %>%
    ungroup()
  
  # Validate lag feature creation
  lag_features <- paste0("Prev_", c("Pelo", "Individual", "IndividualCompact", "MassStart", "Pct_of_Max_Points"))
  
  created_lag_features <- intersect(lag_features, names(elo_df))
  cat(sprintf("Created nordic combined lag features: %d/%d\n", length(created_lag_features), length(lag_features)))
  
  # Apply season filter
  cat("Applying season filter (> 2015)...\n")
  before_season_filter <- nrow(elo_df)
  
  elo_df <- elo_df %>%
    filter(Season > 2015)
  
  after_season_filter <- nrow(elo_df)
  cat(sprintf("After season filter: %d rows (removed %d rows from ≤2015)\n", 
              after_season_filter, before_season_filter - after_season_filter))
  
  if (after_season_filter == 0) {
    stop(sprintf("%s: No rows remaining after nordic combined season filtering (>2015)", data_name))
  }
  
  # Validate season range
  season_range <- range(elo_df$Season, na.rm = TRUE)
  cat(sprintf("Final nordic combined season range: %.0f - %.0f\n", season_range[1], season_range[2]))
  
  # Handle missing values by replacing with quartiles within each season
  cat("\n--- Nordic Combined ELO Missing Value Treatment ---\n")
  
  # Count NAs before treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_before <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_before <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_before) > 0) {
    cat("Nordic combined ELO NAs before treatment:\n")
    print(na_summary_before)
  } else {
    cat("No NAs found in nordic combined lag features\n")
  }
  
  # Apply quartile replacement by season for nordic combined disciplines
  cat("Applying quartile replacement by season for nordic combined disciplines...\n")
  
  elo_df <- elo_df %>%
    group_by(Season) %>%
    mutate(
      Prev_Individual = if("Prev_Individual" %in% names(.)) {
        if(all(is.na(Prev_Individual))) Prev_Individual else replace_na_with_quartile(Prev_Individual, "Prev_Individual")
      } else Prev_Individual,
      Prev_IndividualCompact = if("Prev_IndividualCompact" %in% names(.)) {
        if(all(is.na(Prev_IndividualCompact))) Prev_IndividualCompact else replace_na_with_quartile(Prev_IndividualCompact, "Prev_IndividualCompact")
      } else Prev_IndividualCompact,
      Prev_MassStart = if("Prev_MassStart" %in% names(.)) {
        if(all(is.na(Prev_MassStart))) Prev_MassStart else replace_na_with_quartile(Prev_MassStart, "Prev_MassStart")
      } else Prev_MassStart,
      Prev_Pelo = if("Prev_Pelo" %in% names(.)) {
        if(all(is.na(Prev_Pelo))) Prev_Pelo else replace_na_with_quartile(Prev_Pelo, "Prev_Pelo")
      } else Prev_Pelo,
      Prev_Pct_of_Max_Points = replace(Prev_Pct_of_Max_Points, is.na(Prev_Pct_of_Max_Points), 0)
    ) %>%
    ungroup()
  
  # Validate missing value treatment
  if (length(created_lag_features) > 0) {
    available_lag_features <- intersect(created_lag_features, names(elo_df))
    if (length(available_lag_features) > 0) {
      na_summary_after <- elo_df[available_lag_features] %>%
        summarise_all(~ sum(is.na(.))) %>%
        gather(variable, na_count) %>%
        filter(na_count > 0)
    } else {
      na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
    }
  } else {
    na_summary_after <- data.frame(variable = character(0), na_count = numeric(0))
  }
  
  if (nrow(na_summary_after) > 0) {
    cat("Remaining nordic combined ELO NAs after season-wise treatment:\n")
    print(na_summary_after)
    
    # Apply global quartile replacement for any remaining NAs
    cat("Applying global quartile replacement for remaining NAs...\n")
    
    elo_df <- elo_df %>%
      mutate(
        Prev_Individual = if("Prev_Individual" %in% names(.)) {
          if(any(is.na(Prev_Individual))) {
            global_q1 <- quantile(Prev_Individual, 0.25, na.rm = TRUE)
            cat(sprintf("  Global Q1 for Prev_Individual: %.1f\n", global_q1))
            replace(Prev_Individual, is.na(Prev_Individual), global_q1)
          } else Prev_Individual
        } else Prev_Individual,
        Prev_IndividualCompact = if("Prev_IndividualCompact" %in% names(.)) {
          if(any(is.na(Prev_IndividualCompact))) {
            global_q1 <- quantile(Prev_IndividualCompact, 0.25, na.rm = TRUE)
            cat(sprintf("  Global Q1 for Prev_IndividualCompact: %.1f\n", global_q1))
            replace(Prev_IndividualCompact, is.na(Prev_IndividualCompact), global_q1)
          } else Prev_IndividualCompact
        } else Prev_IndividualCompact,
        Prev_MassStart = if("Prev_MassStart" %in% names(.)) {
          if(any(is.na(Prev_MassStart))) {
            global_q1 <- quantile(Prev_MassStart, 0.25, na.rm = TRUE)
            cat(sprintf("  Global Q1 for Prev_MassStart: %.1f\n", global_q1))
            replace(Prev_MassStart, is.na(Prev_MassStart), global_q1)
          } else Prev_MassStart
        } else Prev_MassStart,
        Prev_Pelo = if("Prev_Pelo" %in% names(.)) {
          if(any(is.na(Prev_Pelo))) {
            global_q1 <- quantile(Prev_Pelo, 0.25, na.rm = TRUE)
            cat(sprintf("  Global Q1 for Prev_Pelo: %.1f\n", global_q1))
            replace(Prev_Pelo, is.na(Prev_Pelo), global_q1)
          } else Prev_Pelo
        } else Prev_Pelo
      )
    
    # Check again for any remaining NAs
    final_na_check <- elo_df[available_lag_features] %>%
      summarise_all(~ sum(is.na(.))) %>%
      gather(variable, na_count) %>%
      filter(na_count > 0)
    
    if (nrow(final_na_check) > 0) {
      cat("NAs still remaining after global treatment:\n")
      print(final_na_check)
      warning(sprintf("%s: Some nordic combined ELO NAs still remain", data_name))
    } else {
      cat("✓ All nordic combined ELO NAs successfully treated\n")
    }
  } else {
    cat("✓ All nordic combined ELO NAs successfully treated\n")
  }
  
  # Final validation checks
  cat("\n--- Final Nordic Combined ELO Validation ---\n")
  
  # Check for infinite values
  numeric_cols <- select_if(elo_df, is.numeric) %>% names()
  if (length(numeric_cols) > 0) {
    inf_check <- elo_df[numeric_cols] %>%
      summarise_all(~ sum(!is.finite(.))) %>%
      gather(variable, inf_count) %>%
      filter(inf_count > 0)
  } else {
    inf_check <- data.frame(variable = character(0), inf_count = numeric(0))
  }
  
  if (nrow(inf_check) > 0) {
    cat("Infinite values found in nordic combined ELO data:\n")
    print(inf_check)
    warning(sprintf("%s: Contains infinite values", data_name))
  } else {
    cat("✓ No infinite values detected in nordic combined ELO data\n")
  }
  
  # Validate key relationships for nordic combined
  if ("Age" %in% names(elo_df)) {
    age_issues <- elo_df %>%
      filter(Age < 15 | Age > 50) %>%
      nrow()
    
    if (age_issues > 0) {
      warning(sprintf("%s: %d rows with unusual ages (<15 or >50)", data_name, age_issues))
    }
    
    cat(sprintf("Nordic combined athlete age range: %.0f - %.0f\n", min(elo_df$Age, na.rm = TRUE), max(elo_df$Age, na.rm = TRUE)))
  }
  
  # Summary statistics
  cat(sprintf("✓ Nordic combined ELO preparation complete for %s\n", data_name))
  cat(sprintf("Final rows: %d (%.1f%% of original)\n", nrow(elo_df), 100 * nrow(elo_df) / original_rows))
  cat(sprintf("Unique nordic combined athletes: %d\n", length(unique(elo_df$Skier))))
  cat(sprintf("Nordic combined seasons: %d (%s)\n", 
              length(unique(elo_df$Season)), paste(sort(unique(elo_df$Season)), collapse = ", ")))
  
  return(elo_df)
}

# Prepare nordic combined ELO data for both men and ladies with comprehensive validation
cat("\n=== PREPARING MEN'S NORDIC COMBINED ELO DATA ===\n")
tryCatch({
  M_elo <- prepare_nordic_combined_elo_data(M_processed, "Men's")
}, error = function(e) {
  stop("Failed to prepare men's nordic combined ELO data: ", e$message)
})

cat("\n=== PREPARING LADIES' NORDIC COMBINED ELO DATA ===\n")
tryCatch({
  L_elo <- prepare_nordic_combined_elo_data(L_processed, "Ladies")
}, error = function(e) {
  stop("Failed to prepare ladies nordic combined ELO data: ", e$message)
})

# Cross-validation between nordic combined ELO datasets
cat("\n=== CROSS-DATASET NORDIC COMBINED ELO VALIDATION ===\n")

# Compare season ranges
men_elo_seasons <- sort(unique(M_elo$Season))
ladies_elo_seasons <- sort(unique(L_elo$Season))

cat("Men's nordic combined ELO seasons:", paste(range(men_elo_seasons), collapse = " - "), "(", length(men_elo_seasons), "seasons )\n")
cat("Ladies nordic combined ELO seasons:", paste(range(ladies_elo_seasons), collapse = " - "), "(", length(ladies_elo_seasons), "seasons )\n")

# Check for season overlap
common_elo_seasons <- intersect(men_elo_seasons, ladies_elo_seasons)
cat("Common nordic combined ELO seasons:", length(common_elo_seasons), "\n")

if (length(common_elo_seasons) == 0) {
  warning("No common seasons between men's and ladies nordic combined ELO data")
}

# Validate nordic combined ELO distributions
cat("\n--- Nordic Combined ELO Distribution Analysis ---\n")

# Check ELO ranges for men
if ("Prev_Pelo" %in% names(M_elo)) {
  men_pelo_range <- range(M_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Men's Prev_Pelo range: %.0f - %.0f\n", men_pelo_range[1], men_pelo_range[2]))
}

if ("Prev_Individual" %in% names(M_elo)) {
  men_individual_range <- range(M_elo$Prev_Individual, na.rm = TRUE)
  cat(sprintf("Men's Prev_Individual range: %.0f - %.0f\n", men_individual_range[1], men_individual_range[2]))
}

if ("Prev_IndividualCompact" %in% names(M_elo)) {
  men_individualcompact_range <- range(M_elo$Prev_IndividualCompact, na.rm = TRUE)
  cat(sprintf("Men's Prev_IndividualCompact range: %.0f - %.0f\n", men_individualcompact_range[1], men_individualcompact_range[2]))
}

if ("Prev_MassStart" %in% names(M_elo)) {
  men_massstart_range <- range(M_elo$Prev_MassStart, na.rm = TRUE)
  cat(sprintf("Men's Prev_MassStart range: %.0f - %.0f\n", men_massstart_range[1], men_massstart_range[2]))
}

# Check ELO ranges for ladies
if ("Prev_Pelo" %in% names(L_elo)) {
  ladies_pelo_range <- range(L_elo$Prev_Pelo, na.rm = TRUE)
  cat(sprintf("Ladies Prev_Pelo range: %.0f - %.0f\n", ladies_pelo_range[1], ladies_pelo_range[2]))
}

if ("Prev_Individual" %in% names(L_elo)) {
  ladies_individual_range <- range(L_elo$Prev_Individual, na.rm = TRUE)
  cat(sprintf("Ladies Prev_Individual range: %.0f - %.0f\n", ladies_individual_range[1], ladies_individual_range[2]))
}

if ("Prev_IndividualCompact" %in% names(L_elo)) {
  ladies_individualcompact_range <- range(L_elo$Prev_IndividualCompact, na.rm = TRUE)
  cat(sprintf("Ladies Prev_IndividualCompact range: %.0f - %.0f\n", ladies_individualcompact_range[1], ladies_individualcompact_range[2]))
}

if ("Prev_MassStart" %in% names(L_elo)) {
  ladies_massstart_range <- range(L_elo$Prev_MassStart, na.rm = TRUE)
  cat(sprintf("Ladies Prev_MassStart range: %.0f - %.0f\n", ladies_massstart_range[1], ladies_massstart_range[2]))
}

# Test specific athletes to validate ELO preparation
cat("\n=== NORDIC COMBINED ELO ATHLETE VALIDATION ===\n")

# Test Jens Lurås Oftebro (men) - if available
oftebro_elo_data <- M_elo %>% 
  filter(Skier == "Jens Lurås Oftebro") %>%
  arrange(Season)

if (nrow(oftebro_elo_data) > 0) {
  cat("Jens Lurås Oftebro ELO validation:\n")
  cat(sprintf("  ELO seasons: %s - %s\n", min(oftebro_elo_data$Season), max(oftebro_elo_data$Season)))
  cat(sprintf("  ELO rows: %d\n", nrow(oftebro_elo_data)))
  
  if ("Prev_Pelo" %in% names(oftebro_elo_data)) {
    cat(sprintf("  Prev_Pelo range: %.0f - %.0f\n", 
                min(oftebro_elo_data$Prev_Pelo, na.rm = TRUE), max(oftebro_elo_data$Prev_Pelo, na.rm = TRUE)))
  }
} else {
  cat("Jens Lurås Oftebro not found in men's ELO data\n")
}

# Test Ida Marie Hagen (ladies) - if available
hagen_elo_data <- L_elo %>% 
  filter(Skier == "Ida Marie Hagen") %>%
  arrange(Season)

if (nrow(hagen_elo_data) > 0) {
  cat("Ida Marie Hagen ELO validation:\n")
  cat(sprintf("  ELO seasons: %s - %s\n", min(hagen_elo_data$Season), max(hagen_elo_data$Season)))
  cat(sprintf("  ELO rows: %d\n", nrow(hagen_elo_data)))
  
  if ("Prev_Pelo" %in% names(hagen_elo_data)) {
    cat(sprintf("  Prev_Pelo range: %.0f - %.0f\n", 
                min(hagen_elo_data$Prev_Pelo, na.rm = TRUE), max(hagen_elo_data$Prev_Pelo, na.rm = TRUE)))
  }
} else {
  cat("Ida Marie Hagen not found in ladies ELO data\n")
}

cat("\n=== NORDIC COMBINED ELO DATA PREPARATION COMPLETE ===\n")
cat(sprintf("Nordic combined ELO dataset sizes: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))
```

### Season Points Prediction Model

```{r comprehensive-feature-selection}
cat("=== COMPREHENSIVE NORDIC COMBINED FEATURE SELECTION & VALIDATION ===\n")

# Comprehensive Feature Selection using multiple methods with validation
# Adapted for nordic combined disciplines and ELO ratings

cat("\n--- Nordic Combined Training Data Preparation ---\n")

# Input validation for nordic combined ELO datasets
if (nrow(M_elo) == 0) {
  stop("Men's nordic combined ELO dataset is empty")
}
if (nrow(L_elo) == 0) {
  stop("Ladies nordic combined ELO dataset is empty")
}

cat(sprintf("Input nordic combined datasets: Men %d rows, Ladies %d rows\n", nrow(M_elo), nrow(L_elo)))

# Prepare training data - include more historical seasons to capture early breakthroughs
# Use data from 2016+ to include breakthrough seasons in nordic combined
cat("Filtering nordic combined training data (2016-2025, non-NA Pct_of_Max_Points)...\n")

# Check available seasons before filtering
men_seasons_available <- sort(unique(M_elo$Season))
ladies_seasons_available <- sort(unique(L_elo$Season))

cat(sprintf("Men's nordic combined available seasons: %s\n", paste(range(men_seasons_available), collapse = " - ")))
cat(sprintf("Ladies nordic combined available seasons: %s\n", paste(range(ladies_seasons_available), collapse = " - ")))

# Apply training filters with validation
train_men <- M_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

train_ladies <- L_elo %>% 
  filter(Season <= 2025, Season >= 2016) %>% 
  filter(!is.na(Pct_of_Max_Points))

# Validate training datasets
if (nrow(train_men) == 0) {
  stop("No men's nordic combined training data remains after filtering")
}
if (nrow(train_ladies) == 0) {
  stop("No ladies nordic combined training data remains after filtering")
}

cat(sprintf("Nordic combined training datasets: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Check season coverage in training data
train_men_seasons <- sort(unique(train_men$Season))
train_ladies_seasons <- sort(unique(train_ladies$Season))

cat(sprintf("Men's nordic combined training seasons: %s (%d seasons)\n", 
            paste(train_men_seasons, collapse = ", "), length(train_men_seasons)))
cat(sprintf("Ladies nordic combined training seasons: %s (%d seasons)\n", 
            paste(train_ladies_seasons, collapse = ", "), length(train_ladies_seasons)))

if (length(train_men_seasons) < 3) {
  warning("Men's nordic combined training data has fewer than 3 seasons - may affect model robustness")
}
if (length(train_ladies_seasons) < 3) {
  warning("Ladies nordic combined training data has fewer than 3 seasons - may affect model robustness")
}

# Define and validate potential nordic combined features
cat("\n--- Nordic Combined Feature Validation ---\n")

all_features <- c("Pelo", "Individual_Pelo", "IndividualCompact_Pelo", 
                  "MassStart_Pelo", "Pct_of_Max_Points", "Age")

# Check feature availability in nordic combined training datasets
men_available_features <- intersect(all_features, names(train_men))
ladies_available_features <- intersect(all_features, names(train_ladies))

cat(sprintf("Men's available nordic combined features: %d/%d\n", length(men_available_features), length(all_features)))
cat(sprintf("Ladies available nordic combined features: %d/%d\n", length(ladies_available_features), length(all_features)))

# Report missing features
men_missing_features <- setdiff(all_features, men_available_features)
ladies_missing_features <- setdiff(all_features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing nordic combined features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some nordic combined features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing nordic combined features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some nordic combined features missing from ladies training data")
}

# Update feature lists to only include available features
all_features_men <- men_available_features
all_features_ladies <- ladies_available_features

if (length(all_features_men) < 3) {
  stop("Insufficient nordic combined features for men's modeling (need at least 3)")
}
if (length(all_features_ladies) < 3) {
  stop("Insufficient nordic combined features for ladies modeling (need at least 3)")
}

# Validate nordic combined feature data quality
cat("\n--- Nordic Combined Feature Data Quality Checks ---\n")

# Check for missing values in nordic combined features
men_feature_na_counts <- sapply(train_men[all_features_men], function(x) sum(is.na(x)))
ladies_feature_na_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(is.na(x)))

if (any(men_feature_na_counts > 0)) {
  cat("Men's nordic combined features with NAs:\n")
  print(men_feature_na_counts[men_feature_na_counts > 0])
  warning("Men's nordic combined training data contains missing values in features")
}
if (any(ladies_feature_na_counts > 0)) {
  cat("Ladies nordic combined features with NAs:\n")
  print(ladies_feature_na_counts[ladies_feature_na_counts > 0])
  warning("Ladies nordic combined training data contains missing values in features")
}

# Check for infinite values
men_feature_inf_counts <- sapply(train_men[all_features_men], function(x) sum(!is.finite(x)))
ladies_feature_inf_counts <- sapply(train_ladies[all_features_ladies], function(x) sum(!is.finite(x)))

if (any(men_feature_inf_counts > 0)) {
  cat("Men's nordic combined features with infinite values:\n")
  print(men_feature_inf_counts[men_feature_inf_counts > 0])
  warning("Men's nordic combined training data contains infinite values")
}
if (any(ladies_feature_inf_counts > 0)) {
  cat("Ladies nordic combined features with infinite values:\n")
  print(ladies_feature_inf_counts[ladies_feature_inf_counts > 0])
  warning("Ladies nordic combined training data contains infinite values")
}

# Check target variable quality
men_target_na <- sum(is.na(train_men$Pct_of_Max_Points))
ladies_target_na <- sum(is.na(train_ladies$Pct_of_Max_Points))

if (men_target_na > 0) {
  warning(sprintf("Men's nordic combined target variable has %d NA values", men_target_na))
}
if (ladies_target_na > 0) {
  warning(sprintf("Ladies nordic combined target variable has %d NA values", ladies_target_na))
}

cat(sprintf("Nordic combined target variable ranges: Men %.3f-%.3f, Ladies %.3f-%.3f\n",
            min(train_men$Pct_of_Max_Points, na.rm = TRUE), max(train_men$Pct_of_Max_Points, na.rm = TRUE),
            min(train_ladies$Pct_of_Max_Points, na.rm = TRUE), max(train_ladies$Pct_of_Max_Points, na.rm = TRUE)))

cat("\n=== COMPREHENSIVE NORDIC COMBINED FEATURE SELECTION FOR MEN ===\n")

# 1. CORRELATION ANALYSIS with validation
cat("1. NORDIC COMBINED CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient nordic combined features for correlation analysis\n")
    cor_matrix_men <- NULL
    high_cor_men <- data.frame()
  } else {
    cor_matrix_men <- cor(train_men[all_features_men], use = "complete.obs")
    
    # Validate correlation matrix
    if (any(is.na(cor_matrix_men))) {
      warning("Nordic combined correlation matrix contains NA values")
    }
    
    high_cor_men <- which(abs(cor_matrix_men) > 0.7 & upper.tri(cor_matrix_men), arr.ind = TRUE)
    if(nrow(high_cor_men) > 0) {
      cat("High nordic combined correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_men)) {
        row_name <- rownames(cor_matrix_men)[high_cor_men[i,1]]
        col_name <- colnames(cor_matrix_men)[high_cor_men[i,2]]
        cor_val <- cor_matrix_men[high_cor_men[i,1], high_cor_men[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high nordic combined correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in nordic combined correlation analysis:", e$message, "\n")
  cor_matrix_men <- NULL
  high_cor_men <- data.frame()
})

# 2. LASSO REGULARIZATION with validation
cat("2. NORDIC COMBINED LASSO REGULARIZATION:\n")
lasso_selected_men <- character(0)
tryCatch({
  set.seed(42)
  
  # Prepare data for LASSO
  x_men <- as.matrix(train_men[all_features_men])
  y_men <- train_men$Pct_of_Max_Points
  
  # Validate data for LASSO
  if (any(!is.finite(x_men))) {
    warning("Non-finite values in nordic combined feature matrix for LASSO")
  }
  if (any(!is.finite(y_men))) {
    warning("Non-finite values in nordic combined target variable for LASSO")
  }
  
  cv_lasso_men <- cv.glmnet(x_men, y_men, alpha = 1, nfolds = 5)
  best_lambda_men <- cv_lasso_men$lambda.min
  lasso_coef_men <- coef(cv_lasso_men, s = best_lambda_men)
  
  lasso_selected_men <- rownames(lasso_coef_men)[which(lasso_coef_men != 0)][-1]  # Remove intercept
  
  if (length(lasso_selected_men) > 0) {
    cat("Nordic combined LASSO selected features:\n")
    for (feature in lasso_selected_men) {
      coef_val <- lasso_coef_men[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by nordic combined LASSO (may indicate weak predictors)\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_men))
  
}, error = function(e) {
  cat("Error in nordic combined LASSO analysis:", e$message, "\n")
  lasso_selected_men <- character(0)
})

# 3. BORUTA FEATURE SELECTION with validation
cat("3. NORDIC COMBINED BORUTA FEATURE SELECTION:\n")
boruta_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient nordic combined features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_men <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                         data = train_men, doTrace = 0)
    
    boruta_selected_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_men) > 0) {
      cat("Nordic combined Boruta confirmed features:\n")
      for (feature in boruta_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by nordic combined Boruta\n")
    }
    
    # Check for tentative features
    tentative_men <- names(boruta_men$finalDecision)[boruta_men$finalDecision == "Tentative"]
    if (length(tentative_men) > 0) {
      cat("Nordic combined Boruta tentative features:\n")
      for (feature in tentative_men) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in nordic combined Boruta analysis:", e$message, "\n")
  boruta_selected_men <- character(0)
})

# 4. EXHAUSTIVE SEARCH with validation
cat("4. NORDIC COMBINED EXHAUSTIVE SEARCH:\n")
leaps_selected_men <- character(0)
tryCatch({
  if (length(all_features_men) < 2) {
    cat("Insufficient nordic combined features for exhaustive search\n")
  } else if (length(all_features_men) > 8) {
    cat("Too many nordic combined features for exhaustive search - using best subset\n")
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, nvmax = min(8, length(all_features_men)))
  } else {
    leaps_men <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_men, collapse = " + "))), 
                           data = train_men, really.big = TRUE)
  }
  
  if (exists("leaps_men")) {
    summary_leaps_men <- summary(leaps_men)
    best_model_size <- which.max(summary_leaps_men$adjr2)
    leaps_selected_men <- names(which(summary_leaps_men$which[best_model_size, -1]))  # Remove intercept
    
    if (length(leaps_selected_men) > 0) {
      cat("Nordic combined exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_men) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_men$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by nordic combined exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in nordic combined exhaustive search:", e$message, "\n")
  leaps_selected_men <- character(0)
})

# 5. CONSENSUS FEATURE SELECTION
cat("5. NORDIC COMBINED CONSENSUS FEATURE SELECTION:\n")

all_selected_men <- c(lasso_selected_men, boruta_selected_men, leaps_selected_men)
if (length(all_selected_men) > 0) {
  feature_counts_men <- table(all_selected_men)
  consensus_men <- names(feature_counts_men)[feature_counts_men >= 2]  # Features selected by 2+ methods
  
  if (length(consensus_men) > 0) {
    cat("Nordic combined consensus features (selected by 2+ methods):\n")
    for (feature in consensus_men) {
      count <- feature_counts_men[feature]
      methods <- c(
        if (feature %in% lasso_selected_men) "LASSO" else NULL,
        if (feature %in% boruta_selected_men) "Boruta" else NULL,
        if (feature %in% leaps_selected_men) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No nordic combined consensus features - using union of all methods\n")
    consensus_men <- unique(all_selected_men)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_men) && "Pct_of_Max_Points" %in% names(train_men)) {
    target_cors <- cor(train_men[all_features_men], train_men$Pct_of_Max_Points, use = "complete.obs")
    consensus_men <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_men))]
  } else {
    consensus_men <- all_features_men[1:min(3, length(all_features_men))]
  }
}

final_features_men <- consensus_men
cat(sprintf("Final nordic combined features for men: %s\n", paste(final_features_men, collapse = ", ")))

cat("\n=== COMPREHENSIVE NORDIC COMBINED FEATURE SELECTION FOR LADIES ===\n")

# Repeat the same process for ladies with nordic combined-specific adaptations
# 1. CORRELATION ANALYSIS
cat("1. NORDIC COMBINED CORRELATION ANALYSIS:\n")
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient nordic combined features for correlation analysis\n")
    cor_matrix_ladies <- NULL
    high_cor_ladies <- data.frame()
  } else {
    cor_matrix_ladies <- cor(train_ladies[all_features_ladies], use = "complete.obs")
    
    if (any(is.na(cor_matrix_ladies))) {
      warning("Nordic combined correlation matrix contains NA values")
    }
    
    high_cor_ladies <- which(abs(cor_matrix_ladies) > 0.7 & upper.tri(cor_matrix_ladies), arr.ind = TRUE)
    if(nrow(high_cor_ladies) > 0) {
      cat("High nordic combined correlations (|r| > 0.7):\n")
      for(i in 1:nrow(high_cor_ladies)) {
        row_name <- rownames(cor_matrix_ladies)[high_cor_ladies[i,1]]
        col_name <- colnames(cor_matrix_ladies)[high_cor_ladies[i,2]]
        cor_val <- cor_matrix_ladies[high_cor_ladies[i,1], high_cor_ladies[i,2]]
        cat(sprintf("  %s - %s: %.3f\n", row_name, col_name, cor_val))
      }
    } else {
      cat("✓ No high nordic combined correlations found\n")
    }
  }
}, error = function(e) {
  cat("Error in nordic combined correlation analysis:", e$message, "\n")
  cor_matrix_ladies <- NULL
  high_cor_ladies <- data.frame()
})

# 2. LASSO REGULARIZATION
cat("2. NORDIC COMBINED LASSO REGULARIZATION:\n")
lasso_selected_ladies <- character(0)
tryCatch({
  set.seed(42)
  
  x_ladies <- as.matrix(train_ladies[all_features_ladies])
  y_ladies <- train_ladies$Pct_of_Max_Points
  
  if (any(!is.finite(x_ladies))) {
    warning("Non-finite values in nordic combined feature matrix for LASSO")
  }
  if (any(!is.finite(y_ladies))) {
    warning("Non-finite values in nordic combined target variable for LASSO")
  }
  
  cv_lasso_ladies <- cv.glmnet(x_ladies, y_ladies, alpha = 1, nfolds = 5)
  best_lambda_ladies <- cv_lasso_ladies$lambda.min
  lasso_coef_ladies <- coef(cv_lasso_ladies, s = best_lambda_ladies)
  
  lasso_selected_ladies <- rownames(lasso_coef_ladies)[which(lasso_coef_ladies != 0)][-1]
  
  if (length(lasso_selected_ladies) > 0) {
    cat("Nordic combined LASSO selected features:\n")
    for (feature in lasso_selected_ladies) {
      coef_val <- lasso_coef_ladies[feature, 1]
      cat(sprintf("  %s: %.4f\n", feature, coef_val))
    }
  } else {
    cat("✓ No features selected by nordic combined LASSO\n")
  }
  
  cat(sprintf("Best lambda: %.6f\n", best_lambda_ladies))
  
}, error = function(e) {
  cat("Error in nordic combined LASSO analysis:", e$message, "\n")
  lasso_selected_ladies <- character(0)
})

# 3. BORUTA FEATURE SELECTION
cat("3. NORDIC COMBINED BORUTA FEATURE SELECTION:\n")
boruta_selected_ladies <- character(0)
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient nordic combined features for Boruta analysis\n")
  } else {
    set.seed(42)
    boruta_ladies <- Boruta(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                           data = train_ladies, doTrace = 0)
    
    boruta_selected_ladies <- names(boruta_ladies$finalDecision)[boruta_ladies$finalDecision == "Confirmed"]
    
    if (length(boruta_selected_ladies) > 0) {
      cat("Nordic combined Boruta confirmed features:\n")
      for (feature in boruta_selected_ladies) {
        cat(sprintf("  %s\n", feature))
      }
    } else {
      cat("✓ No features confirmed by nordic combined Boruta\n")
    }
    
    tentative_ladies <- names(boruta_ladies$finalDecision)[boruta_ladies$finalDecision == "Tentative"]
    if (length(tentative_ladies) > 0) {
      cat("Nordic combined Boruta tentative features:\n")
      for (feature in tentative_ladies) {
        cat(sprintf("  %s (tentative)\n", feature))
      }
    }
  }
}, error = function(e) {
  cat("Error in nordic combined Boruta analysis:", e$message, "\n")
  boruta_selected_ladies <- character(0)
})

# 4. EXHAUSTIVE SEARCH
cat("4. NORDIC COMBINED EXHAUSTIVE SEARCH:\n")
leaps_selected_ladies <- character(0)
tryCatch({
  if (length(all_features_ladies) < 2) {
    cat("Insufficient nordic combined features for exhaustive search\n")
  } else if (length(all_features_ladies) > 8) {
    cat("Too many nordic combined features for exhaustive search - using best subset\n")
    leaps_ladies <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                              data = train_ladies, nvmax = min(8, length(all_features_ladies)))
  } else {
    leaps_ladies <- regsubsets(as.formula(paste("Pct_of_Max_Points ~", paste(all_features_ladies, collapse = " + "))), 
                              data = train_ladies, really.big = TRUE)
  }
  
  if (exists("leaps_ladies")) {
    summary_leaps_ladies <- summary(leaps_ladies)
    best_model_size <- which.max(summary_leaps_ladies$adjr2)
    leaps_selected_ladies <- names(which(summary_leaps_ladies$which[best_model_size, -1]))
    
    if (length(leaps_selected_ladies) > 0) {
      cat("Nordic combined exhaustive search selected features (best adj R²):\n")
      for (feature in leaps_selected_ladies) {
        cat(sprintf("  %s\n", feature))
      }
      cat(sprintf("Best model size: %d features, Adj R²: %.4f\n", 
                  best_model_size, summary_leaps_ladies$adjr2[best_model_size]))
    } else {
      cat("✓ No features selected by nordic combined exhaustive search\n")
    }
  }
}, error = function(e) {
  cat("Error in nordic combined exhaustive search:", e$message, "\n")
  leaps_selected_ladies <- character(0)
})

# 5. CONSENSUS FEATURE SELECTION
cat("5. NORDIC COMBINED CONSENSUS FEATURE SELECTION:\n")

all_selected_ladies <- c(lasso_selected_ladies, boruta_selected_ladies, leaps_selected_ladies)
if (length(all_selected_ladies) > 0) {
  feature_counts_ladies <- table(all_selected_ladies)
  consensus_ladies <- names(feature_counts_ladies)[feature_counts_ladies >= 2]
  
  if (length(consensus_ladies) > 0) {
    cat("Nordic combined consensus features (selected by 2+ methods):\n")
    for (feature in consensus_ladies) {
      count <- feature_counts_ladies[feature]
      methods <- c(
        if (feature %in% lasso_selected_ladies) "LASSO" else NULL,
        if (feature %in% boruta_selected_ladies) "Boruta" else NULL,
        if (feature %in% leaps_selected_ladies) "Exhaustive" else NULL
      )
      cat(sprintf("  %s (%d methods: %s)\n", feature, count, paste(methods, collapse = ", ")))
    }
  } else {
    cat("No nordic combined consensus features - using union of all methods\n")
    consensus_ladies <- unique(all_selected_ladies)
  }
} else {
  cat("No features selected by any method - using top correlated features\n")
  if (!is.null(cor_matrix_ladies) && "Pct_of_Max_Points" %in% names(train_ladies)) {
    target_cors <- cor(train_ladies[all_features_ladies], train_ladies$Pct_of_Max_Points, use = "complete.obs")
    consensus_ladies <- names(sort(abs(target_cors), decreasing = TRUE))[1:min(3, length(all_features_ladies))]
  } else {
    consensus_ladies <- all_features_ladies[1:min(3, length(all_features_ladies))]
  }
}

final_features_ladies <- consensus_ladies
cat(sprintf("Final nordic combined features for ladies: %s\n", paste(final_features_ladies, collapse = ", ")))

cat("\n=== NORDIC COMBINED FEATURE SELECTION SUMMARY ===\n")
cat(sprintf("Men's final nordic combined features (%d): %s\n", length(final_features_men), paste(final_features_men, collapse = ", ")))
cat(sprintf("Ladies final nordic combined features (%d): %s\n", length(final_features_ladies), paste(final_features_ladies, collapse = ", ")))

# Store feature selection results for later use
feature_selection_results_men <- list(
  lasso = lasso_selected_men,
  boruta = boruta_selected_men,
  exhaustive = leaps_selected_men,
  final = final_features_men
)

feature_selection_results_ladies <- list(
  lasso = lasso_selected_ladies,
  boruta = boruta_selected_ladies,
  exhaustive = leaps_selected_ladies,
  final = final_features_ladies
)

cat("\n=== COMPREHENSIVE NORDIC COMBINED FEATURE SELECTION COMPLETE ===\n")
```

```{r gam-model}
cat("=== NORDIC COMBINED GAM MODEL BUILDING & VALIDATION ===\n")

# Generalized Additive Model (GAM) building with comprehensive validation
# Adapted for nordic combined disciplines and ELO ratings

cat("\n--- Nordic Combined GAM Model Input Validation ---\n")

# Validate feature selection results
if (!exists("final_features_men") || length(final_features_men) == 0) {
  warning("No features selected for men's nordic combined model - using fallback features")
  final_features_men <- c("Prev_Pelo", "Prev_Pct_of_Max_Points", "Age")
}

if (!exists("final_features_ladies") || length(final_features_ladies) == 0) {
  warning("No features selected for ladies nordic combined model - using fallback features")
  final_features_ladies <- c("Prev_Pelo", "Prev_Pct_of_Max_Points", "Age")
}

cat(sprintf("Men's nordic combined GAM features: %s\n", paste(final_features_men, collapse = ", ")))
cat(sprintf("Ladies nordic combined GAM features: %s\n", paste(final_features_ladies, collapse = ", ")))

# Validate training data availability
if (!exists("train_men") || nrow(train_men) == 0) {
  stop("Men's nordic combined training data not available for GAM modeling")
}
if (!exists("train_ladies") || nrow(train_ladies) == 0) {
  stop("Ladies nordic combined training data not available for GAM modeling")
}

cat(sprintf("Nordic combined training data available: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Ensure selected features exist in training data
men_available_gam_features <- intersect(final_features_men, names(train_men))
ladies_available_gam_features <- intersect(final_features_ladies, names(train_ladies))

if (length(men_available_gam_features) < length(final_features_men)) {
  missing_men <- setdiff(final_features_men, men_available_gam_features)
  warning(sprintf("Men's nordic combined GAM missing features: %s", paste(missing_men, collapse = ", ")))
}

if (length(ladies_available_gam_features) < length(final_features_ladies)) {
  missing_ladies <- setdiff(final_features_ladies, ladies_available_gam_features)
  warning(sprintf("Ladies nordic combined GAM missing features: %s", paste(missing_ladies, collapse = ", ")))
}

# Use available features for GAM
final_features_men <- men_available_gam_features
final_features_ladies <- ladies_available_gam_features

# Ensure minimum features for GAM
if (length(final_features_men) < 2) {
  warning("Insufficient features for men's nordic combined GAM - adding core nordic combined features")
  core_nordic_combined_features <- c("Prev_Pelo", "Prev_Pct_of_Max_Points", "Age")
  available_core <- intersect(core_nordic_combined_features, names(train_men))
  final_features_men <- unique(c(final_features_men, available_core))[1:min(3, length(names(train_men)))]
}

if (length(final_features_ladies) < 2) {
  warning("Insufficient features for ladies nordic combined GAM - adding core nordic combined features")
  core_nordic_combined_features <- c("Prev_Pelo", "Prev_Pct_of_Max_Points", "Age")
  available_core <- intersect(core_nordic_combined_features, names(train_ladies))
  final_features_ladies <- unique(c(final_features_ladies, available_core))[1:min(3, length(names(train_ladies)))]
}

cat(sprintf("Final nordic combined GAM features: Men (%d) %s, Ladies (%d) %s\n", 
            length(final_features_men), paste(final_features_men, collapse = ", "),
            length(final_features_ladies), paste(final_features_ladies, collapse = ", ")))

cat("\n=== BUILDING MEN'S NORDIC COMBINED GAM MODEL ===\n")

# Build Men's Nordic Combined GAM Model with comprehensive error handling
tryCatch({
  # Create GAM formula with smooth terms for nordic combined features
  gam_formula_men <- as.formula(paste("Pct_of_Max_Points ~ ", 
                                     paste(paste0("s(", final_features_men, ")"), collapse = " + ")))
  
  cat("Men's nordic combined GAM formula:", deparse(gam_formula_men), "\n")
  
  # Validate data for GAM fitting
  gam_data_men <- train_men[c("Pct_of_Max_Points", final_features_men)]
  
  # Check for missing values
  na_counts_men <- sapply(gam_data_men, function(x) sum(is.na(x)))
  if (any(na_counts_men > 0)) {
    cat("Men's nordic combined GAM data NA counts:\n")
    print(na_counts_men[na_counts_men > 0])
    warning("Missing values in men's nordic combined GAM data")
  }
  
  # Check for insufficient variation
  for (feature in final_features_men) {
    if (feature %in% names(gam_data_men)) {
      unique_vals <- length(unique(gam_data_men[[feature]]))
      if (unique_vals < 5) {
        warning(sprintf("Men's nordic combined feature '%s' has only %d unique values - may cause GAM issues", feature, unique_vals))
      }
    }
  }
  
  # Fit GAM model
  set.seed(42)
  gam_men <- gam(gam_formula_men, data = gam_data_men, family = gaussian())
  
  cat("✓ Men's nordic combined GAM model fitted successfully\n")
  
}, error = function(e) {
  cat("Error fitting men's nordic combined GAM model:", e$message, "\n")
  
  # Fallback to simpler model
  cat("Attempting fallback men's nordic combined GAM model...\n")
  tryCatch({
    fallback_features <- intersect(c("Prev_Pelo", "Age"), names(train_men))
    if (length(fallback_features) >= 1) {
      fallback_formula <- as.formula(paste("Pct_of_Max_Points ~ ", 
                                          paste(paste0("s(", fallback_features, ")"), collapse = " + ")))
      gam_men <- gam(fallback_formula, data = train_men, family = gaussian())
      final_features_men <- fallback_features
      cat("✓ Men's nordic combined fallback GAM model fitted\n")
    } else {
      stop("No suitable features for men's nordic combined GAM model")
    }
  }, error = function(e2) {
    stop("Failed to fit men's nordic combined GAM model: ", e2$message)
  })
})

cat("\n=== BUILDING LADIES' NORDIC COMBINED GAM MODEL ===\n")

# Build Ladies Nordic Combined GAM Model with comprehensive error handling
tryCatch({
  # Create GAM formula with smooth terms for nordic combined features
  gam_formula_ladies <- as.formula(paste("Pct_of_Max_Points ~ ", 
                                        paste(paste0("s(", final_features_ladies, ")"), collapse = " + ")))
  
  cat("Ladies nordic combined GAM formula:", deparse(gam_formula_ladies), "\n")
  
  # Validate data for GAM fitting
  gam_data_ladies <- train_ladies[c("Pct_of_Max_Points", final_features_ladies)]
  
  # Check for missing values
  na_counts_ladies <- sapply(gam_data_ladies, function(x) sum(is.na(x)))
  if (any(na_counts_ladies > 0)) {
    cat("Ladies nordic combined GAM data NA counts:\n")
    print(na_counts_ladies[na_counts_ladies > 0])
    warning("Missing values in ladies nordic combined GAM data")
  }
  
  # Check for insufficient variation
  for (feature in final_features_ladies) {
    if (feature %in% names(gam_data_ladies)) {
      unique_vals <- length(unique(gam_data_ladies[[feature]]))
      if (unique_vals < 5) {
        warning(sprintf("Ladies nordic combined feature '%s' has only %d unique values - may cause GAM issues", feature, unique_vals))
      }
    }
  }
  
  # Fit GAM model
  set.seed(42)
  gam_ladies <- gam(gam_formula_ladies, data = gam_data_ladies, family = gaussian())
  
  cat("✓ Ladies nordic combined GAM model fitted successfully\n")
  
}, error = function(e) {
  cat("Error fitting ladies nordic combined GAM model:", e$message, "\n")
  
  # Fallback to simpler model
  cat("Attempting fallback ladies nordic combined GAM model...\n")
  tryCatch({
    fallback_features <- intersect(c("Prev_Pelo", "Age"), names(train_ladies))
    if (length(fallback_features) >= 1) {
      fallback_formula <- as.formula(paste("Pct_of_Max_Points ~ ", 
                                          paste(paste0("s(", fallback_features, ")"), collapse = " + ")))
      gam_ladies <- gam(fallback_formula, data = train_ladies, family = gaussian())
      final_features_ladies <- fallback_features
      cat("✓ Ladies nordic combined fallback GAM model fitted\n")
    } else {
      stop("No suitable features for ladies nordic combined GAM model")
    }
  }, error = function(e2) {
    stop("Failed to fit ladies nordic combined GAM model: ", e2$message)
  })
})

cat("\n=== NORDIC COMBINED GAM MODEL PERFORMANCE EVALUATION ===\n")

# Evaluate Men's Nordic Combined GAM Model Performance
cat("--- Men's Nordic Combined GAM Performance ---\n")
tryCatch({
  men_summary <- summary(gam_men)
  men_deviance_explained <- men_summary$dev.expl * 100
  men_r_squared <- men_summary$r.sq
  men_gcv_score <- men_summary$sp.criterion
  
  cat(sprintf("Deviance explained: %.2f%%\n", men_deviance_explained))
  cat(sprintf("R-squared: %.4f\n", men_r_squared))
  cat(sprintf("GCV score: %.4f\n", men_gcv_score))
  
  # Check model convergence
  if (gam_men$converged) {
    cat("✓ Model converged successfully\n")
  } else {
    warning("Men's nordic combined GAM model did not converge")
  }
  
  # Validate performance thresholds
  if (men_deviance_explained < 10) {
    warning("Men's nordic combined GAM model explains very little deviance (<10%)")
  } else if (men_deviance_explained > 90) {
    warning("Men's nordic combined GAM model may be overfitting (>90% deviance explained)")
  }
  
}, error = function(e) {
  cat("Error evaluating men's nordic combined GAM performance:", e$message, "\n")
  men_deviance_explained <- NA
  men_r_squared <- NA
  men_gcv_score <- NA
})

# Evaluate Ladies Nordic Combined GAM Model Performance
cat("\n--- Ladies Nordic Combined GAM Performance ---\n")
tryCatch({
  ladies_summary <- summary(gam_ladies)
  ladies_deviance_explained <- ladies_summary$dev.expl * 100
  ladies_r_squared <- ladies_summary$r.sq
  ladies_gcv_score <- ladies_summary$sp.criterion
  
  cat(sprintf("Deviance explained: %.2f%%\n", ladies_deviance_explained))
  cat(sprintf("R-squared: %.4f\n", ladies_r_squared))
  cat(sprintf("GCV score: %.4f\n", ladies_gcv_score))
  
  # Check model convergence
  if (gam_ladies$converged) {
    cat("✓ Model converged successfully\n")
  } else {
    warning("Ladies nordic combined GAM model did not converge")
  }
  
  # Validate performance thresholds
  if (ladies_deviance_explained < 10) {
    warning("Ladies nordic combined GAM model explains very little deviance (<10%)")
  } else if (ladies_deviance_explained > 90) {
    warning("Ladies nordic combined GAM model may be overfitting (>90% deviance explained)")
  }
  
}, error = function(e) {
  cat("Error evaluating ladies nordic combined GAM performance:", e$message, "\n")
  ladies_deviance_explained <- NA
  ladies_r_squared <- NA
  ladies_gcv_score <- NA
})

cat("\n=== NORDIC COMBINED GAM FEATURE IMPORTANCE ANALYSIS ===\n")

# Analyze Men's Nordic Combined GAM Feature Importance
cat("--- Men's Nordic Combined GAM Feature Importance ---\n")
tryCatch({
  men_summary <- summary(gam_men)
  
  if (!is.null(men_summary$s.table)) {
    men_edf <- men_summary$s.table[, "edf"]
    men_pvals <- men_summary$s.table[, "p-value"]
    
    cat("Feature importance (Effective Degrees of Freedom):\n")
    for (i in 1:length(men_edf)) {
      feature_name <- gsub("s\\((.+)\\)", "\\1", rownames(men_summary$s.table)[i])
      edf_val <- men_edf[i]
      p_val <- men_pvals[i]
      significance <- if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
      
      cat(sprintf("  %s: EDF=%.2f, p=%.4f %s\n", feature_name, edf_val, p_val, significance))
      
      # Identify non-linear relationships
      if (edf_val > 3) {
        cat(sprintf("    → Strong non-linear relationship detected\n"))
      }
    }
  } else {
    cat("No smooth terms in men's nordic combined GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing men's nordic combined GAM feature importance:", e$message, "\n")
})

# Analyze Ladies Nordic Combined GAM Feature Importance
cat("\n--- Ladies Nordic Combined GAM Feature Importance ---\n")
tryCatch({
  ladies_summary <- summary(gam_ladies)
  
  if (!is.null(ladies_summary$s.table)) {
    ladies_edf <- ladies_summary$s.table[, "edf"]
    ladies_pvals <- ladies_summary$s.table[, "p-value"]
    
    cat("Feature importance (Effective Degrees of Freedom):\n")
    for (i in 1:length(ladies_edf)) {
      feature_name <- gsub("s\\((.+)\\)", "\\1", rownames(ladies_summary$s.table)[i])
      edf_val <- ladies_edf[i]
      p_val <- ladies_pvals[i]
      significance <- if (p_val < 0.001) "***" else if (p_val < 0.01) "**" else if (p_val < 0.05) "*" else ""
      
      cat(sprintf("  %s: EDF=%.2f, p=%.4f %s\n", feature_name, edf_val, p_val, significance))
      
      # Identify non-linear relationships
      if (edf_val > 3) {
        cat(sprintf("    → Strong non-linear relationship detected\n"))
      }
    }
  } else {
    cat("No smooth terms in ladies nordic combined GAM model\n")
  }
}, error = function(e) {
  cat("Error analyzing ladies nordic combined GAM feature importance:", e$message, "\n")
})

cat("\n=== NORDIC COMBINED GAM MODEL DIAGNOSTICS ===\n")

# Generate Nordic Combined GAM Diagnostic Plots
cat("--- Nordic Combined GAM Diagnostic Plots ---\n")
tryCatch({
  cat("Generating men's nordic combined GAM diagnostic plots...\n")
  # Note: In a full implementation, diagnostic plots would be generated here
  # par(mfrow = c(2, 2))
  # gam.check(gam_men)
  cat("✓ Men's nordic combined GAM diagnostics available\n")
  
  cat("Generating ladies nordic combined GAM diagnostic plots...\n")
  # Note: In a full implementation, diagnostic plots would be generated here
  # par(mfrow = c(2, 2))
  # gam.check(gam_ladies)
  cat("✓ Ladies nordic combined GAM diagnostics available\n")
  
}, error = function(e) {
  cat("Error generating nordic combined GAM diagnostic plots:", e$message, "\n")
})

# Check Basis Dimensions
cat("\n--- Nordic Combined GAM Basis Dimension Validation ---\n")
tryCatch({
  cat("Men's nordic combined GAM basis dimension check:\n")
  men_k_check <- k.check(gam_men)
  print(men_k_check)
  
  cat("\nLadies nordic combined GAM basis dimension check:\n")
  ladies_k_check <- k.check(gam_ladies)
  print(ladies_k_check)
  
}, error = function(e) {
  cat("Error checking nordic combined GAM basis dimensions:", e$message, "\n")
})

cat("\n=== 2026 NORDIC COMBINED SEASON PREDICTIONS ===\n")

# Prepare 2026 Nordic Combined Prediction Data
cat("--- Preparing 2026 Nordic Combined Prediction Data ---\n")

# Get 2025 ELO data for 2026 predictions (most recent available)
tryCatch({
  # Filter for latest available data (2025) for predictions
  pred_men_2025 <- M_elo %>% 
    filter(Season == 2025) %>%
    group_by(Skier) %>%
    slice_tail(n = 1) %>%  # Get most recent record per skier
    ungroup()
  
  pred_ladies_2025 <- L_elo %>% 
    filter(Season == 2025) %>%
    group_by(Skier) %>%
    slice_tail(n = 1) %>%  # Get most recent record per skier
    ungroup()
  
  cat(sprintf("2025 nordic combined prediction base data: Men %d skiers, Ladies %d skiers\n", 
              nrow(pred_men_2025), nrow(pred_ladies_2025)))
  
  # Validate prediction data has required features
  men_pred_features_available <- intersect(final_features_men, names(pred_men_2025))
  ladies_pred_features_available <- intersect(final_features_ladies, names(pred_ladies_2025))
  
  if (length(men_pred_features_available) < length(final_features_men)) {
    missing_pred_men <- setdiff(final_features_men, men_pred_features_available)
    warning(sprintf("Men's 2026 nordic combined prediction missing features: %s", paste(missing_pred_men, collapse = ", ")))
  }
  
  if (length(ladies_pred_features_available) < length(final_features_ladies)) {
    missing_pred_ladies <- setdiff(final_features_ladies, ladies_pred_features_available)
    warning(sprintf("Ladies 2026 nordic combined prediction missing features: %s", paste(missing_pred_ladies, collapse = ", ")))
  }
  
}, error = function(e) {
  cat("Error preparing 2026 nordic combined prediction data:", e$message, "\n")
  pred_men_2025 <- data.frame()
  pred_ladies_2025 <- data.frame()
})

# Apply quartile replacement to handle missing values in 2025 nordic combined prediction data
cat("Applying quartile replacement for missing values in 2025 nordic combined prediction data...\n")

if (nrow(pred_men_2025) > 0) {
  pred_men_2025 <- pred_men_2025 %>%
    group_by(Season) %>%
    mutate(
      Pelo = replace_na_with_quartile(Pelo, "Pelo"),
      Individual_Pelo = replace_na_with_quartile(Individual_Pelo, "Individual_Pelo"),
      IndividualCompact_Pelo = replace_na_with_quartile(IndividualCompact_Pelo, "IndividualCompact_Pelo"),
      MassStart_Pelo = replace_na_with_quartile(MassStart_Pelo, "MassStart_Pelo"),
      Pct_of_Max_Points = replace_na_with_quartile(Pct_of_Max_Points, "Pct_of_Max_Points")
    ) %>%
    ungroup()
  cat("✓ Men's nordic combined prediction data NA replacement completed\n")
}

if (nrow(pred_ladies_2025) > 0) {
  pred_ladies_2025 <- pred_ladies_2025 %>%
    group_by(Season) %>%
    mutate(
      Pelo = replace_na_with_quartile(Pelo, "Pelo"),
      Individual_Pelo = replace_na_with_quartile(Individual_Pelo, "Individual_Pelo"),
      IndividualCompact_Pelo = replace_na_with_quartile(IndividualCompact_Pelo, "IndividualCompact_Pelo"),
      MassStart_Pelo = replace_na_with_quartile(MassStart_Pelo, "MassStart_Pelo"),
      Pct_of_Max_Points = replace_na_with_quartile(Pct_of_Max_Points, "Pct_of_Max_Points")
    ) %>%
    ungroup()
  cat("✓ Ladies nordic combined prediction data NA replacement completed\n")
}

# Generate 2026 Nordic Combined Predictions for Men
cat("\n--- Men's 2026 Nordic Combined Predictions ---\n")
tryCatch({
  if (nrow(pred_men_2025) > 0 && exists("gam_men")) {
    # Store full prediction dataset for statistical-odds section
    men_pred_data <- pred_men_2025
    
    # Extract features for GAM prediction
    men_pred_features_data <- pred_men_2025[men_pred_features_available]
    
    # Check for missing values in prediction features
    pred_na_counts <- sapply(men_pred_features_data, function(x) sum(is.na(x)))
    if (any(pred_na_counts > 0)) {
      cat("Men's nordic combined prediction features NA counts:\n")
      print(pred_na_counts[pred_na_counts > 0])
      warning("Missing values in men's nordic combined prediction features")
    }
    
    # Debug: Show input data for Jens Lurås Oftebro
    if ("Jens Lurås Oftebro" %in% pred_men_2025$Skier) {
      oftebro_idx <- which(pred_men_2025$Skier == "Jens Lurås Oftebro")
      cat("\n=== DEBUG: Jens Lurås Oftebro Input Data ===\n")
      cat("Full 2025 data:\n")
      print(pred_men_2025[oftebro_idx, c("Skier", "Pelo", "Individual_Pelo", "IndividualCompact_Pelo", "MassStart_Pelo", "Pct_of_Max_Points")])
      cat("GAM model features used:\n")
      print(men_pred_features_data[oftebro_idx, ])
      cat("Available features:", paste(names(men_pred_features_data), collapse = ", "), "\n")
    }
    
    men_predictions <- predict(gam_men, newdata = men_pred_features_data, se.fit = TRUE)
    
    # Create prediction dataframe matching structure
    men_pred_data_full <- pred_men_2025 %>%
      mutate(
        Predicted_Pct_2026 = men_predictions$fit,
        Lower_CI = men_predictions$fit - 1.96 * men_predictions$se.fit,
        Upper_CI = men_predictions$fit + 1.96 * men_predictions$se.fit
      )
    
    # Create Excel-ready dataframe
    men_pred_results <- men_pred_data_full %>%
      dplyr::select(Skier, Nation, Predicted_Pct_2026, 
                    Pelo, Individual_Pelo, IndividualCompact_Pelo, MassStart_Pelo, Pct_of_Max_Points) %>%
      mutate(
        `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2),
        `Current Overall ELO` = round(Pelo, 0),
        `Current Individual ELO` = round(Individual_Pelo, 0),
        `Current IndividualCompact ELO` = round(IndividualCompact_Pelo, 0),
        `Current Mass Start ELO` = round(MassStart_Pelo, 0),
        `2025 Pct of Max Points` = round(Pct_of_Max_Points * 100, 2)
      ) %>%
      dplyr::select(Skier, Nation, `Predicted Percent 2026`,
                    `Current Overall ELO`, `Current Individual ELO`, `Current IndividualCompact ELO`, 
                    `Current Mass Start ELO`, `2025 Pct of Max Points`) %>%
      arrange(desc(`Predicted Percent 2026`))
    
    cat(sprintf("✓ Generated predictions for %d men's nordic combined athletes\n", nrow(men_pred_results)))
    cat("Top 5 men's nordic combined predictions:\n")
    print(head(men_pred_results[c("Skier", "Predicted Percent 2026")], 5))
    
  } else {
    cat("No data available for men's 2026 nordic combined predictions\n")
    men_pred_results <- data.frame()
  }
}, error = function(e) {
  cat("Error generating men's 2026 nordic combined predictions:", e$message, "\n")
  men_pred_results <- data.frame()
})

# Generate 2026 Nordic Combined Predictions for Ladies
cat("\n--- Ladies 2026 Nordic Combined Predictions ---\n")
tryCatch({
  if (nrow(pred_ladies_2025) > 0 && exists("gam_ladies")) {
    # Store full prediction dataset for statistical-odds section
    ladies_pred_data <- pred_ladies_2025
    
    # Extract features for GAM prediction
    ladies_pred_features_data <- pred_ladies_2025[ladies_pred_features_available]
    
    # Check for missing values in prediction features
    pred_na_counts <- sapply(ladies_pred_features_data, function(x) sum(is.na(x)))
    if (any(pred_na_counts > 0)) {
      cat("Ladies nordic combined prediction features NA counts:\n")
      print(pred_na_counts[pred_na_counts > 0])
      warning("Missing values in ladies nordic combined prediction features")
    }
    
    # Debug: Show input data for Ida Marie Hagen
    if ("Ida Marie Hagen" %in% pred_ladies_2025$Skier) {
      hagen_idx <- which(pred_ladies_2025$Skier == "Ida Marie Hagen")
      cat("\n=== DEBUG: Ida Marie Hagen Input Data ===\n")
      cat("Full 2025 data:\n")
      print(pred_ladies_2025[hagen_idx, c("Skier", "Pelo", "Individual_Pelo", "IndividualCompact_Pelo", "MassStart_Pelo", "Pct_of_Max_Points")])
      cat("GAM model features used:\n")
      print(ladies_pred_features_data[hagen_idx, ])
      cat("Available features:", paste(names(ladies_pred_features_data), collapse = ", "), "\n")
    }
    
    ladies_predictions <- predict(gam_ladies, newdata = ladies_pred_features_data, se.fit = TRUE)
    
    # Create prediction dataframe matching structure
    ladies_pred_data_full <- pred_ladies_2025 %>%
      mutate(
        Predicted_Pct_2026 = ladies_predictions$fit,
        Lower_CI = ladies_predictions$fit - 1.96 * ladies_predictions$se.fit,
        Upper_CI = ladies_predictions$fit + 1.96 * ladies_predictions$se.fit
      )
    
    # Create Excel-ready dataframe
    ladies_pred_results <- ladies_pred_data_full %>%
      dplyr::select(Skier, Nation, Predicted_Pct_2026, 
                    Pelo, Individual_Pelo, IndividualCompact_Pelo, MassStart_Pelo, Pct_of_Max_Points) %>%
      mutate(
        `Predicted Percent 2026` = round(Predicted_Pct_2026 * 100, 2),
        `Current Overall ELO` = round(Pelo, 0),
        `Current Individual ELO` = round(Individual_Pelo, 0),
        `Current IndividualCompact ELO` = round(IndividualCompact_Pelo, 0),
        `Current Mass Start ELO` = round(MassStart_Pelo, 0),
        `2025 Pct of Max Points` = round(Pct_of_Max_Points * 100, 2)
      ) %>%
      dplyr::select(Skier, Nation, `Predicted Percent 2026`,
                    `Current Overall ELO`, `Current Individual ELO`, `Current IndividualCompact ELO`, 
                    `Current Mass Start ELO`, `2025 Pct of Max Points`) %>%
      arrange(desc(`Predicted Percent 2026`))
    
    cat(sprintf("✓ Generated predictions for %d ladies nordic combined athletes\n", nrow(ladies_pred_results)))
    cat("Top 5 ladies nordic combined predictions:\n")
    print(head(ladies_pred_results[c("Skier", "Predicted Percent 2026")], 5))
    
  } else {
    cat("No data available for ladies 2026 nordic combined predictions\n")
    ladies_pred_results <- data.frame()
  }
}, error = function(e) {
  cat("Error generating ladies 2026 nordic combined predictions:", e$message, "\n")
  ladies_pred_results <- data.frame()
})

cat("\n=== NORDIC COMBINED PREDICTIONS EXPORT ===\n")

# Export Nordic Combined Predictions to Excel
cat("--- Exporting 2026 Nordic Combined Predictions to Excel ---\n")
tryCatch({
  # Create excel365 directory if it doesn't exist
  if (!dir.exists("excel365")) {
    dir.create("excel365", recursive = TRUE)
    cat("Created excel365 directory\n")
  }
  
  # Export Men's Nordic Combined Predictions
  if (exists("men_pred_results") && nrow(men_pred_results) > 0) {
    men_wb <- createWorkbook()
    addWorksheet(men_wb, "Men_NordicCombined_2026")
    writeData(men_wb, "Men_NordicCombined_2026", men_pred_results)
    
    # Format the sheet
    headerStyle <- createStyle(textDecoration = "bold", fgFill = "#4F81BD", fontColour = "white")
    addStyle(men_wb, "Men_NordicCombined_2026", headerStyle, rows = 1, cols = 1:ncol(men_pred_results))
    
    # Save men's workbook
    men_output_file <- "excel365/Men_WorldCup_Predictions_2026.xlsx"
    saveWorkbook(men_wb, men_output_file, overwrite = TRUE)
    
    cat(sprintf("✓ Men's nordic combined predictions exported to: %s\n", men_output_file))
  }
  
  # Export Ladies Nordic Combined Predictions
  if (exists("ladies_pred_results") && nrow(ladies_pred_results) > 0) {
    ladies_wb <- createWorkbook()
    addWorksheet(ladies_wb, "Ladies_NordicCombined_2026")
    writeData(ladies_wb, "Ladies_NordicCombined_2026", ladies_pred_results)
    
    # Format the sheet
    headerStyle <- createStyle(textDecoration = "bold", fgFill = "#4F81BD", fontColour = "white")
    addStyle(ladies_wb, "Ladies_NordicCombined_2026", headerStyle, rows = 1, cols = 1:ncol(ladies_pred_results))
    
    # Save ladies workbook
    ladies_output_file <- "excel365/Ladies_WorldCup_Predictions_2026.xlsx"
    saveWorkbook(ladies_wb, ladies_output_file, overwrite = TRUE)
    
    cat(sprintf("✓ Ladies nordic combined predictions exported to: %s\n", ladies_output_file))
  }
  
}, error = function(e) {
  cat("Error exporting nordic combined predictions to Excel:", e$message, "\n")
})

cat("\n=== NORDIC COMBINED GAM MODEL ANALYSIS COMPLETE ===\n")
cat("Summary:\n")
if (exists("men_deviance_explained") && !is.na(men_deviance_explained)) {
  cat(sprintf("- Men's nordic combined model explains %.2f%% of deviance\n", men_deviance_explained))
}
if (exists("ladies_deviance_explained") && !is.na(ladies_deviance_explained)) {
  cat(sprintf("- Ladies nordic combined model explains %.2f%% of deviance\n", ladies_deviance_explained))
}
if (exists("men_pred_results")) {
  cat(sprintf("- Generated %d men's nordic combined predictions\n", nrow(men_pred_results)))
}
if (exists("ladies_pred_results")) {
  cat(sprintf("- Generated %d ladies nordic combined predictions\n", nrow(ladies_pred_results)))
}
```

### Odds Setup

```{r odds-setup}
cat("=== NORDIC COMBINED ODDS SETUP & VALIDATION ===\n")

# Validate training data availability for odds calculations
cat("\n--- Training Data Validation for Odds ---\n")

if (!exists("train_men") || !exists("train_ladies")) {
  stop("Training data not available - ensure previous sections completed successfully")
}

if (nrow(train_men) == 0) {
  stop("Men's training data is empty")
}
if (nrow(train_ladies) == 0) {
  stop("Ladies training data is empty") 
}

cat(sprintf("Training data for nordic combined odds: Men %d rows, Ladies %d rows\n", nrow(train_men), nrow(train_ladies)))

# Validate required columns exist
required_odds_cols <- c("Pct_of_Max_Points", "Season")
missing_men_cols <- setdiff(required_odds_cols, names(train_men))
missing_ladies_cols <- setdiff(required_odds_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop(sprintf("Men's training data missing required columns for nordic combined odds: %s", paste(missing_men_cols, collapse = ", ")))
}
if (length(missing_ladies_cols) > 0) {
  stop(sprintf("Ladies training data missing required columns for nordic combined odds: %s", paste(missing_ladies_cols, collapse = ", ")))
}

# Add Place column based on rankings within each season with validation
cat("\n--- Season Ranking Calculation ---\n")

tryCatch({
  df_place <- train_men %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
  
  cat(sprintf("✓ Men's place rankings calculated: %d rows\n", nrow(df_place)))
}, error = function(e) {
  stop("Failed to calculate men's place rankings: ", e$message)
})

tryCatch({
  df_place_ladies <- train_ladies %>%
    group_by(Season) %>%
    mutate(Place = rank(-Pct_of_Max_Points, ties.method = "min")) %>%
    ungroup()
    
  cat(sprintf("✓ Ladies place rankings calculated: %d rows\n", nrow(df_place_ladies)))
}, error = function(e) {
  stop("Failed to calculate ladies place rankings: ", e$message)
})

# Validate Place column creation
place_na_men <- sum(is.na(df_place$Place))
place_na_ladies <- sum(is.na(df_place_ladies$Place))

if (place_na_men > 0) {
  warning(sprintf("Men's Place column has %d NA values", place_na_men))
}
if (place_na_ladies > 0) {
  warning(sprintf("Ladies Place column has %d NA values", place_na_ladies))
}

# Check Place column ranges
men_place_range <- range(df_place$Place, na.rm = TRUE)
ladies_place_range <- range(df_place_ladies$Place, na.rm = TRUE)

cat(sprintf("Men's place range: %d - %d\n", men_place_range[1], men_place_range[2]))
cat(sprintf("Ladies place range: %d - %d\n", ladies_place_range[1], ladies_place_range[2]))

# Validate place rankings within seasons
cat("\n--- Place Ranking Validation ---\n")

# Check that rankings are consistent within seasons
men_season_check <- df_place %>%
  group_by(Season) %>%
  summarise(
    Min_Place = min(Place, na.rm = TRUE),
    Max_Place = max(Place, na.rm = TRUE),
    Unique_Places = length(unique(Place)),
    Total_Athletes = n(),
    .groups = 'drop'
  )

ladies_season_check <- df_place_ladies %>%
  group_by(Season) %>%
  summarise(
    Min_Place = min(Place, na.rm = TRUE),
    Max_Place = max(Place, na.rm = TRUE),
    Unique_Places = length(unique(Place)),
    Total_Athletes = n(),
    .groups = 'drop'
  )

# Check if minimum place is always 1
men_bad_seasons <- men_season_check %>% filter(Min_Place != 1)
ladies_bad_seasons <- ladies_season_check %>% filter(Min_Place != 1)

if (nrow(men_bad_seasons) > 0) {
  warning("Men's nordic combined seasons with minimum place != 1:")
  print(men_bad_seasons)
}
if (nrow(ladies_bad_seasons) > 0) {
  warning("Ladies nordic combined seasons with minimum place != 1:")
  print(ladies_bad_seasons)
}

cat(sprintf("Men's nordic combined season validation: %d seasons checked\n", nrow(men_season_check)))
cat(sprintf("Ladies nordic combined season validation: %d seasons checked\n", nrow(ladies_season_check)))

# Define nordic combined position thresholds for odds calculations
cat("\n--- Nordic Combined Position Threshold Definition ---\n")

# Nordic combined specific position thresholds based on typical field sizes
# Adjusted for nordic combined competition structure
position_thresholds <- c(1, 3, 5, 10, 15, 20, 30)  # Top positions that matter in nordic combined

cat("Nordic combined position thresholds for odds calculation:\n")
for (threshold in position_thresholds) {
  cat(sprintf("  Top %d\n", threshold))
}

# Create position indicator columns for men's nordic combined data
cat("\n--- Creating Men's Nordic Combined Position Indicators ---\n")

tryCatch({
  for (threshold in position_thresholds) {
    col_name <- paste0("Top", threshold)
    df_place[[col_name]] <- as.integer(df_place$Place <= threshold)
  }
  
  cat("✓ Men's nordic combined position indicators created:\n")
  for (threshold in position_thresholds) {
    col_name <- paste0("Top", threshold)
    count <- sum(df_place[[col_name]], na.rm = TRUE)
    pct <- round(100 * count / nrow(df_place), 2)
    cat(sprintf("  %s: %d cases (%.2f%%)\n", col_name, count, pct))
  }
}, error = function(e) {
  stop("Failed to create men's nordic combined position indicators: ", e$message)
})

# Create position indicator columns for ladies nordic combined data
cat("\n--- Creating Ladies Nordic Combined Position Indicators ---\n")

tryCatch({
  for (threshold in position_thresholds) {
    col_name <- paste0("Top", threshold)
    df_place_ladies[[col_name]] <- as.integer(df_place_ladies$Place <= threshold)
  }
  
  cat("✓ Ladies nordic combined position indicators created:\n")
  for (threshold in position_thresholds) {
    col_name <- paste0("Top", threshold)
    count <- sum(df_place_ladies[[col_name]], na.rm = TRUE)
    pct <- round(100 * count / nrow(df_place_ladies), 2)
    cat(sprintf("  %s: %d cases (%.2f%%)\n", col_name, count, pct))
  }
}, error = function(e) {
  stop("Failed to create ladies nordic combined position indicators: ", e$message)
})

# Validate position indicators
cat("\n--- Position Indicator Validation ---\n")

# Check that higher thresholds always have more cases than lower thresholds
for (i in 1:(length(position_thresholds) - 1)) {
  current_threshold <- position_thresholds[i]
  next_threshold <- position_thresholds[i + 1]
  
  current_col <- paste0("Top", current_threshold)
  next_col <- paste0("Top", next_threshold)
  
  # Men's validation
  men_current_count <- sum(df_place[[current_col]], na.rm = TRUE)
  men_next_count <- sum(df_place[[next_col]], na.rm = TRUE)
  
  if (men_current_count > men_next_count) {
    warning(sprintf("Men's nordic combined: %s (%d) has more cases than %s (%d)", 
                    current_col, men_current_count, next_col, men_next_count))
  }
  
  # Ladies validation
  ladies_current_count <- sum(df_place_ladies[[current_col]], na.rm = TRUE)
  ladies_next_count <- sum(df_place_ladies[[next_col]], na.rm = TRUE)
  
  if (ladies_current_count > ladies_next_count) {
    warning(sprintf("Ladies nordic combined: %s (%d) has more cases than %s (%d)", 
                    current_col, ladies_current_count, next_col, ladies_next_count))
  }
}

# Check for perfect predictors (thresholds that are always 0 or always 1)
cat("\n--- Perfect Predictor Check ---\n")

men_perfect_predictors <- character(0)
ladies_perfect_predictors <- character(0)

for (threshold in position_thresholds) {
  col_name <- paste0("Top", threshold)
  
  # Men's check
  men_unique_vals <- length(unique(df_place[[col_name]]))
  if (men_unique_vals == 1) {
    men_perfect_predictors <- c(men_perfect_predictors, col_name)
    cat(sprintf("WARNING: Men's %s is a perfect predictor (constant value)\n", col_name))
  }
  
  # Ladies check
  ladies_unique_vals <- length(unique(df_place_ladies[[col_name]]))
  if (ladies_unique_vals == 1) {
    ladies_perfect_predictors <- c(ladies_perfect_predictors, col_name)
    cat(sprintf("WARNING: Ladies %s is a perfect predictor (constant value)\n", col_name))
  }
}

if (length(men_perfect_predictors) == 0) {
  cat("✓ No perfect predictors found in men's nordic combined data\n")
}
if (length(ladies_perfect_predictors) == 0) {
  cat("✓ No perfect predictors found in ladies nordic combined data\n")
}

# Create feature sets for odds modeling
cat("\n--- Feature Set Creation for Odds Modeling ---\n")

# Get available ELO features for men and ladies
available_elo_features_men <- intersect(c("Prev_Pelo", "Prev_Individual", "Prev_IndividualCompact", "Prev_MassStart"), names(df_place))
available_elo_features_ladies <- intersect(c("Prev_Pelo", "Prev_Individual", "Prev_IndividualCompact", "Prev_MassStart"), names(df_place_ladies))

cat(sprintf("Available ELO features for men: %s\n", paste(available_elo_features_men, collapse = ", ")))
cat(sprintf("Available ELO features for ladies: %s\n", paste(available_elo_features_ladies, collapse = ", ")))

# Add other available features
other_features <- c("Prev_Pct_of_Max_Points", "Age")
available_other_men <- intersect(other_features, names(df_place))
available_other_ladies <- intersect(other_features, names(df_place_ladies))

cat(sprintf("Available other features for men: %s\n", paste(available_other_men, collapse = ", ")))
cat(sprintf("Available other features for ladies: %s\n", paste(available_other_ladies, collapse = ", ")))

# Combine all available features for odds modeling
odds_features_men <- c(available_elo_features_men, available_other_men)
odds_features_ladies <- c(available_elo_features_ladies, available_other_ladies)

if (length(odds_features_men) == 0) {
  stop("No features available for men's nordic combined odds modeling")
}
if (length(odds_features_ladies) == 0) {
  stop("No features available for ladies nordic combined odds modeling")
}

cat(sprintf("Final odds modeling features for men (%d): %s\n", length(odds_features_men), paste(odds_features_men, collapse = ", ")))
cat(sprintf("Final odds modeling features for ladies (%d): %s\n", length(odds_features_ladies), paste(odds_features_ladies, collapse = ", ")))

# Validate feature data quality for odds modeling
cat("\n--- Feature Data Quality for Odds Modeling ---\n")

# Check for missing values in odds features
men_odds_na_counts <- sapply(df_place[odds_features_men], function(x) sum(is.na(x)))
ladies_odds_na_counts <- sapply(df_place_ladies[odds_features_ladies], function(x) sum(is.na(x)))

if (any(men_odds_na_counts > 0)) {
  cat("Men's nordic combined odds features with NAs:\n")
  print(men_odds_na_counts[men_odds_na_counts > 0])
  warning("Missing values in men's nordic combined odds features")
}

if (any(ladies_odds_na_counts > 0)) {
  cat("Ladies nordic combined odds features with NAs:\n")
  print(ladies_odds_na_counts[ladies_odds_na_counts > 0])
  warning("Missing values in ladies nordic combined odds features")
}

# Check for infinite values in odds features
men_odds_inf_counts <- sapply(df_place[odds_features_men], function(x) sum(!is.finite(x)))
ladies_odds_inf_counts <- sapply(df_place_ladies[odds_features_ladies], function(x) sum(!is.finite(x)))

if (any(men_odds_inf_counts > 0)) {
  cat("Men's nordic combined odds features with infinite values:\n")
  print(men_odds_inf_counts[men_odds_inf_counts > 0])
  warning("Infinite values in men's nordic combined odds features")
}

if (any(ladies_odds_inf_counts > 0)) {
  cat("Ladies nordic combined odds features with infinite values:\n")
  print(ladies_odds_inf_counts[ladies_odds_inf_counts > 0])
  warning("Infinite values in ladies nordic combined odds features")
}

# Summary statistics for final odds datasets
cat("\n--- Final Odds Dataset Summary ---\n")

cat(sprintf("Men's nordic combined odds dataset: %d rows, %d features\n", nrow(df_place), length(odds_features_men)))
cat(sprintf("Ladies nordic combined odds dataset: %d rows, %d features\n", nrow(df_place_ladies), length(odds_features_ladies)))

# Show season distribution
men_season_dist <- table(df_place$Season)
ladies_season_dist <- table(df_place_ladies$Season)

cat("Men's nordic combined season distribution:\n")
print(men_season_dist)
cat("Ladies nordic combined season distribution:\n")
print(ladies_season_dist)

# Store datasets for use in statistical-odds section
cat("\n--- Storing Datasets for Statistical Odds Modeling ---\n")

# Store the processed datasets with position indicators
men_odds_data <- df_place
ladies_odds_data <- df_place_ladies

# Store feature lists
men_odds_features <- odds_features_men
ladies_odds_features <- odds_features_ladies

# Store position thresholds
odds_position_thresholds <- position_thresholds

cat("✓ Men's nordic combined odds data stored for statistical modeling\n")
cat("✓ Ladies nordic combined odds data stored for statistical modeling\n")
cat("✓ Feature lists and position thresholds stored\n")

cat("\n=== NORDIC COMBINED ODDS SETUP COMPLETE ===\n")
cat("Summary:\n")
cat(sprintf("- Men's nordic combined odds data: %d rows\n", nrow(men_odds_data)))
cat(sprintf("- Ladies nordic combined odds data: %d rows\n", nrow(ladies_odds_data)))
cat(sprintf("- Position thresholds: %s\n", paste(odds_position_thresholds, collapse = ", ")))
cat(sprintf("- Men's features: %d (%s)\n", length(men_odds_features), paste(men_odds_features, collapse = ", ")))
cat(sprintf("- Ladies features: %d (%s)\n", length(ladies_odds_features), paste(ladies_odds_features, collapse = ", ")))

# Create categorical outcomes for different cutoffs with validation
cat("\n--- Categorical Outcome Creation ---\n")

tryCatch({
  men_odds_data <- men_odds_data %>%
    mutate(
      Win = factor(ifelse(Place == 1, 1, 0)),      # Binary: 1=Winner, 0=Not Winner
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Men's categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create men's categorical outcomes: ", e$message)
})

tryCatch({
  ladies_odds_data <- ladies_odds_data %>%
    mutate(
      Win = factor(ifelse(Place == 1, 1, 0)),      # Binary: 1=Winner, 0=Not Winner
      TopThree = factor(ifelse(Place <= 3, 1, 0)),  # Binary: 1=Top3, 0=Not Top3
      Top5 = factor(ifelse(Place <= 5, 1, 0)),
      Top10 = factor(ifelse(Place <= 10, 1, 0)),
      Top30 = factor(ifelse(Place <= 30, 1, 0))
    )
  
  cat("✓ Ladies categorical outcomes created\n")
}, error = function(e) {
  stop("Failed to create ladies categorical outcomes: ", e$message)
})

# Validate categorical outcome creation
cat("\n--- Categorical Outcome Validation ---\n")

# Check TopThree creation for ladies
cat("Ladies Place vs TopThree validation:\n")
if ("TopThree" %in% names(ladies_odds_data)) {
  topthree_crosstab <- table(ladies_odds_data$Place, ladies_odds_data$TopThree, useNA = "always")
  print(topthree_crosstab[1:min(10, nrow(topthree_crosstab)), ])
}

# Validate factor levels
expected_levels <- c("0", "1")
targets <- c("TopThree", "Top5", "Top10", "Top30")

for (target in targets) {
  if (target %in% names(men_odds_data)) {
    men_levels <- levels(men_odds_data[[target]])
    
    if (!all(expected_levels %in% men_levels)) {
      warning(sprintf("Men's %s missing expected levels: %s", target, paste(setdiff(expected_levels, men_levels), collapse = ", ")))
    }
    
    # Check for class imbalance
    men_table <- table(men_odds_data[[target]])
    men_minority_pct <- min(men_table) / sum(men_table) * 100
    
    cat(sprintf("%s class balance: Men %.1f%% minority\n", target, men_minority_pct))
    
    if (men_minority_pct < 5) {
      warning(sprintf("Men's %s has severe class imbalance (<5%% minority class)", target))
    }
  }
  
  if (target %in% names(ladies_odds_data)) {
    ladies_levels <- levels(ladies_odds_data[[target]])
    
    if (!all(expected_levels %in% ladies_levels)) {
      warning(sprintf("Ladies %s missing expected levels: %s", target, paste(setdiff(expected_levels, ladies_levels), collapse = ", ")))
    }
    
    # Check for class imbalance
    ladies_table <- table(ladies_odds_data[[target]])
    ladies_minority_pct <- min(ladies_table) / sum(ladies_table) * 100
    
    cat(sprintf("%s class balance: Ladies %.1f%% minority\n", target, ladies_minority_pct))
    
    if (ladies_minority_pct < 5) {
      warning(sprintf("Ladies %s has severe class imbalance (<5%% minority class)", target))
    }
  }
}

# Sample TopThree values
cat("First 20 ladies Place and TopThree values:\n")
if ("TopThree" %in% names(ladies_odds_data)) {
  sample_topthree <- ladies_odds_data %>% 
    dplyr::select(Skier, Season, Place, TopThree) %>% 
    head(20)
  print(sample_topthree)
}

# Prepare 2025 prediction data with validation
cat("\n--- 2025 Prediction Data Preparation ---\n")

# Validate prediction data exists
cat("Debug: exists('men_pred_data'):", exists("men_pred_data"), "\n")
if (exists("men_pred_data")) {
  cat("Debug: nrow(men_pred_data):", nrow(men_pred_data), "\n")
  cat("Debug: ncol(men_pred_data):", ncol(men_pred_data), "\n")
  if (ncol(men_pred_data) > 0) {
    cat("Debug: men_pred_data columns:", paste(names(men_pred_data), collapse = ", "), "\n")
  }
}

cat("Debug: exists('ladies_pred_data'):", exists("ladies_pred_data"), "\n")
if (exists("ladies_pred_data")) {
  cat("Debug: nrow(ladies_pred_data):", nrow(ladies_pred_data), "\n")
  cat("Debug: ncol(ladies_pred_data):", ncol(ladies_pred_data), "\n")
  if (ncol(ladies_pred_data) > 0) {
    cat("Debug: ladies_pred_data columns:", paste(names(ladies_pred_data), collapse = ", "), "\n")
  }
}

if (!exists("men_pred_data") || is.null(men_pred_data)) {
  warning("Men's 2026 nordic combined prediction data not available from previous section")
  men_pred_data <- data.frame()
}
if (!exists("ladies_pred_data") || is.null(ladies_pred_data)) {
  warning("Ladies 2026 nordic combined prediction data not available from previous section") 
  ladies_pred_data <- data.frame()
}

# Men's prediction data preparation
pred_data_men <- NULL
if (nrow(men_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (nordic combined-specific)
    expected_pred_cols <- c("Skier", "City", "Pelo", "Individual_Pelo", "IndividualCompact_Pelo", 
                           "MassStart_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(men_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(men_pred_data))
    
    cat(sprintf("Men's nordic combined prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing men's nordic combined prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_men <- men_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (nordic combined-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Individual" = "Individual_Pelo", 
                     "Prev_IndividualCompact" = "IndividualCompact_Pelo",
                     "Prev_MassStart" = "MassStart_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "City")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_men)) {
          names(pred_data_men)[names(pred_data_men) == rename_map[old_name]] <- old_name
        }
      }
      
      cat(sprintf("✓ Men's nordic combined prediction data prepared: %d athletes\n", nrow(pred_data_men)))
      
    } else {
      warning("Insufficient men's nordic combined prediction columns available")
      pred_data_men <- NULL
    }
    
  }, error = function(e) {
    warning("Error preparing men's nordic combined prediction data: ", e$message)
    pred_data_men <- NULL
  })
} else {
  cat("No men's nordic combined prediction data available\n")
}

# Ladies prediction data preparation
pred_data_ladies <- NULL
if (nrow(ladies_pred_data) > 0) {
  tryCatch({
    # Define expected columns for prediction data (nordic combined-specific)
    expected_pred_cols <- c("Skier", "City", "Pelo", "Individual_Pelo", "IndividualCompact_Pelo", 
                           "MassStart_Pelo", "Pct_of_Max_Points")
    
    available_pred_cols <- intersect(expected_pred_cols, names(ladies_pred_data))
    missing_pred_cols <- setdiff(expected_pred_cols, names(ladies_pred_data))
    
    cat(sprintf("Ladies nordic combined prediction columns: %d available, %d missing\n", 
                length(available_pred_cols), length(missing_pred_cols)))
    
    if (length(missing_pred_cols) > 0) {
      cat("Missing ladies nordic combined prediction columns:", paste(missing_pred_cols, collapse = ", "), "\n")
    }
    
    if (length(available_pred_cols) >= 4) {  # Need at least basic info
      pred_data_ladies <- ladies_pred_data[available_pred_cols]
      
      # Rename to match training data feature names (nordic combined-specific)
      rename_map <- c("Prev_Pelo" = "Pelo", "Prev_Individual" = "Individual_Pelo", 
                     "Prev_IndividualCompact" = "IndividualCompact_Pelo",
                     "Prev_MassStart" = "MassStart_Pelo", 
                     "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points", "Nation" = "City")
      
      for (old_name in names(rename_map)) {
        if (rename_map[old_name] %in% names(pred_data_ladies)) {
          names(pred_data_ladies)[names(pred_data_ladies) == rename_map[old_name]] <- old_name
        }
      }
      
      cat(sprintf("✓ Ladies nordic combined prediction data prepared: %d athletes\n", nrow(pred_data_ladies)))
      
    } else {
      warning("Insufficient ladies nordic combined prediction columns available")
      pred_data_ladies <- NULL
    }
    
  }, error = function(e) {
    warning("Error preparing ladies nordic combined prediction data: ", e$message)
    pred_data_ladies <- NULL
  })
} else {
  cat("No ladies nordic combined prediction data available\n")
}

# Store training data with places for use in odds calculations
train_men_with_places <- men_odds_data
train_ladies_with_places <- ladies_odds_data

if (nrow(train_men_with_places) == 0 || nrow(train_ladies_with_places) == 0) {
  stop("Training data with places not available - ensure nordic combined odds-setup section completed successfully")
}

cat(sprintf("\n✓ Training data with places prepared: Men %d rows, Ladies %d rows\n", 
            nrow(train_men_with_places), nrow(train_ladies_with_places)))

cat("✓ Nordic combined odds setup completed successfully\n")
```

### Non-Machine Learning Features

```{r non-ml-feat}
cat("=== FEATURE SELECTION FOR NORDIC COMBINED ODDS MODELS & VALIDATION ===\n")

# Load required libraries with validation
cat("\n--- Library Loading ---\n")
tryCatch({
  library(leaps)
  cat("✓ leaps library loaded\n")
}, error = function(e) {
  stop("Failed to load leaps library: ", e$message)
})

tryCatch({
  library(caret)
  cat("✓ caret library loaded\n")
}, error = function(e) {
  stop("Failed to load caret library: ", e$message)
})

# Validate input data availability
cat("\n--- Input Data Validation ---\n")

if (!exists("men_odds_data") || !exists("ladies_odds_data")) {
  stop("Training data with places not available - ensure nordic combined odds-setup section completed successfully")
}

if (nrow(men_odds_data) == 0) {
  stop("Men's training data with places is empty")
}
if (nrow(ladies_odds_data) == 0) {
  stop("Ladies training data with places is empty")
}

cat(sprintf("Training data with outcomes: Men %d rows, Ladies %d rows\n", nrow(men_odds_data), nrow(ladies_odds_data)))

# Define and validate features for nordic combined odds models
cat("\n--- Nordic Combined Feature Definition & Validation ---\n")

features <- c("Prev_Pelo", "Prev_Individual", "Prev_IndividualCompact", 
              "Prev_MassStart", "Prev_Pct_of_Max_Points")

# Check feature availability in training data
men_available_features <- intersect(features, names(men_odds_data))
ladies_available_features <- intersect(features, names(ladies_odds_data))

cat(sprintf("Men's available nordic combined features: %d/%d\n", length(men_available_features), length(features)))
cat(sprintf("Ladies available nordic combined features: %d/%d\n", length(ladies_available_features), length(features)))

men_missing_features <- setdiff(features, men_available_features)
ladies_missing_features <- setdiff(features, ladies_available_features)

if (length(men_missing_features) > 0) {
  cat("Men's missing nordic combined features:", paste(men_missing_features, collapse = ", "), "\n")
  warning("Some nordic combined features missing from men's training data")
}
if (length(ladies_missing_features) > 0) {
  cat("Ladies missing nordic combined features:", paste(ladies_missing_features, collapse = ", "), "\n")
  warning("Some nordic combined features missing from ladies training data")
}

# Update feature lists to only include available features
features_men <- men_available_features
features_ladies <- ladies_available_features

if (length(features_men) < 3) {
  stop("Insufficient nordic combined features for men's odds modeling (need at least 3)")
}
if (length(features_ladies) < 3) {
  stop("Insufficient nordic combined features for ladies odds modeling (need at least 3)")
}

# Function to evaluate binary logistic model with validation
evaluate_glm <- function(feature_set, data, target, gender_label = "Unknown") {
  tryCatch({
    # Validate inputs
    if (length(feature_set) == 0) {
      return(Inf)
    }
    
    # Check if features exist in data
    missing_features <- setdiff(feature_set, names(data))
    if (length(missing_features) > 0) {
      return(Inf)
    }
    
    # Check if target exists and has variation
    if (!target %in% names(data)) {
      return(Inf)
    }
    
    target_table <- table(data[[target]])
    if (length(target_table) < 2 || any(target_table < 5)) {
      return(Inf)  # Skip if not enough levels or insufficient observations
    }
    
    # Build and evaluate model
    formula_str <- as.formula(paste(target, "~", paste(feature_set, collapse = " + ")))
    model <- glm(formula_str, family = binomial, data = data)
    
    # Validate model convergence
    if (!model$converged) {
      return(Inf)
    }
    
    aic_value <- AIC(model)
    
    # Validate AIC value
    if (!is.finite(aic_value)) {
      return(Inf)
    }
    
    return(aic_value)
  }, error = function(e) {
    return(Inf)
  })
}

# Exhaustive feature search function with validation
exhaustive_feature_search <- function(target, data_df, gender_label, available_features) {
  cat(sprintf("Searching %s nordic combined features for %s...\n", gender_label, target))
  
  # Validate inputs
  if (!target %in% names(data_df)) {
    cat(sprintf("Target %s not found in %s data\n", target, gender_label))
    return(list(features = character(0), aic = Inf))
  }
  
  if (length(available_features) < 2) {
    cat(sprintf("Insufficient nordic combined features for %s %s search\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  }
  
  best_aic <- Inf
  best_features <- NULL
  total_combinations <- 0
  successful_models <- 0
  
  # Search through feature combinations (2-5 features)
  max_features <- min(5, length(available_features))
  
  for(i in 2:max_features) {
    if (i > length(available_features)) break
    
    combinations <- combn(available_features, i, simplify = FALSE)
    total_combinations <- total_combinations + length(combinations)
    
    for(feature_set in combinations) {
      aic <- evaluate_glm(feature_set, data_df, target, gender_label)
      if(is.finite(aic)) {
        successful_models <- successful_models + 1
        if(aic < best_aic) {
          best_aic <- aic
          best_features <- feature_set
        }
      }
    }
  }
  
  cat(sprintf("  Tested %d combinations, %d successful models\n", total_combinations, successful_models))
  
  if (is.null(best_features)) {
    cat(sprintf("  No successful models found for %s %s\n", gender_label, target))
    return(list(features = character(0), aic = Inf))
  } else {
    cat(sprintf("  Best %s %s nordic combined features: %s (AIC: %.2f)\n", 
                gender_label, target, paste(best_features, collapse = ", "), best_aic))
  }
  
  return(list(features = best_features, aic = best_aic))
}

# Debug and validate data structure
cat("\n--- Data Structure Validation ---\n")

# Check target variable distributions
targets <- c("Win", "TopThree", "Top5", "Top10", "Top30")
for (target in targets) {
  if (target %in% names(men_odds_data)) {
    men_table <- table(men_odds_data[[target]])
    cat(sprintf("Men's %s distribution: %s\n", target, paste(names(men_table), men_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Men's %s target not found", target))
  }
  
  if (target %in% names(ladies_odds_data)) {
    ladies_table <- table(ladies_odds_data[[target]])
    cat(sprintf("Ladies %s distribution: %s\n", target, paste(names(ladies_table), ladies_table, sep="=", collapse=", ")))
  } else {
    warning(sprintf("Ladies %s target not found", target))
  }
}

cat(sprintf("Men's data dimensions: %d rows × %d columns\n", nrow(men_odds_data), ncol(men_odds_data)))
cat(sprintf("Ladies data dimensions: %d rows × %d columns\n", nrow(ladies_odds_data), ncol(ladies_odds_data)))

# Validate sufficient data for modeling
min_obs_per_class <- 10
for (target in targets) {
  if (target %in% names(men_odds_data)) {
    men_min_class <- min(table(men_odds_data[[target]]))
    if (men_min_class < min_obs_per_class) {
      warning(sprintf("Men's %s has insufficient minority class observations (%d < %d)", 
                     target, men_min_class, min_obs_per_class))
    }
  }
  
  if (target %in% names(ladies_odds_data)) {
    ladies_min_class <- min(table(ladies_odds_data[[target]]))
    if (ladies_min_class < min_obs_per_class) {
      warning(sprintf("Ladies %s has insufficient minority class observations (%d < %d)", 
                     target, ladies_min_class, min_obs_per_class))
    }
  }
}

# Perform exhaustive feature search with validation
cat("\n=== EXHAUSTIVE NORDIC COMBINED FEATURE SEARCH ===\n")

# Initialize result storage
best_features_odds_men <- list()
best_features_odds_ladies <- list()

# Men's nordic combined feature search
cat("\n--- Men's Nordic Combined Feature Search ---\n")
for(target in targets) {
  if (target %in% names(men_odds_data)) {
    result <- exhaustive_feature_search(target, men_odds_data, "Men's", features_men)
    best_features_odds_men[[target]] <- result
  } else {
    cat(sprintf("Skipping men's %s - target not available\n", target))
    best_features_odds_men[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Ladies nordic combined feature search  
cat("\n--- Ladies Nordic Combined Feature Search ---\n")
for(target in targets) {
  if (target %in% names(ladies_odds_data)) {
    result <- exhaustive_feature_search(target, ladies_odds_data, "Ladies", features_ladies)
    best_features_odds_ladies[[target]] <- result
  } else {
    cat(sprintf("Skipping ladies %s - target not available\n", target))
    best_features_odds_ladies[[target]] <- list(features = character(0), aic = Inf)
  }
}

# Validate search results
cat("\n--- Nordic Combined Feature Search Validation ---\n")

for(target in targets) {
  men_result <- best_features_odds_men[[target]]
  ladies_result <- best_features_odds_ladies[[target]]
  
  cat(sprintf("%s nordic combined results:\n", target))
  
  if (length(men_result$features) > 0) {
    cat(sprintf("  Men: %s (AIC: %.2f)\n", paste(men_result$features, collapse = ", "), men_result$aic))
  } else {
    cat("  Men: No successful nordic combined model found\n")
  }
  
  if (length(ladies_result$features) > 0) {
    cat(sprintf("  Ladies: %s (AIC: %.2f)\n", paste(ladies_result$features, collapse = ", "), ladies_result$aic))
  } else {
    cat("  Ladies: No successful nordic combined model found\n")
  }
}

# Check for any successful models
successful_men_targets <- sum(sapply(best_features_odds_men, function(x) length(x$features) > 0))
successful_ladies_targets <- sum(sapply(best_features_odds_ladies, function(x) length(x$features) > 0))

cat(sprintf("Successful nordic combined models: Men %d/%d targets, Ladies %d/%d targets\n", 
            successful_men_targets, length(targets), successful_ladies_targets, length(targets)))

if (successful_men_targets == 0) {
  warning("No successful men's nordic combined odds models found")
}
if (successful_ladies_targets == 0) {
  warning("No successful ladies nordic combined odds models found")
}

# Maintain backwards compatibility
best_features_odds <- best_features_odds_men

cat("\n✓ Nordic combined feature selection for odds models completed\n")

# Set unified prediction data for backwards compatibility  
if (exists("pred_data_men") && !is.null(pred_data_men) && nrow(pred_data_men) > 0) {
  pred_data <- pred_data_men
  cat("Using men's nordic combined prediction data as default for backwards compatibility\n")
} else if (exists("pred_data_ladies") && !is.null(pred_data_ladies) && nrow(pred_data_ladies) > 0) {
  pred_data <- pred_data_ladies
  cat("Using ladies nordic combined prediction data as fallback default\n")
} else {
  pred_data <- data.frame()
  warning("No nordic combined prediction data available for odds calculations")
}

# Final validation summary
cat("\n--- Final Nordic Combined Prediction Data Summary ---\n")

# Debug: Check what we have
cat("Debug: exists('pred_data'):", exists("pred_data"), "\n")
if (exists("pred_data")) {
  cat("Debug: is.null(pred_data):", is.null(pred_data), "\n")
  cat("Debug: class(pred_data):", class(pred_data), "\n")
  if (!is.null(pred_data) && is.data.frame(pred_data)) {
    cat("Debug: nrow(pred_data):", nrow(pred_data), "\n")
  }
}

if (exists("pred_data") && !is.null(pred_data) && nrow(pred_data) > 0) {
  cat(sprintf("✓ Unified pred_data created: %d rows, %d columns\n", nrow(pred_data), ncol(pred_data)))
  cat("Available features:", paste(names(pred_data), collapse = ", "), "\n")
} else {
  warning("No unified prediction data available")
}
```

### Statistical Odds Models

```{r statistical-odds}
cat("=== NORDIC COMBINED STATISTICAL ODDS MODELS ===\n")

# Input validation for nordic combined odds modeling
if (!exists("best_features_odds_men") || !exists("best_features_odds_ladies")) {
  stop("Nordic combined feature selection objects not found. Please run non-ml-feat section first.")
}

# Define outcomes for nordic combined
outcomes <- c("Win", "TopThree", "Top5", "Top10", "Top30")

# Validate feature selection results
cat("\n--- Nordic Combined Feature Selection Validation ---\n")
for (outcome in outcomes) {
  men_result <- best_features_odds_men[[outcome]]
  ladies_result <- best_features_odds_ladies[[outcome]]
  
  if (length(men_result$features) == 0) {
    warning(sprintf("No features selected for men's nordic combined %s model", outcome))
  } else {
    cat(sprintf("Men's %s features: %s\n", outcome, paste(men_result$features, collapse = ", ")))
  }
  
  if (length(ladies_result$features) == 0) {
    warning(sprintf("No features selected for ladies nordic combined %s model", outcome))
  } else {
    cat(sprintf("Ladies %s features: %s\n", outcome, paste(ladies_result$features, collapse = ", ")))
  }
}

# Validate training data availability
if (!exists("men_odds_data") || nrow(men_odds_data) == 0) {
  stop("Men's nordic combined odds training data not available")
}
if (!exists("ladies_odds_data") || nrow(ladies_odds_data) == 0) {
  stop("Ladies nordic combined odds training data not available")
}

cat(sprintf("Training data validated: %d men's obs, %d ladies obs\n", 
            nrow(men_odds_data), nrow(ladies_odds_data)))

# Helper function to fit GLM with validation for nordic combined
fit_validated_glm <- function(features, data, outcome, gender_label) {
  if (length(features) == 0) {
    cat(sprintf("No features available for %s nordic combined %s model\n", gender_label, outcome))
    return(NULL)
  }
  
  formula_str <- sprintf("%s ~ %s", outcome, paste(features, collapse = " + "))
  
  tryCatch({
    model <- glm(as.formula(formula_str), data = data, family = binomial(link = "logit"))
    
    # Check for convergence
    if (!model$converged) {
      warning(sprintf("%s nordic combined %s model did not converge", gender_label, outcome))
      return(NULL)
    }
    
    # Check for valid coefficients
    if (any(!is.finite(model$coefficients))) {
      warning(sprintf("%s nordic combined %s model has invalid coefficients", gender_label, outcome))
      return(NULL)
    }
    
    # Add coefficient direction validation for odds prediction
    cat(sprintf("\n--- %s Nordic Combined %s Model Coefficient Validation ---\n", gender_label, outcome))
    tryCatch({
      # Get logistic regression coefficients
      logistic_coefs <- summary(model)$coefficients
      
      # Expected positive coefficients for odds prediction (nordic combined specific)
      expected_positive_vars <- c("Prev_Pelo", "Prev_Pct_of_Max_Points")
      expected_negative_vars <- c("Age")  # Younger athletes more likely to achieve good results
      
      # Check coefficient directions
      for (var in names(model$coefficients)) {
        if (var != "(Intercept)" && var %in% rownames(logistic_coefs)) {
          coef_value <- logistic_coefs[var, "Estimate"]
          coef_pvalue <- logistic_coefs[var, "Pr(>|z|)"]
          
          # Check if coefficient direction matches expectation
          if (var %in% expected_positive_vars) {
            if (coef_value > 0) {
              cat("✓", var, "has positive coefficient (", round(coef_value, 4), ") - VALID for", outcome, "prediction\n")
            } else {
              cat("⚠️  WARNING:", var, "has negative coefficient (", round(coef_value, 4), ") - unexpected for", outcome, "prediction\n")
            }
          } else if (var %in% expected_negative_vars) {
            if (coef_value < 0) {
              cat("✓", var, "has negative coefficient (", round(coef_value, 4), ") - VALID for", outcome, "prediction\n")
            } else {
              cat("⚠️  WARNING:", var, "has positive coefficient (", round(coef_value, 4), ") - unexpected for", outcome, "prediction\n")
            }
          } else {
            # For other variables, include regardless of direction but note it
            cat("?", var, "has coefficient (", round(coef_value, 4), ") - included (direction not specified)\n")
          }
          
          # Also check statistical significance
          if (coef_pvalue > 0.1) {
            cat("  NOTE:", var, "p-value =", round(coef_pvalue, 4), "(not significant at 0.1 level)\n")
          }
        }
      }
      
    }, error = function(e) {
      cat("Error in nordic combined", outcome, "coefficient validation:", e$message, "\n")
    })
    
    # Calculate model diagnostics
    null_deviance <- model$null.deviance
    residual_deviance <- model$deviance
    pseudo_r2 <- 1 - (residual_deviance / null_deviance)
    
    cat(sprintf("✓ %s nordic combined %s model: AIC=%.2f, Pseudo-R²=%.3f\n", 
                gender_label, outcome, model$aic, pseudo_r2))
    
    return(model)
    
  }, error = function(e) {
    warning(sprintf("Failed to fit %s nordic combined %s model: %s", gender_label, outcome, e$message))
    return(NULL)
  })
}

# Train men's nordic combined models
cat("\n--- Men's Nordic Combined Models ---\n")
men_models <- list()

for (outcome in outcomes) {
  features <- best_features_odds_men[[outcome]]$features
  men_models[[outcome]] <- fit_validated_glm(features, men_odds_data, outcome, "Men's")
}

# Train ladies nordic combined models  
cat("\n--- Ladies Nordic Combined Models ---\n")
ladies_models <- list()

for (outcome in outcomes) {
  features <- best_features_odds_ladies[[outcome]]$features
  ladies_models[[outcome]] <- fit_validated_glm(features, ladies_odds_data, outcome, "Ladies")
}

# Validate prediction data for nordic combined
cat("\n--- Nordic Combined Prediction Data Validation ---\n")

if (!exists("pred_data_men") || nrow(pred_data_men) == 0) {
  warning("Men's nordic combined prediction data not available")
  pred_data_men <- data.frame()
}

if (!exists("pred_data_ladies") || nrow(pred_data_ladies) == 0) {
  warning("Ladies nordic combined prediction data not available")
  pred_data_ladies <- data.frame()
}

cat(sprintf("Prediction data: %d men, %d ladies\n", nrow(pred_data_men), nrow(pred_data_ladies)))

# Function to generate predictions with validation for nordic combined
generate_nordic_combined_predictions <- function(model, pred_data, outcome, gender_label) {
  if (is.null(model)) {
    cat(sprintf("No %s nordic combined %s model available\n", gender_label, outcome))
    return(rep(NA, nrow(pred_data)))
  }
  
  if (nrow(pred_data) == 0) {
    cat(sprintf("No %s nordic combined prediction data available\n", gender_label))
    return(numeric(0))
  }
  
  tryCatch({
    predictions <- predict(model, newdata = pred_data, type = "response")
    
    # Validate predictions
    if (any(!is.finite(predictions))) {
      invalid_count <- sum(!is.finite(predictions))
      warning(sprintf("%s nordic combined %s: %d invalid predictions", 
                     gender_label, outcome, invalid_count))
      predictions[!is.finite(predictions)] <- 0
    }
    
    # Cap extreme probabilities
    predictions <- pmax(0.001, pmin(0.999, predictions))
    
    cat(sprintf("✓ %s nordic combined %s predictions: min=%.3f, max=%.3f, mean=%.3f\n",
                gender_label, outcome, min(predictions), max(predictions), mean(predictions)))
    
    return(predictions)
    
  }, error = function(e) {
    warning(sprintf("Failed to generate %s nordic combined %s predictions: %s", 
                   gender_label, outcome, e$message))
    return(rep(0.001, nrow(pred_data)))
  })
}

# Generate men's nordic combined predictions
cat("\n--- Men's Nordic Combined Predictions ---\n")
men_predictions <- list()

for (outcome in outcomes) {
  men_predictions[[outcome]] <- generate_nordic_combined_predictions(
    men_models[[outcome]], pred_data_men, outcome, "Men's"
  )
}

# DEBUG: Show prediction values for Oftebro
oftebro_indices <- which(pred_data_men$Skier == "Jens Lurås Oftebro")
if (length(oftebro_indices) > 0) {
  cat("\n--- DEBUG: Oftebro Nordic Combined Model Values ---\n")
  oftebro_data <- pred_data_men[oftebro_indices[1], , drop = FALSE]
  
  # Show all available features for Oftebro
  cat("Available data for Oftebro:\n")
  for (col_name in names(oftebro_data)) {
    value <- oftebro_data[[col_name]]
    cat(sprintf("  %s: %s\n", col_name, 
               ifelse(is.na(value), "NA", 
                     ifelse(is.numeric(value), round(value, 4), value))))
  }
  
  # Show predictions for each outcome
  cat("\nOftebro predictions:\n")
  for (outcome in outcomes) {
    if (outcome %in% names(men_predictions) && length(men_predictions[[outcome]]) >= oftebro_indices[1]) {
      prob <- men_predictions[[outcome]][oftebro_indices[1]]
      cat(sprintf("  %s probability: %.4f (%.2f%%)\n", outcome, prob, prob * 100))
    }
  }
  cat("--- End Oftebro Debug ---\n\n")
} else {
  cat("Oftebro not found in men's prediction data\n")
}

# Generate ladies nordic combined predictions
cat("\n--- Ladies Nordic Combined Predictions ---\n") 
ladies_predictions <- list()

for (outcome in outcomes) {
  ladies_predictions[[outcome]] <- generate_nordic_combined_predictions(
    ladies_models[[outcome]], pred_data_ladies, outcome, "Ladies"
  )
}

# DEBUG: Show prediction values for Ida Marie Hagen
ida_indices <- which(pred_data_ladies$Skier == "Ida Marie Hagen")
if (length(ida_indices) > 0) {
  cat("\n--- DEBUG: Ida Marie Hagen Nordic Combined Model Values ---\n")
  ida_data <- pred_data_ladies[ida_indices[1], , drop = FALSE]
  
  # Show all available features for Ida Marie Hagen
  cat("Available data for Ida Marie Hagen:\n")
  for (col_name in names(ida_data)) {
    value <- ida_data[[col_name]]
    cat(sprintf("  %s: %s\n", col_name, 
               ifelse(is.na(value), "NA", 
                     ifelse(is.numeric(value), round(value, 4), value))))
  }
  
  # Show predictions for each outcome
  cat("\nIda Marie Hagen predictions:\n")
  for (outcome in outcomes) {
    if (outcome %in% names(ladies_predictions) && length(ladies_predictions[[outcome]]) >= ida_indices[1]) {
      prob <- ladies_predictions[[outcome]][ida_indices[1]]
      cat(sprintf("  %s probability: %.4f (%.2f%%)\n", outcome, prob, prob * 100))
    }
  }
  cat("--- End Ida Marie Hagen Debug ---\n\n")
} else {
  cat("Ida Marie Hagen not found in ladies prediction data\n")
}

# Probability normalization function for nordic combined
normalize_nordic_combined_probabilities <- function(predictions, target_sum, max_prob = 0.95) {
  # Handle edge cases
  if (length(predictions) == 0 || all(is.na(predictions))) {
    return(predictions)
  }
  
  # Replace NA values with small probability
  predictions[is.na(predictions)] <- 0.001
  
  # Calculate current sum
  current_sum <- sum(predictions)
  
  if (current_sum <= 0) {
    # If all probabilities are zero, distribute equally
    return(rep(target_sum / length(predictions), length(predictions)))
  }
  
  # Scale to target sum
  scaled_predictions <- predictions * (target_sum / current_sum)
  
  # Cap maximum probability
  scaled_predictions <- pmin(scaled_predictions, max_prob)
  
  # Renormalize after capping
  final_sum <- sum(scaled_predictions)
  if (final_sum > 0 && abs(final_sum - target_sum) > 0.01) {
    scaled_predictions <- scaled_predictions * (target_sum / final_sum)
  }
  
  return(scaled_predictions)
}

# Normalize men's nordic combined probabilities
cat("\n--- Men's Nordic Combined Probability Normalization ---\n")

men_norm_predictions <- list()
normalization_targets <- list(Win = 1.0, TopThree = 3.0, Top5 = 5.0, Top10 = 10.0, Top30 = 30.0)

for (outcome in outcomes) {
  if (outcome %in% names(normalization_targets)) {
    target <- normalization_targets[[outcome]]
    men_norm_predictions[[outcome]] <- normalize_nordic_combined_probabilities(
      men_predictions[[outcome]], target
    )
    
    sum_before <- sum(men_predictions[[outcome]], na.rm = TRUE)
    sum_after <- sum(men_norm_predictions[[outcome]], na.rm = TRUE)
    
    cat(sprintf("Men's %s: %.2f → %.2f (target: %.1f)\n", 
                outcome, sum_before, sum_after, target))
  }
}

# Normalize ladies nordic combined probabilities
cat("\n--- Ladies Nordic Combined Probability Normalization ---\n")

ladies_norm_predictions <- list()

for (outcome in outcomes) {
  if (outcome %in% names(normalization_targets)) {
    target <- normalization_targets[[outcome]]
    ladies_norm_predictions[[outcome]] <- normalize_nordic_combined_probabilities(
      ladies_predictions[[outcome]], target
    )
    
    sum_before <- sum(ladies_predictions[[outcome]], na.rm = TRUE)
    sum_after <- sum(ladies_norm_predictions[[outcome]], na.rm = TRUE)
    
    cat(sprintf("Ladies %s: %.2f → %.2f (target: %.1f)\n", 
                outcome, sum_before, sum_after, target))
  }
}

# Create men's nordic combined results
cat("\n--- Men's Nordic Combined Results Creation ---\n")

if (nrow(pred_data_men) > 0) {
  men_results <- pred_data_men %>%
    dplyr::select(Skier, Nation) %>%
    mutate(
      Win_Prob = if("Win" %in% names(men_norm_predictions)) {
        men_norm_predictions[["Win"]]
      } else {
        rep(0, nrow(pred_data_men))
      },
      Top3_Prob = if("TopThree" %in% names(men_norm_predictions)) {
        men_norm_predictions[["TopThree"]]
      } else {
        rep(0, nrow(pred_data_men))
      },
      Top5_Prob = if("Top5" %in% names(men_norm_predictions)) {
        men_norm_predictions[["Top5"]]
      } else {
        rep(0, nrow(pred_data_men))
      },
      Top10_Prob = if("Top10" %in% names(men_norm_predictions)) {
        men_norm_predictions[["Top10"]]
      } else {
        rep(0, nrow(pred_data_men))
      },
      Top30_Prob = if("Top30" %in% names(men_norm_predictions)) {
        men_norm_predictions[["Top30"]]
      } else {
        rep(0, nrow(pred_data_men))
      }
    ) %>%
    mutate(
      # Enforce logical ordering constraint: Win <= Top3 <= Top5 <= Top10 <= Top30
      Win_Prob = pmax(Win_Prob, 0),
      Top3_Prob = pmax(Top3_Prob, Win_Prob),
      Top5_Prob = pmax(Top5_Prob, Top3_Prob),
      Top10_Prob = pmax(Top10_Prob, Top5_Prob),
      Top30_Prob = pmax(Top30_Prob, Top10_Prob)
    ) %>%
    mutate(
      # Convert to percentages
      Win_Pct = round(Win_Prob * 100, 2),
      Top3_Pct = round(Top3_Prob * 100, 2),
      Top5_Pct = round(Top5_Prob * 100, 2),
      Top10_Pct = round(Top10_Prob * 100, 2),
      Top30_Pct = round(Top30_Prob * 100, 2),
      
      # Calculate decimal odds
      Win_Decimal_Odds = round(1 / pmax(Win_Prob, 0.001), 2),
      Top3_Decimal_Odds = round(1 / pmax(Top3_Prob, 0.001), 2),
      Top5_Decimal_Odds = round(1 / pmax(Top5_Prob, 0.001), 2),
      Top10_Decimal_Odds = round(1 / pmax(Top10_Prob, 0.001), 2),
      Top30_Decimal_Odds = round(1 / pmax(Top30_Prob, 0.001), 2),
      
      # Calculate American odds
      Win_American_Odds = ifelse(Win_Decimal_Odds >= 2, 
                                paste0("+", round((Win_Decimal_Odds - 1) * 100)), 
                                round(-100 / (Win_Decimal_Odds - 1))),
      Top3_American_Odds = ifelse(Top3_Decimal_Odds >= 2,
                                 paste0("+", round((Top3_Decimal_Odds - 1) * 100)),
                                 round(-100 / (Top3_Decimal_Odds - 1))),
      Top5_American_Odds = ifelse(Top5_Decimal_Odds >= 2,
                                 paste0("+", round((Top5_Decimal_Odds - 1) * 100)),
                                 round(-100 / (Top5_Decimal_Odds - 1))),
      Top10_American_Odds = ifelse(Top10_Decimal_Odds >= 2,
                                  paste0("+", round((Top10_Decimal_Odds - 1) * 100)),
                                  round(-100 / (Top10_Decimal_Odds - 1))),
      Top30_American_Odds = ifelse(Top30_Decimal_Odds >= 2,
                                  paste0("+", round((Top30_Decimal_Odds - 1) * 100)),
                                  round(-100 / (Top30_Decimal_Odds - 1)))
    ) %>%
    arrange(desc(Win_Prob))
  
  cat(sprintf("✓ Men's nordic combined results created: %d athletes\n", nrow(men_results)))
  
} else {
  cat("No men's nordic combined prediction data available\n")
  men_results <- data.frame()
}

# Create ladies nordic combined results
cat("\n--- Ladies Nordic Combined Results Creation ---\n")

if (nrow(pred_data_ladies) > 0) {
  ladies_results <- pred_data_ladies %>%
    dplyr::select(Skier, Nation) %>%
    mutate(
      Win_Prob = if("Win" %in% names(ladies_norm_predictions)) {
        ladies_norm_predictions[["Win"]]
      } else {
        rep(0, nrow(pred_data_ladies))
      },
      Top3_Prob = if("TopThree" %in% names(ladies_norm_predictions)) {
        ladies_norm_predictions[["TopThree"]]
      } else {
        rep(0, nrow(pred_data_ladies))
      },
      Top5_Prob = if("Top5" %in% names(ladies_norm_predictions)) {
        ladies_norm_predictions[["Top5"]]
      } else {
        rep(0, nrow(pred_data_ladies))
      },
      Top10_Prob = if("Top10" %in% names(ladies_norm_predictions)) {
        ladies_norm_predictions[["Top10"]]
      } else {
        rep(0, nrow(pred_data_ladies))
      },
      Top30_Prob = if("Top30" %in% names(ladies_norm_predictions)) {
        ladies_norm_predictions[["Top30"]]
      } else {
        rep(0, nrow(pred_data_ladies))
      }
    ) %>%
    mutate(
      # Enforce logical ordering constraint: Win <= Top3 <= Top5 <= Top10 <= Top30
      Win_Prob = pmax(Win_Prob, 0),
      Top3_Prob = pmax(Top3_Prob, Win_Prob),
      Top5_Prob = pmax(Top5_Prob, Top3_Prob),
      Top10_Prob = pmax(Top10_Prob, Top5_Prob),
      Top30_Prob = pmax(Top30_Prob, Top10_Prob)
    ) %>%
    mutate(
      # Convert to percentages
      Win_Pct = round(Win_Prob * 100, 2),
      Top3_Pct = round(Top3_Prob * 100, 2),
      Top5_Pct = round(Top5_Prob * 100, 2),
      Top10_Pct = round(Top10_Prob * 100, 2),
      Top30_Pct = round(Top30_Prob * 100, 2),
      
      # Calculate decimal odds
      Win_Decimal_Odds = round(1 / pmax(Win_Prob, 0.001), 2),
      Top3_Decimal_Odds = round(1 / pmax(Top3_Prob, 0.001), 2),
      Top5_Decimal_Odds = round(1 / pmax(Top5_Prob, 0.001), 2),
      Top10_Decimal_Odds = round(1 / pmax(Top10_Prob, 0.001), 2),
      Top30_Decimal_Odds = round(1 / pmax(Top30_Prob, 0.001), 2),
      
      # Calculate American odds
      Win_American_Odds = ifelse(Win_Decimal_Odds >= 2,
                                paste0("+", round((Win_Decimal_Odds - 1) * 100)),
                                round(-100 / (Win_Decimal_Odds - 1))),
      Top3_American_Odds = ifelse(Top3_Decimal_Odds >= 2,
                                 paste0("+", round((Top3_Decimal_Odds - 1) * 100)),
                                 round(-100 / (Top3_Decimal_Odds - 1))),
      Top5_American_Odds = ifelse(Top5_Decimal_Odds >= 2,
                                 paste0("+", round((Top5_Decimal_Odds - 1) * 100)),
                                 round(-100 / (Top5_Decimal_Odds - 1))),
      Top10_American_Odds = ifelse(Top10_Decimal_Odds >= 2,
                                  paste0("+", round((Top10_Decimal_Odds - 1) * 100)),
                                  round(-100 / (Top10_Decimal_Odds - 1))),
      Top30_American_Odds = ifelse(Top30_Decimal_Odds >= 2,
                                  paste0("+", round((Top30_Decimal_Odds - 1) * 100)),
                                  round(-100 / (Top30_Decimal_Odds - 1)))
    ) %>%
    arrange(desc(Win_Prob))
  
  cat(sprintf("✓ Ladies nordic combined results created: %d athletes\n", nrow(ladies_results)))
  
} else {
  cat("No ladies nordic combined prediction data available\n")
  ladies_results <- data.frame()
}

# Export to Excel files for nordic combined
cat("\n--- Nordic Combined Excel Export ---\n")

# Define output directory
output_dir <- "/Users/syverjohansen/blog/daehl-e/content/post/nordic-combined/drafts/season-prediction/2026/excel365/"
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
  cat("Created output directory:", output_dir, "\n")
}

# Export men's nordic combined odds
if (nrow(men_results) > 0) {
  tryCatch({
    # Win odds
    win_file <- file.path(output_dir, "Men_Win_Odds_2026.xlsx")
    win_data <- men_results %>%
      dplyr::select(Skier, Nation, Win_Pct, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(`Win %` = Win_Pct, `Decimal Odds` = Win_Decimal_Odds, `American Odds` = Win_American_Odds)
    write.xlsx(win_data, win_file, overwrite = TRUE)
    cat("✓ Men's nordic combined win odds exported:", win_file, "\n")
    
    # Top 3 odds
    top3_file <- file.path(output_dir, "Men_Top3_Odds_2026.xlsx")
    top3_data <- men_results %>%
      dplyr::select(Skier, Nation, Top3_Pct, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(`Top 3 %` = Top3_Pct, `Decimal Odds` = Top3_Decimal_Odds, `American Odds` = Top3_American_Odds)
    write.xlsx(top3_data, top3_file, overwrite = TRUE)
    cat("✓ Men's nordic combined top 3 odds exported:", top3_file, "\n")
    
    # Top 10 odds
    top10_file <- file.path(output_dir, "Men_Top10_Odds_2026.xlsx")
    top10_data <- men_results %>%
      dplyr::select(Skier, Nation, Top10_Pct, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(`Top 10 %` = Top10_Pct, `Decimal Odds` = Top10_Decimal_Odds, `American Odds` = Top10_American_Odds)
    write.xlsx(top10_data, top10_file, overwrite = TRUE)
    cat("✓ Men's nordic combined top 10 odds exported:", top10_file, "\n")
    
    # Top 30 odds
    top30_file <- file.path(output_dir, "Men_Top30_Odds_2026.xlsx")
    top30_data <- men_results %>%
      dplyr::select(Skier, Nation, Top30_Pct, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(`Top 30 %` = Top30_Pct, `Decimal Odds` = Top30_Decimal_Odds, `American Odds` = Top30_American_Odds)
    write.xlsx(top30_data, top30_file, overwrite = TRUE)
    cat("✓ Men's nordic combined top 30 odds exported:", top30_file, "\n")
    
  }, error = function(e) {
    warning("Failed to export men's nordic combined odds: ", e$message)
  })
} else {
  cat("No men's nordic combined results to export\n")
}

# Export ladies nordic combined odds
if (nrow(ladies_results) > 0) {
  tryCatch({
    # Win odds
    win_file <- file.path(output_dir, "Ladies_Win_Odds_2026.xlsx")
    win_data <- ladies_results %>%
      dplyr::select(Skier, Nation, Win_Pct, Win_Decimal_Odds, Win_American_Odds) %>%
      rename(`Win %` = Win_Pct, `Decimal Odds` = Win_Decimal_Odds, `American Odds` = Win_American_Odds)
    write.xlsx(win_data, win_file, overwrite = TRUE)
    cat("✓ Ladies nordic combined win odds exported:", win_file, "\n")
    
    # Top 3 odds
    top3_file <- file.path(output_dir, "Ladies_Top3_Odds_2026.xlsx")
    top3_data <- ladies_results %>%
      dplyr::select(Skier, Nation, Top3_Pct, Top3_Decimal_Odds, Top3_American_Odds) %>%
      rename(`Top 3 %` = Top3_Pct, `Decimal Odds` = Top3_Decimal_Odds, `American Odds` = Top3_American_Odds)
    write.xlsx(top3_data, top3_file, overwrite = TRUE)
    cat("✓ Ladies nordic combined top 3 odds exported:", top3_file, "\n")
    
    # Top 10 odds
    top10_file <- file.path(output_dir, "Ladies_Top10_Odds_2026.xlsx")
    top10_data <- ladies_results %>%
      dplyr::select(Skier, Nation, Top10_Pct, Top10_Decimal_Odds, Top10_American_Odds) %>%
      rename(`Top 10 %` = Top10_Pct, `Decimal Odds` = Top10_Decimal_Odds, `American Odds` = Top10_American_Odds)
    write.xlsx(top10_data, top10_file, overwrite = TRUE)
    cat("✓ Ladies nordic combined top 10 odds exported:", top10_file, "\n")
    
    # Top 30 odds
    top30_file <- file.path(output_dir, "Ladies_Top30_Odds_2026.xlsx")
    top30_data <- ladies_results %>%
      dplyr::select(Skier, Nation, Top30_Pct, Top30_Decimal_Odds, Top30_American_Odds) %>%
      rename(`Top 30 %` = Top30_Pct, `Decimal Odds` = Top30_Decimal_Odds, `American Odds` = Top30_American_Odds)
    write.xlsx(top30_data, top30_file, overwrite = TRUE)
    cat("✓ Ladies nordic combined top 30 odds exported:", top30_file, "\n")
    
  }, error = function(e) {
    warning("Failed to export ladies nordic combined odds: ", e$message)
  })
} else {
  cat("No ladies nordic combined results to export\n")
}

cat("\n✓ Nordic combined statistical odds models completed\n")
```

### Breakthrough Candidate Analysis

```{r breakout-identifier}
cat("=== NORDIC COMBINED BREAKTHROUGH ANALYSIS VALIDATION ===\n")

# Validate training data availability
if (!exists("train_men") || !is.data.frame(train_men)) {
  stop("train_men dataset not found or invalid")
}
if (!exists("train_ladies") || !is.data.frame(train_ladies)) {
  stop("train_ladies dataset not found or invalid")
}

if (nrow(train_men) == 0) stop("train_men dataset is empty")
if (nrow(train_ladies) == 0) stop("train_ladies dataset is empty")

cat("Training data validated - Men:", nrow(train_men), "observations, Ladies:", nrow(train_ladies), "observations\n")

# Validate required columns for breakthrough analysis
required_breakthrough_cols <- c("Skier", "Nation", "Season", "Pct_of_Max_Points", "Age")
missing_men_cols <- setdiff(required_breakthrough_cols, names(train_men))
missing_ladies_cols <- setdiff(required_breakthrough_cols, names(train_ladies))

if (length(missing_men_cols) > 0) {
  stop("Missing required columns in train_men: ", paste(missing_men_cols, collapse = ", "))
}
if (length(missing_ladies_cols) > 0) {
  stop("Missing required columns in train_ladies: ", paste(missing_ladies_cols, collapse = ", "))
}
cat("✓ All required columns present in both datasets\n")

# Validate Pct_of_Max_Points data quality
cat("\n--- Data Quality Validation ---\n")

# Men's data validation
men_invalid_pct <- sum(is.na(train_men$Pct_of_Max_Points) | 
                      train_men$Pct_of_Max_Points < 0 | 
                      train_men$Pct_of_Max_Points > 1 | 
                      !is.finite(train_men$Pct_of_Max_Points))

ladies_invalid_pct <- sum(is.na(train_ladies$Pct_of_Max_Points) | 
                         train_ladies$Pct_of_Max_Points < 0 | 
                         train_ladies$Pct_of_Max_Points > 1 | 
                         !is.finite(train_ladies$Pct_of_Max_Points))

cat("Men's invalid Pct_of_Max_Points values:", men_invalid_pct, "\n")
cat("Ladies invalid Pct_of_Max_Points values:", ladies_invalid_pct, "\n")

if (men_invalid_pct > nrow(train_men) * 0.1) {
  warning("More than 10% of men's Pct_of_Max_Points values are invalid")
}
if (ladies_invalid_pct > nrow(train_ladies) * 0.1) {
  warning("More than 10% of ladies Pct_of_Max_Points values are invalid")
}

# Identify historical top performers with validation
cat("\n--- Historical Top Performers Analysis ---\n")

tryCatch({
  top_performers_men <- train_men %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.5,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_men) == 0) {
    warning("No men's breakthrough performers found with >50% points")
  } else {
    cat("✓ Men's breakthrough performers identified:", nrow(top_performers_men), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying men's top performers: ", e$message)
})

tryCatch({
  top_performers_ladies <- train_ladies %>%
    filter(!is.na(Pct_of_Max_Points), 
           Pct_of_Max_Points > 0.5,
           !is.na(Skier),
           !is.na(Season),
           !is.na(Age)) %>%
    dplyr::select(Skier, Nation, Season, Pct_of_Max_Points, Age)
  
  if (nrow(top_performers_ladies) == 0) {
    warning("No ladies breakthrough performers found with >50% points")
  } else {
    cat("✓ Ladies breakthrough performers identified:", nrow(top_performers_ladies), "entries\n")
  }
  
}, error = function(e) {
  stop("Error identifying ladies top performers: ", e$message)
})

# Summary statistics with validation
tryCatch({
  unique_men_breakthroughs <- length(unique(top_performers_men$Skier))
  unique_ladies_breakthroughs <- length(unique(top_performers_ladies$Skier))
  
  cat("✓ Analysis completed successfully\n")
  cat("Men's breakthrough entries:", nrow(top_performers_men), "\n")
  cat("Ladies breakthrough entries:", nrow(top_performers_ladies), "\n")
  
  print("=== MEN'S HISTORICAL NORDIC COMBINED BREAKTHROUGH PERFORMERS (>50% of max points) ===")
  print(paste("Unique men's breakthrough skiers:", unique_men_breakthroughs))
  
  if (nrow(top_performers_men) > 0) {
    print("Recent men's breakthrough examples:")
    recent_men <- top_performers_men %>%
      arrange(desc(Season), desc(Pct_of_Max_Points))
    print(recent_men)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_men$Age))) {
      cat("Men's breakthrough age range:", 
          round(min(top_performers_men$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_men$Age, na.rm = TRUE), 1), "\n")
      cat("Men's mean breakthrough age:", 
          round(mean(top_performers_men$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No men's breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in men's breakthrough summary: ", e$message)
})

tryCatch({
  print("=== LADIES HISTORICAL NORDIC COMBINED BREAKTHROUGH PERFORMERS (>50% of max points) ===")
  print(paste("Unique ladies breakthrough skiers:", unique_ladies_breakthroughs))
  
  if (nrow(top_performers_ladies) > 0) {
    print("Recent ladies breakthrough examples:")
    recent_ladies <- top_performers_ladies %>%
      arrange(desc(Season), desc(Pct_of_Max_Points))
    print(recent_ladies)
    
    # Age distribution analysis
    if (!all(is.na(top_performers_ladies$Age))) {
      cat("Ladies breakthrough age range:", 
          round(min(top_performers_ladies$Age, na.rm = TRUE), 1), "-", 
          round(max(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
      cat("Ladies mean breakthrough age:", 
          round(mean(top_performers_ladies$Age, na.rm = TRUE), 1), "\n")
    }
  } else {
    print("No ladies breakthrough examples to display")
  }
  
}, error = function(e) {
  stop("Error in ladies breakthrough summary: ", e$message)
})
```

### Breakthrough Prediction Models

```{r feat-select-break}
# Load required libraries for breakthrough analysis
tryCatch({
  library(caret)
  library(ranger)
  library(pROC)
  cat("✓ Required libraries loaded successfully\n")
}, error = function(e) {
  stop("Error loading required libraries: ", e$message)
})

# Enhanced function to evaluate predictor importance for breakthrough prediction
evaluate_breakthrough_predictors <- function(df, predictors) {
  cat("\n--- Breakthrough Predictor Evaluation ---\n")
  
  # Input validation
  if (!is.data.frame(df)) stop("Input df is not a data frame")
  if (nrow(df) == 0) stop("Input dataframe is empty")
  if (is.null(predictors) || length(predictors) == 0) stop("No predictors provided")
  
  # Validate predictors exist in dataframe
  missing_predictors <- setdiff(predictors, names(df))
  if (length(missing_predictors) > 0) {
    warning("Missing predictors: ", paste(missing_predictors, collapse = ", "))
    predictors <- intersect(predictors, names(df))
  }
  
  if (length(predictors) == 0) stop("No valid predictors remain after filtering")
  cat("Using", length(predictors), "predictors for breakthrough analysis\n")
  
  # Prepare data with validation and adaptive age filtering
  tryCatch({
    # First, try broader age range to get sufficient breakthrough cases
    initial_data <- df %>%
      mutate(
        # Define breakthrough as achieving >50% in this season
        Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.5),
        Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                 labels = c("No", "Yes")),
        Age = as.numeric(Age)
      ) %>%
      filter(!is.na(Will_Breakthrough),
             !is.na(Pct_of_Max_Points),
             !is.na(Age)) %>%
      dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
      na.omit()
    
    # Check breakthrough distribution across age ranges
    breakthrough_by_age <- initial_data %>%
      filter(Will_Breakthrough == "Yes") %>%
      summarise(
        n_breakthroughs = n(),
        min_age = min(Age, na.rm = TRUE),
        max_age = max(Age, na.rm = TRUE),
        mean_age = mean(Age, na.rm = TRUE)
      )
    
    cat("Initial breakthrough cases found:", breakthrough_by_age$n_breakthroughs, "\n")
    if (breakthrough_by_age$n_breakthroughs > 0) {
      cat("Breakthrough age range:", round(breakthrough_by_age$min_age, 1), "-", round(breakthrough_by_age$max_age, 1), "\n")
    }
    
    # If still too few cases, try lower breakthrough threshold
    if (breakthrough_by_age$n_breakthroughs < 5) {
      cat("Very few breakthrough cases at 50% threshold, trying 40% threshold\n")
      initial_data <- df %>%
        mutate(
          # Lower threshold for breakthrough (40%)
          Will_Breakthrough = ifelse(is.na(Pct_of_Max_Points), NA, Pct_of_Max_Points >= 0.4),
          Will_Breakthrough = factor(Will_Breakthrough, levels = c(FALSE, TRUE), 
                                   labels = c("No", "Yes")),
          Age = as.numeric(Age)
        ) %>%
        filter(!is.na(Will_Breakthrough),
               !is.na(Pct_of_Max_Points),
               !is.na(Age)) %>%
        dplyr::select(Will_Breakthrough, Age, all_of(predictors)) %>%
        na.omit()
      
      # Recalculate breakthrough stats
      breakthrough_by_age <- initial_data %>%
        filter(Will_Breakthrough == "Yes") %>%
        summarise(
          n_breakthroughs = n(),
          min_age = min(Age, na.rm = TRUE),
          max_age = max(Age, na.rm = TRUE),
          mean_age = mean(Age, na.rm = TRUE)
        )
      
      cat("Breakthrough cases at 40% threshold:", breakthrough_by_age$n_breakthroughs, "\n")
    }
    
    # Use all ages for model training (no age restrictions for breakthrough potential)
    cat("Using all ages for breakthrough model training (no age restrictions)\n")
    
    model_data <- initial_data %>%
      dplyr::select(Will_Breakthrough, all_of(predictors))
    
    # Impute missing values with first quartile (using existing function)
    cat("\n--- Missing Data Imputation ---\n")
    for (pred in predictors) {
      if (pred %in% names(model_data)) {
        initial_nas <- sum(is.na(model_data[[pred]]))
        if (initial_nas > 0) {
          cat(sprintf("Imputing %d missing values in %s\n", initial_nas, pred))
          model_data[[pred]] <- replace_na_with_quartile(model_data[[pred]], pred)
          final_nas <- sum(is.na(model_data[[pred]]))
          cat(sprintf("  %s: %d -> %d NAs after imputation\n", pred, initial_nas, final_nas))
        }
      }
    }
    
    cat("✓ Data preparation completed\n")
    
  }, error = function(e) {
    stop("Error in data preparation: ", e$message)
  })
  
  print("Breakthrough data dimensions after filtering:")
  print(dim(model_data))
  
  # Validate class distribution
  breakthrough_dist <- table(model_data$Will_Breakthrough, useNA = "always")
  print("Breakthrough distribution:")
  print(breakthrough_dist)
  
  # Check for class imbalance with adaptive thresholds
  min_class_size <- min(breakthrough_dist[breakthrough_dist > 0])  # Exclude NA count
  breakthrough_count <- breakthrough_dist[["Yes"]]
  no_breakthrough_count <- breakthrough_dist[["No"]]
  
  cat("Breakthrough cases (Yes):", breakthrough_count, "\n")
  cat("Non-breakthrough cases (No):", no_breakthrough_count, "\n")
  
  # Adaptive validation based on data availability
  if (min_class_size < 2) {
    stop("Insufficient data for model training - need at least 2 cases per class")
  } else if (min_class_size < 5) {
    warning("Very few cases in minority class (", min_class_size, ") - model may be unstable")
  } else if (breakthrough_count < 10) {
    warning("Few breakthrough cases (", breakthrough_count, ") - consider this when interpreting results")
  }
  
  # Calculate class imbalance ratio
  imbalance_ratio <- max(breakthrough_count, no_breakthrough_count) / min(breakthrough_count, no_breakthrough_count)
  if (imbalance_ratio > 20) {
    warning("Severe class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  } else if (imbalance_ratio > 10) {
    warning("Moderate class imbalance detected (ratio: ", round(imbalance_ratio, 1), ":1)")
  }
  
  # Validate examples with error handling
  tryCatch({
    print("Sample breakthrough cases (Will_Breakthrough = Yes):")
    breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "Yes") %>% 
      head(10)
    
    if(nrow(breakthrough_examples) > 0) {
      print(breakthrough_examples)
      cat("✓ Breakthrough examples validated\n")
    } else {
      warning("No breakthrough examples found in filtered data!")
    }
    
  }, error = function(e) {
    warning("Error displaying breakthrough examples: ", e$message)
  })
  
  tryCatch({
    print("Sample non-breakthrough cases (Will_Breakthrough = No):")
    non_breakthrough_examples <- model_data %>% 
      filter(Will_Breakthrough == "No") %>% 
      head(10)
    
    if(nrow(non_breakthrough_examples) > 0) {
      print(non_breakthrough_examples)
      cat("✓ Non-breakthrough examples validated\n")
    } else {
      warning("No non-breakthrough examples found!")
    }
    
  }, error = function(e) {
    warning("Error displaying non-breakthrough examples: ", e$message)
  })
  
  # Cross-validation setup with adaptive parameters
  tryCatch({
    # Adaptive CV parameters based on data size
    if (nrow(model_data) < 50) {
      cv_method <- "LOOCV"  # Leave-one-out for very small datasets
      cv_number <- NULL
    } else if (nrow(model_data) < 200) {
      cv_method <- "cv"
      cv_number <- 5  # 5-fold for small datasets
    } else {
      cv_method <- "cv"
      cv_number <- 10  # 10-fold for larger datasets
    }
    
    if (cv_method == "LOOCV") {
      ctrl <- trainControl(method = "LOOCV", classProbs = TRUE, summaryFunction = twoClassSummary)
      cat("Using Leave-One-Out Cross-Validation\n")
    } else {
      ctrl <- trainControl(method = cv_method, number = cv_number, classProbs = TRUE, summaryFunction = twoClassSummary)
      cat("Using", cv_number, "-fold Cross-Validation\n")
    }
    
  }, error = function(e) {
    stop("Error setting up cross-validation: ", e$message)
  })
  
  # Train logistic model with validation
  tryCatch({
    breakthrough_formula <- as.formula(paste("Will_Breakthrough ~", paste(predictors, collapse = " + ")))
    cat("Training logistic regression model with", length(predictors), "predictors\n")
    
    logistic_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "glm",
      family = "binomial",
      trControl = ctrl,
      metric = "ROC"
    )
    
    cat("✓ Logistic regression model trained\n")
    
    # Extract coefficient importance
    logistic_coefs <- summary(logistic_model$finalModel)$coefficients
    logistic_importance <- abs(logistic_coefs[-1, "Estimate"])  # Exclude intercept
    names(logistic_importance) <- rownames(logistic_coefs)[-1]
    
  }, error = function(e) {
    stop("Error training logistic regression: ", e$message)
  })
  
  # Train Random Forest with validation
  tryCatch({
    cat("Training Random Forest model for variable importance\n")
    
    rf_model <- train(
      breakthrough_formula,
      data = model_data,
      method = "ranger",
      trControl = ctrl,
      importance = 'impurity',
      metric = "ROC"
    )
    
    cat("✓ Random Forest model trained\n")
    
    # Extract variable importance
    rf_importance <- rf_model$finalModel$variable.importance
    
  }, error = function(e) {
    warning("Error training Random Forest - using logistic regression only: ", e$message)
    rf_model <- NULL
    rf_importance <- NULL
  })
  
  # Combine and rank importance scores with validation
  tryCatch({
    if (!is.null(rf_importance)) {
      # Normalize importance scores to 0-1 scale
      logistic_norm <- (logistic_importance - min(logistic_importance)) / 
                      (max(logistic_importance) - min(logistic_importance))
      rf_norm <- (rf_importance - min(rf_importance)) / 
                 (max(rf_importance) - min(rf_importance))
      
      # Combine scores (equal weighting)
      common_vars <- intersect(names(logistic_norm), names(rf_norm))
      combined_importance <- (logistic_norm[common_vars] + rf_norm[common_vars]) / 2
      
      # Create comprehensive importance dataframe
      importance_df <- data.frame(
        Variable = common_vars,
        Logistic_Importance = logistic_norm[common_vars],
        RF_Importance = rf_norm[common_vars],
        Combined_Importance = combined_importance,
        stringsAsFactors = FALSE
      ) %>%
        arrange(desc(Combined_Importance))
      
      cat("✓ Combined importance scores calculated\n")
      
    } else {
      # Use only logistic regression importance
      importance_df <- data.frame(
        Variable = names(logistic_importance),
        Logistic_Importance = logistic_importance,
        RF_Importance = NA,
        Combined_Importance = logistic_importance,
        stringsAsFactors = FALSE
      ) %>%
        arrange(desc(Combined_Importance))
      
      cat("✓ Logistic-only importance scores calculated\n")
    }
    
  }, error = function(e) {
    stop("Error calculating variable importance: ", e$message)
  })
  
  # Model performance comparison with validation
  tryCatch({
    models_list <- list(Logistic = logistic_model)
    if (!is.null(rf_model)) {
      models_list$RandomForest <- rf_model
    }
    
    model_comparison <- resamples(models_list)
    performance_summary <- summary(model_comparison)
    
    cat("✓ Model performance comparison completed\n")
    
  }, error = function(e) {
    warning("Error in model comparison: ", e$message)
    model_comparison <- NULL
    performance_summary <- NULL
  })
  
  # Select top predictors with validation
  tryCatch({
    # Select top predictors (up to 5, or fewer if not enough predictors)
    n_top <- min(5, nrow(importance_df))
    top_predictors <- importance_df$Variable[1:n_top]
    
    cat("✓ Top", n_top, "predictors selected\n")
    
    # Train reduced model with only top predictors
    if (n_top >= 2) {  # Need at least 2 predictors for meaningful model
      reduced_formula <- as.formula(paste("Will_Breakthrough ~", paste(top_predictors, collapse = " + ")))
      
      reduced_model <- train(
        reduced_formula,
        data = model_data,
        method = "glm",
        family = "binomial",
        trControl = ctrl,
        metric = "ROC"
      )
      
      cat("✓ Reduced model with top predictors trained\n")
      
      # Add coefficient direction validation for breakthrough prediction
      cat("\n--- Nordic Combined Breakthrough Model Coefficient Validation ---\n")
      tryCatch({
        # Get logistic regression coefficients
        logistic_coefs <- summary(reduced_model$finalModel)$coefficients
        
        # Expected positive coefficients for breakthrough prediction (nordic combined specific)
        expected_positive_vars <- c("Prev_Pelo", "Prev_Individual", "Prev_IndividualCompact", 
                                    "Prev_MassStart", "Prev_Pct_of_Max_Points")
        expected_negative_vars <- c("Age")  # Younger athletes more likely to breakthrough
        
        cat("=== DEBUG: Predictor Values Used ===\n")
        for (var in top_predictors) {
          if (var %in% names(model_data)) {
            vals <- model_data[[var]]
            cat(sprintf("%s: min=%.3f, max=%.3f, mean=%.3f, na_count=%d\n", 
                       var, min(vals, na.rm=TRUE), max(vals, na.rm=TRUE), 
                       mean(vals, na.rm=TRUE), sum(is.na(vals))))
          }
        }
        
        # Check coefficient directions
        for (var in top_predictors) {
          if (var %in% rownames(logistic_coefs)) {
            coef_value <- logistic_coefs[var, "Estimate"]
            coef_pvalue <- logistic_coefs[var, "Pr(>|z|)"]
            
            # Check if coefficient direction matches expectation
            if (var %in% expected_positive_vars) {
              if (coef_value > 0) {
                cat("✓", var, "has positive coefficient (", round(coef_value, 4), ") - VALID for breakthrough prediction\n")
              } else {
                cat("⚠️  WARNING:", var, "has negative coefficient (", round(coef_value, 4), ") - unexpected for breakthrough prediction\n")
              }
            } else if (var %in% expected_negative_vars) {
              if (coef_value < 0) {
                cat("✓", var, "has negative coefficient (", round(coef_value, 4), ") - VALID for breakthrough prediction\n")
              } else {
                cat("⚠️  WARNING:", var, "has positive coefficient (", round(coef_value, 4), ") - unexpected for breakthrough prediction\n")
              }
            } else {
              # For other variables, include regardless of direction but note it
              cat("?", var, "has coefficient (", round(coef_value, 4), ") - included (direction not specified)\n")
            }
            
            # Also check statistical significance
            if (coef_pvalue > 0.1) {
              cat("  NOTE:", var, "p-value =", round(coef_pvalue, 4), "(not significant at 0.1 level)\n")
            }
          }
        }
        
        # Implement intelligent model selection to find best model with correct coefficient directions
        cat("\n--- Intelligent Model Selection for Correct Coefficient Directions ---\n")
        
        # Define core predictors we want to prioritize
        core_predictors <- c("Age", "Prev_Pct_of_Max_Points")
        available_predictors <- intersect(top_predictors, names(model_data))
        
        # Function to check if all coefficients have correct directions
        check_coefficient_directions <- function(model_coefs, predictors_used) {
          all_correct <- TRUE
          for (var in predictors_used) {
            if (var %in% rownames(model_coefs)) {
              coef_value <- model_coefs[var, "Estimate"]
              if (var %in% expected_positive_vars && coef_value <= 0) {
                all_correct <- FALSE
              } else if (var %in% expected_negative_vars && coef_value >= 0) {
                all_correct <- FALSE
              }
            }
          }
          return(all_correct)
        }
        
        best_model <- NULL
        best_predictors <- NULL
        best_roc <- 0
        best_directions_correct <- FALSE
        
        # Try different combinations, starting with simpler models
        for (n_predictors in 2:min(6, length(available_predictors))) {
          # Always include Age if available
          if ("Age" %in% available_predictors) {
            remaining_predictors <- setdiff(available_predictors, "Age")
            
            # Try combinations that include Age
            if (n_predictors > 1 && length(remaining_predictors) >= (n_predictors - 1)) {
              combinations <- combn(remaining_predictors, n_predictors - 1, simplify = FALSE)
              
              for (combo in combinations[1:min(20, length(combinations))]) {  # Limit to 20 combinations
                test_predictors <- c("Age", combo)
                
                tryCatch({
                  test_formula <- as.formula(paste("Will_Breakthrough ~", paste(test_predictors, collapse = " + ")))
                  
                  test_model <- train(
                    test_formula,
                    data = model_data,
                    method = "glm",
                    family = "binomial",
                    trControl = ctrl,
                    metric = "ROC"
                  )
                  
                  test_roc <- max(test_model$results$ROC, na.rm = TRUE)
                  test_coefs <- summary(test_model$finalModel)$coefficients
                  directions_correct <- check_coefficient_directions(test_coefs, test_predictors)
                  
                  # Prioritize models with correct directions, then by ROC
                  is_better <- FALSE
                  if (directions_correct && !best_directions_correct) {
                    is_better <- TRUE  # First model with correct directions
                  } else if (directions_correct && best_directions_correct && test_roc > best_roc) {
                    is_better <- TRUE  # Better ROC among models with correct directions
                  } else if (!directions_correct && !best_directions_correct && test_roc > best_roc) {
                    is_better <- TRUE  # Better ROC when no good directions found yet
                  }
                  
                  if (is_better) {
                    best_model <- test_model
                    best_predictors <- test_predictors
                    best_roc <- test_roc
                    best_directions_correct <- directions_correct
                    
                    cat("New best model found:", paste(test_predictors, collapse = ", "), 
                        "ROC:", round(test_roc, 3), 
                        "Directions:", ifelse(directions_correct, "✓ Correct", "✗ Wrong"), "\n")
                  }
                  
                }, error = function(e) {
                  # Skip combinations that fail
                })
              }
            }
          }
        }
        
        # Use the best model found
        if (!is.null(best_model)) {
          reduced_model <- best_model
          top_predictors <- best_predictors
          
          cat("\n--- Final Selected Model ---\n")
          cat("Selected predictors:", paste(best_predictors, collapse = ", "), "\n")
          cat("Model ROC:", round(best_roc, 3), "\n")
          cat("All coefficients correct direction:", ifelse(best_directions_correct, "✓ Yes", "✗ No"), "\n")
          
          # Show final coefficients
          final_coefs <- summary(best_model$finalModel)$coefficients
          cat("\nFinal model coefficients:\n")
          for (var in best_predictors) {
            if (var %in% rownames(final_coefs)) {
              coef_value <- final_coefs[var, "Estimate"]
              coef_pvalue <- final_coefs[var, "Pr(>|z|)"]
              direction_ok <- ""
              if (var %in% expected_positive_vars) {
                direction_ok <- ifelse(coef_value > 0, "✓", "✗")
              } else if (var %in% expected_negative_vars) {
                direction_ok <- ifelse(coef_value < 0, "✓", "✗")
              }
              cat(sprintf("  %s %s: coef=%.4f, p=%.4f\n", direction_ok, var, coef_value, coef_pvalue))
            }
          }
        } else {
          cat("No valid model found - keeping original\n")
        }
        
      }, error = function(e) {
        cat("Error in nordic combined breakthrough coefficient validation:", e$message, "\n")
      })
    } else {
      warning("Too few predictors for reduced model")
      reduced_model <- logistic_model
    }
    
  }, error = function(e) {
    warning("Error creating reduced model: ", e$message)
    top_predictors <- predictors[1:min(3, length(predictors))]  # Fallback
    reduced_model <- logistic_model
  })
  
  # Return comprehensive results
  return(list(
    importance = importance_df,
    top_predictors = top_predictors,
    full_model = logistic_model,
    reduced_model = reduced_model,
    rf_model = rf_model,
    model_comparison = model_comparison,
    performance = performance_summary,
    data_summary = list(
      n_observations = nrow(model_data),
      n_breakthrough = breakthrough_count,
      n_no_breakthrough = no_breakthrough_count,
      age_cutoff = "No age restriction"
    )
  ))
}

# Nordic Combined predictors from Elo preparation section
nc_predictors <- c("Prev_Pelo", "Prev_Individual", "Prev_IndividualCompact", 
                   "Prev_MassStart", "Prev_Pct_of_Max_Points", "Age")

# Train breakthrough prediction models for men
cat("\n=== MEN'S NORDIC COMBINED BREAKTHROUGH MODELS ===\n")
men_breakthrough_results <- evaluate_breakthrough_predictors(
  df = train_men,
  predictors = nc_predictors
)

# Train breakthrough prediction models for ladies  
cat("\n=== LADIES NORDIC COMBINED BREAKTHROUGH MODELS ===\n")
ladies_breakthrough_results <- evaluate_breakthrough_predictors(
  df = train_ladies,
  predictors = nc_predictors
)

# Model performance summary
cat("\n=== NORDIC COMBINED MODEL PERFORMANCE SUMMARY ===\n")

# Men's model summary
if (!is.null(men_breakthrough_results$reduced_model)) {
  cat("Men's Nordic Combined Breakthrough Model:\n")
  cat("  Selected predictors:", paste(men_breakthrough_results$top_predictors, collapse = ", "), "\n")
  
  # Get performance metrics
  if (!is.null(men_breakthrough_results$model_comparison)) {
    perf_metrics <- summary(men_breakthrough_results$model_comparison)
    if ("Logistic" %in% names(perf_metrics$statistics$ROC)) {
      men_roc <- round(perf_metrics$statistics$ROC$Logistic["Mean"], 3)
      cat("  Cross-validation ROC:", men_roc, "\n")
    }
  }
  
  cat("  Data summary:\n")
  cat("    Total observations:", men_breakthrough_results$data_summary$n_observations, "\n")
  cat("    Breakthrough cases:", men_breakthrough_results$data_summary$n_breakthrough, "\n")
  cat("    Non-breakthrough cases:", men_breakthrough_results$data_summary$n_no_breakthrough, "\n")
} else {
  cat("Men's model training failed\n")
}

# Ladies model summary
if (!is.null(ladies_breakthrough_results$reduced_model)) {
  cat("\nLadies Nordic Combined Breakthrough Model:\n")
  cat("  Selected predictors:", paste(ladies_breakthrough_results$top_predictors, collapse = ", "), "\n")
  
  # Get performance metrics
  if (!is.null(ladies_breakthrough_results$model_comparison)) {
    perf_metrics <- summary(ladies_breakthrough_results$model_comparison)
    if ("Logistic" %in% names(perf_metrics$statistics$ROC)) {
      ladies_roc <- round(perf_metrics$statistics$ROC$Logistic["Mean"], 3)
      cat("  Cross-validation ROC:", ladies_roc, "\n")
    }
  }
  
  cat("  Data summary:\n")
  cat("    Total observations:", ladies_breakthrough_results$data_summary$n_observations, "\n")
  cat("    Breakthrough cases:", ladies_breakthrough_results$data_summary$n_breakthrough, "\n")
  cat("    Non-breakthrough cases:", ladies_breakthrough_results$data_summary$n_no_breakthrough, "\n")
} else {
  cat("Ladies model training failed\n")
}

# Store models for future use
breakthrough_models_men <- men_breakthrough_results
breakthrough_models_ladies <- ladies_breakthrough_results

cat("\n✓ Nordic Combined breakthrough prediction models completed\n")
cat("✓ Cross-validation performance evaluated\n") 
cat("✓ Feature importance analysis completed\n")
cat("✓ Models ready for 2026 breakthrough candidate prediction\n")
```

### 2026 Breakthrough Candidates

```{r big-break}
# Load required libraries for machine learning and comprehensive breakthrough analysis
tryCatch({
  library(caret)
  library(ranger)
  library(pROC)
  library(openxlsx)
  cat("✓ Required libraries loaded successfully\n")
}, error = function(e) {
  stop("Error loading required libraries: ", e$message)
})

# Enhanced missing data imputation function (consistent with training preparation)
replace_na_with_quartile <- function(x) {
  if (all(is.na(x))) return(x)
  quartiles <- quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)
  first_quartile_val <- quartiles[1]  # Use first quartile for nordic combined
  x[is.na(x)] <- first_quartile_val
  return(x)
}

# Comprehensive function to predict 2026 breakthrough candidates with enhanced validation
predict_2026_breakthroughs <- function(current_data, breakthrough_model, top_predictors, gender_label) {
  cat(sprintf("\n=== Predicting 2026 %s Nordic Combined Breakthrough Candidates ===\n", gender_label))
  
  # Enhanced input validation
  if (!is.data.frame(current_data)) stop("current_data is not a data frame")
  if (nrow(current_data) == 0) stop("current_data is empty")
  if (is.null(breakthrough_model)) stop("breakthrough_model is NULL")
  if (is.null(top_predictors) || length(top_predictors) == 0) stop("No top_predictors provided")
  
  cat(sprintf("Input validation passed: %d total %s records\n", nrow(current_data), gender_label))
  
  # Nordic Combined specific predictor mapping (training variables → current data variables)
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Individual" = "Individual_Pelo",
    "Prev_IndividualCompact" = "IndividualCompact_Pelo",
    "Prev_MassStart" = "MassStart_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points",
    "Age" = "Age"
  )
  
  # Get 2025 season data as most recent complete season
  tryCatch({
    season_2025 <- current_data %>%
      filter(Season == 2025) %>%
      group_by(Skier) %>%
      slice_tail(n = 1) %>%  # Most recent record per skier in 2025
      ungroup()
    
    if (nrow(season_2025) == 0) {
      warning(sprintf("No 2025 data available for %s breakthrough prediction", gender_label))
      return(data.frame())
    }
    
    cat(sprintf("✓ Found %d %s skiers in 2025 season data\n", nrow(season_2025), gender_label))
    
  }, error = function(e) {
    stop("Error extracting 2025 season data: ", e$message)
  })
  
  # Calculate comprehensive career statistics
  tryCatch({
    career_maximums <- current_data %>%
      filter(!is.na(Pct_of_Max_Points)) %>%
      group_by(Skier) %>%
      summarise(
        Career_Max_Pct = max(Pct_of_Max_Points, na.rm = TRUE),
        Career_Seasons = n_distinct(Season),
        Career_Races = n(),
        First_Season = min(Season, na.rm = TRUE),
        Last_Season = max(Season, na.rm = TRUE),
        Avg_Performance = mean(Pct_of_Max_Points, na.rm = TRUE),
        .groups = "drop"
      )
    
    cat(sprintf("✓ Career statistics calculated for %d skiers\n", nrow(career_maximums)))
    
  }, error = function(e) {
    stop("Error calculating career statistics: ", e$message)
  })
  
  # Identify breakthrough candidates with comprehensive filtering
  tryCatch({
    prediction_data <- season_2025 %>%
      left_join(career_maximums, by = "Skier") %>%
      filter(
        # Nordic Combined: Exclude skiers who already achieved 50% breakthrough threshold
        Career_Max_Pct < 0.5,
        # Age range: minimum 16 (junior age) with no upper limit for breakthrough potential
        Age >= 16,
        # Must have meaningful competitive activity in 2025 (>1% of max points)
        Pct_of_Max_Points > 0.01,
        # Must have complete data for key variables
        !is.na(Age), !is.na(Pct_of_Max_Points)
      )
    
    # Calculate detailed filtering statistics
    total_skiers <- nrow(season_2025)
    already_breakthrough <- sum(career_maximums$Career_Max_Pct >= 0.5, na.rm = TRUE)
    too_young <- sum(season_2025$Age < 16, na.rm = TRUE)
    inactive_2025 <- sum(season_2025$Pct_of_Max_Points <= 0.01, na.rm = TRUE)
    missing_data <- sum(is.na(season_2025$Age) | is.na(season_2025$Pct_of_Max_Points))
    final_candidates <- nrow(prediction_data)
    
    cat(sprintf("\n--- %s Breakthrough Candidate Filtering ---\n", gender_label))
    cat(sprintf("Total %s skiers in 2025: %d\n", gender_label, total_skiers))
    cat(sprintf("Already achieved breakthrough (≥50%%): %d excluded\n", already_breakthrough))
    cat(sprintf("Too young (<16 years): %d excluded\n", too_young))
    cat(sprintf("Inactive in 2025 (≤1%% max points): %d excluded\n", inactive_2025))
    cat(sprintf("Missing key data: %d excluded\n", missing_data))
    cat(sprintf("Final breakthrough candidates: %d\n", final_candidates))
    
    if (nrow(prediction_data) == 0) {
      warning(sprintf("No eligible %s breakthrough candidates identified", gender_label))
      return(data.frame())
    }
    
  }, error = function(e) {
    stop("Error filtering breakthrough candidates: ", e$message)
  })
  
  # Debug information for key athletes (Nordic Combined representatives)
  debug_athletes <- c("Joergen Graabak", "Jens Luraas Oftebro")  # Norwegian men's representatives
  if (gender_label == "Ladies") {
    debug_athletes <- c("Gyda Westvold Hansen", "Mari Leinan Lund")  # Norwegian ladies representatives  
  }
  
  for (athlete in debug_athletes) {
    if (athlete %in% prediction_data$Skier) {
      athlete_idx <- which(prediction_data$Skier == athlete)
      cat(sprintf("\n=== DEBUG: %s Breakthrough Model Input ===\n", athlete))
      athlete_data <- prediction_data[athlete_idx, ]
      cat(sprintf("Age: %.1f\n", athlete_data$Age))
      cat(sprintf("2025 Performance: %.1f%% of max points\n", athlete_data$Pct_of_Max_Points * 100))
      cat(sprintf("Career Maximum: %.1f%% of max points\n", athlete_data$Career_Max_Pct * 100))
      cat(sprintf("Career Seasons: %d\n", athlete_data$Career_Seasons))
      cat(sprintf("Improvement Potential: %.1f points\n", (0.5 - athlete_data$Career_Max_Pct) * 100))
    }
  }
  
  # Feature mapping and validation
  tryCatch({
    # Map current 2025 performance to "Prev_" variables that the trained model expects
    feature_mapping <- predictor_mapping[names(predictor_mapping) %in% top_predictors]
    
    cat(sprintf("\n--- Feature Mapping for %s Prediction ---\n", gender_label))
    cat(sprintf("Top predictors from model: %s\n", paste(top_predictors, collapse = ", ")))
    
    # Apply feature mapping
    for (prev_feature in names(feature_mapping)) {
      current_feature <- feature_mapping[[prev_feature]]
      if (prev_feature %in% top_predictors && current_feature %in% names(prediction_data)) {
        prediction_data[[prev_feature]] <- prediction_data[[current_feature]]
        cat(sprintf("✓ Mapped %s -> %s\n", current_feature, prev_feature))
      } else if (prev_feature %in% top_predictors) {
        cat(sprintf("✗ Missing feature: %s (needed for %s)\n", current_feature, prev_feature))
      }
    }
    
    # Validate predictor availability
    available_predictors <- intersect(top_predictors, names(prediction_data))
    missing_predictors <- setdiff(top_predictors, names(prediction_data))
    
    if (length(missing_predictors) > 0) {
      cat(sprintf("WARNING: Missing predictors: %s\n", paste(missing_predictors, collapse = ", ")))
    }
    
    if (length(available_predictors) == 0) {
      stop(sprintf("No valid predictors available for %s breakthrough prediction", gender_label))
    }
    
    cat(sprintf("Using %d/%d predictors: %s\n", 
                length(available_predictors), length(top_predictors),
                paste(available_predictors, collapse = ", ")))
    
  }, error = function(e) {
    stop("Error in feature mapping: ", e$message)
  })
  
  # Data quality checks and missing value handling
  tryCatch({
    prediction_clean <- prediction_data %>%
      dplyr::select(all_of(c("Skier", "Nation", "Age", "Pct_of_Max_Points", 
                      "Career_Max_Pct", "Career_Seasons", "Career_Races", available_predictors)))
    
    # Check for missing values in predictors
    missing_counts <- prediction_clean %>%
      dplyr::select(all_of(available_predictors)) %>%
      summarise_all(~sum(is.na(.)))
    
    cat(sprintf("\n--- Missing Value Analysis for %s ---\n", gender_label))
    for (predictor in available_predictors) {
      missing_count <- missing_counts[[predictor]]
      missing_pct <- round(missing_count / nrow(prediction_clean) * 100, 1)
      cat(sprintf("%s: %d missing (%.1f%%)\n", predictor, missing_count, missing_pct))
    }
    
    # Apply quartile imputation for missing values (consistent with training)
    prediction_clean <- prediction_clean %>%
      mutate(across(all_of(available_predictors), replace_na_with_quartile))
    
    # Check for infinite values and replace with NA
    infinite_counts <- prediction_clean %>%
      dplyr::select(all_of(available_predictors)) %>%
      summarise_all(~sum(is.infinite(.)))
    
    if (sum(infinite_counts) > 0) {
      cat("WARNING: Found infinite values in predictors, replacing with NA\n")
      prediction_clean <- prediction_clean %>%
        mutate(across(all_of(available_predictors), ~ifelse(is.infinite(.), NA, .)))
    }
    
    cat(sprintf("✓ Data quality validation completed for %d candidates\n", nrow(prediction_clean)))
    
  }, error = function(e) {
    stop("Error in data quality checks: ", e$message)
  })  
  # Generate breakthrough probability predictions
  tryCatch({
    # Use the trained model for breakthrough predictions
    breakthrough_probs <- tryCatch({
      predict(breakthrough_model, newdata = prediction_clean, type = "prob")
    }, error = function(e) {
      cat(sprintf("Initial prediction failed: %s\n", e$message))
      cat("Attempting fallback prediction with na.action = na.pass\n")
      predict(breakthrough_model, newdata = prediction_clean, type = "prob", na.action = na.pass)
    })
    
    # Extract breakthrough probabilities ("Yes" class)
    if ("Yes" %in% colnames(breakthrough_probs)) {
      prob_values <- breakthrough_probs[, "Yes"]
    } else if (ncol(breakthrough_probs) == 2) {
      prob_values <- breakthrough_probs[, 2]  # Assume second column is positive class
    } else {
      prob_values <- breakthrough_probs[, 1]  # Fallback
    }
    
    cat(sprintf("✓ Breakthrough predictions generated for %d candidates\n", length(prob_values)))
    cat(sprintf("Probability range: %.1f%% to %.1f%%\n", 
                min(prob_values, na.rm = TRUE) * 100, 
                max(prob_values, na.rm = TRUE) * 100))
    
  }, error = function(e) {
    stop("Error generating breakthrough predictions: ", e$message)
  })
  
  # Create comprehensive results with enhanced classification
  tryCatch({
    breakthrough_results <- prediction_clean %>%
      mutate(
        Breakthrough_Prob = prob_values,
        Breakthrough_Result = NA_real_,  # For 2026 predictions (unknown)
        
        # Nordic Combined breakthrough likelihood classification
        Likelihood = case_when(
          is.na(Breakthrough_Prob) ~ "Unknown",
          Breakthrough_Prob >= 0.6 ~ "Very High",
          Breakthrough_Prob >= 0.4 ~ "High", 
          Breakthrough_Prob >= 0.2 ~ "Moderate",
          Breakthrough_Prob >= 0.1 ~ "Low",
          TRUE ~ "Very Low"
        ),
        
        # Performance metrics
        Current_Performance_Pct = round(Pct_of_Max_Points * 100, 1),
        Career_Best_Pct = round(Career_Max_Pct * 100, 1),
        Points_to_Threshold = pmax(0, 0.5 - Pct_of_Max_Points, na.rm = TRUE) * 100,
        Improvement_Potential = round((0.5 - Career_Max_Pct) * 100, 1),
        
        # Additional context
        Season = 2026,
        Type = "2026 Prediction"
      ) %>%
      arrange(desc(Breakthrough_Prob))
    
    cat(sprintf("✓ Results processing completed for %d candidates\n", nrow(breakthrough_results)))
    
  }, error = function(e) {
    stop("Error creating results dataframe: ", e$message)
  })
  
  # Enhanced summary statistics
  tryCatch({
    total_candidates <- nrow(breakthrough_results)
    
    # Likelihood distribution
    likelihood_summary <- breakthrough_results %>%
      count(Likelihood) %>%
      arrange(desc(n))
    
    cat(sprintf("\n--- %s Breakthrough Prediction Summary ---\n", gender_label))
    cat(sprintf("Total candidates analyzed: %d\n", total_candidates))
    
    for (i in 1:nrow(likelihood_summary)) {
      likelihood <- likelihood_summary$Likelihood[i]
      count <- likelihood_summary$n[i]
      pct <- round(count / total_candidates * 100, 1)
      cat(sprintf("%s likelihood: %d candidates (%.1f%%)\n", likelihood, count, pct))
    }
    
    # Age analysis for high-potential candidates
    high_potential <- breakthrough_results %>%
      filter(Likelihood %in% c("Very High", "High", "Moderate"))
    
    if (nrow(high_potential) > 0) {
      age_range <- range(high_potential$Age, na.rm = TRUE)
      avg_age <- mean(high_potential$Age, na.rm = TRUE)
      cat(sprintf("\nHigh-potential candidates age analysis:\n"))
      cat(sprintf("Age range: %.1f - %.1f years\n", age_range[1], age_range[2]))
      cat(sprintf("Average age: %.1f years\n", avg_age))
      
      # Young prospects (under 25)
      young_prospects <- sum(high_potential$Age < 25, na.rm = TRUE)
      cat(sprintf("Young prospects (under 25): %d\n", young_prospects))
    }
    
  }, error = function(e) {
    warning("Error calculating summary statistics: ", e$message)
  })
  
  return(breakthrough_results)
}

# Enhanced function for historical breakthrough prediction with debugging
predict_historical_breakthrough <- function(historical_data, breakthrough_model, top_predictors) {
  cat("\n--- Applying 2026 Model to Pre-Breakthrough Historical Cases ---\n")
  
  if (nrow(historical_data) == 0) {
    cat("No historical data provided\n")
    return(data.frame())
  }
  
  # Nordic Combined predictor mapping for historical validation
  predictor_mapping <- c(
    "Prev_Pelo" = "Pelo",
    "Prev_Individual" = "Individual_Pelo",
    "Prev_IndividualCompact" = "IndividualCompact_Pelo",
    "Prev_MassStart" = "MassStart_Pelo",
    "Prev_Pct_of_Max_Points" = "Pct_of_Max_Points",
    "Age" = "Age"
  )
  
  tryCatch({
    # Create prediction dataset by mapping pre-breakthrough values to "Prev_" model variables
    prediction_data <- historical_data
    
    cat(sprintf("Processing %d historical cases\n", nrow(prediction_data)))
    
    # Debug: Show sample of input data
    if (nrow(prediction_data) > 0) {
      sample_case <- prediction_data[1, ]
      cat(sprintf("Sample case: %s, Season %d, Pre-breakthrough: %.1f%%, Will breakthrough in %d with %.1f%%\n",
                  sample_case$Skier, sample_case$Season, 
                  sample_case$Pre_Breakthrough_Pct * 100,
                  sample_case$Breakthrough_Season,
                  sample_case$Breakthrough_Performance * 100))
    }
    
    # Apply feature mapping for historical validation
    for (prev_var in names(predictor_mapping)) {
      if (prev_var %in% top_predictors) {
        current_var <- predictor_mapping[[prev_var]]
        if (current_var %in% names(prediction_data)) {
          prediction_data[[prev_var]] <- prediction_data[[current_var]]
          cat(sprintf("✓ Mapped %s -> %s\n", current_var, prev_var))
        } else {
          cat(sprintf("✗ Missing feature: %s\n", current_var))
        }
      }
    }
    
    # Handle missing values with quartile imputation
    available_predictors <- intersect(top_predictors, names(prediction_data))
    cat(sprintf("Available predictors: %s\n", paste(available_predictors, collapse = ", ")))
    
    for (predictor in available_predictors) {
      missing_count <- sum(is.na(prediction_data[[predictor]]))
      if (missing_count > 0) {
        q1_val <- quantile(prediction_data[[predictor]], 0.25, na.rm = TRUE)
        prediction_data[[predictor]][is.na(prediction_data[[predictor]])] <- q1_val
        cat(sprintf("Imputed %d missing values for %s using Q1 = %.3f\n", 
                    missing_count, predictor, q1_val))
      }
    }
    
    # Generate predictions for historical cases
    historical_probs <- predict(breakthrough_model, newdata = prediction_data, type = "prob")
    
    if ("Yes" %in% colnames(historical_probs)) {
      prob_values <- historical_probs[, "Yes"]
    } else {
      prob_values <- historical_probs[, 2]  # Assume second column is "Yes"
    }
    
    cat(sprintf("Generated predictions for %d cases, probability range: %.1f%% - %.1f%%\n",
                length(prob_values), min(prob_values) * 100, max(prob_values) * 100))
    
    # Debug: Check dimensions before mutate
    cat(sprintf("prediction_data rows: %d, prob_values length: %d\\n", 
                nrow(prediction_data), length(prob_values)))
    
    # Ensure prob_values length matches dataframe rows
    if (length(prob_values) != nrow(prediction_data)) {
      warning(sprintf("Length mismatch: prediction_data has %d rows but prob_values has %d elements", 
                      nrow(prediction_data), length(prob_values)))
      # Truncate or pad as needed
      if (length(prob_values) > nrow(prediction_data)) {
        prob_values <- prob_values[1:nrow(prediction_data)]
      } else {
        prob_values <- c(prob_values, rep(NA, nrow(prediction_data) - length(prob_values)))
      }
      cat(sprintf("Adjusted prob_values length to: %d\\n", length(prob_values)))
    }
    
    # Create results with correct historical context
    historical_results <- tryCatch({
      # Verify required columns exist
      required_cols <- c("Breakthrough_Performance", "Pre_Breakthrough_Pct", "Season", 
                        "Age_at_Prediction", "Breakthrough_Season", "Skier", "Nation")
      missing_cols <- setdiff(required_cols, names(prediction_data))
      
      if (length(missing_cols) > 0) {
        cat(sprintf("Missing required columns: %s\\n", paste(missing_cols, collapse = ", ")))
        return(data.frame())
      }
      
      # Create a completely new dataframe with only the columns we need
      results_df <- data.frame(
        Skier = prediction_data$Skier,
        Nation = prediction_data$Nation,
        Age = prediction_data$Age_at_Prediction,
        Breakthrough_Prob = as.numeric(prob_values),
        Breakthrough_Result = round(prediction_data$Breakthrough_Performance * 100, 1),
        Pct_of_Max_Points = prediction_data$Pre_Breakthrough_Pct,
        Pre_Breakthrough_Display = round(prediction_data$Pre_Breakthrough_Pct * 100, 1),
        Breakthrough_Season = prediction_data$Breakthrough_Season,
        Breakthrough_Performance = prediction_data$Breakthrough_Performance,
        Season = prediction_data$Season,
        Type = "Historical Success",
        stringsAsFactors = FALSE
      )
      
      return(results_df)
    }, error = function(e) {
      cat(sprintf("Error in historical validation: %s\\n", e$message))
      cat(sprintf("prediction_data columns: %s\\n", paste(names(prediction_data), collapse = ", ")))
      cat(sprintf("prob_values class: %s, length: %d\\n", class(prob_values), length(prob_values)))
      return(data.frame())
    })
    
    # Debug output
    if (nrow(historical_results) > 0) {
      cat("\nSample historical results:\n")
      for (i in 1:min(3, nrow(historical_results))) {
        result <- historical_results[i, ]
        cat(sprintf("  %s: Pre-season %d (%.1f%%) -> Predicted %.1f%% -> Actual breakthrough %.1f%%\n",
                    result$Skier, result$Season, result$Pre_Breakthrough_Display,
                    result$Breakthrough_Prob * 100, result$Breakthrough_Result))
      }
    }
    
    cat(sprintf("✓ Historical validation completed for %d breakthrough cases\n", nrow(historical_results)))
    
    return(historical_results)
    
  }, error = function(e) {
    cat(sprintf("Error in historical breakthrough prediction: %s\n", e$message))
    cat(sprintf("Available columns: %s\n", paste(names(historical_data), collapse = ", ")))
    return(data.frame())
  })
}

# Execute breakthrough prediction analysis
cat("\n=== 2026 NORDIC COMBINED BREAKTHROUGH PREDICTION ANALYSIS ===\n")

# Validate that trained models exist
if (!exists("breakthrough_models_men") || is.null(breakthrough_models_men)) {
  stop("Men's breakthrough model not found. Ensure feat-select-break section completed successfully.")
}
if (!exists("breakthrough_models_ladies") || is.null(breakthrough_models_ladies)) {
  stop("Ladies breakthrough model not found. Ensure feat-select-break section completed successfully.")
}

# Men's breakthrough prediction
men_breakthrough_predictions <- predict_2026_breakthroughs(
  current_data = train_men,
  breakthrough_model = breakthrough_models_men$reduced_model,
  top_predictors = breakthrough_models_men$top_predictors,
  gender_label = "Men's"
)

# Ladies breakthrough prediction
ladies_breakthrough_predictions <- predict_2026_breakthroughs(
  current_data = train_ladies,
  breakthrough_model = breakthrough_models_ladies$reduced_model,
  top_predictors = breakthrough_models_ladies$top_predictors,
  gender_label = "Ladies"
)

# Display comprehensive breakthrough analysis results
cat("\n=== 2026 NORDIC COMBINED BREAKTHROUGH PREDICTION RESULTS ===\n")

# Men's breakthrough candidate analysis
if (nrow(men_breakthrough_predictions) > 0) {
  cat("\n--- Men's Nordic Combined Breakthrough Candidates ---\n")
  
  # Top candidates by probability
  men_top_candidates <- head(men_breakthrough_predictions, 10)
  
  for (i in 1:nrow(men_top_candidates)) {
    candidate <- men_top_candidates[i, ]
    cat(sprintf("%d. %s (%s): %.1f%% probability (%s)\n",
                i, candidate$Skier, candidate$Nation, 
                round(candidate$Breakthrough_Prob * 100, 1), candidate$Likelihood))
    cat(sprintf("   Age: %.0f, Current: %.1f%%, Career best: %.1f%%, Points needed: %.1f\n",
                candidate$Age, candidate$Current_Performance_Pct, 
                candidate$Career_Best_Pct, candidate$Points_to_Threshold))
  }
  
  # High-potential candidates analysis
  men_high_potential <- men_breakthrough_predictions %>%
    filter(Likelihood %in% c("Very High", "High", "Moderate")) %>%
    head(5)
  
  if (nrow(men_high_potential) > 0) {
    cat("\nMen's high-potential breakthrough candidates:\n")
    for (i in 1:nrow(men_high_potential)) {
      candidate <- men_high_potential[i, ]
      cat(sprintf("  %s (%s): %.1f%% probability, Age %.0f, %.1f points to breakthrough\n",
                  candidate$Skier, candidate$Nation, 
                  round(candidate$Breakthrough_Prob * 100, 1),
                  candidate$Age, candidate$Points_to_Threshold))
    }
  }
  
  # Young prospects (under 25)
  men_young_prospects <- men_breakthrough_predictions %>%
    filter(Age < 25, Breakthrough_Prob >= 0.1) %>%
    head(5)
  
  if (nrow(men_young_prospects) > 0) {
    cat("\nMen's young prospects (under 25):\n")
    for (i in 1:nrow(men_young_prospects)) {
      prospect <- men_young_prospects[i, ]
      cat(sprintf("  %s (%s): Age %.0f, %.1f%% probability, %.1f points needed\n",
                  prospect$Skier, prospect$Nation, prospect$Age, 
                  round(prospect$Breakthrough_Prob * 100, 1), prospect$Points_to_Threshold))
    }
  }
} else {
  cat("No men's Nordic Combined breakthrough candidates identified for 2026\n")
}

# Ladies breakthrough candidate analysis
if (nrow(ladies_breakthrough_predictions) > 0) {
  cat("\n--- Ladies Nordic Combined Breakthrough Candidates ---\n")
  
  # Top candidates by probability
  ladies_top_candidates <- head(ladies_breakthrough_predictions, 10)
  
  for (i in 1:nrow(ladies_top_candidates)) {
    candidate <- ladies_top_candidates[i, ]
    cat(sprintf("%d. %s (%s): %.1f%% probability (%s)\n",
                i, candidate$Skier, candidate$Nation, 
                round(candidate$Breakthrough_Prob * 100, 1), candidate$Likelihood))
    cat(sprintf("   Age: %.0f, Current: %.1f%%, Career best: %.1f%%, Points needed: %.1f\n",
                candidate$Age, candidate$Current_Performance_Pct, 
                candidate$Career_Best_Pct, candidate$Points_to_Threshold))
  }
  
  # High-potential candidates analysis
  ladies_high_potential <- ladies_breakthrough_predictions %>%
    filter(Likelihood %in% c("Very High", "High", "Moderate")) %>%
    head(5)
  
  if (nrow(ladies_high_potential) > 0) {
    cat("\nLadies high-potential breakthrough candidates:\n")
    for (i in 1:nrow(ladies_high_potential)) {
      candidate <- ladies_high_potential[i, ]
      cat(sprintf("  %s (%s): %.1f%% probability, Age %.0f, %.1f points to breakthrough\n",
                  candidate$Skier, candidate$Nation, 
                  round(candidate$Breakthrough_Prob * 100, 1),
                  candidate$Age, candidate$Points_to_Threshold))
    }
  }
  
  # Young prospects (under 25)
  ladies_young_prospects <- ladies_breakthrough_predictions %>%
    filter(Age < 25, Breakthrough_Prob >= 0.1) %>%
    head(5)
  
  if (nrow(ladies_young_prospects) > 0) {
    cat("\nLadies young prospects (under 25):\n")
    for (i in 1:nrow(ladies_young_prospects)) {
      prospect <- ladies_young_prospects[i, ]
      cat(sprintf("  %s (%s): Age %.0f, %.1f%% probability, %.1f points needed\n",
                  prospect$Skier, prospect$Nation, prospect$Age, 
                  round(prospect$Breakthrough_Prob * 100, 1), prospect$Points_to_Threshold))
    }
  }
} else {
  cat("No ladies Nordic Combined breakthrough candidates identified for 2026\n")
}

# Historical breakthrough analysis for model validation
cat("\n=== HISTORICAL BREAKTHROUGH VALIDATION ===\n")

# Comprehensive function to identify genuine breakthrough cases
identify_historical_breakthroughs <- function(data, gender_label) {
  cat(sprintf("\n--- Identifying Historical %s Breakthrough Cases ---\n", gender_label))
  
  # Step 1: Identify all athletes who achieved breakthrough (≥50%)
  breakthrough_athletes <- data %>%
    filter(!is.na(Pct_of_Max_Points), Season >= 2016, Season <= 2024) %>%
    group_by(Skier) %>%
    summarise(
      max_performance = max(Pct_of_Max_Points, na.rm = TRUE),
      first_breakthrough_season = min(Season[Pct_of_Max_Points >= 0.5], na.rm = TRUE),
      .groups = "drop"
    ) %>%
    filter(
      max_performance >= 0.5,  # Must have achieved breakthrough
      !is.infinite(first_breakthrough_season)  # Must have valid breakthrough season
    )
  
  cat(sprintf("Found %d athletes who achieved breakthrough\n", nrow(breakthrough_athletes)))
  
  # Step 2: Get their data from the season BEFORE breakthrough
  pre_breakthrough_data <- breakthrough_athletes %>%
    rowwise() %>%
    do({
      skier_name <- .$Skier
      breakthrough_season <- .$first_breakthrough_season
      pre_season <- breakthrough_season - 1
      
      # Get pre-breakthrough season data
      pre_data <- data %>%
        filter(
          Skier == skier_name, 
          Season == pre_season,
          !is.na(Pct_of_Max_Points)
        ) %>%
        slice_tail(n = 1)  # Most recent data from pre-breakthrough season
      
      if (nrow(pre_data) > 0) {
        # Get breakthrough season performance for validation
        breakthrough_data <- data %>%
          filter(
            Skier == skier_name,
            Season == breakthrough_season,
            Pct_of_Max_Points >= 0.5
          ) %>%
          slice_head(n = 1)  # First breakthrough performance
        
        if (nrow(breakthrough_data) > 0) {
          pre_data %>%
            mutate(
              Pre_Breakthrough_Pct = Pct_of_Max_Points,
              Breakthrough_Season = breakthrough_season,
              Breakthrough_Performance = breakthrough_data$Pct_of_Max_Points[1],
              Age_at_Prediction = Age,
              Age_at_Breakthrough = breakthrough_data$Age[1]
            )
        } else {
          data.frame()  # No valid breakthrough data
        }
      } else {
        data.frame()  # No pre-breakthrough data
      }
    }) %>%
    bind_rows()
  
  # Step 3: Filter for valid cases with relaxed age criteria
  valid_cases <- pre_breakthrough_data %>%
    filter(
      !is.na(Pre_Breakthrough_Pct),
      !is.na(Breakthrough_Performance),
      Pre_Breakthrough_Pct < 0.5,  # Must not have already achieved breakthrough in pre-season
      Breakthrough_Performance >= 0.5,  # Must have achieved breakthrough in next season
      Age_at_Prediction >= 15  # Relaxed age filter to include more young athletes
    )
  
  # Debug: Show why cases were filtered out
  cat(sprintf("Filtering breakdown:\\n"))
  cat(sprintf("  Total pre-breakthrough data found: %d\\n", nrow(pre_breakthrough_data)))
  if (nrow(pre_breakthrough_data) > 0) {
    missing_pre <- sum(is.na(pre_breakthrough_data$Pre_Breakthrough_Pct))
    missing_breakthrough <- sum(is.na(pre_breakthrough_data$Breakthrough_Performance))
    already_high <- sum(pre_breakthrough_data$Pre_Breakthrough_Pct >= 0.5, na.rm = TRUE)
    low_breakthrough <- sum(pre_breakthrough_data$Breakthrough_Performance < 0.5, na.rm = TRUE)
    too_young <- sum(pre_breakthrough_data$Age_at_Prediction < 15, na.rm = TRUE)
    
    cat(sprintf("  Missing pre-breakthrough data: %d excluded\\n", missing_pre))
    cat(sprintf("  Missing breakthrough performance: %d excluded\\n", missing_breakthrough))
    cat(sprintf("  Already above 50%% in pre-season: %d excluded\\n", already_high))
    cat(sprintf("  Breakthrough season <50%%: %d excluded\\n", low_breakthrough))
    cat(sprintf("  Too young (<15): %d excluded\\n", too_young))
  }
  
  cat(sprintf("Final valid cases: %d\n", nrow(valid_cases)))
  
  if (nrow(valid_cases) > 0) {
    cat("\nValid breakthrough cases found:\n")
    for (i in 1:min(5, nrow(valid_cases))) {
      case <- valid_cases[i, ]
      cat(sprintf("  %s: Pre-season %d = %.1f%%, Breakthrough season %d = %.1f%%\n",
                  case$Skier, case$Season, case$Pre_Breakthrough_Pct * 100,
                  case$Breakthrough_Season, case$Breakthrough_Performance * 100))
    }
  }
  
  return(valid_cases)
}

# Identify historical breakthrough cases
historical_men_breakthroughs <- identify_historical_breakthroughs(train_men, "Men's")
historical_ladies_breakthroughs <- identify_historical_breakthroughs(train_ladies, "Ladies")

# Apply current models to historical breakthrough cases
men_historical_predictions <- data.frame()
ladies_historical_predictions <- data.frame()

if (nrow(historical_men_breakthroughs) > 0) {
  tryCatch({
    men_historical_predictions <- predict_historical_breakthrough(
      historical_men_breakthroughs, 
      breakthrough_models_men$reduced_model,
      breakthrough_models_men$top_predictors
    )
    cat(sprintf("✓ Men's historical validation completed: %d cases\n", nrow(men_historical_predictions)))
  }, error = function(e) {
    warning(sprintf("Men's historical validation failed: %s", e$message))
  })
}

if (nrow(historical_ladies_breakthroughs) > 0) {
  tryCatch({
    ladies_historical_predictions <- predict_historical_breakthrough(
      historical_ladies_breakthroughs,
      breakthrough_models_ladies$reduced_model, 
      breakthrough_models_ladies$top_predictors
    )
    cat(sprintf("✓ Ladies historical validation completed: %d cases\n", nrow(ladies_historical_predictions)))
  }, error = function(e) {
    warning(sprintf("Ladies historical validation failed: %s", e$message))
  })
}

# Comprehensive Excel export with biathlon-style structure
cat("\n=== COMPREHENSIVE EXCEL EXPORT ===\n")

output_dir <- "/Users/syverjohansen/blog/daehl-e/content/post/nordic-combined/drafts/season-prediction/2026/excel365/"

# Ensure output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
  cat(sprintf("✓ Created output directory: %s\n", output_dir))
}

# Export 2026 breakthrough candidates
if (nrow(men_breakthrough_predictions) > 0) {
  tryCatch({
    men_export <- men_breakthrough_predictions %>%
      arrange(desc(Breakthrough_Prob)) %>%
      mutate(
        Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
        Pre_Breakthrough_Pct = round(Pct_of_Max_Points * 100, 1)
      ) %>%
      dplyr::select(
        Name = Skier, Nation, Age, 
        `Breakthrough Probability %` = Breakthrough_Probability_Pct,
        Likelihood, 
        `Pre-Breakthrough %` = Pre_Breakthrough_Pct,
        `Career Best %` = Career_Best_Pct,
        `Points to Threshold` = Points_to_Threshold,
        Season, Type
      )
    
    men_filename <- file.path(output_dir, "mens_breakthrough_candidates_2026.xlsx")
    write.xlsx(men_export, men_filename, overwrite = TRUE)
    cat(sprintf("✓ Men's breakthrough candidates exported: %s (%d candidates)\n", 
                men_filename, nrow(men_export)))
  }, error = function(e) {
    warning(sprintf("Failed to export men's breakthrough candidates: %s", e$message))
  })
}

if (nrow(ladies_breakthrough_predictions) > 0) {
  tryCatch({
    ladies_export <- ladies_breakthrough_predictions %>%
      arrange(desc(Breakthrough_Prob)) %>%
      mutate(
        Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
        Pre_Breakthrough_Pct = round(Pct_of_Max_Points * 100, 1)
      ) %>%
      dplyr::select(
        Name = Skier, Nation, Age,
        `Breakthrough Probability %` = Breakthrough_Probability_Pct,
        Likelihood,
        `Pre-Breakthrough %` = Pre_Breakthrough_Pct,
        `Career Best %` = Career_Best_Pct,
        `Points to Threshold` = Points_to_Threshold,
        Season, Type
      )
    
    ladies_filename <- file.path(output_dir, "ladies_breakthrough_candidates_2026.xlsx")
    write.xlsx(ladies_export, ladies_filename, overwrite = TRUE)
    cat(sprintf("✓ Ladies breakthrough candidates exported: %s (%d candidates)\n", 
                ladies_filename, nrow(ladies_export)))
  }, error = function(e) {
    warning(sprintf("Failed to export ladies breakthrough candidates: %s", e$message))
  })
}

# Export historical comparison files (biathlon-style comprehensive analysis)
if (nrow(men_historical_predictions) > 0 && nrow(men_breakthrough_predictions) > 0) {
  tryCatch({
    # Combine historical and 2026 predictions for comparison
    men_comparison <- bind_rows(
      men_historical_predictions %>%
        mutate(
          Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
          Likelihood = case_when(
            Breakthrough_Prob >= 0.6 ~ "Very High",
            Breakthrough_Prob >= 0.4 ~ "High",
            Breakthrough_Prob >= 0.2 ~ "Moderate", 
            Breakthrough_Prob >= 0.1 ~ "Low",
            TRUE ~ "Very Low"
          )
        ) %>%
        dplyr::select(
          Name = Skier, Nation, Age,
          `Breakthrough Probability %` = Breakthrough_Probability_Pct,
          Likelihood,
          `Pre-Breakthrough %` = Pre_Breakthrough_Display,  # Use correct pre-breakthrough display
          `Breakthrough Result` = Breakthrough_Result,
          Season, Type
        ),
      men_breakthrough_predictions %>%
        mutate(
          Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
          Pre_Breakthrough_Pct = round(Pct_of_Max_Points * 100, 1)
        ) %>%
        dplyr::select(
          Name = Skier, Nation, Age,
          `Breakthrough Probability %` = Breakthrough_Probability_Pct,
          Likelihood,
          `Pre-Breakthrough %` = Pre_Breakthrough_Pct,
          `Breakthrough Result` = Breakthrough_Result,
          Season, Type
        )
    ) %>%
      arrange(desc(`Breakthrough Probability %`))
    
    men_comparison_filename <- file.path(output_dir, "mens_breakthrough_comparison_historical_vs_2026.xlsx")
    write.xlsx(men_comparison, men_comparison_filename, overwrite = TRUE)
    cat(sprintf("✓ Men's historical comparison exported: %s (%d total entries)\n", 
                men_comparison_filename, nrow(men_comparison)))
  }, error = function(e) {
    warning(sprintf("Failed to export men's comparison file: %s", e$message))
  })
}

if (nrow(ladies_historical_predictions) > 0 && nrow(ladies_breakthrough_predictions) > 0) {
  tryCatch({
    # Combine historical and 2026 predictions for comparison
    ladies_comparison <- bind_rows(
      ladies_historical_predictions %>%
        mutate(
          Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
          Likelihood = case_when(
            Breakthrough_Prob >= 0.6 ~ "Very High",
            Breakthrough_Prob >= 0.4 ~ "High",
            Breakthrough_Prob >= 0.2 ~ "Moderate",
            Breakthrough_Prob >= 0.1 ~ "Low",
            TRUE ~ "Very Low"
          )
        ) %>%
        dplyr::select(
          Name = Skier, Nation, Age,
          `Breakthrough Probability %` = Breakthrough_Probability_Pct,
          Likelihood,
          `Pre-Breakthrough %` = Pre_Breakthrough_Display,  # Use correct pre-breakthrough display
          `Breakthrough Result` = Breakthrough_Result,
          Season, Type
        ),
      ladies_breakthrough_predictions %>%
        mutate(
          Breakthrough_Probability_Pct = round(Breakthrough_Prob * 100, 1),
          Pre_Breakthrough_Pct = round(Pct_of_Max_Points * 100, 1)
        ) %>%
        dplyr::select(
          Name = Skier, Nation, Age,
          `Breakthrough Probability %` = Breakthrough_Probability_Pct,
          Likelihood,
          `Pre-Breakthrough %` = Pre_Breakthrough_Pct,
          `Breakthrough Result` = Breakthrough_Result,
          Season, Type
        )
    ) %>%
      arrange(desc(`Breakthrough Probability %`))
    
    ladies_comparison_filename <- file.path(output_dir, "ladies_breakthrough_comparison_historical_vs_2026.xlsx")
    write.xlsx(ladies_comparison, ladies_comparison_filename, overwrite = TRUE)
    cat(sprintf("✓ Ladies historical comparison exported: %s (%d total entries)\n", 
                ladies_comparison_filename, nrow(ladies_comparison)))
  }, error = function(e) {
    warning(sprintf("Failed to export ladies comparison file: %s", e$message))
  })
}

cat("\n=== ANALYSIS COMPLETION SUMMARY ===\n")
cat("✓ 2026 Nordic Combined breakthrough prediction analysis completed\n")
cat("✓ Comprehensive breakthrough candidates identified with 50% threshold\n") 
cat("✓ Historical validation performed on past breakthrough cases\n")
cat("✓ Debug information provided for key Nordic Combined athletes\n")
cat("✓ Excel files exported with biathlon-style comprehensive structure\n")
cat("✓ Young prospects highlighted for development tracking\n")
cat("✓ Model reliability assessed through historical comparison\n")
```
